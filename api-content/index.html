{"posts":[{"title":"Guardant Shield 获批：详谈这5年你该了解的按部就班、跌跌撞撞 、布局和野望","content":"本文是熊言熊语邮件通讯的会员内容，限时同步首发于熊言熊语微信公众号。文章较长，引用较多。 写在前面 Guardant health Shield 近日官宣获批，从我2021年入行关注至今终于等来了这一天。作为熊言熊语邮件通讯产品系列的早就定下的选题之一，趁热打铁，把零散记录了很久的draft详细整理成文与你分享。 在本次通讯中，你将会： 从 Shield 按部就班的获批之路中看到立场如何决定性能、嘴硬如何与谨慎并行； 在 Shield 稳定产出的产品进化过程中看到 Guardant health 清晰的学术发声节奏； 在 Shield 跌跌撞撞的性能提升之路中看到研发和产品的反复横跳和究极取舍； 也别忘了一起了解 Shield 在多癌早筛上的布局和野望。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接 即可进行免费订阅。 按部就班的获批之路 7 月 29 日，Guardant Health 在官网宣布 FDA 批准 Shield 作为结直肠癌 (CRC) 的筛查方案。 Shield 因此成为 FDA 批准的第一款用于 CRC 筛查、满足美国医保要求的血液检测产品。其使用范围是 45 岁及以上具有平均患病风险的成年人。 Shield 的获批并不令人意外，似乎这一切都在按照 Guardant Health（下文简称 GH）计划的路线稳步推进。 在 2024 JP Morgan 上 GH 给出了如下清晰的时间线。 今年 5 月，FDA 分子和临床遗传学专家小组经过一番「热烈」讨论，对 Shield 的安全性、有效性和风险收益比都给出了整体积极的评价。这次讨论通过也已经预示着 Shield「有望」成为第一个获 FDA 批准的肠癌血液筛查产品。 立场决定性能 如果再往前追溯，是什么促成了这次专家小组的通过呢？ 一是基于 Guardant Shield 之前已经获得的上市前批准 (PMA) 申请，二是评估平均风险人群使用 Shield 检测性能关键结果的 ECLIPSE 研究于今年 3 月发表在《新英格兰医学杂志》(NEJM) 上。 ECLIPSE 是一项非随机、前瞻性、多中心研究，纳入了年龄在 45 岁至 84 岁之间计划接受肠镜筛查的患者。 如下图所示，虽然研究招募的患者人数达到 2 万多例，但其中 1.2 万例并没有纳入实际的临床验证队列。研究团队通过下采样方法随机抽样了 1 万人，删删减减之后有 7000 多人进入了最后的临床评估阶段。 ECLIPSE 的主要终点是相对于肠镜检查 CRC 的敏感性和对晚期肿瘤（结直肠癌或晚期癌前病变）的特异性，次要终点是检测晚期癌前病变的敏感性。在 clinicaltrials 注册的临床试验中，次要终点还包括 CRC 检测的阳性预测值 (PPV) 和阴性预测值 (NPV)。 对于 Shield 的性能，GH 在发布的 PROVIDER BROCHURE 中已经给出了一个非常清晰的总结。 在 NEJM 的论文中，更详细的主要结果总结如下： 检测 CRC 的总体敏感性为 83.1% 对具有筛查价值、病理确诊的 I-III 期 CRC 的敏感性为 87.5% 对不同分期 CRC 的敏感性: I 期 (病理确诊):65%; I 期 (临床诊断):55% II 期、III 期和 IV 期: 均为 100% 在非进展期腺瘤、未发现肿瘤和肠镜阴性人群中的特异性为 89.6% 在未发现肿瘤和肠镜阴性人群中的特异性为 89.9% 如果以上这些数据都还算说得过去，但晚期癌前病变 (AA) 的敏感性仅为 13.2%。 emmm，因为这不是计划中的研究终点，只能算是软肋谈不上硬伤。 关于 AA 的问题，我们还会在后文有一个详细的展开。 在同期 NEJM 上，Exact Sciences Cologuard 和 GH 背靠背发表了自家产品最新一代产品的实验结果。 我们得以给出一个相对清晰（但并不严谨）的对比。 cfDNA stool CRC 敏感性 83.1% 93.9% I 期 CRC 敏感性 65% 86% 晚期癌前病变敏感性 13.3% 43.4%（HGD 74.6%） 晚期肿瘤特异性 89.6% 90.6% NPV 99.92% 99.97% PPV 3.16% 3.4% 虽然各项指标相比对方都不占优，但是 GH 说：不是比不过，而是你不会比，不考虑依从性的敏感性，在真实世界里就是耍流氓。 在 2023 年的 JP Morgan 大会上，GH 提出了一个并不算新的新概念——&quot; 有效敏感性 &quot;（Effective Sensitivity）。Shield 的依从性为 90%，敏感性为 83%，两者相乘得出有效敏感性为 75%；而 Cologuard 的依从性为 65%，敏感性虽然略高（87%），但两者相乘后的有效敏感性仅为 60%。 论秀，还是 GH 秀，散了吧。 然而，仔细思考后会发现，这两种检测方法之间的差异其实并不令人意外。无论是微小残留病灶（MRD）还是肿瘤筛查，对于血液检测，我们有一个基本共识：只有脱落的 DNA 进入血液循环系统才有可能被检测到，而且通常来说，越接近病变部位的样本越敏感。这也同样可以解释为什么在泌尿系统相关肿瘤的检测中，尿液样本的早期筛查性能要比血液检测好得多。 Shield 自身具有的便利性和高依从性，在满足同样筛查条件下可以提高筛查率，这一点没有问题。 但我们也需要清楚地认识到，Shield 目前并不能算是真正意义上预防结直肠癌（CRC）的「筛查」工具（其对进展期腺瘤 AA 的检出率仅为 13%），它更像是一种非侵入性的 &quot; 检查 &quot; 方法。即便如此，它仍可能会漏诊接近一半的 1 期患者。 嘴硬和谨慎并不冲突 虽然面对投资人描绘着美好的概念，但 GH 比任何人都清楚自己产品的局限性。 这一点从 GH Shield 产品手册中随处可见的防御性极强的限制性说明就能看出。 一起来感受一下。 Precaution：基于临床研究数据，Shield 对 I 期结直肠癌的检测灵敏度有限（55%-65%），并且无法检测到 87% 的癌前病变。每 10 名 Shield 结果为阴性的患者中，可能有 1 名患有癌前病变，而这种病变本可以通过结肠镜筛查检测到。Shield 对 II、III 和 IV 期结直肠癌的检测显示出较高的检测率。 限制性因素众多，我们列举几个主要的： Shield 无法检出小于 10 毫米的结直肠癌病灶。 Shield 对高级别腺瘤（可能发展为结直肠癌的癌前病变）的检测能力有限，可能影响预防结直肠癌发展的效果。临床研究数据显示，Shield 仅正确识别了 13.2% 的高级别腺瘤患者，意味着 86.8% 的高级别腺瘤患者被误判为阴性。 Shield 的假阳性率为 10%，即每 10 名没有晚期肿瘤（结直肠癌或高级腺瘤）的人中就有 1 人会得到假阳性结果。 有趣的是，这些 label 上的预防性声明甚至成为了今天投资者电话说明会的提问重点，多个问题都围绕这些预防性声明可能产生的潜在影响展开。 另外值得注意的是，Shield 检测尚未被美国预防服务工作组（USPSTF）或美国癌症协会（ACS）的指南收录，许多非公立保险公司可能要求产品被纳入指南才会提供覆盖，这意味着 Shield 还有一段路要走。 此外，在 NCT04136002 实验记录中，项目入组人数从最初预估的 2 万人，在 2023 年 4 月修改为 4 万人，到今年 4 月又修改为实际入组人数 44467 人。 在电话会议上，GH 高管一再强调他们与 Medicare 保持着顺畅的沟通。入组人数增加，想必也是有 NEJM 中没有充分回答的问题需要继续回答。 稳定产出的产品进化史 聊完产品获批的 part，我们再回过头来聊聊 Shield 产品本身。 时间回到 2019 年，GH 通过 2019年AACR 首次公开介绍了他们针对结直肠癌（CRC）的检测产品。这个产品的独特之处在于同时分析 ctDNA 的基因组和表观基因组特征。 基因组变异包括：SNV，Indel，fusion 和 CNV；表观遗传变异包括 DNA 甲基化信号和核小体站位/片段组学。 产品设计上，GH 利用晚期癌症患者的 cfDNA 大型数据库，开发了一个 500Kb 大小的靶向测序 panel。这个 panel 可以检测与 CRC 相关转录因子结合位点的体细胞变异、甲基化变化和其他表观基因组变异。技术上能同时检测甲基化和非甲基化的 cfDNA。 初步分析结果显示，相比单独的体细胞突变分析，加入表观基因组分析显著提高了 ctDNA 的检测能力。 2020 年 AACR 会议上，GH 继续发布了 相关研究进展。这时，他们的检测产品被命名为 LUNAR-2 assay（即现在的 Shield），其靶向区域针对常见的致癌突变以及在癌症中可能经历表观基因组修饰变化的区域（差异甲基化和核小体定位变化导致差异的 DNA 片段化模式）。 析过程包括 检测体细胞基因组突变和变异过滤； 评估观察到的 cDNA 分子在不同甲基化分区中的分布； 评估 panel 上基因组区域中 cDNA 片段化模式。 这次的 poster 还明确指出了 panel 设计数据来源于超过 10 万例 Guardant360 数据以及健康人/晚期 CRC 患者的全基因组测序 (WGS) 数据。 研究发现，在 CRC 肿瘤组织中，根据差异甲基化选择的区域显示出明显的甲基化信号。通过比较结肠镜检查阴性的受试者和晚期 CRC 患者的 cfDNA 全基因组测序数据，研究者观察到一致且强烈的甲基化信号差异，提高了区分能力。 随着算法和技术的逐渐成熟，2021年 ASCO 上，GH 公布了一项涉及 434 名患者和 271 名对照样本的更大规模 LUNAR-2 性能评估。研究结果显示，该检测方法在多个临床特征中都表现出具有临床意义的敏感性。这项 poster 的最后提到： A prospective registrational study is ongoing to evaluate the test in an average risk CRC screening cohort. 同年，在美国胃肠病学会（American College of Gastroenterology）年会上，GH 发表了一个更详细的口头报告，重点强调了该产品在早期 CRC 筛查中的潜力，以及在一般风险人群中的应用前景。 进而引出了该产品应用于早期 CRC 进行 screening 的潜力，也提到了把它应用在一般风险人群中的应用场景。 一年之后，2022 年 ASCO 会议 中 GH 进一步发声。这次他们带来了在西班牙四家医院开展的前瞻性研究分析结果。 值得注意的是，这次 Shield 代替 LUNAR-2 成为了产品名，而整个检测方案里增加了一个看起来「不怎么和谐」的蛋白质组学结果。这一变化也不难理解，既然 GH 选择了结合突变信息和表观遗传学的多组学策略，那么在产品迭代过程中自然会考虑到蛋白质组学。 不过，事后证明，蛋白质检测结果整合到最终的 YES or No 判断中，这一策略似乎对也不对，并没有真实提高检测性能（后面我们会具体提到）。 在这项研究中，GH 对超过 6000 个样本上进行了训练，其中包括 2685 个 ACN 阴性样本和 1698 个 ACN 阳性样本。通过 1072 个 ACN 阴性样本和 551 个 ACN 阳性样本确定阈值，在验证之前，以 91.5% 的特异性为目标锁定模型阈值。 随后在六个中心验证中得到了如下结果。两个小细节，I 期癌症的敏感性高达 90%，AA 的敏感性还在 20%。 时间来到，2023 年 5 月，在著名的消化系统疾病年会（Digestive Disease Week）上，GH 首次正式对外公布了 ECLIPSE 研究的初步结果。 这次公布的分期敏感性和我们在 NEJM 看到的已经基本一致。 AA 的敏感性掉到了 13%，当时还公布了 HGD 的性能（23%），但在最终的 NEJM 文章中并未提及。 同时，GH 也提到了如何在真实世界中考虑依从性的问题：评估筛查项目时需要考虑真实世界的条件和患者因素。倡导从理想化条件下的有效性评估向更实际、更贴近临床实践的效果评估转变。 从 Shield 的发展历程来看，从 19 年开始，基本每年都会有非常稳定的产出，整体的产品技术路径和临床应用场景也越来越清晰。点赞 GH Shield 的研发和科学团队。 在这次展示内容的最后，GH 提到 Further assay development to expand detection capabilities。而这件事， Shield 一直在尝试。 跌跌撞撞的性能提升之路 来来去去的蛋白 如果说 Shield 的 FDA 获批之路看起来顺风顺水按部就班，那它的性能提升之路似乎就只能摸着石头过河。 在上文，我留了一个扣子，2022 年 6 月 ASCO 的 Poster 里，GH 提到在既往的分析方法基础上新整合了蛋白质检测的结果。 可到了 2023 年 5 月 DDW 大会的结果展示中，蛋白质组学又默默地消失了。 发生了什么？ 这其中的缘由，我们可以从 2023 年 10 月 GH 在 Annals of Oncology 发表的结果和 2024 年 NEJM ECLIPSE 主文章中窥见一二。 2023 年 10 月的 Annals of Oncology 论文中，GH 提到： The aim of this study was to determine the performance of a novel multimodal ctDNA-based blood assay (that includes detection of genomic mutations, methylations, fragmentomics and proteomics) to detect CRC at different Tumor-node-metastasis (TNM) stages (primary endpoint) and advanced precancerous lesions (secondary endpoint), in a pilot study of FIT-positive individuals from a population-based screening program and individuals with known CRC. emm，看来最初并未打算放弃晚期癌前病变的检测。 在这项涉及 623 例样本的研究中，首先使用不包含蛋白的算法进行分析，晚期癌前病变的敏感性为 14% GH 似乎对这个结果并不满意，还想挣扎一下。于是他们说道： In order to improve the accuracy to detect precancerous lesions, an exploratory analysis that used a refined version of the blood multimodal ctDNA-based test was carried out in a subgroup of 86 individuals from cohort 1. 他们的做法是加入蛋白质组学数据。 首先在癌症样本和健康样本之间对表达水平存在差异的多种蛋白质标记物进行分析，然后开发统计模型整合这些蛋白质标记物的水平，生成蛋白质分类结果，最终与之前的结果整合，生成一个二分类判断。（合理怀疑是 Olink 的销售手段高超，说服了他们😂） 一顿操作猛如虎，性能提升 5%。 在这 86 个样本的小队列中，AA 的敏感性被提升到了 23%（小队列不加蛋白的原始版本 AA 敏感性是 18%）。可随之而来的小问题是特异性也从之前的 90% 掉到了 86%。 虽然文章发在 Annals of Oncology，但是如果通过蛋白质组学加成让 AA 提升 5% 敏感性的代价是牺牲 4% 的特异性。我想，这是除AA 性能党之外所有人都不能接受的。 别忘了，Shield 的底线是坚守 90% 特异性，满足 Medicare 的要求。 于是，在 2024 年 3 月 NEJM 主文章的附件材料中，我读到了这样一段话。 虽然只是一句轻描淡写的「添加蛋白质反而不如只用 cfDNA 效果好」。懂得都懂：两全相害取其轻，特异性上不放松。 默默翻倍的 panel 从 2019 年开始到 NEJM 文章发表前，公开的学术资料中凡是涉及到产品设计路线图的，GH 一直宣称 LUNAR2 的 panel 大小为 500Kb，甚至 2024 ASCO 一篇摘要中，方法学部分仍然标注了 500Kb。 但到了 MEJM 的文章中 panel 大小默默变成了 1Mb，无奖竞猜，多出来的 500Kb 是干什么的？ Shield V2 新版本性能几何 Cologuard 有 V2，Shield 同样也并非不思进取。 早在 2023 年的几次公开会议中，GH 就已经透露了 Shield V2 版本的消息。 在放弃 AA 性能的挣扎之后，V2 版本的 Shield 保证特异性不降的前提下，将整体敏感性从 V1 版本的 84% 提升到了 91%。 这一结果最终正式发表在 2024 年 ASCO-GI 会议 中。GH 1M panel，10X 测序深度的数据中，通过提高噪声过滤和模型调参，更好地检测了 ctDNA 低脱落的肿瘤样本。相比 ECLIPSE 实验中的模型，LoD95 下降到十万分之四，I/II 期敏感性从 76% 提高到 88%。 多癌筛查的布局和野望 在 Guardant 用 Shield 对标 Cologuard 的这几年里，他们面对 Grail 左手右手的几个大动作，想必也无法视而不见。 早在 2022 年 AACR 年会上，GH 的口头报告就介绍了其 多癌筛查规划。 依旧基于 Shield 的甲基化信号富集技术，完成多模态信号输出。 这种技术能在降低测序成本的同时提高信噪比。当时披露的 SHIELD 面板大小为 1M，测序量接近 40M。而新一代 Shield 在 15Mb 面板（据报道包括约 20000 个表观基因组生物标志物）的基础上，只需不到 20M 的测序量。 在这次研究结果中，他们也公布了结直肠癌、肺癌、胰腺癌和膀胱癌四种癌症的初步分析结果。 一年后的 ASCO 年会，GH 再次详细介绍了他们计划开展的 一项针对多癌种的前瞻性、观察性、多中心篮子研究 SHIELD (Screening for High Frequency Malignant Disease) 该研究的主要目标是评估基于血液的多癌筛查测试（Guardant LUNAR-2）与标准筛查方式相比的检测性能。每个研究队列代表一种（或多种）癌症类型。 符合条件的个人在相应癌症类型的标准护理筛查的 90 天内进行全血采集，临床诊断按照标准护理进行。 主要目标：基于血液多癌筛查测试的敏感性、特异性、PPV 和 NPV。次要目标：每 1000 名筛查者中检测到的癌症数量、早期和晚期数量。同时随访收集一年和两年的临床结果。 正在进行的队列 A 为肺癌筛查队列，入组条件与 USPSTF 筛查推荐一致。当时的公布内容显示该队列将在 24 个月内招募 9000 名受试者。启动一年后入组 4866 人并预计在 2023 年底达到目标，2024 年 12 月完成主要结果数据收集。 如果查看实际的 临床实验注册信息，A 队列又增加了 3000 名受试者入组配额，2024 年 7 月状态修改为停止招募。随访计划也从原来的 1 年和 2 年各随访一次调整为仅 1 年随访一次，预计今年底就会有主要结果。 以及，从 GH 的对外发言中，我们可以大致了解他们的癌症筛查产品线规划： 肠癌目前已经完成 FDA 获批，随后启动 IVD 和 ADLT，针对一般风险人群每 1 年进行 1 次检测，预计 2026 年搞定 USPSTF。 肺癌在路上，目标是针对一般风险人群 3 年检测 1 次，针对高风险人群推荐 1 年检测 1 次。 更有趣的是，他们要如何做到：用相同的检测和费用，只需简单的软件升级就完成新癌种的检测呢？ 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2024-08-03-guardant-shield-fda-5-year/"},{"title":"除了E人变I，断网半年后我的3个感悟和1个项目","content":"写在前面 你好，我是思考问题的熊，熊言熊语公众号/播客的主理人。一个超过半年没有和你通过邮件通讯相见的拖更作者。诚惶诚恐，不知道你这半年可好。 不只是没有和你交流，2024 年过去半年多时间里自己基本处于断网状态，变成了一个只有线下模式的 NPC。 此刻，当我打开电脑准备写点什么，感觉熟悉又有些陌生。就像准备要和很久没联系的朋友见一面，难免会觉得忐忑。纠结许久，还是只能先说一句：好久不见。 在本期通讯内容中，我将和你分享过去一段时间我的经历感受和反思，也会为你推荐一个我在进行的秘密项目，邀请你参与体验。 我从E人变成了I人 过去半年多，我扎扎实实地经历了几种情绪和几件事：亲人的离开、价值感的缺失、不知道被什么裹挟着看起来的努力，还有重新理解人和人的各种亲密关系。 很多时候我都想把这些事情和感受分享给你，甚至有两次一大早起来已经打开话筒准备录一期播客，但又都放弃了。 我起初把这种心态变化归结于年龄上涨之后「表达欲」的降低。但这半年密集经历的事情让我明白，这种变化可能来源于：经历了新的一件事之后就会发现之前经历过的似乎也没什么。 有趣的是，16 型人格测试的结果一年前我是 ENFJ，但是前一段时间又进行了一次检测自己变成了 INFP。我从E人变成了I人，不知道预示着什么。 美化智商和把手弄脏 我习惯一段时间内对一件事情异常投入。这个性格和方法上的缺陷会导致我容易在「一件事情上」周期性地出现和消失。而这种转变往往是因为我突然「阶段性」地想明白了一点东西。 2023 年 11 月初，我曾经摘录了这样一段读书笔记： 美化智商的表现之一，是把别人的见解转述出来，以获得影响力。重要的不是通过美化智商提升影响力，而是亲身实践后获得的观点或洞察。by《笔记的方法》 《笔记的方法》这本书里提到一种「美化智商」的概念。作为一个几乎不用美图功能的人，看到这段内容之后不得不承认，公共视野下的自己是不是偶尔也有美智的行为。 我曾经和一位好友聊过关于「分享」的话题，当时表达了关于「分享」的三种理解，也在这里转述给你讨论。 分享这件事，根据我的观察有 3 个层次。 第一层是利用信息差，把我看到但你还没看到的信息转达给你。 这件事本身不存在能力差别（emm，也许快速接触到信息也是一种能力）。做好这一层的要务是「快」，同一个信息在不同节点间流动，只能争取做第一个信息传递节点，而且这个节点的辐射范围越大越好。 第二层是整合转述和总结未经实践的他人观点。 其实，能做到这一点已经有很高的要求，也是绝大多数创作者的终点。日常学习、读文献和读书都是如此，我在大多数时间也才停留在这一层。做好这一层的要务是「想」，和别人接触到的信息没有什么区别，但是肯花功夫理解和思考，这样就不需要一直追热点和时效。 第三层是躬身入局把手弄脏。 你分享的是真实地实践反馈与感悟。做好这一层的要务是「做」，这个过程中你可能会重复自己看到的，验证自己想到的，也可能发现一些从未有人提到的洞察。 一句话总结这三个层次就是：你看到了什么，想到了什么，做到了什么。有效的分享不仅仅是传播信息，更需要深入理解分析和思考并将其应用于实践。 过去半年，我把大量时间放在了一个真实的研究项目上。有自己的数据，尝试了各种方法希望能从中获得 Know how，也经历了各种波折和困难。这个项目的部分研究结果会在今年 ESMO 会议上发表。 在这个过程中，如书中写的，我希望让那些看到想到的观点穿过自己，沉淀出属于自己的知识。我也希望，今后带给你更多的是第二层和第三层的内容。 在这个过程中，我又一次深刻理解了所谓解释深度错觉（Illusion of Explanatory Depth, IOED） 这种认知偏差。IOED 是由耶鲁大学研究人员 Leonid Rozenblit 和 Frank Keil 在 2002 年提出的概念。这种认知偏差指出：人们倾向于认为自己对某个主题的理解程度比实际上要好得多。 如你所感，对别人，我们总是会看到一些文章，看起来感觉头头是道，但只要让他再稍微要求多一步解释就会露馅。对自己，我们有时候会以为自己已经很了解一件事，但只有动手做一下才能意识到自己并不清楚。 重新审视 LLM 基建下自己在做的事情 也是在过去半年时间里，各种大语言模型层出不穷。借着自己能写一点的代码，我尝试将 LLM 融入到自己各项日常学习和工作流中。 虽来不及思考 AI 会不会替代人或者何时会替代人，但我一直努力尝试用 AI 替代自己。我把自己会做的每一件事都尝试用AI做一遍，去探索今天 AI 的边界，也重新认识今天的自己。 到目前为止，大概日常 20% 的重复性工作和信息获取与整理可以丝滑地让 AI 配合我完成，不到 30% 可以让 AI 参与进来。而剩下的一半我还在持续探索，这也让我看到了目前即便最强大的LLM仍然存在局限。 在让AI替代自己的过程中，我反复审视过去几年一直在坚持的内容输出。 发现除了时效性信息的传达和知识性内容的归纳，在 LLM 逐渐可以成为基建能力的今天，和你分享我一直完善和践行的各种方法，反而可以产生更重要的价值。也是因为有了 LLM 这个趁手工具，「授人以鱼不如授人以渔」这个道理越来越格外正确。 秘密项目 insightpaper 在我既往和你分享过的各种思考碎片中，我一直反复安利我们每个人应该持续拥有两个东西。 一个是好奇心，有了好奇心，我们才可能不只做有明确目标和熟悉的事情，才能有机会做出一些好玩的东西。 另一个是属于自己的产品，它可以是一本书、一个软件或者是一个实际的物件。总之你要全程参与决策它的构思、生产和未来发展。 一个属于自己的产品，会帮助我们顺其自然地完成从看到什么到想到什么再到做到什么的三级跳，也会自然地帮助我们克服&quot;解释深度错觉&quot;的认知偏误。 类似的观点我前几天也在万维刚的一篇文章中看到，他提到：人应该有个自己的&quot;秘密项目&quot;，做个 maker 去设法创造一个东西。你对这个东西的要求应该是，除你之外至少还有一个人很愿意用它。 写到这里，我就再和你汇报过去半年我一直在&quot;秘密&quot;进行的另一个项目： 过去几年，无论是写博客还是录播客，无论是分享思考还是专业知识，我做的每一件事，本质都是将自己日常输入的海量信息，通过自己逐渐形成的逻辑和方法进行追踪、过滤、加工和整理，变成一种更优质的内容进行输出。 如今，我希望可以把这一套逻辑方法进行提炼总结和产品化，让更多的人可以高效的获取信息和吸收知识。于是，就有了第一步 InsightPaper。 by 思考问题的熊 InsightPaper 是一款整合了大语言模型能力的研究进展追踪和文献辅助阅读工具，其背后的开发逻辑是我自己这些年摸索出的一套完整的研究进展追踪和文献学习方法体系。 InsightPaper 不止提供答案，更重要的，是配合你一起完成答案的探索。 如果你是最近一年关注和订阅了熊言熊语，我想大概是因为你看到了我很多关于最新研究进展的梳理和总结，你也一定对&quot;读文献这件事并没有那么简单&quot;有所体会。 读什么和怎么读，这两个最根本的问题就让很多人感到困扰。当想把这件事的系统理解讲清楚时，我发现通过写文章把这件事情说明白远不如直接做一个工具让需要它的人用起来实在。 于是，在几十个夜晚和周末的反复测试和完善后，就有了目前这个前端后端加起来接近 3000 行代码的工具。 目前测试版形态大概是下面的样子（虽然不炫酷，但是挺好用） 文献检索小结 核心文献检索 核心信息提炼 最新相似内容推荐 一些好朋友在内测 InsightPaper 的过程中给出的反馈大多数是： 搜到的结果比常规的搜索引擎有更多是我想要的 推荐的相关文献既有最新的研究结果也有既往引用数最高的经典内容 给客户做调研报告、准备论文综述的时候，检索总结和文献提炼确实有帮我省时间 InsightPaper 今天正式面向所有熊言熊语订阅读者发出小范围公测邀请。 如果你对于文献阅读有需求，对 InsightPaper 感兴趣，可以**通过添加我的微信 kaopu_bear 备注&quot;InsightPaper 内测&quot;**获取 InsightPaper 的使用方式，并进入测试交流群随时沟通。 关于邮件通讯 以上，就是我过去一段时间的思考感悟和insightPaper介绍。在本期内容最后，我想说一下关于熊言熊语邮件通讯本身。 过去一年多的时间，相继有一百多位认可信任我的朋友，先后通过付费会员的方式支持熊言熊语，但是如你所见，我并没有为大家完成足够的交付。这点一直让我惴惴不安，如鲠在喉。而绝大多数朋友表现出的理解和宽容，又让我感谢满满和有所亏欠。 从本周开始，熊言熊语邮件通讯将在「insightPaper」能力加持下正式恢复更新。 过去半年，我完成了自己信息获取工作流和写作工作流的升级，在有能力保证常规内容更新的基础上，也可以拿出更多精力完成上文中我提到的第二层次和第三层次的输出和分享。 很快再见，这次就写到这儿。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2024-07-21-insightpaper-intro/"},{"title":"同源重组修复缺陷HRD ：产品总览","content":" 本文为熊言熊语邮件通讯会员计划内容的试读版，完整内容请点击通讯主页订阅并查看。 写在前面 你好，我是思考问题的熊，本内容是参加会员计划读·者的专属内容，感谢你通过会员计划支持我持续创作。展信佳～ 本期内容： 在关于生物标志物 HRD 的前两期内容中，我们分别了解了 HRD 作为生物标志物的提出和临床核心应用场景，具象感受了一个生物标志物从逐渐被人们认知到接受，究竟需要经历怎样的过程。 在本期内容中，我们将继续了解 HRD 这种生物学现象可以如何检测以及目前市面上那些相关的国内外产品，共同感受一下当 HRD 被人们认可后，各家国内外厂商的跟进方式。（本期内容字数 5700+） 下期预告 下期内容中，我将和你分享一些自己关于 HRD 及相关产品目前临床应用的困惑和思考。 HRD 的检测思路 了解了 HRD 作为生物标志物目前在临床上的核心应用场景，下一个主要话题就是了解 HRD 这种生物学现象应该如何检测以及目前市面上对应的产品。 笼统讲，检测一个生物学现象可以从两个维度出发：检测造成这个生物学现象的原因；检测这个生物学现象导致的结果。 具体讲，针对同源重组修复缺陷，我们既可以考虑检测其原因，例如对应通路的 BRCA 或其它基因突变，BRCA 启动子甲基化等等；也可以考虑检测同源重组修复缺陷造成的结果，也就是所体现出的基因组不稳定性。 HRD 检测产品 Myriad MyChoice 在介绍 HRD 的临床验证过程时，其实我们就反复提到了 Myriad 这家公司和它的 HRD 检测产品。说到 Myriad，这家成立于 1991 年的公司在肿瘤 NGS 检测历史上有这非常重要的地位。在后续国内外知名公司的系列内容中，我们会继续深入了解它。 在这里，你只需要知道他们早在 1994 年就申请了关于 BRCA 遗传基因以及其诊断方法的相关专利，且这件事情引发了后来一系列接近 20 年的基因是否可以作为专利的争论。从 BRCA 到 HRD，Myriad 能走在 HRD 检测的最前列也似乎是情理之中。正如在上一期通讯的中，我写到： 至此，这几项大型的三期临床研究一方面证实了几家 PARPi 在卵巢癌维持治疗中的作用，另一方面因为他们都不约而同选择了 Myriad 的 MyChoice 检测产品，也让 Myriad MyChoice 事实上成为了 HRD 检测临床使用的「金标准」。 HRD 会产生特定、可量化、稳定的基因组改变，其中包含可鉴别突变、插入 / 缺失，以及染色体结构异常、基因拷贝数变异等，这也是当前构建 HRD 临床检测方法的理论基础。 HRD 临床检测所描述的肿瘤基因组特定改变也被称为「基因组瘢痕」。自 2012 年以来，杂合性缺失（loss of heterozygosity，LOH）、端粒等位基因不平衡（telomeric allelic imbalance，TAI）、大片段迁移（large-scale state transition，LST）等被作为基因组瘢痕标志物，以量化基因组瘢痕程度。 如同他们在 2016 年发表的论文，Myriad 将自己家 HRD 评估的产品命名为 MyChoice 和后来升级版的 MyChoice Plus，并将 HRD score 定义为 LOH + TAI + LST 加和（这部分具体内容可以参考 part1 部分正文）。 详细地说，LOH 定义为大于 15 Mb 且小于整个染色体长度的杂合性缺失；TAI 定义为延伸到其中一个亚端粒但不超过着丝粒且大于 11 Mb 的等位基因不平衡的染色体片段；LST 定义为两个相邻区域（两个区域长度均大于等于 10 Mb，且区域间距小于 3 Mb）之间的染色体断裂位点的总数。 LOH、TAI 和 LST 等 3 个指标都有独特的定义，在一定程度上都能描述细胞 HRD 状态的程度。然而，相较单个指标描述，三者组合综合计算评分能更全面反映基因组瘢痕状态，进而对基因组不稳定状态进行评估。所以 MyChoice 就是以 BRCA 1/2 的致病性变异状态加上基因组不稳定评分（genomic instability score，GIS）来评估 HRD 状态。 如果你还记得在 part1 中，我们提到了最早的论文中 LST 这个指标需要进行基因组倍性矫正，进而会产生负数，但随后它们取消了这个矫正，让这个计算更容易理解。 这里多说几句，对于不同组合构成的模型，我们往往会通过添加系数的方式，给每个不同的指标分配不同的权重，进而取得最好的预测效果，类似与 index = 0.2A + 0.65B + 0.3C，但是为什么 LOH TAI 和 LST 这三者刚好就是同等系数的简单加和效果最好呢？ 其实，很早一期 Myriad 团队成员自己录制的播客节目 Myriad Live - Let's Talk HRD 中，它们给了这样一个解释：看似同等重要，其实并非如此。 如果你看一下等式，它们看起来是同等权重的，因为我们所做的就是把它们加在一起，但实际上，LST 分数的动态范围大约是其他两个分数的两倍，所以这意味着它对最终分数的贡献比 LOH 或 TAI 更大。 它往往比其他两个分数更高，所以我们实际得到的结果是，大约一半的最终分数来自 LST，平均大约四分之一来自 LST 和 TAI。 我们之所以对最后的设置感到满意，并发现它表现最好，部分原因是在我们早期的研究中发现 LST 实际上是 HRD 的最佳预测因子。因此，它比 LOH TAI 在数值上更重要，几乎占最终分数的一半。 如果你想更加具体的了解 myriad 官网自己对于这款产品的介绍，可以详细阅读下面的两个链接。 🍺🍺试读结束🍺🍺 剩余内容是参加会员计划读者的专属内容 欢迎你通过会员计划支持我持续创作 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2023-05-03-cancer-homologous-recombination-deficiency-part3/"},{"title":"同源重组修复缺陷HRD：临床验证","content":" 本文为熊言熊语邮件通讯会员计划内容的试读版，完整内容请点击通讯主页订阅并查看。 写在前面 本期内容： 你将阅读到HRD临床验证的后半部分历程（2016-2020年），这几年内多个重要的临床实验证实了PARPi的临床价值，同时也顺便验证了HRD的应用价值（主要是 Myriad MyChoice 产品）。结合上期和本期内容，我们可以具象感受到一个生物标志物从逐渐被人们认知到接受，究竟需要经历怎样的过程。 下期预告 了解了 HRD 作为生物标志物目前在临床的核心应用场景后，下期我们就会了解 HRD 这种生物学现象应该如何检测以及目前市面上对应的那些国内外产品。 临床应用场景 2016 年 NOVA 研究 2014年12月FDA批准了首个PARP抑制剂——奥拉帕利（orlaparib），用于治疗晚期卵巢癌或携带BRCA基因突变的卵巢癌。 2016年发表在NEJM的一项名为NOVA的随机双盲 3 期试验中，另一款PARPi 尼拉帕利（niraparib）在铂敏感型复发卵巢癌患者维持治疗中展现了极为良好的疗效。研究人员招募了553例铂类化疗后复发卵巢癌患者，并根据是否带有生殖系_BRCA_基因突变，进行了安慰剂对照的随机临床试验。在带有BRCA突变的组中，经过尼拉帕利治疗的患者无进展生存期的中位数长达21个月，明显长于对照组的5.5个月。 令人兴奋的是，该研究还证实：不论患者为何种基因背景，尼拉帕利均可显著延长患者的无进展生存期，只是该作用在BRCA基因突变携带者或DNA同源重组修复功能缺陷（HRD）的人群中更明显。彼时尼拉帕利为治疗铂敏感型复发的卵巢癌患者带来了新曙光。 如果详细对论文相关材料，可以发现，有趣的是在制定研究方案时尚不清楚几个候选生物标志物中，哪一个适合作为接受过多种铂类疗法的患者使用尼拉帕利作为维持治疗的辅助诊断（CDx）进行评估。因此，最初的临床研究目标之一是利用研究数据来选择一个生物标志物并确定一个适当的阳性阈值。 研究开展后不久，Myriad 便开发了一种基于DNA测序的HRD检测方法：myChoice HRD，原理就是我们在上一篇文章末尾提到的检测方法。 于是这个研究目标也就不再需要探索，而是决定直接使用HRDscore &gt;= 42 作为同源重组修复缺陷的标准进行分组研究。在 HRD-阳性加体细胞BRCA突变的患者以及那些具有胚系BRCA突变的患者中观察到类似风险比，体现了该药物在患者人群中反应的一致性。 2018年 SOLO1 研究 再来说说奥拉帕利。 名为 SOLO 1 的三期试验在 2018 年底发表，结果说明患有新诊断的晚期 BRCA 突变卵巢癌患者，手术和化疗后接受 PARP 抑制剂奥拉帕利（Olaparib）的维持治疗与不接受维持治疗相比，疾病进展或死亡风险降低了 70%。 这个结果结果不仅使 FDA 批准了奥拉帕利（Olaparib）用于这一适应症，也代表着在治疗BRCA突变卵巢癌患者方面又向前迈出了一大步。不过这项研究使用了 Myriad 的 BRACAnalysis test 产品进行 BRCA 检测，并未涉及到 HRD 评分。 紧接着，2019 年又有三项三期临床试验结果发表。它们分别是 PRIMA、 PAOLA-1 和 VELIA 研究，这些试验考察了 BRCA1/2 突变患者以外的一线 PARP 抑制剂使用，它们分分展示了 HRD 相关亚组的临床结果。 🍺🍺试读结束🍺🍺 剩余内容是参加会员计划读者的专属内容 欢迎你通过会员计划支持我持续创作 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2023-05-03-cancer-homologous-recombination-deficiency-part2/"},{"title":"同源重组修复缺陷HRD：从无到有","content":" 本文为熊言熊语邮件通讯会员计划内容的试读版，完整内容请点击通讯主页订阅并查看。 写在前面 你好，我是思考问题的熊，本内容是参加会员计划读者的专属内容，感谢你通过会员计划支持我持续创作。展信佳～ 本期内容： 今天这一期内容（part1），你将会阅读到 HRD/DDR 生物学背景、临床应用场景和临床验证历程的前半部分内容（2010-2016年），全文接近5000字。 下期预告： Part2中，你会阅读到HRD临床验证历程的后半部分内容（2016-2020年） 生物学背景 同源重组修复缺陷（homologous recombination deficiency, HRD）我们在 V012plus.熊言熊语：从靶向治疗耐药机制到联合用药策略 介绍靶向治疗核心原理中合成致死的时候就埋下了一个引子。 了解同源重组修复缺陷的前提是明白何为同源重组修复（homologous recombination repair, HRR），而明白 HRR 需要从其更上游的概念 DNA 损伤修复（DNA damage repair, DDR）开始。 只要用 DNA damage repair/response + cancer 去检索，你就可以看到不少综述，以下是部分综述的 DDR 通路图供你赏析。 如果你想了解相对全面的通路，不妨参考 cellsignal 网站的整理版本。 如果你想参考相对清晰简洁的示意图，可以理解下面这个示意图。 简单说，不同的 DNA 损伤类型可以通过不同的方式进行修复。 比如，含有错配核苷酸的 DNA 复制错误可以通过错配修复(DNA mismatch repair, MMR)途径进行修复（在 TMB 对应的文章中我们会进一步展开）；针对 DNA 损伤常见的单链断裂（single-strand break, SSB）或者对双螺旋结构影响较小的损伤等，可以通过碱基切除修复（base excision repair, BER）；针对双链损伤（DSB），则有多种不同的修复方法。 其中，HRR 是负责修复 DSB 与 DNA 链间交联（interstrand crosslinks）最为准确且高保真的 DNA 损伤修复系统（依赖 DNA 模板）；而非同源末端连接（non-homologous end joining，NHEJ）、微同源末端连接（microhomology mediated end joining，MMEJ）和单链退火途径 （single-strand annealing，SSA）这些属于低保真高易错的损伤修复途径（可以理解为稀里糊涂先把断了的接上，不管原先是什么样子）。 如果细胞的 HRR 功能出现问题（HRD），细胞就不得不调用那些低保真的修复方案，产生各种大片段的缺失插入，拷贝数异常等现象，进而造成细胞染色体和基因组的极度不稳定。 造成 HRD 的原因很复杂而且目前也没有完全研究清楚。一方面 HR 过程中主要涉及到 BRCA1/2，RAD51，以及 BRCA2 定位基因 (PALB2) 等基因突变；另一方面，研究人员还发现像 BRCA 基因的表观遗传甲基化失活也可以导致 HRD。 临床应用场景 在上一部分我们提到 HRD 的出现会使得细胞依赖低保真的方案进行 DNA 修复，而基于此出现的基因组不稳定则又是癌症的 Hallmarks 之一。（HRD 是造成基因组不稳定性的重要原因之一） 尤其是包括乳腺癌、卵巢癌、胰腺癌和前列腺癌在内的这四个癌种中，研究发现 HRD（BRCA 等基因突变）发生的频率很高，这四个癌种也因此被称作 BRCA assocatied cancer。 因为 HRR 在 DNA 双链修复上的重要功能，如果一个细胞发生了 HRD 同时人为让其单链修复出现问题，就会触发「合成致死」效应，让癌细胞的 DNA 修复系统就会被破坏进而死亡；另外一方面，HRD 会让肿瘤细胞对能诱发 DNA 交联的含铂化疗药物更加敏感。 基于以上基础原理，HRD 自然就有可能作为一个生物标志物，在铂化疗和抑制单链修复的PARP 抑制剂治疗中发挥临床作用。 虽然原理如此，HRD 究竟能在什么癌种的什么条件下指导治疗，直到目前都还存在很多疑问，而已经获批的临床场景验证也经历了非常漫长的过程。 临床验证历程 HRD 作为生物标志物的验证史可以说就是 PARPi 适应症的发展史。 需要说明的是，因为 PARPi 目前在包括卵巢癌、乳腺癌和胰腺癌等多个癌种中均有临床应用，为了更好的梳理 HRD 作为生物标志物的提出和临床验证历程，这一部分我们仅选取一种 HRD 计算方法（GIS）在卵巢癌单一癌种的应用进行展开。 关于 HRD 的更多评价计算方法和 HRD 在非卵巢癌中的应用场景，我们会在后续的「方法和产品」以及「前景和思考」部分有所涉及。 PARP 抑制剂效果初现 PARP 全称是 Poly (ADP-ribose) polymerase，PARP 蛋白家族涉及包括 DNA 修复、基因组稳定性和细胞程序性死亡在内的诸多细胞生物学过程。 2009 年的 ASCO 大会，研究人员分享了一类新型靶向药物令人鼓舞的研究发现，代号为 AZD2281 的药物适用于那些涉及到 BRCA 基因突变的卵巢癌。这类药物就是如今我们所知的 PARPi，而 AZD2281 的中文名字就是如今应用很广泛的奥拉帕利（Olaparib）。 PARP 抑制剂旨在使癌细胞用于修复 DNA 损伤的关键酶失效并促使癌细胞死亡，还可能使癌细胞对其他治疗如化疗药物更加敏感。 当然，彼时还需要进一步长期随机临床试验来确定 PARP 抑制剂是否真正有益于卵巢癌患者，如果是的话，哪些特定类型的卵巢癌最有可能对该药物产生反应？其它癌种效果如何？ 这些都是以后的故事。 陆陆续续，三种 PARPis：奥拉帕利（Olaparib），鲁卡帕利（Rucaparib），尼拉帕利（Niraparib） 早期相继被 FDA 批准用于具有胚系 BRCA 突变的卵巢癌患者。 然而，后续越来越多的研究发现仅仅检测胚系或体细 BRCA 突变会低估甚至错误地鉴别可能受益于 PARPi 治疗患者，于是又把对铂类药物的敏感性也用作 HRD 的提示用来选择预期对 PARPi 敏感的患者。但是铂类药物的耐药机制也超出了 BRCA1/2 状态还是可能低估 PARPi 获益患者。 那是否有什么更好用的指标来提示HRD进而指导 PARPi的用药呢？说来话长，接下来我们需要回到2010年，从一篇方法学文章开始聊起。 🍺🍺试读结束🍺🍺 剩余内容是参加会员计划读者的专属内容 欢迎你通过会员计划支持我持续创作 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2023-05-03-cancer-homologous-recombination-deficiency-part1/"},{"title":"聊肿瘤生物标志物时我们在聊什么","content":" 本文为熊言熊语邮件通讯会员计划内容的试读版，完整内容请点击通讯主页订阅并查看。 写在前面 你好，我是思考问题的熊，本内容是参加会员计划读者的专属内容，感谢你通过会员计划支持我持续创作。展信佳～ 本期内容： 作为生物标志物系列开篇内容，考虑订阅读者专业背景各异，我思来想去还是感觉有必要做一个提纲挈领的整体介绍。它既可以作为这个系列内容的说明，也可以作为你今后自主学习相关知识的方法参考。 在本期内容中，你将会看到： 生物标志物的简单介绍 了解生物标志物的六个不同维度 哪些生物标志物值得关注 具体学习生物标志物的五个层面 推荐三个生物标志物学习资源 生物标志物简介 所谓 肿瘤生物标志物，广泛的说，可以指癌细胞或体内其他细胞对癌症或某些良性肿瘤疾病作出反应时产生的任何物质，这些物质提供了有关癌症的信息，如侵袭性强弱，对何种治疗有反应，或是否对治疗有反应等等。 传统上，肿瘤标记物是指由癌细胞产生的含量高于正常细胞蛋白质或其他物质，在一些癌症患者的血液、尿液、粪便、肿瘤或其他组织/体液中都可以发现这些物质。 除了基于免疫组化的大量蛋白标志物外，越来越多的基因组标志物(如基因突变、肿瘤基因表达模式、肿瘤DNA非遗传变化)被发现存在于肿瘤本身和体液的肿瘤碎片中。 生物标记物是可以在血液、其他体液或组织中测量到的任何分子。 基于检测的来源不同，目前我们通常将肿瘤生物标志物分为两大类：循环肿瘤标志物（circulating tumor markers）和肿瘤组织标志物（tumor tissue markers）。 前者循环肿瘤标志物可以在某些癌症患者的血液、尿液、或其他体液（如胸腹水和脑脊液）中找到；而后者肿瘤组织标记物存在于实际肿瘤中，通常来自于活检切除的样本。 NIH 的美国国家癌症研究所列举了目前常见的一些肿瘤标志物，你感兴趣的话可以参考。 了解肿瘤生物标志物的维度 如果你想了解生物标志物，不妨尝试如下几个维度进行思考。 从生物标志物的临床作用来说，可以考虑是用来进行早筛还是用于诊断还是用来指导治疗，所谓指导治疗又包括了指导患者进行何种治疗（比如是否应该进行靶向治疗或者免疫治疗），疾病进展或治疗效果如何（比如MRD和ctDNA）以及何时应该停止/更换治疗（比如监控耐药）。 从生物标志物的应用价值，还有一类分类方法是所谓的预后标志物（prognostic biomarker）和预测标志物（predictive biomarker）。关于这两类的区分，你大体可以理解为预后标志物是能够独立地预测癌症结局（复发，进展或死亡），与其接受的治疗无关，而如果某种治疗的效果在生物标记物阳性和阴性两组之间不同，那么它就可以称之为预测标志物。 从生物学角度来说，生物标志物可以包括但不限于：基因组、表观基因组、蛋白质组、细胞和形态，以及易患疾病或指示疾病发生的遗传风险因素。 单就基因组层面的改变而言，我们借助从微观到宏观的视角，又可以继续进行分类。小到某个基因某个具体碱基突变带来的氨基酸改变（比如BRAF V600E），到某个基因本身的缺失或者扩增（比如MET扩增），到某个染色体片段（cytoband）的变异，再到肿瘤细胞整体的基因组不稳定性，都可能是我们关注的生物标志物。 再从检测手段来说，生物标志物最经典的检测方法是免疫组织化学（IHC）检测，此外还有PCR检测、基于NGS的 DNA panel，WES、WGS以及转录组WTS的检测。Cell Signaling Technology (CST) 加的产品宣传册中，就有一段关于用免疫组织化学检测的癌症生物标志物类别说明。 最后，从检测范围来看，有时可以是针对某单一基因（指标）的检测（比如PDL1的表达水平），有时又可以是多个基因（指标）的组合（比如乳腺癌的21基因和70基因检测等），有时还需要对全基因组范围内的大量位点进行综合判断（比如MSI TMB HRD检测等）。 这个系列怎么聊 我们不会聊什么 如上文所说，肿瘤生物标志物实在是一个过于庞大的话题。那么熊言熊语聊生物标志物，我们会聊什么呢？ 首先在这个板块的系列文章中不会涉及驱动基因相关的介绍，比如EGFR、KRAS等等。这些重要的能够指导靶向治疗的驱动基因我们会单独开启一个系列。 其次，上文中显示的多数免疫组化指标我们也不会具体涉及，会将关注重点放在基于NGS检测技术下的肿瘤生物标志物。 此外，像肿瘤早筛（DNA甲基化和cfDNA片段组学应用）和MRD这样非常重要且热门的应用场景，我们会单独通过系列文章进行详细介绍。 哪些生物标志物值得关注 说完这个系列不会聊什么，再来说说我们会聊什么以及怎么聊。 在这个系列内容中，我们会把目光聚焦于那些已经有明确临床应用场景和很大潜在应用价值的生物标志物，同时尽可能多的涉及不同癌种和治疗方式，也尽可能覆盖上文提到的从微观到宏观和不同的检测范围。 比如，我们会涉及到基因组不稳定性相关的生物标志物，如同源重组修复缺陷（HRD），染色体不稳定性（CIN）和非整倍体评分（aneuploidy score）；会涉及到染色体片段缺失和基因杂合性缺失。 除了介绍免疫治疗的生物标志物TMB以及MSI，还会涉及到抗血管生成治疗相关以及术后复发监控相关的生物标志物。 除了DNA层面，同样会涉及到基于多基因表达模式的生物标志物。 学习生物标志物的五个层面 每一个生物标志物，我都会争取用尽量可控的篇幅完成如下尽可能所有层面的介绍： 生物学背景：了解相关指标的生物学原理是了解biomarker的基础，比如什么是同源重组修复缺陷，为什么高TMB容易对免疫治疗产生相应。 临床应用场景：了解该生物标志物在不同的癌症和治疗方式下的应用场景，比如是针对某个癌种有效还是针对多个癌种有效，是针对单药治疗有效还是针对联合治疗有效。 临床验证历程：一个生物标志物的提出到验证再到写入临床只能往往是一个非常复杂和漫长的过程。了解生物标志物的重要临床实验里程碑有助于我们认识到从研究到临床的复杂度。（进行文献整合阅读学习的机会） 方法和产品：一个成功的生物标志物往往背后都用核心的商业化公司在进行推动，也都有标志性的产品，比如Myriad MyChoice之于HRD，再比如多基因检测产品 Oncotype 和 MammaPrint 预测乳腺癌复发。（了解国内外成功商业公司和产品的机会） 前景和思考：在这个部分，我们会简要讨论这些生物标志物目前的临床应用潜力和限制，比如有哪些正在进行中的临床实验，以及我们未来应该关注它的哪些进展。 学有余力的资源推荐 如果你对生物标志物很感兴趣或者工作和科研项目中会涉及到生物标志物相关的内容，我可以再推荐几个学有余力的了解途径。 🍺🍺试读结束🍺🍺 剩余内容是参加会员计划读者的专属内容 欢迎你通过会员计划支持我持续创作 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2025-05-03-how-to-learn-biomarker/"},{"title":"肿瘤组织和液体活检结果不一致，好事还是坏事","content":"组织和血检的一致性比较发了很多文章，不过当组织和血检结果不一致的时候，对患者的预后有什么研究价值呢？ Rosenberg, Shai, Gil Ben Cohen, Shumei Kato, Ryosuke Okamura, Scott M. Lippman, and Razelle Kurzrock. 2023. “Concordance between Cancer Gene Alterations in Tumor and Circulating Tumor DNA Correlates with Poor Survival in a Real-World Precision-Medicine Population.” Molecular Oncology, January. https://doi.org/10.1002/1878-0261.13383. 3 月 25 号 online 在 Molecular Oncology 的一项研究进行了相关的分析。 这篇比较组织和血检一致性的文章，看起来更像是在比较两家不同公司产品的性能。 组织检测的数据来自 FMI ，测序细节: Mean sequencing depth was &gt;250×, with 100× at &gt;99% of exons. 血检数据来自 Guardant，测序细节是: The panels utilize hybrid capture followed by NGS of the crucial exons in a panel of 54–73 genes ，5–30 ng of ctDNA was isolated from plasma and complete sequencing at 15,000× read depth。 两者相比，它们能共同分析的基因信息有55个，然后根据收集到的临床数据，就做出了看起来「理所当然」的结论。 组织和血液基因层面较高的一致突变数与更短的总生存期相关。 多变量分析证实，血液和组织中≥2个一致基因水平突变的患者的死亡风险比(HR)为1.49(95% CI 为 1-2.2; P = 0.047) ，而≥3个一致的基因水平突变的患者的 HR 为2.38(95% CI = 1.47-3.87; P = 0.0005)。 也就是说，组织 DNA 和 ctDNA 间的基因突变一致性是一个独立因素，可以用来预测患者生存期。 多想一步。 这个结论很可能意味着：组织和血检不一致的样本，也许其实是血液的ctDNA占比（ctDNA fraction ）偏低导致了突变不一致的发生。 这件事情，去年 10 月 online 在 Annals fo Oncology 的一项研究就是发现了一个和它相关的结果。 其结论显示，plasma ctDNA 占比是在多个癌种中可以广泛应用的血检生物标志物(ctDNA TF)。在多变量分析中显示，ctDNA TF 对预后的影响独立，且当 TF &gt;= 10% 的时候，患者的在CRPC BC NSCLC CRC 这四个癌种中的HR可以达到1.68到3。 再多想一步。 根据这个两个结论，如果组织检出突变，但血检呈阴性，这类患者的预后OS很可能是显著更好的吧？emmm，这个结论对应的研究结果似乎将在2023年的ASCO会议上进行详细报道，作者同样来自于第二项研究的团队。 不过，事情到这里还没有结束。 如果组织和血液突变检测的一致性，ctDNA的肿瘤占比，组织阳性且血液阴性，都可以是预后的生物标志物，那么血检基因的AF本身是不是也单独可以作为一个预后标志物呢？是的，如果仔细研究可能还是用药的预测标志物。 前几天同样发在 Annals fo Oncology 的研究就证明：针对有 BRAF V600E 突变的结直肠癌，血液 BRAF V600E 的 ddPCR 检测结果，在 BRAF V600E AF 2% 分组下，AF 高的患者OS和PFS更差，也更有可能在 BRAF+EGFR+MEK 抑制剂三药联用中获益。 Husain, Hatim, Dean C. Pavlick, Bernard J. Fendler, Russell W. Madison, Brennan Decker, Ole Gjoerup, Christine A. Parachoniak, et al. 2022. “Tumor Fraction Correlates With Detection of Actionable Variants Across &gt; 23,000 Circulating Tumor DNA Samples.” JCO Precision Oncology, no. 6 (November): e2200261. https://doi.org/10.1200/PO.22.00261. 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2023-03-27-tissue-vs-ctdna/"},{"title":"肿瘤精准治疗究竟多难 看这7个临床实践障碍","content":" 换句话，除了「贵」，还有哪些因素影响了癌症精准治疗在临床实践中的应用呢？ 今年过年发生的一段对话如下： 👨：小伙子，哪里发财？ 🐻：呃，没发财。 👨：那瞎忙啥呢？ 🐻：往大了说是精准医疗，研究一些可以检测癌症病人基因组变化的东西，用了之后就能找到针对患者精准的治疗方式。 👨：一种很新的东西？ 🐻：算上老美那边，行业从起步到现在已经很多很多年了 👨：那我听说的人得了癌症怎么还都是化疗？ 🐻：可能是还没真正普及这种看病方法，而且小地方也有很多不规范 👨：那你不白研究了？ 🐻：来，叔，喝一杯 过年回来，这段对话我一直忘不掉，除了不知道该如何发财，还好奇一个问题：这么多上下游公司，有药企有诊断，这么多做科研、做研发、做销售的从业者，吭哧吭哧这么多年，究竟有多少患者从中受益，应该从哪里找问题？ 换句话，除了闭眼能想到的「贵」，到底有哪些因素影响了癌症精准治疗在临床实践中的应用？ 前几天一查，还真找到了 2022 年 10 月发表在 JCO Precision Oncology 的一篇论文。 这篇论文以晚期非小细胞肺癌（NSCLC）为例，详细介绍了将预测生物标志物（predictive biomarker）检测整合到癌症个性化诊疗过程中面临的挑战，并量化分析了各种临床实践障碍对治疗的真实影响。 先说结论：在美国，从诊断到治疗的过程中，由于不同临床实践障碍叠加造成的患者损失，最终大约 64% 的潜在获益晚期 NSCLC 患者没有受益于适合其疾病的癌症精确治疗。 如上图所示，该研究使用的 Diaceutics 是一个来自美国超过50万名非小细胞肺癌患者数据，包括商业和医疗保险以及实验室数据在内的多来源数据库。 其研究重点放在了精准治疗过程中从诊断到治疗七个步骤出现的障碍和各自独立及累计影响。 七个步骤如下： Step 1: Biopsy referral: Initial solid or blood biopsy was never performed. 未进行最初的组织或血液活检。 Step 2: Biospecimen collection: Biospecimen collection challenges including insufficient tissue or tumor cell content of initial biopsy or rebiopsy inhibited biomarker testing and its accuracy. 生物标本收集影响了生物标志物检测和准确性 Step 3: Biospecimen evaluation/pathology: Biospecimen tumor cell content was overestimated, inhibiting biomarker testing and its accuracy. 被高估的肿瘤细胞含量影响了生物标志物检测和准确性。 Step 4: Biomarker test ordering: Appropriate testing was not ordered, or treatment began before testing was ordered. 未进行相关检测或在检测前即开始治疗 Step 5: Biomarker testing performance: Biomarker testing provided inconclusive or false-negative (FN) results. 生物标志物检测提供了不确定或假阴性结果。 Step 6: Test result reporting: As a result of turnaround time (TAT) delays, treatment was initiated without consideration of test results. 周转时间问题，治疗并为考虑检测结果即开始 Step 7: Treatment decision: Targeted treatment was not selected despite positive test results. 尽管测试结果为阳性，但未选择对应的靶向治疗。 当将人数标准化为1000时，如下图你可以看到每一步具体存在的问题以及陆续措施治疗机会的患者人数和比例。 在上面这幅图，我们可以发现，研究者估计有29.2%的病人没有根据他们的检测结果接受适当的针对性治疗。 根据索赔数据，确定有18.5%的病人没有接受治疗。在81.5%的接受了各种治疗的患者中 9.1%只接受化疗，14.3% 接受化疗和免疫治疗，40.8% 只接受免疫治疗，16.6% 接受靶向治疗，还有 0.7% 接受其他治疗。 14.3%的肿瘤本可以使用TKI却没有接受指定的治疗。另有11.6%的患者在IHC检测基础上获得了可针对治疗的结果，但没有接受适当免疫治疗，此外估计共有3.3%的患者的检测结果不正确（假阳性）。 推测没有接受相应治疗的原因，如下图显示，可能包括：检测报告问题（报告中的错误、过时的临床和药物信息）；缺乏FDA批准的适应症（医生不清楚或不愿在适应症外用药）；对靶向治疗选择的认识滞后；治疗可及性；治疗成本/保险报销范围等。 如果你关注的是肿瘤NGS检测，那么有一个好消息和一个坏消息。 坏消息是turnaround time (TAT) 统计显示：在接受生物标志物检测并报告结果的29227名患者中，研究估计有4%经历了TAT延迟进而导致治疗决定没有考虑分子检测结果，在所有方法中 13.1% 的 NGS 检测 TAT 超过了14天。 好消息是，在包括 PCR Sanger IHC和FISH在内的检测手段中，根据多项研究估计的假阴性和假阳性率现实，NGS方法的FN和其它相比要明显小的多。 看到最后这张汇总的患者丢失示意图，不知道你作何感受。 问题代表着机会和改进空间，问题越大的步骤被优化的可能性也相对越大。不过，除了注意数据的实效性（来自2019年）以外，你或许还需要注意如下几点内容： 这项研究针对 NSCLC，算是实体瘤中精准治疗机会偏高的癌种，那其它癌种的情况又如何？ 七个临床实践障碍中，美国患者流失率最高的是障碍七，随后不分伯仲的是障碍四和五，如果在国内进行类似研究又可能是哪几步问题最大？ 第一步中，84.6% 接受了组织活检；8.8% 接受了液体活检，6.6% 没有组织或液体活检的患者可能只通过成像进行诊断。从这个数据看，液体活检和组织活检相比优势究竟是什么，空间还有多大 第三步中，根据估算，肿瘤细胞含量&lt;\\20%的 14% 的组织样本中，有 38% 被高估为&gt;20%，进而被错误地认为适合分子检测。这一部分在各家肿瘤检测公司中，有多少本不该检测的样本进行了检测？ 以上研究，如果考虑一个患者随着治疗展开多次检测，又会是一个什么结果呢？ 如果治疗前（基线）检测尚且存在如此大比例潜在可获益的患者流失，各家你争我夺的MRD和早筛，目前又是什么情况？ 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-03-14-clinical-practice-gaps/"},{"title":"关于wolai被钉钉收购：多研究些问题少谈些逻辑","content":"说明：本文写在听闻钉钉收购在线笔记工具wolai，并看到两篇相关评论文章之后。 不在效率工具圈子很久，刚刚刷少数派看到老麦发了一篇「钉钉收购我来 wolai 的背后逻辑」才知道这个软件被钉钉收了，紧接着又看到一篇发表在MacTalk上池老师团队成员写的文章「钉钉居然收购了我来wolai」。 还是忍不住说几句自己的观感：如果你和我一样是个普通用户，还是多研究些问题，少谈些逻辑。 一个大厂办公软件收购了一家做 toC 个人知识管理工具的公司。 这件事无论是行业逻辑还是商业逻辑听起来多么合理，无论从收购方还是被收购方角度看多么双赢，作为个人用户，你我最好既不要投资人视角也不要创业者视角，还是多为自己想想吧。 我在少数派最早被大家知道是因为很多年前写了一篇彼时用「Evernote」记笔记的个人经验心得开始，后来因为各种机缘混了个「资深印象大使」的名头。再后来布幕出来后借势安利了一波幕布，因为实在不老少人从我这里注册，又混了个「幕布布道师」的名头。 那时，我还对这个小圈子充满了热情和兴趣，又过了很久，语雀出来了。 我想这个产品背靠蚂蚁应该靠谱点，再加上一开始的知识库功能刚好满足我那是的实际需求。就在自己的专业圈子开始安利，还在上面建了好几个访问量不小的专业相关知识库，慢慢也发想很多专业相关的小伙伴开始用语雀。 后来 wolai 出来，有很多小伙伴问我怎么样，我当时抱着中立的态度推荐试用，过了一段时间我对它家每日更新的说明日志感到困惑，写了文章之后就开始被一些人diss。 再后来就没有后来了，我基本就不再写这类效率工具相关的文章也对国内各类型的新东西不感兴趣。 一是觉得自己的方法论已经成形，实在写不出什么能给自己和别人带来新认知的内容，二是我发现了一个非常大的bug：经过好多年好多产品的亲身见证，国内公司无论是大厂还是（有心做大的）创业公司，2C这类知识管理产品基本上就不能推荐。 说的爆论一些：推荐约等于坑人。 笔记工具，尤其是在线笔记工具，除去少部分喜欢尝鲜的极客用户，对于绝大多数人来说最重要的是稳定。 用户需要稳定，一方面需要产品做到服务和功能的稳定，另一方面更要做到发展和策略的稳定。 但，这两个稳定，在我们目前的商业环境下，我的体感是都极难。Evernote 完全剥离后的印象笔记，被字节收购的幕布，有靠山支撑的语雀，再加上被钉钉收购的 wolai，这四个样本基本代表了国内目前这类产品所有类型的公司。 想要做大做强又不想被收购还想要继续盈利，基本思路就得是印象笔记这种，vip会员到vvvvvip会员，从没广告再到会员广告。留下忠实用户懵逼。 产品逐渐有起色（这里先不聊所谓抄袭原罪）的创业团队想做大做强，在国内全靠2C做付费生意真是很难。创始团队最成功的结果就是把东西卖了，自己全身而退。 结局就是幕布这种早早彻底进入维护模式，实际产品能力并入被收购方创始人风风光光的财务自由或者开始新征程。留下一个自己连续创业者的光辉形象，忠实用户继续懵逼。 出生在大厂，全力产研总行了吧？结果语雀这种大佬带队一众精兵强将，干了一段时间还是要面对营收压力和创业公司挑战，然后就是频繁改版和频繁求变，继续让忠实用户懵逼。甚至到了今天，都是阿里系的，还因为内部各种原因没办法近水楼台被钉钉带走。 wolai 两三年前在 Notion 席卷国内创投圈那波浪潮下拿到融资，已算当时国内同类新产品里最光鲜亮丽的一个，但熬过这三年还是突破不了这个局。创始人退出（企查查可查），产品能力接入钉钉，从历史经验来看，大概率不远的将来也是……算了，说多了又招骂。 所以，最近一两年，但凡还有人问我知识管理类工具，我是真不敢推荐国内的产品，他是无心问的还好，要真是诚心提问，到头来约等于坑人。 我就简简单单老老实实说自己一直在用的 Workflowy，Obsidian 和 Notion。 workflowy 这个大纲笔记爷爷辈产品这么多年多克制和稳定不妨自行了解；Obsidian 和 Notion 到目前也没给你来几个改头换面的创新改版，某天打开软件连主页都不认识。这三个产品的规模和团队以及盈利水平都不一样，但至少都能做到所谓「稳定」。 以及，我唯一还在坚持用的国内创业公司的同类型产品就是 flomo。 不是因为少楠在产品圈子的影响力，也不是受教于他那套配合flomo到处宣贯的知识方法论，而是因为创始人保证说能让这个产品最低限度稳定运行个六七年。如果真这样，我就能持续再付费六七年。 最后，推荐所有使用在线云笔记类产品的小伙伴参考这样一个原则：如果你想用的工具不支持「全量且可读」格式的导出（简单说就是允许你一次性导出所有内容且都可以直接阅读），那尝尝鲜就行。 借用老麦文章里的原话：面对收购消息，大部分我来 wolai 用户还是会担心产品服务的延续性。 与其担心着用，为什么不让自己的数据真的在自己的手里呢？而且这也并不难。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2023-03-08-about-wolai-dingding/"},{"title":"MSKCC 尚待解决的肿瘤基因组检测临床应用问题","content":"MSK前瞻性临床队列 MSK-IMPACT和MSK-ACCESS样本量突破10万之后，MSKCC的分子肿瘤中心 (Center for Molecular Oncology, CMO)主任 David Solit 最近在个人社交媒体上晒了这样一个截图，并补充到： 随着数十种tumor-agnostic和肿瘤特异性的基因组生物标记得到FDA批准，肿瘤以及胚系基因组检测应该被考虑用于所有需要系统治疗的癌症患者。 关于MSK-IMPACT和MSK-ACCESS MSK-IMPACT中IMPACT是Integrated Mutation Profiling of Actionable Cancer Targets的缩写。IMPACT panel 可以检测的基因数量也经历了很多版不同的变化，从最早的341基因到410 基因到2017年FDA获批时的468基因，再到如今的505基因，可以同时进行MSI和TMB检测。 而MSK-ACCESS中的ACCESS则是指 Analysis of Circulating cfDNA to Evaluate Somatic Status，它从IMPACT中挑选了129个关键的肿瘤相关基因，在cfDNA中进行深度测序。 尚未完全回答的关键问题 更值得关注的是，在「展示成果」的同时，David Solit 还提出了自己想到的，8个关于肿瘤NGS检测临床应用尚未完全解决的问题。 如果你目前就在这个领域中，也许其中有些 point 会给你启发。 cfDNA能否取代肿瘤组织进行检测，如果可以的话是针对哪些病人，什么时候cfDNA和肿瘤组织检测又是互补的呢？ 更全面的全外显子组/全基因组测序在临床中的应用是什么？ 与其配套其它技术平台，比如全转录组测序和蛋白质组学的的应用又是什么？ 哪些人应该进行胚系检测？胚系突变不仅可以为遗传性癌症风险提供信息，而且还可以成为药物反应的生物标志物。 5. 怎样才能提高肿瘤/胚系检测的可及性？如果需要进行基因组分析来确定最有效的治疗方法，无法获得这种技术的患者很可能就不能得到最好的治疗。 如何才能扩大精准肿瘤治疗的影响？最重要的是需要更好的药物，仍然有太多「无法治疗」的靶点，比如RB1、TP53、STK11、NF1和多数RAS突变。我们也需要更多具有选择性/低毒性的药物以便进行更精准的联合治疗。 我们还需要更低的检测价格（这是采用全基因组测序的主要障碍）以及更好的报告注释。 还能从目前的panel测序中得出哪些更丰富的信息：大片段拷贝数；杂合性缺失评估；靶向突变克隆性评估；更好的signatures分析来为突变解读提供信息。 从5万到10万样本的变与不变 MSK-IMPACT 和 MSK-ACCESS 样本突破10万例的时间是2023年2月，而2020年1月这个数字刚来到5万。 下图是当时他晒出来的样本量截图。 好巧不巧，该说不说。 3年前样本量突破五万的时候，David Solit 同样发表了一些他自己的想法和评论（可以看作未解之谜前传）。 我同样顺手把它整理出来分享给你，你可以看看这三年时间，他的想法哪些变了哪些又没变。 1. 所有晚期癌症患者都应考虑进行肿瘤NGS检测。肿瘤NGS历来被认为只是一个辅助诊断手段，主要是那些系统性进行靶向治疗的患者需要，这样的想法低估了其临床价值。 2. 肿瘤NGS检测对以下几项内容也很关键：确保正确的癌症类型诊断，这将影响手术、放疗和化疗的决策；了解患者复发和死亡风险；评估可遗传的胚系突变。 3. 一些专家认为肿瘤NGS和精准治疗约等于「夸大其词」。在MSK的经验中大约40%的晚期癌症患者治疗直接取决于肿瘤NGS检测结果。为什么这个比例似乎不高呢？ 到目前为止，MSK队列中发现的最常见突变清楚地说明了更多患者并未从靶向治疗中受益的主要原因。如下图所示，我们对大多数基因突变(TP53、TERT、APC、NF1)驱动缺乏有效的靶向治疗。 可见，增加受益于肿瘤NGS检测的患者比例需要更多的新药开发。 4. 根据MSK的经验，更大范围的NGS检测可以一定程度上扩大指导范围。那测多少才够呢？ 肿瘤NGS检测通常有3个结果：确定可信的可靶向驱动因素；确定可信的足以让细胞发生转化的非靶向驱动因素；没有找到可靶向的驱动因素。根据经验，更大范围的NGS检测主要是可能让第三组患者增加收益。 在少数情况下，识别被靶向测序遗漏的基因融合可能会影响治疗结果。将来在可靶向驱动因素的患者中识别伴发突变也可能促使靶向治疗的合理组合。 5. 更大范围的NGS检测目前看来可以识别预测药物敏感性的突变特征（比如 MSI），不过能够识别HRD或其他特征的WGS检测是否真的有临床价值仍有待确认。 6. 我们是否仍需要争论配对肿瘤和正常组织测序是否是最佳方法？越来越清楚的是最好对「正常」样本同时进行分析以确保突变不是来自胚系或克隆造血。 7. cfDNA 在哪里应用更合适呢？cfDNA显然比肿瘤组织NGS检测有一些好处。比如：更容易获得样本和更短的周转时间；更容易对患者进行重复采样；更好地反映肿瘤异质性。 然而，cfDNA 检测必须进行更深的测序，这意味着更高的测序成本和通常更少的检测基因数量。 由于肿瘤DNA脱落率低，就有可能出现假阴结果；而敏感性又因突变类型而不同，克隆性造血也可能会混淆结果。 因此，肿瘤和血液NGS检测可能会被证明是互补而非竞争的方法。医生需要能正确地识别可能因肿瘤来源DNA比例低而错过关键突变的患者。 8. MSKCC 接下来该怎么做？关键步骤是不断收集参与MSKCC前瞻性计划的数万名患者的临床治疗信息和检测结果数据。 我们需要更好地了解为什么病人从目前的治疗中获得了不同的益处。加快开发更有效的方法治疗那些现有方法无法获益的患者，为那些能够获益的患者找到毒性更小的方案。 9. 为了促进这项工作，MSKCC 同样是 AACR GENIE 项目的创始成员之一，这一计划将汇集世界各地机构的基因组和临床数据，更好地了解特定基因组图谱如何影响癌症患者预后。 10. 期待未来几年MSKCC的团队合作能够充分揭示基于肿瘤和血液NGS检测的应用潜力。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2023-02-04-mskcc-cmo-tumor-ngs-test/"},{"title":"不要错过的14档肿瘤研究专业相关播客","content":"今天是2023年2月2号正月十二，俗话说的好啊朋友：没过十五就是年儿。还算赶趟，熊言熊语在这里先给你拜年。 今年的更新计划中，熊言熊语会增加一个合集系列 「我想问问熊」。顾名思义，你问我答。我会从大家在各种渠道的提问中，挑出一些受众相对广的问题，通过文章或者播客的形式进行回答。 今天就是这个系列的第一个问答，来自一位会员计划读者： 熊，我因为之前听你的「熊言熊语」播客养成了听播客的习惯，现在你已经很久没有更新音频内容，不知道平时有没有听一些肿瘤研究专业相关的播客呢，可否推荐一些？ 得嘞，感谢你的提问，另外别骂了别骂了。 在大学听了一段时间播客之后（当时竟然是为了练听力），我是从19年底又开始重新密集听播客的，中文和英文都在听。现在播客确实已经成了我的一个重要的信息获取来源，这其中当然也包括专业相关内容。 俗话又说的好啊朋友：授人以渔不如红鲤鱼与绿鲤鱼与驴。 今天借着这个提问，我整理了一下自己追更比较勤的肿瘤研究相关播客，分几类推荐给你。在做家务、通勤或者想休息休息眼睛的时候，可以尝试听听看。 目前主题为介绍肿瘤研究相关进展和相关访谈类的内容，我订阅的都是英文播客，暂时还没发现很优质的中文内容，如果你有好的中文播客推荐，欢迎通过留言介绍给大家。 杂志期刊 大多数你能叫上名字的知名期刊往往都会有配套的音频播客。如果你对某个专业相关的杂志感兴趣，不妨去官网搜搜看。 在这个类别下，我可以推荐两个节目。 一个是来自JAMA的「JAMA Network」，这个播客每期会采访最近在 JAMA 系列杂志中发文的作者，因为 JAMA 系列很多是肿瘤相关内容，所以这档播客也会经常有肿瘤研究相关的话题出现。 另外一个是来自 The Cancer Letter 杂志组织的「The Cancer History Project」，作为一档口述历史的播客节目，其中有很多对那些塑造了我们肿瘤学认知的大佬采访。如果你对这类内容感兴趣，也推荐直接访问他们的官网访问文字内容。 知名大厂 在国外众多专业类内容中，非常重要的一个组成部分是各家知名公司的企业播客。 播客这种媒介形式在美国有非常广的受众基础，很多公司都会通过播客来进行科普和宣传。 在这个类别下我推荐三个节目，更多内容可以自行探索～ Genentech 有一档叫做「Two Scientists Walk Into a Bar」的播客节目我非常喜欢，这档播客从2016年开始到今年已经发布了四季34期。 内容如其名，因为背景音是那种酒吧的环境白噪音，听的时候就真的像在酒吧里听隔壁桌的科学家们聊天。 Myriad 作为一家肿瘤NGS检测公司，他们在2020年也推出了自己的播客「Inside the GENOME」。这档节目由Myriad 的CMO亲自坐镇，目前主要是他们组织的在线 webinar 录音以及少量的嘉宾访谈。 肿瘤早筛领头羊 Grail 在去年10月也推出了自己的月更播客「The Cancer SIGNAL」，目前已经更新了4期内容。 这档节目的主题自然是科普和介绍关于多癌症早筛的内容，Grial公司内部和不同领域的嘉宾会分享他们对多癌症早筛的看法和经验。如果你对这个话题感兴趣不妨听听看。 医院机构 肿瘤研究相关的另一大类内容，可以汇总为来自知名医院或者机构出品的官方播客。 比如约翰·霍普金斯基梅尔癌症中心的同名播客、Dana Farber的 Unraveled 和威尔康奈尔医学院的 CancerCast。 ASCO 和国际肺癌研究协会(IASLC)这样的机构，也都会有自己的播客节目定期更新。 名人教授 最后一个类型可以归类为由一个或者几个名人/教授主持的相关节目。 这类播客的主理人往往是某个领域内的专家学者，节目带有浓厚的个人色彩，能请来什么嘉宾也很大程度上依赖于他们的人脉。这里列举四个。 Neil Love 主持的「Oncology Today」以及他公司名下的系列播客内容，通常会采访临床研究人员的研究内容和临床实践 Chadi Nabhan 主持的「Healthcare Unfiltered」经常会涉及一些比较有争论性的话题 Harry Glorikian 作为一个投资人和商业顾问，他的播客节目「The Harry Glorikian Show」 时不时会采访到一些公司的创始人 由三位血液瘤研究人员共同主持的「Blood Cancer Talks」节目会邀请血液恶性肿瘤领域的相关专家深入讨论血液瘤相关的热门话题。 以上，就是为你推荐的14档肿瘤研究相关的播客节目，祝收听愉快。 我们下次再见👋 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2023-02-03-cancer-research-podcast/"},{"title":"从靶向治疗耐药机制到联合用药策略（下篇）","content":" 本文为熊言熊语邮件通讯会员计划内容的试读版，完整内容请点击通讯主页订阅并查看。 写在前面 你好，我是思考问题的熊，本内容是参加会员计划读者的专属内容，感谢你通过会员计划支持我持续创作。展信佳～ 马上就是农历新年，本期内容是虎年最后一期会员计划推送，再见面就是兔年。提前祝你新年快乐。 本期内容： 在第12期熊言熊语plus内容中我们一起学习了「从靶向治疗耐药机制到联合用药策略」的前半部门内容。 针对耐药机制，我们说靶向药物的耐药可以分为原发性耐药和继发性耐药，其中继发性耐药又可以划分为遗传机制和非遗传机制。此外，越来越多的研究发现肿瘤的瘤内异质性也是耐药重要原因。 而联合治疗策略便是针对上述不同耐药机制展开的，在今天第14期plus内容中，我们将一起完成下半部分的学习。 下期预告： 如果在过年期间，我没有看到特别有意思的内容想要插队和你分享，下期我们将正式开启「生物标志物」系列内容的更新。生物标志物有不同的维度，大到基因组本身的不稳定性，小到一个基因的点突变。在第一期「生物标志物」内容中，我们将会一起学习基因组不稳定性的衡量指标之一：同源重组修复缺陷（HRD）。 以下为本期内容正文，约7000字。 克服原发性耐药 在这个系列文章的上篇中，我们提到： 理解内在耐药性的机制，重要的是要认识到正常的细胞平衡在很大程度上取决于信号通路之间和内部的相互影响和反馈调节。比如为了维持平衡状态，对一条信号通路的抑制往往会导致第二条通路（或同一条通路）的补偿性增强。这种缓冲作用确保了生物系统的稳健性，但在癌症治疗中就变成了一个重大挑战。 既然一种信号通路的抑制会被另一种信号的激活所补偿，那么一个或许可行的思路就是同时抑制这两条通路。 因为BRAF突变的CRC对BRAF抑制剂存在原发性耐药的情况，2012年先后有两篇发表Nature和Cancer Discovery的文章想要探索可以和BRAF抑制剂协同作用的其它激酶。 前者通过RNAi的基因编辑方法，在BRAF V600E 突变的细胞中，抑制了518个激酶和17个额外的激酶相关基因。研究结果现实，通过西妥昔单抗或小分子药物如吉非替尼或厄洛替尼对EGFR的抑制与BRAF(V600E)的抑制在体外和体内都具有强烈的协同作用。从机制上讲，BRAF(V600E)抑制会导致EGFR的快速反馈激活，从而使癌细胞继续增殖，而黑色素瘤细胞因为表达低水平的EGFR，因此和结直肠癌不同不会受这种反馈激活的影响。 在经过临床试验验证后，BRAF和EGFR抑制剂的联合治疗现被批准用于BRAF突变型结肠癌。 在上期文章中，我们也提到了合成致死原理。这一应用于描述基因之间相互左右的概念，后来也被广泛的用来描述基因药物相互作用（如BRCA+PARPi）或者药物和药物的相互作用。 这类合成致死性基因筛选方法可以在一种药物在大多数患者中没有产生临床反应的情况下开展实验，尤其是随着CRISPR-Cas9技术的成熟。 肝癌的主要基因突变如TP53、CTNNB1、TERT启动子等突变缺乏成药性（undrugable），无法直接作为有效药物靶点。目前，肝癌一线靶向药物仑伐替尼和索拉非尼、二线靶向药物瑞戈非尼等均为多激酶靶点药物，临床疗效远未达到期望值。 例如，在肝癌的一线治疗中，可以同时抑制抑制血管内皮生长因子受体（VEGFR 1-3）、成纤维细胞生长因子受体（FGFR1-4）、血小板衍生生长因子受体a（PDGFRa）、KIT和RET的多激酶抑制剂仑伐替尼（Lenvatinib）仅仅能让约五分之一的患者临床获益。 为了确定能与仑伐替尼协同作用的药物靶点，2021年发表在Nature的一项研究中，研究人员进行了CRISPR-Cas9合成致死性筛选，以剖析对仑伐替尼的耐药机制，确定了EGFR TKI 与仑伐替尼在肝癌中的合成致死性。随后的I期临床试验中，仑伐替尼和吉非替尼的组合被证明对仑伐替尼耐药的肝细胞癌患者是安全和潜在有效。 克服获得性耐药性 在上篇内容中，我们提到获得性耐药性最常见的形式之一是药物靶点本身的二次突变。这种类型的耐药性最容易通过设计对这些变异靶点有活性的下一代抑制剂来克服，例如三代EGFR抑制剂Osimertinib，它能有效抑制一代EGFR TKI治疗时经常出现的T790M突变，并因此使患者的临床获益增加一倍。 双重阻断（Double blockade） 但更具挑战性的情况是治疗获得了上游或下游激活性突变而对关键致癌信号通路的抑制产生耐药的情况。 在BRAF突变的黑色素瘤中，MAPK通路的重新激活是最主要的获得性BRAF抑制剂耐药机制，这导致了临床研究使用MAPK途径的垂直双阻断来避免这种重激活。逻辑类似下图。 事实上，BRAF和MEK抑制剂的组合结果优于单独的BRAF抑制，现在是BRAF突变黑色素瘤的标准治疗方法。 2015年发表在NEJM的一篇临床研究，探索了BRAF和MEK抑制剂联合使用对于BRAF V600 突变的黑色素瘤患者的疗效。 该研究将入组患者分为三组，其中一组仅使用达拉菲尼 (Dabrafenib)，另外两组分别配合不同剂量的曲美替尼 (Trametinib)。结果显示，联合治疗的效果要远好于单独治疗。 KRAS G12C 抑制剂无疑是2022年最引人瞩目的靶向治疗药物，但是最近关于选择性KRAS G12C 抑制剂有效性的研究也呼应了我们今天的耐药和联合治疗话题。 KRAS G12C 抑制剂在临床上显示出不同的结果，总的来说，KRAS G12C 突变的NSCLC患者获益处远大于携带相同KRAS基因突变的CRC患者。 我曾经在2022年ESMO会议的时候碰巧感慨发了一个朋友圈，说的就是这个事情。 KRAS G12C 突变的结肠癌，CodeBreak 101 和 KRYSTAL-1 都表明无论是Sotorasib 还是 Adagrasib 加上 EGFR 单抗效果都要更好。 多节点抑制(Multi-node inhibition) 如果两种药物联合使用更好，那么在同一通路中使用三种或更多的药物联合是否可行呢？ 🍺🍺试读结束🍺🍺 剩余内容是参加会员计划读者的专属内容 欢迎你通过会员计划支持我持续创作 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2023-01-18-mechanisms-of-resistance-2/"},{"title":"那些获得FDA突破性设备认证的多癌种早筛公司","content":" 本文为熊言熊语邮件通讯会员计划内容的完整试读版，更多内容欢迎点击通讯主页订阅并查看。 写在前面 本期内容： 上周，国内肿瘤NGS检测公司燃石医学发布了一篇新闻稿，其中写道： 自主研发的多癌种早检产品OverC Multi-Cancer Detection Blood Test（以下简称OverC）获得美国FDA授予的“突破性医疗器械”（Breakthrough Device Designation）认定，成为全球第三个获得此项认定的多癌种早检产品。 OverC 可以通过抽取一管外周血(8~10毫升)，为50-75岁的受检人筛查肺癌、肝癌等多个癌种，并进行组织溯源，提示癌症相关甲基化信号的来源器官，临床医生可根据筛查结果进行针对性检查并进一步诊断。 而基于OverC和ELSA-seq技术，燃石目前也在国内启动了PREDICT、PRESCIENT和PREVENT三个大型临床研究（如下图介绍）。 关于这则新闻，你可以通过其公众号查看或者在官网阅读英文介绍。我看完之后，它背后没有写出来的几个内容反而勾起了自己的好奇心。 比如，文章中提到OverC是全球第三个获得此项认定的多癌种早检产品，那么第一个和第二个又是谁，这两家公司和产品如今怎么样了呢？ 再比如，FDA Breakthrough Device Designation 是什么，它的申请需要符合什么条件，有了FDA BDD认证究竟又意味着什么？ 带着这两个维度的好奇，通过本期内容，我希望和你就上面的内容展开聊聊，同时也希望像 从2002年的Nature论文到2022年的亿元营收 这篇文章一样向你尝试距离剖析自己看到一篇文章之后的思考路径。 多癌种早筛 FDA BDD 认证的前辈 「多癌种早筛」在不同的公司和产品语境下有不同叫法，比如 Multi-Cancer Detection assays (MCDs) 或者 Multi-Cancer Early Detection assays (MCEDs)。在上面提到的燃石OverC中，又被称为 Multi-Cancer Detection Blood Test (MCDBT)。所以如果今后你看到诸如 MCD、MCED 或者 MCDBT 这样的缩写，不用怀疑，它们都指的是多癌种早筛这一件事。 目前国内外涉及到多癌种早筛业务的主要公司，可以参考下面这张图。 而它们的主要产品和技术以及覆盖癌种，可以参考下面这张图。 👆这两张图涉及到的公司产品和技术，有不少值得我们单独继续学习了解，今后会陆续涉及到。 今天，我们暂时聚焦于FDA授予突破性医疗器械（Breakthrough Device Designation，BDD）认定的前两家公司。嗯，某种意义上说它们倒也都在这两幅图里。 当仁不让但并非首家的 Grail 如果你对多癌种早筛这个技术或者市场略有了解，不难猜到其中应该有一家是目前专注在MCED领域的领头羊 Grail。如果你感兴趣Grail 2022年的业务表现，可以参考我前几天写的和头部肿瘤早筛公司 GRAIL CEO 学写年终工作总结。 事实也确实如此，时间回到四年前，2019年5月13号 GRAIL在其官网宣布自己的 Multi-Cancer Early Detection Test 获得FDA BDD 认证（for its blood test being developed to detect multiple cancer types in people aged 50 years and above）。 彼时，GRAIL 如今最受关注的 PATHFINDER和PATHFINDER 2研究还没什么影子，其最重要的研究结果是 Circulating Cell-free Genome Atlas (CCGA)。 在这项研究中，GRAIL希望从不同的NGS检测方法出发，去探索癌症患者和正常人血液中的基因组癌症信号特征。这其中就包括如今被广泛采用的甲基化策略、所谓cfDNA的片段组学以及染色体突变缺失特征等等。 在2019年的ASCO会议上，GRAIL 一口气发了好几篇poster来介绍CCGA项目的研究成果。 通过CCGA的子研究，其最终选择甲基化作为首选方法来同时检测多种类型癌症并进行组织溯源。 这套基于甲基化数据进行早筛检测和溯源的策略，国内目前开展最好的也是燃石。不过，从 FDA BDD 批准时间和几个大型临床试验开展进度看，和 Grail 线性相比大致要慢个2年左右时间。 如果你对于这些技术之间的更多细节感兴趣，Grail 最近在 Cancer Cell 发表了题为 Evaluation of cell-free DNA approaches for multi-cancer early detection的文章，（从他们的视角）详细比较了不同技术之间的优劣，最后的结论当然甲基化技术是坠好的。 Grail 的确是目前发展最快的专注于肿瘤早筛的公司。不过它确不是第一家获得该类FDA BDD认证的企业。 首家认证但已不存在的PapGene 时间再往前回溯到2011年，来自约翰霍普金斯大学的液体活检早筛研究团队开发了一项名为SafeSeqS的NGS测序技术。 两年后，SafeSeqS被纳入他们的一项液体活检试点研究中，该测试使用常规巴氏检查中获得的宫颈液来检测子宫内膜癌和卵巢癌。在这项研究中，使用 Papgene 方法测出了所有24例子宫内膜癌和22例卵巢癌中的9例，这一研究结果于2013年发表在 Science Translational Medicine。 2015年，团队中的 Papadopoulos, Kinzler 和 Vogelstein 三个人在约翰·霍普金斯风险投资公司(JHTV)的帮助下，成立了一家名字就叫做 Papgene 的初创公司并计划将这项技术商业化。 与此同时，三位创始人再接再厉，开发了另一个多种类型的癌症液体活检技术 CancerSEEK。2018年初，发表在 Science 杂志上的一项研究对 CancerSEEK 的八种癌症类型检测效果进行了分析，发现它对卵巢、肝癌、胃癌、胰腺和食管癌癌的特异性超过99%，敏感性则从69%到98%不等。 随后，2018年8月8号，PapGene 宣布 FDA 基于其产品同时检测卵巢癌和胰腺癌的能力，正式授予 PapGene Blood-Based Cancer Test BDD 认证（uses a combination of circulating tumor DNA and protein biomarkers to detect cancers in average-risk, asymptomatic individuals over the age of 65）。 嗯，PapGene 就是第一个获得该项认证的泛癌种早筛产品了。 不过，一年后，随着 CancerSEEK 的影响力扩大和产品日渐成熟，PapGene 这家初创公司最终改名为 Thrive Earlier Detection Corp 并完成首轮1.1亿美元融资，同时获得了CancerSEEK 和 SafeSeqS 的商业授权。曾在 Foundation Medicine 担任了5年 COO 的Steven J. Kafka 成为了 Thrive 首任CEO兼执行主席。 2020年4月，Thrive和约翰霍普金斯大学的研究人员宣布有9911名没有癌症证据或病史的女性接受了基于 CancerSEEK 的多癌血液检测，并检测到26种未诊断的癌症，而这项发表在Science名为 DETECT-A 的研究也是首次将液体活检血液测试用于这一目的。 三个月后，2020年8月 Thrive 宣布再融资2.57亿美元，再三个月后，Exact Sciences 宣布以超过 21.5 亿美元的价格收购 Thrive，并在2021年初正式完成了这一收购。 从 Papgene 到 Thrive 再到 Exact Sciences，这也就是为什么在文章开头的那幅图里，CancerSeek 目前是 Exact Sciences 的技术，以及我提到的某种意义上说 FDA BDD 认证的三家公司和泛癌种早筛产品都在那两幅图里。 这里可以多说几句的是，同样在 2020 年， Exact Sciences 还以4.1亿美元收购了另外一家从高校走出的癌症检测公司 Base Genomics，其核心DNA甲基化检测技术 TAPS 由牛津大学 ludwig 癌症研究中心的华人科学家 Chunxiao Song 团队开发。Base Genomics + Thrive 也就构成了Exact Sciences如今的MCED。 如果再多说一句，我博士实验室的一位大牛师姐此时正在Song lab做博士后，继续优化开发基于TAPS的扩展方法。是的，世界就是这么小。 和早筛产品技术无关的一点评论 GRAIL 和 Thrive 两家公司，如今前者被illumina收购保持独立运营，后者被 Exact Sciences 收购。其实肿瘤NGS领域的另一家头部公司 Foundation Medicine 也早在2018被Roche完全收购并成为其独立子公司。 在肿瘤NGS检测这个领域，国外最近两年的不少公司的结局就是：小公司被大公司收购，大公司被药企巨头收购，下游厂商被上游供应商收购。 国内这些同类型公司未来两三年是否会出现比较大的格局变动，也值得持续关注。 另外，上文提到的 Steven J. Kafka 也是个神奇的公司领导人。 他在Foundation Medicine 担任五年COO之后，FMI 被 Roche 收购，随后在ArcherDX担任了2年执行主席之后这家公司被Invitae收购，紧接着加入的Thrive在他当了两年多执行主席之后又被 Exact Sciences 收购。嗯，易被收购体质。 关于 FDA Breakthrough Device Designation 以上，我们大致了解了 FDA BDD 认证的前两家泛癌种早筛公司，另一个还没有解决的小好奇就是 FDA Breakthrough Device Designation 究竟是什么？ 作为 Expedited Access Pathway (EAP) 项目的一部分，FDA于2016年建立了 Breakthrough Devices Program 突破性设备计划。 如果想要申请 FDA BDD，需要满足一个必要条件和另一个四选一的补充条件。 必须要满足的一个条件是：该设备可以为威胁患者生命或不可逆转影响患者健康的疾病提供更有效的治疗或诊断。 必须要满足的补充条件（至少四选一）包括： 代表着突破性技术 没有已获批准或通过的替代品存在 与现有已获批准或通过的替代品相比具有明显的优势 设备的可用性符合患者最佳利益 如果你认为自己的产品符合上述1+1条件，就可以在递交 Marketing Submission 之前的任意时间递交 Breakthrough Designation 申请。所谓的 Marketing Submission 包括为了在美国上市递交的 premarket approval (PMA), premarket notification (510(k)) 和 De Novo classification request。 如果你的产品通过了FDA BDD的认证，目前看来其最主要的优势是在后续申请 510k 和 De Novo submissions 时会比非BDD认证设备的优先级更高，且时间也会略短一些。此外，如果一个医疗设备通过了该认证，也可能在美国医疗保险报销中获得一定优势。然后，也就没有其它更直接的优势了。 目前获得了FDA BDD认证的设备有多少呢？ 根据FDA官方数据，截至2022年9月30日，FDA 的 CDRH 和 CBER 已经批准了 728 个突破性设备认证。 不过需要特别注意的是，在上市授权之前 FDA 通常不会公开披露是否有厂商提交了设备突破性认定请求或 FDA 是否批准/拒绝了该请求，除非厂商决定主动向公众提供这些信息。 此外，FDA BDD 认证似乎和最后能否获得市场授权之间，也并没有体现出特别直接的关系。 过去在这 728 个突破性认定设备中，目前也仅有56个真正获得了market authorization。在其中包括FMI的 Foundation CDx、Foundation liquid CDx；Guardant 的 Guardant360 CDx。 所以获得 FDA BDD 认证确实是有意义的一步，不过更多的是有意义的起步。 如果你对本期话题有更多想分享和讨论的内容，不妨直接给我回复邮件。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-01-08-fda-bdd-multi-cancer-early-detection/"},{"title":"2022的混乱和坚持 2023的困难和勇敢","content":" 本文为熊言熊语邮件通讯内容，第一时间接收邮件可以通过通讯主页订阅并查看。 写在前面 你好，我是思考问题的熊，展信佳。你现在阅读的是熊言熊语邮件通讯常规更新内容，阅读愉快。 在2023年元旦假期最后一天，很高兴能够再次通过邮件和你交流。 2022的混乱和坚持 如果让我用一个词形容2022，我首先想到的是「混乱」。 整个12月感觉自己都是生活在新冠的笼罩中，前面半个月宣布放开之后担心自己会快速中招，后面半个月阳了之后就处于发烧头疼咳嗽和缓慢的恢复中。 12月的情景似乎又是整个2022年的缩影。2022年上半年春节后没多久，上海经历了长时间的静默，在3个多月的时间里，不得不面朝阳台关心粮食和蔬菜。解封之后，虽然天气逐渐转暖，但很多行业依旧在冰冷的寒冬里，人们不得不继续关心自己的生计。 面对外部的混乱，你我能做的就是做好自我的坚持。 我相信思考和输出对于我的重要性。2021年小结里，我立下了2022年完成30篇文章写作的flag，面对外部的混乱，我强迫自己还是要留下些什么。 翻了翻博客和公众号，算上你目前在读的这篇通讯，刚刚够上了30篇这个数量。 没什么流量的个人主页，过去一年也迎来了1.4万个朋友的光临，按照平均互动时长77秒和每天8小时工作时长统计，2022年的我似乎又在物理时间之外多出了37天。很可能这37天时间里也有你的一点时间，感谢2022年你来过。 单纯从公众号的阅读数据来看，比较受欢迎的5篇文章分别是： 别再用DEseq2和edgeR进行大样本差异表达基因分析了 染色体不稳定性，凭什么2022年还能用TCGA数据发Nature 同样做肿瘤NGS检测，美股上市的这9家公司近况如何 Nature Reviews Cancer 发文：未来10年肿瘤精准治疗的6个未解之谜 跨越60年的癌症靶向治疗里程碑 通过这些内容，不少和我有专业交集的朋友知道了「熊言熊语」和这只思考问题的熊，其中有正在读研读博的学生，也有工作了几年的同行。我陆续收到了一些小伙伴关于专业相关内容的写作建议和持续写作的鼓励。 基于此，在2022年12月初，我决定恢复熊言熊语邮件通讯 并推出了专业相关的会员内容计划，12月期间，会员计划更新了三篇长文。其中有我关于行业新人如何构建知识体系的思考；也有通过OncoKB新增biomarker和FDA药物审批的视角回顾2022年的肿瘤精准治疗进展；还有靶向治疗耐药机制的详细总结。 正式向你汇报一下，目前有超过70位朋友加入了会员计划，其中有不少是认识很久的老朋友，也有些是刚刚认识的新朋友。 这种信任和契约，是我持续交付内容的动力。如果你也对肿瘤生物医药领域的研究进展行业动态感兴趣，欢迎加入。 这70多位朋友，让我在混乱的2022年尾巴明白了一个道理。 你相信什么，就继续坚持什么。因为总有人也同样相信着你的相信，坚持着你的坚持。你要做的，就是找到他们。 2023的困难和勇敢 在2022年底，不少公司又经历了一轮悄咪咪的组织架构人员优化和产品线瘦身，国内外都是一样。比如Oncocyte这家公司优化了40%的员工，同时卖掉了自己的DetermaRx Test产品，再比如，Invitae 卖掉了在家的Archer NGS assays。 今天去常去的理发店剪发，在歇业半个月重新开门之后，我发现他们的理发价格从29涨到了38。 不需要理解太复杂的周期和宏观背景，仅仅是看看身边的小店，2023或许依旧还是非常艰难的一年（虽然你我都希望2023年能好一点）。 面对这种困难，对于个体而言，我想法你我需要再多一点勇敢。 一种敢于面对自己内核的勇敢，看到自己的不足，更要看到自己的价值；一种敢于认清现实的勇敢，在不景气的环境下，努力看清自己所在领域和行业的前景。然后再回到前面说的，想想自己相信什么就去坚持什么。 2023年，我计划今年自己能完成70篇内容的写作，其中40篇内容是来自熊言熊语会员计划的专业相关内容交付，30篇是面向所有读者的内容分享。 可以预见，这样的整理和写作量需要占据我每天8小时工作时长以外大量的时间，不过因为对于专业的喜欢和对于行业的好奇心，自己反而充满了期待。 2023年，我计划组织10场交流活动，希望其中有5场是线下的形式。疫情三年，我无比怀念曾经围在一起面对面的聊天。 总之，我希望在2023年，依旧可以把自己关注和想到的，用更丰富的形式和更方便的方式，传递给你。 祝你2023年身体硬朗，生活结实，有面对混乱的坚持和面对困难的勇气。 2023年就这么来了，那我们就一起继续。 ","link":"https://kaopubear.top/blog/2023-01-04-my2022/"},{"title":"从靶向治疗耐药机制到联合用药策略（上篇）","content":" 本文为熊言熊语邮件通讯会员计划内容的试读版，完整内容请点击通讯主页订阅并查看。 写在前面 你好，我是思考问题的熊，本内容是参加会员计划读者的专属内容，感谢你通过会员计划支持我持续创作。展信佳～ 在2022年的最后一个工作日晚，提前祝你新年快乐。2023，我们继续一起前行。 本期内容： 在癌症治疗领域，一个又一个振奋人心的新药被开发出来，尽管这是巨大的进步，但它也带来一个新的难题：如何更好地结合许多新的药物以获得持久疗效。 2006年至2020年间，美国食品和药物管理局（FDA）共批准了72种不同的靶向药物，用于18种癌症的36种基因组适应症。这些药物的批准让符合基因组靶向治疗的患者数量逐渐增加，一项基于美国患者的研究显示从2006年的5%增加到2020年的13.6%。 尽管很多靶向治疗药物最初可能非常有效，但单药治疗的耐药仍然是一个重大挑战。耐药研究是肿瘤NGS领域一个非常重要的研究主题，这其中包括各类靶向治疗耐药和免疫治疗耐药。 本期内容我们将围绕靶向治疗的耐药机制这一话题进行了解，主要包括如下四部分内容 靶向治疗核心原理 靶向药物的原发性耐药机制 靶向药物的获得性耐药机制 肿瘤内异质性对耐药的影响 下期预告： 面对耐药，联合用药有时有助于克服耐药性，但药物组合的数量远远超过了可以进行临床试验的数量，此外还需要综合考虑患者承受的经济负担以及毒副作用等等。 因此，我们需要基于对耐药性相关潜在分子机制的深入了解，来确定潜在有效的药物组合抗耐药性。下期内容我们将会从本期的耐药机制出发，一起了解联合治疗策略和相关最新的研究进展。 以下为本期内容正文，7000字。 靶向治疗核心原理 如我曾经在跨越60年的癌症靶向治疗里程碑这篇文章里提到的，过去二十年里，对癌症基础的研究使得我们拥有了大量的新型癌症靶向药物。 自从伊马替尼成功开发，用于治疗BCR-ABL驱动的慢性骨髓系白血病以来，「一个基因异常对应一种药物」就被认为是一种新的药物开发范式。 这一概念加速了一系列癌症靶向治疗的发现。不过，伊马替尼的成功在一定程度上误导了药物研发，因为这些患者在使用伊马替尼单药治疗时可以出现长时间的响应，但是多数其它靶向药物对单药治疗的反应却不持久。 2006年至2020年间，美国食品和药物管理局（FDA）共批准了72种不同的靶向药物，用于18种癌症的36种基因组适应症。这些药物的批准让符合基因组靶向治疗的患者数量逐渐增加，一项基于美国患者的研究显示从2006年的5%增加到2020年的13.6%。 在了解肿瘤相关的基因时，早期我们通常会把基因分为oncogene和tumor suppressor gene(TSG)。在提到多数靶向治疗时，我们多数关注的其实是oncogene发生gain-of-function的这种获得功能的显性突变，这类基因通常功能与细胞的增殖、生长与分化相关，其突变可以造成基因过度活跃，因而在癌症中抑制这些基因就可以限制癌症。 而TSG常见的突变是loss-of-function，这些突变造成的蛋白功能丧失在早期的研究中认为没有办法用来指导治疗决策和直接用药，但是合成致死（synthetic lethality）这一机制的提出改变了TSG LOF 无用的观点。 所谓合成致死，就是A和B两个基因任何一个突变都可以被容忍，但是如果AB两个基因同时突变就会导致细胞死亡。原则上，当两个突变对一个基础的生物学通路产生相加的负影响，或者当两个突变使两个不同但功能重叠的通路失活时，就可能导致合成致死。 在癌症治疗中，如果一个不可药用的TSG的LOF可以诱发对第二个基因的依赖，那么这个基因本身就是一个很好的药物靶点，能使TSG的LOF可以间接药用。针对一种对癌症相关突变具有合成致死的基因，应该只杀死癌细胞，而不会杀死正常细胞。因此，合成致死为开发癌症特异性药物就提供了一个新的概念性框架。 关于合成致死在肿瘤治疗领域目前最成功的应用就是BRCA突变的癌症对PARP抑制剂具有选择敏感性。BRCA突变会使肿瘤细胞同源重组介导的DNA修复存在缺陷（双链修复），因此它们高度依赖PARP介导的碱基切除修复（单链修复），如果针对BRCA突变的癌症使用PARP抑制剂，既可以组织DNA修复。如果负责双链断裂修复的BRCA突变失活，再把单链断裂修复的PARP抑制，癌细胞的DNA修复系统就会被破坏进而死亡。到目前为止，PARP抑制剂已被批准用于与BRCA1/2基因突变有关的卵巢癌、乳腺癌、前列腺癌和胰腺癌的临床使用。 不管是以上哪种机制或者是那种靶向药物，尽管它们最初可能非常有效，但单药治疗的耐药性仍然是一个重大挑战。 面对耐药，联合用药有时有助于克服耐药性，但药物组合的数量远远超过了可以进行临床试验的数量，此外还需要综合考虑患者承受的经济负担以及毒副作用等等。 因此，我们需要基于对耐药性相关潜在分子机制的深入了解，来确定潜在有效的药物组合来对抗耐药性。 靶向药物的原发性耐药 通过上文关于靶向治疗药物的核心原理我们知道「对激活的原癌基因抑制可以产生治疗响应」。这个逻辑在大多数时候都没有问题，但在一些情况下会有意外发生。 维莫非尼 vemurafenib 是第一种被批准用于BRAF突变癌症的药物，其在BRAF突变的黑色素瘤中显示出了很不错的临床效果。但是在结直肠癌的一项临床实验中，21名接受治疗的患者中只有1名患者确认为部分缓解(PR)，中位无进展生存期为2.1个月。 第二个意想不到的临床发现是，阻断KRAS蛋白下游的MEK激酶，对KRAS突变癌症的治疗无效。2017年发表在JAMA的一项研究显示，含有KRAS突变的NSCLC患者，MEK抑制剂Selumetinib 联合多西他赛相比于多西他赛加安慰剂，在PFS和OS上，都没有显示出更优的效果。 对于这类患者在一开始就对治疗没有反应的情况，将其称之为原发性耐药（intrinsic resistance）。 不同癌种不同药物的临床研究发现，这类原发性耐药的另外一类情况是，有时A基因的突变会导致针对B基因突变的药物无效。 比如EGFR单克隆抗体西妥昔单抗可以用于治疗晚期结直肠癌。西妥昔单抗2004年就首次被批准用于临床治疗。但是这类EGFR抗体并非对于所有CRC患者都有效。 KRAS是EGFR下游信号的一个重要组成部分，约30-40%的CRC会发生该基因的激活突变。当西妥昔单抗阻断EGFR信号时，突变的KRAS蛋白还可以维持EGFR下游的信号传递，所以人们预计KRAS突变的结直肠癌对西妥昔单抗不起作用。 基于下游信号的突变激活与作用于同一信号级联上游的药物呈现原发耐药这一个观点，人们发现KRAS野生型，但是BRAF和NRAS突变型CRC患者对EGFR抗体的反应也非常差。 类似的，曲妥珠单抗被批准用于治疗HER2阳性的乳腺癌患者中，但是当这些患者存在PIK3CA突变时，其对曲妥珠单抗的反应就会更差。 基于以上几个事例，为了理解内在耐药性的机制，重要的是要认识到正常的细胞平衡在很大程度上取决于信号通路之间和内部的相互影响和反馈调节。比如为了维持平衡状态，对一条信号通路的抑制往往会导致第二条通路（或同一条通路）的补偿性增强。这种缓冲作用确保了生物系统的稳健性，但在癌症治疗中就变成了一个重大挑战。 靶向药物的获得性耐药 除了以上介绍的原发性耐药，在靶向治疗中，另一种更加常见的耐药机制被称作获得性耐药（acquired resistance）：指患者起初对于某种靶向药物具有明显反应，但是这种反应在治疗期间逐渐减少。 这样的例子很多，比如即便在KRAS野生型的CRC患者中使用西妥昔单抗，往往也会在治疗后几个月内发生获得性耐药。而获得性耐药机制的分析，最容易通过对同一患者耐药前后进行组织/液体活检进行比较研究，看看患者在这个过程中增加了哪些之前没有的基因突变。 获得性耐药的机制研究目前主要发现有两大类，分别是通过突变产生的遗传性耐药和由癌基因表达变化产生的非遗传性耐药。 获得性耐药的遗传机制 通过突变产生的遗传性耐药，又可以宽泛地分为靶点依赖性 on-target 和非靶点依赖性 off-target 两类。 其中on-target可以理解为因为靶向激酶自身的突变，即便使用TKI也会出现持续的信号传导过程；off-target可以理解为靶向基因下游信号蛋白能够激活一个或多个旁路信号通路或者发生表型的转换。 🍺🍺试读结束🍺🍺 剩余内容是参加会员计划读者的专属内容 欢迎你通过会员计划支持我持续创作 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-12-31-mechanisms-of-resistance/"},{"title":"和头部肿瘤早筛公司 GRAIL CEO 学写年终工作总结","content":"到了年底每一位打工人都少不了做工作年终总结，即便是一家公司的CEO也不例外。 前几天，或许是目前最有潜力（成功）的肿瘤早筛公司 GRAIL CEO Bob Ragusa 发表了自己的2022年终工作总结。他在2021年10月接任 GRAIL 的CEO之前在 illumina 担任了近 8 年COO，拥有30多年的基因组行业从业经验。 国内几乎所有涉及到多癌种早筛产品的公司，无一例外都会密切关注 GRAIL 的进展动态。而作为打工人的我们，接下来不妨围观一下他家CEO的年度总结，没准能给自己一些启发。 这份年终总结共有五部分内容。 Galleri is gaining commercial traction We continue to be a leader in scientific and clinical research We are focused on MCED access We see promise in precision medicine We are building a strong culture and team 开头概括性的先介绍了GRAIL这家公司的使命（早期肿瘤检测），核心业务（multi-cancer early detection MCED）和产品（Galleri）。值得一提的是，在 TIME 杂志评选出的2022 The Best Inventions 中 Galleri 入选了医疗板块获奖名单。 第一部分和第二部分分别从商业成绩和科学与临床研究两个维度总结了过去一年GRAIL的成绩。 作为一家商业公司，商业能力自然是所有股东和投资人最最关注的部分。因此第一部分，Bob Ragusa 就直接介绍过去一年GRAIL的商业成绩。 2021年推出的MCED产品Galleri是第一个可用于检测50多种癌症的信号特征的临床检测产品，这些信号可进行组织溯源以帮助临床医生进行诊断评估。 迄今为止，GRAIL已经收到了6万多份Galleri订单，与各类型医疗系统和保险公司等建立了60项商业合作。过去两年，Galleri的结果报告涵盖了I期的胰腺癌、头颈癌、子宫内膜癌、食管癌和胃肠道间质瘤以及II期直肠癌、肝癌和头颈癌。 作为一家科学研究和临床试验驱动的公司，科研文章发表往往体现出这家公司的学术品牌。在第二部分中，Bob Ragusa 提到2022年他们在发表了20多篇论文和各类大会上的45篇摘要。 2022年，其前瞻性随机对照 NHS-Galleri 和前瞻性临床研究 PATHFINDER 2 中共招募了超过12万名新的参与者。在10个多月的时间里，NHS-Galleri试验就完成了超过14万名参与者注册。这种财力，真是让人羡慕。 下图为NHS-Galleri的实验设计方案。 在2022年ESMO大会，GRAIL也展示了PATHFINDER的研究结果，在确认 True Positive 的癌症中，71%的癌症类型没有常规筛查方法，近一半的非复发性癌症的发现处于早期阶段（I期或II期）。 下图为PATHFINDER的实验设计方案。 True Positive的检测结果癌种信息分布。 MCED 第一代的检测性能。 在第三部分，Bob Ragusa 重申了 GRAIL 将专注于通过寻求创新的合作伙伴关系来扩大MCED的可及性。例如其与Ochsner Health、美国退伍军人健康管理局(美国最大的综合医疗保健系统)和退伍军人健康基金会的合作。 前三部分介绍公司过去一年的商业和学术成绩以及关注重心，第四部分则关注未来趋势。通过总结公司的药企合作项目来介绍精准医疗前景。 2022年GRAIL通过与六家领先公司合作的项目，扩大了以研究为重点的伙伴关系，同时与2021年相比实现了收入大幅增长。此外，其还透露「仅限研究使用」技术平台将在2023年初提供给生物制药合作伙伴。 这里特别提到了他们与阿斯利康的战略合作和伴随诊断合作。这一合作证明了GRAIL的专利甲基化技术在癌症早筛以外的应用价值，如预后、早期疾病复发监测和MRD等等。他们与阿斯利康的合作在2022年Scrip大奖上还获得了年度最佳合作伙伴奖。 在最后第五部分，介绍完成绩和之后回归到团队，讲了过去一年自己带领的队伍发展。 不同于多数肿瘤NGS和biotech的降本增效，因为背后有illumina撑腰，GRAIL扩充了包括商业、医疗和运营在内的多个部门后，与2021年相比其员工人数增加了一倍多，发展到1300多人（emm，似乎也没有很多人）。 以及，我们自己写年终总结汇报时或许可以包括如下几部分内容。 你的工作为公司带来了哪些收益：哪些可以体现在直接的营收和销量业绩上，哪些又可以体现在其它诸如学术和效率等方面。 过去一年，你的工作重心是什么，在这方面取得了什么成绩。 过去一年，你看到了明年哪些可以继续深耕的方向和前景。 除了工作本身以外，你队伍带的如何或者有没有为企业文化贡献自己的力量 你和GRAIL CEO 学废了么？ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-12-27-grail-2022-look-back/"},{"title":"2022年肿瘤精准治疗进展回顾 看OncoKB和FDA审批就够了","content":" 本文为熊言熊语邮件通讯会员计划内容的试读版，完整内容请点击通讯主页订阅并查看。 写在前面 你好，我是思考问题的熊，本内容是参加会员计划读者的专属内容，感谢你通过会员计划支持我持续创作。展信佳～ 本期内容： 我们将依托于两篇12月发表在Cancer Discovery的文献，通过OncoKB新增biomarker和FDA药物审批的视角，一起回顾2022年的肿瘤精准治疗进展。 下期预告： 如我曾经在这篇文章所总结的，过去二十年的癌症研究使我们有了大量新型靶向药物。尽管这些药物最初可能非常有效，但单药治疗的耐药性仍然是一个重大挑战。 面对耐药，联合用药有时有助于克服耐药性，不过药物组合的数量已经远远超过了可以进行临床试验的程度，此外还需要综合考虑患者承受的经济负担以及毒副作用等等。因此，我们需要基于对耐药相关分子机制进行了解以确定潜在有效的药物组合。相关内容，下期会员计划与你一起学习。 好了，本期内容正式开始。 文献信息 Rosen, Ezra, Alexander Drilon, and Debyani Chakravarty. 2022. “Precision Oncology: 2022 in Review.” Cancer Discovery 12 (12): 2747–53. https://doi.org/10.1158/2159-8290.CD-22-1154. Duke, Elizabeth S., Michael J. Fusco, Patrick DeMoss, Asma Dilawari, Gulsum E. Pamuk, Jessica Boehmer, Bronwyn Mixter, Kirsten B. Goldberg, Paul Kluetz, and Richard Pazdur. 2022. “Highlights of FDA Oncology Approvals in 2022: Tissue-Agnostic Indications, Dosage Optimization, and Diversity in Drug Development.” Cancer Discovery 12 (12): 2739–46. https://doi.org/10.1158/2159-8290.CD-22-1185. 关于作者 Precision Oncology: 2022 in Review 的三位作者来自 MSKCC，其中通讯作者 Debyani Chakravarty 作为分子遗传学家和很多医生有过合作，在MSKCC参与了非常多「landscape」类型文章发表，比如： Oncogenic signaling pathways in the cancer genome atlas The immune landscape of cancer Mutational landscape of metastatic cancer revealed from prospective clinical sequencing of 10,000 patients Pathogenic germline variants in 10,389 adult cancers 如果你对这类文章感兴趣，可以去搜搜她署名的文章。 关于这类文章，前几天刚刚写过过一篇 Foundation Medicine 42万例样本库分析KRAS泛癌种突变特征得出了这些结论，后续也会有对应专题我们一起学习。 Highlights of FDA Oncology Approvals in 2022 这篇文章的通讯作者 Elizabeth Duke，毕业于哈佛医学院，2020年8月加入FDA 肿瘤疾病办公室(Office of Oncologic Diseases， OOD)参与实体瘤和血液瘤相关药物和生物治疗方法开发的监督、批准和监管工作。 关于 OncoKb 突变评级 Precision Oncology: 2022 in Review 这篇文章出自MSKCC团队之手，选择的切入角度就是基于自家的OncoKB 2022年10月28日 前更新的突变评级内容来进行汇总。 在OncoKB中，对于突变的注释评级分为四个等级： Level 1：与FDA批准的标准治疗药物相关。FDA-recognized biomarker predictive of response to an FDA-approved drug in this indication Level 2：与NCCN或者其它专家共识推荐的标准治疗相关。Standard care biomarker recommended by the NCCN or other expert panels predictive of response to an FDA-approved drug in this indication Level 3：在III期或引人注目的I/II期中被认为是预测临床获益的癌种相关特异性突变。Compelling clinical evidence supports the biomarker as being predictive of response to a drug in this indication but neither biomarker and drug are standard of care Level 4：在临床试验前的模型中被验证可以预测靶向治疗反应的生物标志物。Compelling biological evidence supports the biomarker as being predictive of response to a drug but neither biomarker and drug are standard of care 简单说就是1类为FDA认可的获批药物的biomarker（EGFR L858R 的NSCLC使用奥希替尼），2类是指南推荐的标准治疗biomarker（MET 扩增的NSCLC使用克唑替尼），3类是临床证据级别的biomarker（Adagrasib应用于肠癌KRAS G12C突变患者），4类为生物学证据支持的biomarker（ARID1A Truncating Mutations 实体瘤使用EZH2抑制剂Tazemetostat） 截至到2022年10月28日的OncoKB数据显示，FDA批准了6种特异性生物标志物选择的适应症治疗方法，NCCN指南2022年增加了9种生物标志物特定适应症治疗方法。接下来我们从药物设计、实验研究设计和新的生物标志物三个维度进行归纳总结。 药物设计 KRAS G12C 和 TP53 Y220C 改变了可成药性靶点的定义。 2022年 KRAS G12C 相关的两项重要研究 CodeBreaK100 和 KRYSTAL-1 实验结果公布，前者研究证实 Sotorasib 在胰腺癌中的ORR 为 21.1%，后者研究证实Adagrasib在胃肠道癌中的ORR为41%。KRAS G12C 因此在OncoKB中也获得了对应癌种的新增 level3 评级。 除了最火热的突变G12C以外，我们还应该在未来几年关注其它诸如G12A/D/R等可以靶向针对多个激活RAS突变的pan-RAS抑制剂（比如RMC-6236）。 TP53是癌症中最常见的突变基因，直到最近突变型p53一直都被认为是无法用药治疗的。作为一种肿瘤抑制因子和转录因子，P53参与DNA修复和细胞凋亡相关的调控。其DNA结合域中的杂合突变产生的突变蛋白不能作为转录因子发挥作用。突变型P53可以结合并阻断野生型P53的活性。罕见的TP53 Y220C突变可以导致起DNA结合域的稳定性降低，降低突变蛋白转录活性。 如在2022年ASCO年会上公布的那样，携带TP53 Y220C突变的实体瘤患者在篮子试验中接受了靶向药物PC14586治疗，在33名可评估的患者中有6位确认的PR。 新一代的小分子抑制剂仍旧在持续迭代。 2022年，仍旧有一些新的TKI出现，持续解决各种各样的耐药、穿透血脑屏障以及增加耐受性等问题。 🍺🍺试读结束🍺🍺 剩余内容是参加会员计划读者的专属内容 欢迎你通过会员计划支持我持续创作 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-12-17-newsletter-pro-2022-precision-oncology/"},{"title":"Foundation Medicine 42万例样本库分析KRAS泛癌种突变特征得出了这些结论","content":"KRAS和HRAS以及NRAS都属于RAS家族，这些基因一旦发生突变便可以启动或促进肿瘤生长。尽管KRAS是很多肿瘤中常见的突变致癌基因，但是KRAS基因所编码的蛋白像一个表面光滑的圆球，很难找到能可以抓住它的小分子化合物。过去几十年的时间里，一直认为其「不可成药」。 不过，药物设计方法的改进使科学家开发出了对突变KRAS具有选择性的抑制剂。其中一些抑制剂已被证明对KRAS G12C突变癌症患者有效，Sotorasib和Adagrasib分别获得了FDA的突破性认证，用于治疗携带KRAS G12C突变的晚期或转移性非小细胞肺癌（NSCLC）。 2022年 KRAS G12C 相关的两项重要研究 CodeBreaK100 和 KRYSTAL-1 实验结果公布，前者研究证实 Sotorasib 在胰腺癌中的ORR 为 21.1%，后者研究证实Adagrasib在胃肠道癌中的ORR为41%。KRAS G12C 因此在OncoKB中也获得了对应癌种的新增 level3 评级。 更有趣的是随着KRAS成为热点，2022年尾声，11月和12月分别发表了两篇几万人的大队列回顾性分析，从 Genomic Landscapes的视角来描述 RAS 突变的人群特征。 **如果有一个几十万人的样本数据库，可以做点什么呢？**今天的推文，先来一起看看12月发表在 npj Precision Oncology 的文章。 主要数据和分析内容 文章数据来自Foundation Medicine（下文简称FMI），作者则多数来自FMI和Genentech这两家公司。 在这项研究中，作者进行了一项全面的泛癌基因组分析，确定了24种癌症类型中KRAS突变的发生率，包括G12C和KRAS以外突变的分布。 通过与TMB、PD-L1表达、互斥伴发和mutation signature等相关分析，评估了不同KRAS突变相关的基因组特征。 此外通过 FMI 临床基因组数据库(CGDB)中收集到的临床生存信息，还评估了非小细胞肺癌(NSCLC)、结直肠癌(CRC)和胰腺癌(PDAC)队列中不同 KRAS 突变亚型的预后影响。 随着特定的 KRAS 抑制剂和联合治疗策略的陆续展开，了解共突变和其他可能调节靶向或免疫治疗相关的生物标志物的相关分析是很有必要的。这也是这类描述性研究的临床价值。 核心结论 首先看看不同癌种种KRAS的患病率 2013年12月至2021年12月期间，FMI共检测了成年癌症患者的组织或血液样本426,706份（不知道国内的肿瘤NGS同行们对这个数字作何感想）。 KRAS是最常改变的癌基因，在97062个（23%）泛肿瘤组织样本中发现了突变，其中绝大多数（88%）是short variant mutation，8.4%是扩增，3.8%是突变和扩增伴发。 根据这一患病（prevalence）数据估算发病率（incidence）。在美国，KRAS突变在CRC中最高预计有75,000例，其次是PDAC和非鳞状NSCLC。KRAS扩增在大多数肿瘤类型中是罕见的，但在生殖细胞肿瘤（24%）和食管腺癌（18%）中很常见。 KRAS G12D（29%）、G12V（23%）、G12C（15%）、G13D（7%）和G12R（5%）是五个最常见的KRAS突变，共占所有KRAS突变约80%。 KRAS突变（KRASm）发生率最高的肿瘤类型是PDAC（92%）、阑尾腺癌（61%）、小肠腺癌（SBA，53%）、CRC（49%）和非鳞NSCLC（35%）；CRC、非鳞NSCLC和PDAC共占KRASm泛肿瘤人群的71%。 尽管KRASm在成人肿瘤类型中的分布有所不同，但在来自相似组织类型的肿瘤中也观察到了相似的KRASm模式。 KRAS G12C是NSCLC中最常见的变异(Non-Sq和Sq占比分别为40%和36%)。 胃肠道肿瘤(包括结直肠癌以及食管癌、胃癌、小肠和阑尾癌)也有相似特征，KRAS G12D和G12V是最常见的两种变异。 KRAS G12D 在许多其他肿瘤类型中也是最常见的，包括PDAC(43%)和子宫内膜(30%)，KRAS G12V在大多数研究的肿瘤类型中第二常见，在乳腺癌则最常见(26%)。 在了解了发生率之后。KRAS在共突变，mutation signature 和免疫治疗生物标志物会有怎样的特征呢？我们逐一来看该研究中的分析结果。 在四种主要的 KRAS 突变肿瘤类型中，与 KRAS 伴发互斥的火山图如下所示。值得注意的一点是，在非鳞NSCLC、结直肠癌和子宫内膜癌中，TP53基因是最常见的与KRAS互斥的突变基因，而在PDAC中，TP53基因突变往往与KRAS伴发。 KRAS 作为一个关键的驱动基因，其突变确实与 RTK/MAPK 通路中的其他驱动基因（ EGFR，ALK，MET，ERBB2，BRAF，RET 和 ROS1）突变高度互斥。 在非鳞 NSCLC 中，KRAS G12C 突变肿瘤富集了高 TMB 和高 PD-L1表达，而 KRAS G12D 突变肿瘤相对于其他 KRASm 同种型具有较低的 TMB 高发生率。 相对于非 Sq NSCLC，KRASm 的 CRC，PDAC 和子宫内膜中高 PD-L1表达阳性样品的比例较低，然而子宫内膜与 NSCLC 相似，21-34% 的 TMB ≥10。 在子宫内膜癌中，与 G12V 和 WT 相比，KRAS G13D，G12D，G12C 和 G12A富集高 TMB。 此外，分析了四个主要癌种不同突变亚型对应的mutation signature。烟草相关的特征在不同的KRASm和KRAS WT亚群的非鳞NSCLC中检测到38-45%，但在G12R非Sq NSCLC中较少（22%），在其他肿瘤亚型中很少。错配修复（MMR）特征在非Sq NSCLC中很少见，但在KRASm和KRAS WT PDAC、CRC和子宫内膜癌中很常见，但相对于其他亚组，在KRAS G12C CRC中出现的频率较低。在PDAC、CRC和子宫内膜的小亚群中检测到POLE特征。 最后，再来看看，临床生存和KRAS突变之间的关联。 在肺癌中，KRAS G12C突变的患者与其他常见KRAS突变的患者有相似的总生存率（OS），包括G12V（11 vs. 10 mos，HR 1.0，95% CI 0.86-1.20，p = 0. 88）和G12D（11 vs. 12 mos，HR 0.91，95% CI 0.75-1.11，p = 0.36），与较罕见的非G12/13 KRASm（11 vs. 9 mos，HR 1.1，95% CI 0.82-1.35，p = 0.67）的OS也类似。而没有KRAS突变但表现出其他致癌驱动基因的NSCLC患者，其OS明显优于携带KRAS G12C突变的NSCLC患者。单因素和多因素分析的结果类似。 在CRC中，KRAS G12C突变的患者与其他常见的KRAS突变患者的OS相似，包括G12D和G12V。与BRAF V600E患者和非G12/13突变患者相比，KRAS G12C突变患者的OS略有升高，但无统计学意义。KRAS/NRAS/BRAF V600E阴性(RAS/RAF阴性)患者的OS比KRAS G12C亚组更有利(24vs.19mos，HR0.74，95%CI0.59-0.93，p=0.009)，该结果在多变量模型中也是一致的 在93%的转移性PDAC患者中发现了KRASm，其中94%发生在密码子G12/G13内。具有KRAS G12C突变的肿瘤患者的OS显著低于KRAS阴性肿瘤患者(5.9 vs 8.8 mos，HR 0.59，95%CI 0.37~0.94，p=0.03)，与非G12/13 KRASm肿瘤患者相似(5.9 vs 6.9 mos，HR 0.80，95%CI 0.50~1.29，p=0.36)。然而，在多变量模型中，与KRAS阴性肿瘤患者相比，KRAS G12C突变肿瘤患者的OS没有明显恶化，尽管这可能受到KRAS阴性病例数量较少的限制 尽管有这些局限性，这项研究的发现对针对G12C、G12D、G12V和更高水平的KRAS抑制剂的开发具有重要意义。检测共改变和突变特征的基因组图谱，以及了解这些生物标志物作为靶向治疗和免疫治疗反应预测因子的临床重要性的试验，将是改善治疗选择和结果的当务之急。 多说几句 这篇文章的方法部分很时候相关行业的从业者了解一下FMI不同产品能用来做什么，以及大致是怎么做出来的。很多分析的细节是值得仔细琢磨和理解的～ 作为国际肿瘤NGS检测的绝对头部公司，FMI自己的数据样本库里累计了大量的样本。只要某个基因对应药物的临床结果有了突破性进展，或者在肿瘤相关研究中有了重要的功能性研究结果，他们就可以快速的在几十万的样本库中进行大规模分析。 类似的研究在这篇文章考虑到篇幅就不一一列举了，感兴趣的话你不放搜搜看，后续会在熊言熊语邮件通讯的会员计划中带来整合性主题介绍。欢迎扫描下方二维码免费订阅，第一时间接收内容更新。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-12-16-fmi-kars-pancancer-landscape/"},{"title":"从2002年的Nature论文到2022年的亿元营收 ","content":" 读文献的乐趣通常在于文献之外。通过文献里的线索和场外信息把看起来无关的内容联系在一起。如果赶巧又解答了头脑里萦绕很久的问题，那便是难得的「Paper Aha Moment」。 枯燥的文献读起来能有什么乐趣，我的感受是这种乐趣往往来自于文献之外，一种好奇心的满足和头脑中零碎信息关联后带来的愉悦。 正如在之前这篇文章里所写，总结自己的肿瘤NGS相关内容学习方法时我提到了四部分内容。 通过临床指南了解肿瘤各个癌种 基于主题的文献整合解读 国内外肿瘤精准治疗头部公司/产品梳理 国内外肿瘤精准治疗知名机构/医院梳理 最近在准备熊言熊语的会员计划内容时，发现有一个特别有趣的例子可以与你分享。除了能说明上面这些内容如何关联外，或许也能解释为什么读文献的乐趣通常在于文献之外。 起因 事情的起因是我前几天梳理 nature reviews drug discovery 最新综述时，打算做一点作者信息补充。 这篇的文章的题目是Rational combinations of targeted cancer therapies: background, advances and challenges，如果你感兴趣也可以找来读读看。 文章作者是上海交通大学的金浩杰教授，公开资料显示他2017年到2021年曾在荷兰国家癌症研究所访学并开展合作研究；而本文的通讯作者René Bernards则刚好是荷兰国家癌症研究所的教授（同时也是上海交通大学顾问教授）。 Bernards 的研究成果非常丰富，比如第一个抑癌基因Rb的共同发现者，曾开发用于动物细胞基因沉默的shRNA载体，并通过该技术发现了多个重要肿瘤耐药分子机制和潜在联合治疗策略，想必这也是为什么会有上文我提到的那篇review的原因。 照理说，找到作者的基本信息就可以继续其它内容，但好奇心驱使我又多看了看。于是就梳理出了这么一个从2002年Nature论文到2022年亿元营收的故事。 这个故事里有知名教授的多重角色，有国内外肿瘤NGS公司的交易合作，也有科学研究到临床转化的漫长过程。 一个方法带来两篇顶刊论文 2020年，在第157届年会上美国国家科学院年会上，有一位来自荷兰的教授被评选为美国科学院院士，以表彰和认可其在肿瘤研究领域30年来做出的杰出贡献。他的名字就是René Bernards。 如果你去了解 Bernards 过往几十年引用量很高的两篇论文，会发现他们分别于2002年一头一尾发表在Nature和NEJM上。 2002年出的Nature文章 2002年底的NEJM文章 不难看出说的是一件事情：乳腺癌中发现了一个可以通过表达量来预测患者生存的基因集。 在第一项发表的论文中，作者团队确定了一个由几十个基因组成的基因表达谱与淋巴结阴性乳腺癌患者的早期远处转移风险有关。 在第二项研究中，作者团队又对荷兰癌症研究所医院治疗的295名患者进行测试分析，证明了这一指标可以用来指导患者治疗的疗效预测。该方法一方面比此前传统分类指标找到更多的低危患者，同时也可以在原有分类基础上进行精准分型。 如果乳腺癌的转移能力在肿瘤发生早期就可以被测试和诊断，自然可以改进辅助治疗受益患者的选择，进而降低过度治疗和治疗不足的比率。 两篇论文带来一款诊断产品 漂亮的研究结论，想必是给了大家很大的鼓舞和信心。 2003年7月10日，荷兰成立了一家叫做 Agendia 的初创公司，而Bernards 的身份则是联合创始人和Chief Scientific Officer。 如今，在 Agendia 的官网上他们骄傲地介绍自己是唯一一家专注于乳腺癌的分子诊断公司。 成立不到一年，Agendia 就在欧洲推出了一款可以进行乳腺癌复发风险监测的旗舰产品，随后这一产品进入美国。2007年，它成为第一个获得 FDA 许可的 IVDMIA（In Vitro Diagnostic Multivariate Index Assay），此后又获得了6个额外的 FDA 许可。 如当年的材料所示，这款名为 MammaPrint的产品就是分子诊断行业里鼎鼎大名的乳腺癌70基因检测。而这款70基因表达谱产品的原型，正是来自于 2002 年发表在Nature和NEJM中的那两篇论文。 一款产品为中国公司带来亿级营收 将目光转回国内市场，2014年11月17日在无锡成立了一家名叫臻和科技的肿瘤诊断公司。 2018年，臻和科技与 Agendia 签署了该产品的独家销售协议，在中国正式引进起了这款产品并命名为玛普润。 2020年11月，臻和与Agendia重新修定协议后拥有了MammaPrint在中国的独家商业化权利。作为交换条件，承诺购买最低数量的产品用于在中国销售和分销。 商品进来了，自然就需要推动诊疗指南的更新。 在CSCO乳腺癌诊疗指南2021版的内容中，MammaPrint 也获得了推荐（可以看注释） 作为一款商业化产品，你自然关心它在国内的销售状况如何。 2022年，臻和港股IPO招股书披露的数据显示：2020年、2021年及2022年上半年，MammaPrint的销售收入分別约为3500万，4600万和1900万。 也就是说，过去两年半时间，MammaPrint 为这家中国公司带来了亿级水平营收。 写在最后 作为乳腺癌复发检测的鼻祖产品，MammaPrint 临床研究的循证过程还值得今后单独进行梳理介绍。（emmm~ 会在未来熊言熊语会员计划中呈现，欢迎扫码订阅，第一时间接收更新内容） 从接触肿瘤生物医药行业以来，我时常有一个好奇： 一款产品/药品出现在患者面前时，究竟需要经历怎样的历程和多漫长的时间。 借着这一篇本不相关综述的作者背景调研，从文献到作者，从作者再到实验室和既往研究，从临床研究又看到临床指南和IPO招股说明书。 如此这般，头脑中其实也就有了一个轮廓，Aha，原来是这样。 回到故事本身。 荷兰、美国到中国，Nature和NEJM发文到创立Agendia公司，从美国科学院院士到任职交大顾问教授，从MammaPrint产品上市、FDA获批再到国内引进两年多实现亿级营收。 2002到2022，20年时间我们看到了科学探索到临床研究再到产品商业化的粗略过程，也捎带围观了 Bernards 大佬的精彩人生。 如文章开头所说。 于我而言，读文献的乐趣常在于文献之外。在这件看似枯燥的事情中，打开八卦之心，你也可以找到自己的乐趣。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-12-15-mammaprint-intro-from-nature-to-product/"},{"title":"肿瘤NGS行业新人如何构建自己的知识体系","content":" 本文为熊言熊语邮件通讯会员计划内容精选。如果你也是一个行业新人，或许会有一点点启发；如果不是，不妨分享给你身边的行业新人～ 关于写作，我曾经看过这样一段话觉得很有道理：写作这件事，短期看冲动，中期看回报，长期看水平。 在硕博6年从事生物信息相关学习和研究后，进入生物医药行业从事肿瘤NGS相关工作过去了一年半。虽然我尽可能地去学习和丰富自己的知识体系，但这仍是一个极其漫长的过程，学习的过程看不到尽头。 想长期坚持就需要有一些更具体的计划。 回顾总结了自己过去一年半的学习过程，整理完参与会员计划读者的调查问卷后，未来一年的更新内容将主要围绕如下5个模块展开。 以下内容既是更新计划汇报，也是肿瘤NGS行业新人如何构建知识体系的一点点参考，分享给你。 通过临床指南了解肿瘤各个癌种 对于医生来说，NCCN、ESMO 和 CSCO 这类官方发布的临床诊疗指南是行医看病的重要参考依据；对于学习或者从事相关专业的人来说，这些指南是很好的搭建基础知识框架的阅读手册。 做项目的时候，养成习惯翻翻最新的临床指南。从中可以快速了解所关心的临床问题，在实际临床应用场景中的进展，顺着指南引用的临床研究和参考文献，就能对相关内容有个基础了解。此外，通过修订说明还能了解发展历程。 因此，我会通过NCCN指南和你一起了解各癌种的临床诊疗现状，更多指南学习方法和思路，会在后续通讯中交流。 基于主题的文献整合解读 关注和了解最新的研究进展是目前的工作所需，更是我自己浓厚的个人兴趣。相信你也一样，只要进入了医学相关的领域，持续学习必不可少。比如每年的各个大会上，都少不了所谓的「继续教育」专场。 从个人的体验来说，如果对于一个细分话题（比如一个重要基因或者生物标志物）仔细阅读学习10篇左右的高分/经典论文，做好横向和纵向类比学习，就可以形成对这个细分话题的基础认知。 因此，我将通过每次3-5篇文献整合解读的方式和你一起学习以下主要四个方面的细分主题： 重要癌症驱动基因的研究进展 重要生物标志物的研究进展 重要临床药物的临床实验进展 重要肿瘤生物学基础问题的研究进展 驱动基因除了关注不同癌种特异性强的基因如肺癌 EGFR，也会关注不限癌种应用的（Tissue-Agnostic）基因如RET。 生物标志物，我们会按照从微观到宏观的尺度（基因突变到基因集再到基因组特征）展开，其中基因组特征包括当下最受关注的ctDNA、TMB、ITH、HRD和新抗原等等。除学习临床应用，还需要会了解它们从提出到走向临床实践再到写入指南的历程。 关注临床以外，我们也应该关注肿瘤相关的各种关键基础生物学问题。对于这些内容，将依据最新版的Cancer Hallmarks 来逐一学习交流。 国内外肿瘤精准治疗头部公司/产品梳理 谈肿瘤精准医疗，了解产业最有效的方式之一是关注国内外头部的那些公司和startup 做过什么、正在做什么和打算做什么。 我大致梳理了以下这些公司，也欢迎你和我一起完善补充（每一封邮件都可以直接回复）。 国内肿瘤NGS检测相关公司 Burning Rock Biotech, Genetron Health, Geneplus ,3D Medicines, OrigiMed ,Genecast ,YuceBio ,Haplox ,GenomiCare ,Singlera Genomics ,GenomiCare ,ChosenMed, Genetron Health 国外肿瘤NGS检测相关公司 Foundation Medicine, GRAIL, Memorial Sloan-Kettering Cancer Center, Myriad Genetics, Natera, Inivata, AnchorDx, Exact Sciences Corporation, Freenome ,Guardant Health ,Thrive Earlier Detection, Veracyte, Invitae ,Oncocyte 国内创新药企 Hengrui Pharmaceuticals, Betta Pharmaceuticals, Suzhou Alphamab Co, Adagene, CStone Pharmaceuticals, Legend Biotech, Zai Lab, Henlius Biotech, Junshi Biosciences, Hutchison MediPharma, Innovent Biologics, BeiGene 国外药企 Abbvie, Pfizer, Novartis, Roche, Bristol Myers Squibb, Merck Sharp &amp; Dohme Corp, Sanofi, AstraZeneca, Takeda, Merck &amp; Co, Daiichi Sankyo, Glaxo Smith Kline, Blueprint Medicines 后续，我会逐一梳理这些头部/创新公司的产品线和药品研发管线，这部分内容感觉适合入行初期的打工人和有意愿进入这个行业临近毕业的学生读者。 国内外肿瘤精准治疗知名机构/医院梳理 类比于打工人关注行业头部公司，作为从事科学研究工作的我们来说，了解最新的学术研究方向和热点，也可以关注研究领域内国内外科研实力雄厚的知名机构和医院。 比如 MSKCC、Dana-Farber 和国内的知名高校及各大附属医院。通过医院进而找到领域内的大牛PI，万一你有机会还能做做博后读读博士呢？ 我的个人学习方法和工具介绍 除了以上4个生物医药肿瘤领域相关模块，调查问卷里自由填写感兴趣的话题，很多都指向了学习工作方法、习惯和工具的介绍。 是普遍需求就需要回应，因此在具体信息和知识分享外，也会穿插着详细介绍一些我的个人学习方法和工具，比如读文献读书的方法工具等等，供你参考批评。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-12-10-cancerngs-newbie-guide/"},{"title":"熊言熊语邮件通讯来了 和1800+读者一起订阅吧","content":" 经过一段时间（其实是很长时间）的准备和调整，熊言熊语会员通讯下周恢复继续更新啦。以下是最新一期的邮件内容和你分享～ 写在前面 你好，我是思考问题的熊，很高兴通过这封邮件（信件）和你见面。展信佳～ 如果你对收到这封邮件感到意外，大概率是因为以下三个原因我们建立了联系。 第一种可能：2020年12月开始更新熊言熊语会员通讯，到2021年7月暂停更新，你很大概率是那个时段订阅了这份newsletter，这也是为什么本期的邮件主题序号是「009」而非「001」。 第二种可能：也许你在B站学习了之前公开的「RNA-seq转录组数据分析入门实战」课程并寻求过资料，不知道这门课最终有没有帮助到你，如今已经不知不觉超过了11万次播放。 第三种可能：也许你是「熊言熊语」播客的听友，曾经听我和三五好友聊过学习工作和收获困惑，并且帮助我填写过听友问卷。咳，播客正常更新也是一年半以前的事情了。希望不用等太久可以用另一种方式再回到你的身边。 如果你是在其它渠道读到这封邮件，不妨直接扫描下方二维码或者跳转到邮件通讯订阅页面，订阅后继续阅读。 为何此时继续更新 熊言熊语会员通讯 从下周（2022年12月5日）开始，这份Newsletter将继续更新。 2021年7月暂停更新的时间，是我正式从学生身份转变为职场打工人的节点。那个时间段，我感觉自己开始了一段完全不同于以往的生活，需要更多花一些精力来迎接这种身份的转变。现在，一年半的时间，我不能说自己完全适应了所有，但是已经基本适应了打工人的身份，所以有些事情可以继续。 从暂停更新到今天，在完全没有宣传推广的情况下，又增加了接近1000人订阅。大家从熊言熊语公众号，从博客和播客，找到了这个保持联络的方法，但似乎又再也没有被联系过。每次看到订阅列表的新增订阅我感受到的都是期待和信任，所以有些事情需要继续。 开始工作这一年半的时间，我幸运地找到了一个自己认可的行业和团队，更幸运的是在做感兴趣的事情。我有机会从生物信息出发接触临床实验项目和肿瘤相关的数据挖掘，有机会从科学研究出发接触生物医药行业，有机会看到自己的研究结果可能转换为临床医学的决策参考。 当然，工作不同于读书那会儿，我们涉及到的是复杂系统的一环，一个项目是否推进和如何推进，需要诸多方面的评估和考虑。很多变量是个人无法控制的，工作的过程，就是权衡的过程，需要权衡成本与收益，需要权衡时间与人力。在这些权衡之中，也许你我应该做一些不需要太多顾虑的事情，比如不计ROI的投入，不计收益的付出，所以有些事情应该继续。 今后这份通讯如何更新 熊言熊语会员通讯将会继续通过邮件的形式保持更新。 关于为何要通过邮件来和你保持联系这件事情，我在不同的文章中解释过几次。简单说，邮件系统似乎是如今唯一几乎可以不依托于某个平台存在的联系方式。 只要你的邮件服务商没有停止服务，你就可以通过任何一个邮箱客户端来收取信息，而且也不用担心文章像在微信中一样点开突然变成404。 而即便我使用的邮件推送服务有一天关停，我也可以带着大家的邮箱列表，继续转移到其它的服务商给你发送信息。比如，因为订阅人数即将超过mailchimp的2000人免费上限，为了方便大家接受到邮件，我就从国外的mailchimp迁移到了国内独立开发团队运营的竹白。 今后，除了可以通过邮件订阅以外，在订阅界面你还可以使用微信订阅推送通知和阅读。（当然，邮件订阅仍然是最好的方式，可以自由访问外部链接） 通讯包括哪些内容 和这位通讯创立伊始的构思一样，我还是会和你分享我的所思所学和所想。这份免费会员通讯，每一期将会有三部分内容组成： 行业与专业：订阅这份通讯的朋友保守估计超过半数是生物医学相关的在读学生和生物医药行业的从业者。我将会把我收集整理的最新领域研究进展和行业动态分享给你，其中会包括领域内大佬和头部公司参与的科学研究，也包括值得关注的最新行业动态。 阅读与思考：我依旧是那个没事喜欢瞎读些东西瞎思考些问题的人，所以我会把我平时读到的国外国内的好书和好文章和你分享，也会向你汇报一下最近自己又想了些什么。 推荐与寻找：我们之所以成为今天的样子，很大程度都是受到我们每天接触到的人和物影响，所以我也会给你推荐介绍那些给我了很多启发和帮助的朋友，以及改变了我的工具和习惯。此外，当我面临问题的时候，我也会向你发起求助，寻找那些可以帮助我的人和物。 通过之前的文章长度和阅读情况来看，每次的内容会维持在1000字左右，尽量不超过2000字。 什么是付费会员计划 如果你现在点开这份Newsletter的订阅界面，会看到如下界面。 除了免费订阅选项外还能看到三个不同时长的付费订阅计划。 在付费内容中，我会专注于生物医药领域的研究热点文献梳理和行业动态解读。 目前暂定的模块包括：主题式的文献解读，行业领先产品探究和国内外机构介绍等等。这里的「行业」主要是指肿瘤精准治疗领域，国外国内相关的生物医药公司、NGS检测公司等。 区别于免费会员通讯中关注最新内容的「行业与专业」板块，付费会员内容不会单纯的追踪热点和新闻。 一方面，我希望通过自己的筛选和梳理，能够尽量保证内容在一年之后回看仍然有价值； 另一方面，我希望通过相对长篇幅的写作和思考，持续让自己保持学习状态，并把这个过程也展示给你。 需要留意的是，我无法为你呈现非常细节（如复现文章图表或者解决软件运行包错）和非常宏观的内容（如未来5年的行业发展趋势）。前一阶段已经过去，后一阶段必定是我目前力所不及，以及，有更多的职业团队已经在提供这些内容。 我能呈现的，就是一个身处行业且对这个领域还抱有巨大好奇心的人，在了解什么和学习什么，以及是如何了解和学习的。 这些内容希望读后可以让你感受到我的一点思考，更希望能触发你的一点思考。也许我的视角也很主观，但至少可以为你带来一些不同的视角。 类似的内容，我最近已经更新了一些，如果你想了解写作风格和内容，不妨读读看。 FDA发布ctDNA应用于早期实体瘤药物开发的指导意见 ctDNA系列之一：ctDNA的生物学特征、检测技术问题和临床应用方向 同样做肿瘤NGS检测，美股上市的9家公司近况如何 染色体不稳定性，凭什么2022年还能用TCGA数据发Nature 跨越60年的癌症靶向治疗里程碑 通过一份会议日程多了解点液体活检 [Nature Reviews Cancer：未来10年肿瘤精准治疗的6个未解之谜](Nature Cancer：高度非整倍体非小细胞肺癌 放疗同步免疫治疗更敏感 Nature Genetics：低TMB患者福音 肿瘤非整倍体可预测泛癌免疫治疗疗效 Nature Cancer：高度非整倍体非小细胞肺癌 放疗同步免疫治疗更敏感 之所以选择把这部分内容单独作为付费内容呈现，主要出于三点考虑： 这些内容专业性过强受众很少，考虑到阅读体验并不适合和前面内容在一封邮件中呈现； 这些内容创作需要花费巨大精力，付费订阅这种本质上的契约行为，能让我约束自己更好地交付； 作为一个在上海身背巨额贷款已到而立之年的人，如果通过写作分享可以补贴日常饭票，不仅不丢人，反而是一件让人开心的事情。 因此，如果你和我类似是一个身处相关行业且对这个领域还抱有好奇心的人，这些内容也许适合你；如果你是出于对我个人的支持和喜爱进行订阅，我更要由衷感谢。 目前，这份邮件通讯已经有超过1600位读者订阅，欢迎你的加入，每周接收免费的邮件通讯或者参与会员计划。 直接扫描下方二维码或者跳转到邮件通讯订阅页面即可订阅。 one more thing 如果你曾通过「爱发电」这个平台为熊言熊语播客进行过发电支持。倘若你需要可以联系我（微信 kaopu_bear），我很乐意为你送上今后半年的付费会员计划内容。 感谢曾经的相伴与支持，唯有此最珍贵。来日方长，未来可期。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-12-04-kaopubear-newsletter-intro/"},{"title":"Nature Genetics：低TMB患者福音 肿瘤非整倍体可预测泛癌免疫治疗疗效","content":"写在前面 书接上回，在昨天的文章里，我们从一天连发两篇Nature大子刊是什么体验出发，提到了芝加哥大学的Liam Flinn Spurr 在11月28日，作为第一作者在 Nature Cancer 发文，通过一项临床研究发现高度非整倍体的非小细胞肺癌对放疗联合免疫治疗更敏感。同时在Nature Genetics online 的文章则介绍了在低TMB患者中可以通过肿瘤非整倍体程度预测泛癌的免疫治疗疗效。 如果想看Nature Cancer这篇文章的更多细节以及关于肿瘤非整倍体的简短介绍，可以阅读昨天的文章。 今天的文章，前半部分让我们接着来看第二篇发表Nature Genetics 的 paper有哪些内容，在后半部分，我们也会关注它的 Peer Review 有没有透露出什么接收背后的细节。 话不多说，正式内容走起。 TMB 是好的生物标志物么 免疫治疗彻底改变了很多晚期癌症患者的治疗方式，但免疫检查点抑制剂(ICI)对大多数患者又是无效的。 为了找到那些真正可以通过ICI治疗获益的人群，我们一直在探索能够预测免疫治疗疗效的生物标志物。目前，包括 PD-L1的表达，CD8 + T 细胞特征，肿瘤新抗原负荷和 TMB 都在一些研究中证明了自己在这方面的价值。 其中，在多项独立研究中，TMB 已被确认在 ICI 治疗中针对泛癌预后和预测性生物标志物。例如，2019年Samstein 等人发表在 Nature Genetics上的文章就通过分析1662名接受了ICI治疗的泛癌种患者数据发现，top 20% TMB 和总体生存相关。如下图所示，top10% TMB的患者OS要好于10-20%，其余80%的患者OS最差。 后来，FDA 批准了Pembrolizumab 在泛癌症的应用，其高 TMB 的标准定义为每兆碱基不少于10个突变。从这个角度讲，TMB作为免疫治疗的生物标志物本身没有任何问题，而且一度给我们带来了巨大的希望。 但是，我们姑且不谈论后来人们关于TMB是否在ICI联合中有用的质疑，以及TMB究竟把cutoff定在几更合适的争论。单就TMB作为一个生物标志物而言，也应该看到其两面性。 还是上文提到的研究，从下面两个图可以看出每个癌种对应的OS HR 和 TMB的cutoff，以及不同癌种在不同梯度TMB的分布比例。如果以10作为TMB高的标准，该研究Cox分析中很多癌种的cutoff值都没有达到10。 再进一步讲，不管用于定义高 TMB 的阈值如何，大多数患者仍表现出低 TMB特征，并且对于这个人群结果的基因组预测指标的研究尚不清晰。因此，我们仍然需要新的生物标志物来改善癌症免疫治疗的风险分层。 非整倍体评分区分ICI疗效 肿瘤细胞染色体或染色体臂的数目不平衡被称为非整倍体，就像昨天文章中提到的，它是人类癌症的一个几乎普遍的特征。最近几年，已经有不同的研究揭示了肿瘤非整倍体对肿瘤免疫的负面影响，其中可能的机制包括免疫逃避，包括下调 PD-L1表达和抑制肿瘤内 CD8 + T细胞应答。此外，以前的研究已经证实肿瘤非整倍体程度高其实是总体生存差的标志 ，并提出非整倍体适合作为临床结果的生物标志物。 在这种这样的背景下，本文的作者团队同时发现了非整倍体也是用免疫联合放疗的有效生物标志物。 尽管非整倍体现象是普遍存在的，但是非整倍体的程度的因癌症类型而有很大差异。作者团队重新分析了上文我们提到的1600多名患者的ICI队列，可以看出乳腺癌和黑色素瘤的非整倍体程度整体更加明显，而肾细胞癌、结直肠癌和头颈癌的非整倍体程度则整体偏低。 作者在含有TMB、ICB药物类型和其他潜在临床混杂因素的多变量模型中测试了非整倍体评分的预测价值。在所有肿瘤中，结果显示高非整倍体评分（和PD-L1都）与不良预后显著相关。 在大多数单一的肿瘤类型中观察到了类似的结果。 值得注意的是，TMB和非整倍体评分之间没有相关性，也证明了这些变量的独立。此外，染色体不稳定性的另一个常见衡量标准是基因组改变比例(FGA，fraction of genome altered)，此前也有研究证明这个指标是预测肿瘤免疫的标志物。 虽然不难理解非整倍体评分和FGA具有极高的相关性，但是通过分别使用这两个指标针对不同的癌种进行多因素Cox分析，至少作者在这个队列中的研究结果表明非整倍体评分略好一些。 整体的非整倍体评分是由每个染色体的状态组成的，那么是否有某个染色体臂在某些癌中能更好的对ICI的疗效进行评估呢？为了回答这个问题，作者也检查了非整倍体评分的预后价值是否主要受到特定染色体变化的影响（例如编码 PD-L1的基因 CD274 所在的9p21杂合性丢失）。结果显示，当控制FDR为0.05时，如下图所示没有特定的臂水平变化与生存相关。 非整倍体评分如何结合TMB 其实分析到这里，已有的分析已经支持非整倍体评分在免疫治疗中作为预后生物标志物。但是为了便于将其作为临床生物标记物使用，作者通过使用上文TMB阈值类似的分析，确定了与TMB最佳协同的非整倍体评分阈值，以对ICI治疗患者进行风险分层。简单讲，就是在多因素模型中考虑ICI药物类型，并将top 20%的TMB定义为高TMB，然后每种肿瘤类型的非整倍体评分从20%到80%，每10%作为一个指标进行测试分析。比较后发现非整倍体评分的第50个百分位（top50%）是所有候选阈值中 p value 最低的最佳阈值（如下图所示）。 值得注意的是，当在多变量模型中使用FDA批准的TMB阈值10时，同样获得了相同的最佳非整倍体评分阈值。 在KM分析中，使用top 20% TMB 和top 50% 非整倍体评分作为分类标准，得到的结论是在高TMB肿瘤中，非整倍体评分没有预后价值；然而在低TMB肿瘤中，更高的非整倍体评分的肿瘤患者接受ICI后预后显著更差。 非整倍体评分对哪些癌种作用更明显 最后，在不同的肿瘤类型中，分别比较了不同高低TMB和不同高低非整倍体评分之间的2年OS。结果显示，在结直肠癌、膀胱癌、非小细胞肺癌和原发位置不明的患者中非整倍体评分对预后的影响与TMB评分相当。乳腺癌和肾癌种非整倍体评分显示出了更大的预测价值。 此外，值得注意的是，在低TMB人群中，非整倍体评分高和低的患者的两年总生存率差异最大的是原发位置不明的癌症(13% vs 54%)、结直肠癌(26% vs 60%)和乳腺癌(0% vs 28%)。 回看这篇发表在Nature Genetics 上的 Brief Communication，我们可以得到如下2个结论： 1：对于接受ICI治疗的低TMB肿瘤患者，非整倍体评分升高是一个独立互补的OS预测因子。 2: top 50% 的非整倍体评分可以用来定义高非整倍体分数阈值，该阈值对于 top20% TMB（或TMB不小于10为标准）分类下定义为低TMB的肿瘤具有独立的预后价值。 同时这个结论的可信程度也需要你综合考虑这个含有10个癌种的数据集中每个癌种的样本数量，以及来自单一机构的患者数据集可能会带来的一些偏移。因此如果想进一步提高其循证等级，前瞻性的临床研究也是必不可少的。 此外，在以后的研究中确定可能有助于克服高度非整倍体肿瘤免疫耐药的协同治疗方式也非常必要。 但无论如何，这项多癌种的回顾性研究都为深入了解肿瘤非整倍体在调节低TMB肿瘤免疫治疗反应中的作用迈出了重要一步。 审稿人怎么说 杂志公开了Peer Review的细节文件，让我们来看看审稿人怎么说。 首先两位审稿人都对该研究给予了高度评价。正如编辑所言，尽管他们确实提出了一些改进的要求，但这些要求相对简单而且也不会带来过多的额外工作。 而在最后的正文里，有哪些分析是审稿人提出的修改意见，审稿人又有什么评论呢？不妨猜一猜。 在审稿过程中，两位review提了以下四点内容： 1：基因组拷贝数改变的比例（FGA）是肿瘤免疫的预测因子，讨论一下FGA和非整倍体之间的关系(相关但是不同)也是有价值的。 基于这个问题作者增加了正文中和FGA的比较部分内容，也就是原文的figure1F。 2：似乎非整倍体评分使用20%的cutoff受益更加明显。 基于这个问题，作者增加了原文figure2A的分析。 3：有没有可能大多数影响是特定的染色体变化(例如9p21缺失)而不是非整倍体造成的。 基于这个问题，作者增加了我们上问提到的染色体臂扩增缺失分析。 4：作者能提出一个具有临床意义的案例吗？TMB的真实价值其实本身就不是非常大(很少在临床上使用)，非整倍体的影响似乎更小。虽然这个生物学问题很有趣，但我不相信他会影响临床实践。 这个问题比较有意思，针对这种回顾性分析，作者很难真的给review提供一个根据非整倍体评分指导患者免疫治疗的例子。 作者在回复中，首先通过一篇最新发表的文献(PMID 35764740)强调了TMB目前在临床应用中的最大问题应该是研究哪些低TMB患者对ICI疗效相关的肿瘤全基因组结构异常，进而提出自己的研究刚好符合这个大家最关心的实际临床需求。 同时作者再次强调了比较TMB和非整倍体分组下，不同肿瘤之间的2年OS差异，进而强调出与TMB分组相比，非整倍体评分对于乳腺癌和肾癌患者的预后影响更大。最后又补了一句，基于这个结果，相信非整倍体在OS上的巨大差异值得结合TMB进行进一步的前瞻性验证。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-12-02-tumor-aneuploidy-predicts-ici-survival/"},{"title":"Nature Cancer：高度非整倍体非小细胞肺癌 放疗同步免疫治疗更敏感","content":"写在前面 同一天在 Nature Cancer 和 Nature Genetics 发表两篇文章是一种什么体验？今天我们用一天发表两篇文献解读从侧面体会下 😃 故事要从2022年9月9日说起。因为我最近一年多比较关注肿瘤基因组不稳定性相关临床研究进展，于是会留意一些该领域内活跃大佬的动态。 今年9月9号，我发现来自芝加哥大学的Liam Flinn Spurr（2021年他曾在Bioinformatics发表过肿瘤非整倍体分析的方法学文章）说自己有三篇一作文章在一周之内同时被Nature Cancer、Nature Genetic 和 NPJ journal 接受。 等文章online，这一等就是三个月。 11月28日，他作为第一作者在 Nature Cancer 的文章正式 online，作者通过一项临床研究发现高度非整倍体的非小细胞肺癌对放疗联合免疫治疗更敏感。同时在Nature Genetics online 的文章则介绍了在低TMB患者中可以通过肿瘤非整倍体程度预测泛癌的免疫治疗疗效。 今天的推送我们一起了解第一篇文章的相关内容，万一对你有点启发呢。 关于肿瘤非整倍体 基因组不稳定性是肿瘤 hallmarks 之一，从泛尺度来说，包括碱基 / 基因层面、染色体片段、染色体臂水平和染色体水平的扩增和缺失。如下图所示，我们常说的非整倍体（aneuplooidy）程度就是特指肿瘤细胞染色体臂和染色体层面的扩增缺失现象。 关于非整倍体这类基因组不稳定性对于肿瘤的影响已经有了不同维度的很多研究，不同的肿瘤分期和组织细胞类型会有不同非整倍体特征，非整倍体程度也会对肿瘤免疫系统、肿瘤微环境和基因组变异产生影响。 高度非整倍体非小细胞肺癌对于放疗联合免疫治疗更敏感 先来看看第一篇文章。 联合放疗(RT)和免疫检查点抑制剂(ICB)治疗癌症的临床实验有超过500多项目，然而大多数试验并没有发现积极的相互作用。 目前，一个关键的临床问题是我们是否以及该如何将RT和ICB结合起来以改善患者的预后。此外相关的生物标志物也将有助于选择最有可能从联合治疗中受益的患者。 PD-L1表达、肿瘤突变负荷(TMB)、效应T细胞和肿瘤新抗原的数量等等已经被证明可以预测抗PD-1或者抗CTLA-4的应答。然而，这些生物标志物或者是否有其它更好的生物标志物中可以预测RT和ICB的联合治疗效果也尚不清楚。 作者团队进行了一项随机临床试验，旨在针对未经选择的转移性非小细胞肺癌患者，评估ICB联合多部位消融体部放疗的一线治疗安全性和有效性。本文作为该试验的二次分析，分析了治疗前和治疗中匹配样本的肿瘤活检分子特征，以展示放射治疗和ICB时机对肿瘤免疫基因组环境的影响。 具体的实验设计如下图所示，对于转移性的非小细胞肺癌 (NSCLC) 患者，随机分为两组分别在试验中接受同步或序贯的立体定向消融体部放疗 (SBRT) 联合ipi/nivo (ICB)治疗。 具体的样本收集时间点和样本检测数据类型如下图所示，在两组患者治疗前收集样本，在1-2周的SBRT治疗后再收集一次样本。分别统计临床相关信息和并进行RNA及DNA样本检测。 因为包含RNAseq样本，就可以基于大量免疫相关的基因集通过ssGSEA和差异表达分析等方法，比较两种不同治疗方式前后免疫相关的变化。比如作者研究发现，SBRT + ICB 的联合治疗导致参与抗原呈递、干扰素应答、细胞因子和趋化因子信号传导以及效应 T 细胞功能的基因上调。相反，SBRT 则抑制了细胞毒性T细胞相关基因的表达。 因为这部分相关内容不是我们今天要讨论的重点，如果感兴趣可以阅读原文。 在进行了免疫微环境相关的比较之后，我们自然会关心 ICB 反应的那些生物标志物是否可以用来预测RT + ICB 的响应效果。通过分析发现 T 细胞信号、 TMB、新抗原负荷和 PD-L1表达这些指标都没有表现出预测价值。然而，更高的非整倍体评分确预示着序贯治疗（而非同步治疗）的不良预后。 使用肿瘤纯度变化作为局部反应的替代指标，研究发现在SBRT治疗前的非整倍体评分和肿瘤纯度变化之间没有相关性，但是在同步治疗组内，两者之间的相关性非常强。提示SBRT+ipi/nivo比SBRT 能更有效地消除高度非整倍体肿瘤。 作者进一步研究了非整倍体评分和生存之间的关系。发现呈高度非整倍体的肿瘤(非整倍体评分≥队列中位数)的患者，与序贯治疗相比同步治疗可提高生存率。相反在非整倍体程度较低的肿瘤患者中没有观察到这种关系。 对于同步放疗联合ICB治疗有利于高度非整倍体的患者这一假设，作者研究了他们机构的另外一个58名转移性非小细胞肺癌患者的独立临床队列。 这些患者部分接受单独的ICB治疗（下图实线蓝色），部分接受了放疗和ICB的联合治疗（下图实线橙色），这部分患者这部分采用了同步治疗（下图虚线紫色）部分采用了序贯治疗（虚线黄色）。且该队列的临床和病理因素和之前的队列是平衡的。 与之前的假设一致，对于高非整倍体评分的患者（评分大于队列中位数），可以发现单独使用ICB的效果要显著差于RT+ICB的联合治疗，且在接受RT+ICB的患者中，同步治疗的患者比序贯治疗的患者预后更好（尽管这没有达到统计学意义）。但是相比之下，在非整倍体评分较低的肿瘤患者中，ICB中加入RT并没有改善患者的疗效。 至此，针对该队列的二次分析基本就完成了。我们可以看到，虽然是两个小队列，且验证队列的治疗方式并不是非常规整（其实有能用的验证队列已经很不容易了），但配合上有明确临床价值的分析结果以及包含了DNA和RNA两个维度丰富的分析内容，依旧可以发表在Nature Cancer这样的顶级期刊。 又是基于验证队列的分析结果，我们很自然的也会产生一个疑问：非整倍体的评分是否可以推广到仅有ICB治疗的患者中。 有趣的事，在一组来自MSKCC包括了350名接受了ICB治疗的NSCLC患者中，多因素Cox分析发现TMB和非整倍体评分均可以对立的预测OS。 将患者按TMB的中位数进行划分，高TMB患者中，不同程度的非整倍体无法区分出患者的预后；但是在低TMB的患者中，高非整倍体评分的患者预后要显著的比低非整倍体评分的患者更差。 进一步支持了将高非整倍体评分作为转移性非小细胞肺癌ICB反应的生物标志物实用性。 也正是因为最后这一小部分的研究，衍生出了同一天发表在Nature genetics的另一个文章。关于这篇文章的细节，我们下一篇博客再见～ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-12-01-highly-aneuploid-nsclc-rt-icb/"},{"title":"Nature Reviews Cancer：未来10年肿瘤精准治疗的6个未解之谜","content":"写在前面 「熊言熊语」这个名字来自于我2020年初开始做的一档音频播客节目。那段时间是我读博即将进入尾声。不难想到「熊言熊语」自然是借了「自言自语」这个词再加上「思考问题的熊」这个ID。 彼时，我强迫自己说话和表达，一方面是因为长时间的密闭空间生活让我的表达欲丧失殆尽，另一方面是博士尾声面临的迷茫和困惑让我无法正常思考。这个播客节目虽然在录制了30期之后目前处于停更状态，但自那以后我幸好还能着时不时输出一些什么。 如今，作为一个渺小的个体，无论面对怎样的生活和环境，你我都应该保留思考的能力，保留表达的能力。就像我前几天那篇推送中写到的：无论怎样，都要找到一种和这个世界沟通的方式。 也许，能做的不多，但，多少能做点什么。 未来10年肿瘤精准治疗的6个未解之谜 好了，进入正题。 Nature Reviews Cancer 11月24日在线发表了一篇看题目挺「唬人」的Perspective文章：未来10年肿瘤精准治疗的六个未解之谜。 文章的共同一作是德国亥姆霍兹国家研究中心的Adam Wahida 和德国海德堡国家肿瘤疾病中心的 Lars Buschhorn，通讯作者是肿瘤精准治疗领域内的资深大佬Razelle Kurzrock。 Razelle Kurzrock 曾供职过多家不同的机构。在学术研究层面，她Google学术中的H-index高达119，i10-index高达833（国内肺癌领域大佬吴一龙教授H-index为101，i10-index为391；作为学术民工笔者自己读博至今H-index则为他们的零头8），被引用接近8万次。 在德州大学安德森癌症中心期间，她创立主持了知名的 Phase I Clinical Trials Program。在UCSD（University of California San Diego）领导了利用分子特征开展个性化治疗 的 I-PREDICT 研究（Nature Medicine, 2019）。 据说最新online的这篇文章预定了2023 年 1 月出版的印刷版的封面。接下里就让我们一起来了解一下这六个谜题。 谜题一：是否和时间有关 精准治疗的关键是必须为每个病人在肿瘤的正确阶段使用正确的药物组合。作者首先使用了伊马替尼治疗慢性粒细胞白血病的例子作为说明。关于伊马替尼，你可以阅读我们之前的文章XXXX。 克服慢性粒细胞白血病有三个关键组成部分。首先是发现了异常的BCR-ABL融合基因；第二个是专门抑制BCR-ABL的药物伊马替尼研发成功使得其可以靶向BCR-ABL突变的白血病细胞而不会杀死依赖其他激酶的正常细胞。 精准治疗的关键是为每个病人在肿瘤的正确阶段使用正确的药物组合。作者使用伊马替尼治疗慢性粒细胞白血病的例子作为说明（关于伊马替尼可以阅读之前的文章熊说肿瘤｜跨越60年的癌症靶向治疗里程碑）。 克服慢性粒细胞白血病有三个关键组成部分。首先是发现了异常的BCR-ABL融合基因；第二个是专门抑制BCR-ABL的药物伊马替尼研发成功使得其可以靶向BCR-ABL突变的白血病细胞而不影响依赖其他激酶的正常细胞。 对于确定分子驱动因素和对应靶向药物这两点很多实体瘤中已经取得了一些成功，例如我们熟知的EGFR、ALK、RET和NTRK抑制等等。 但问题在于这些药物的应用虽然对患者的生存结果改善效果远不及伊马替尼。例如ALK重排是肺癌重要驱动因素，然而ALK抑制剂肺癌中有效率约为55%，中位时间为7个月，与在CML中使用BCR-ABL抑制剂的效果相差很多。 虽然这种差异可以被理解为血液瘤和实体瘤的不同。但如果假设两者没有本质区别时，其真正缺少的是第三个因素：治疗时机。 有研究显示，伊马替尼应用于晚期CML增殖转化阶段其反应率约为10%，中位生存期约为1年，疗效不好的原因是因为肿瘤发生了克隆进化后，虽然BCR-ABL仍然是驱动因素但出现了其他分子变异的共同驱动。 在肿瘤发展早期发生复杂克隆演变之前来进行治疗，可能是提高实体癌靶向治疗效果的关键。因此对肿瘤的分子遗传变异的分析应被视为所有癌症患者的一线策略以确保早期和准确的治疗：我们需要在正确的时间为正确的病人提供正确的药物。 不过我们也要认识到一个事实，大多数实体肿瘤都会涉及多个驱动的共突变，其中一些就可能在肿瘤发生的早期。此外，一些功能丧失类型突变药物本身也很难针对其发挥作用。 谜题二：有害突变何时致病 体细胞突变可以使正常细胞转化为癌细胞，细胞通过克隆选择过程获得了肿瘤特征。例如结直肠癌中的腺瘤性息肉就是典型的例子，恶性腺瘤的进展始于APC的突变，在几个获得性致癌基因打击后完全转变为恶性肿瘤。多种获得性突变最终导致了癌细胞的各种异常特征，如异常增殖、逃避细胞死亡、血管生成和组织侵袭。 但随着NGS相关研究的增加，出乎意料的是有害的基因变异其实也可以在非恶性肿瘤中看到，这就混淆了在治疗恶性肿瘤时应针对哪些分子特征进行判断。如下图所示，几乎没有转化风险的子宫内膜异位症往往带有典型的致癌基因的驱动突变，包括ARID1A、PIK3CA、KRAS等。 此外，反向克隆选择的现象（突变基因的等位基因频率在恶性进展过程中下降）在某些情况下也会发生。BRAF V600E 突变是大约50%的黑色素瘤和许多其它肿瘤的标志，但令人困惑的是在约80%的良性痣中也发现了这些突变，而它们的癌变风险可以忽略不计。此外，虽然HER2在乳腺癌中的过表达贯穿了良性到恶性的转变过程，但在良性肿瘤的导管原位癌（27-56%）的检测频率也要高于浸润性乳腺癌（11-20%）。 谜题三：突变是否具有组织偏好 肿瘤精准治疗的另一个关键问题是特定基因组改变在多大程度上存在于特定组织中并影响其生长，且tissue-agnostic的治疗方法是否有效。 同样是BRAF V600E 突变在黑色素瘤可以成功地用BRAF抑制剂进行治疗。然而，有研究发现在BRAF突变的结直肠癌中，由于EGFR介导的MAPK途径重新激活，除了BRAF抑制剂外还需要EGFR抑制剂的联合治疗才可以。 另外，BCR-ABL作为CML的标志在其他癌症中很少发现，但最近一例BCR-AB L阳性的胶质母细胞瘤及其用伊马替尼成功治疗的报道表明也同样有可能获益。 谜题四：应该靶向哪个肿瘤克隆 肿瘤重要的特征之一是克隆演化，治疗后的克隆生长是复发和耐药的主要原因，也是一个重要的治疗挑战。 从精准治疗角度看，通过基因组检测确定的所谓可及性靶点往往仅存在于一部分肿瘤亚克隆中。bulk 测序中发现的基因组变异可能与肿瘤的某些部分不相关，靶向治疗可预期的疗效也就更值得关注。 因此，治疗效果可能很大程度上取决于在避免相关毒副作用的同时有多少克隆可以被一次性锁定。单细胞测序和多个转移部位的液体活检是一个未来的DNA基因组测序方向。 在一个由许多克隆组成的肿瘤中，以一个克隆为目标对姐妹克隆产生的后果尚不清楚。 如下图所示，我们可以想象临床上某一个可靶向的肿瘤克隆被消灭后，其它克隆之间对氧气或营养的竞争就会得到缓解，进而可能会加速其它非靶向克隆的生长，加速整个肿瘤的生长。 这种混合反应是精准治疗的又一个重要难题，对此也许可以设计出可能的干预措施。比如，共同靶向那些被认为不受致癌突变影响通路的野生型蛋白，以提高对整个肿瘤的生存压力。 谜题五：肿瘤科医生应该多了解他们的患者 研究证明，饮食、生活方式、肠道微生物和对细菌病毒的接触、性别、以及病人的地理和种族都会影响癌症的治疗反应和独特的分子特征。为了用个性化的、更优化的精准治疗来治疗病人，必须考虑到这些因素。 过去十年中，微生物菌群作为一个关键的瘤外变量引起了大家的注意。尽管将特定微生物群种类与表型联系起来的功能研究仍然不多，但已有一些有趣的临床可及研究。比如肠道微生物可以改变荷尔蒙代谢从而调节前列腺癌的演变和疗效。 谜题六：何时进行免疫治疗 尽管以前很多肿瘤由于大量基因组变异而被认为无法用传统靶向疗法治疗，但它们最有可能对免疫检查点抑制剂产生反应，甚至可以在原本难治的患者中出现持久的完全缓解。 虽然TMB和PDL1的高表达在临床决策中的重要性越来越大，但是目前还存在非常多的问题。 高TMB肿瘤反应背后的生物学原理可能是只有通过利用使免疫系统失活的检查点才能存在多种突变，一旦用抑制剂阻断免疫系统就会被重新唤醒。此外，高TMB肿瘤可能会呈现更多的突变衍生新抗原，从而增加肿瘤免疫原性。但突变产生的新抗原必须具有免疫原性是由突变特征和免疫反应性共同决定的。 此外，关于免疫和其他治疗如靶向治疗的联合，更加有效的生物标志物，以及在肿瘤早期治疗中何时引入，都还有非常多需要解决的问题。 以上，就是这篇文章中提到未来10年肿瘤精准治疗需要解决的6个问题。就写到这里，我们下次再见。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-11-28-the-coming-decade-in-precision-oncology-six-riddles/"},{"title":"通过一份会议日程多了解点液体活检","content":"写在前面 通过参加自己领域内会议来了解行业动态和现状是非常好的途径。 如果你也在从事肿瘤领域相关的工作和研究，每年召开的 ASCO 和 ESMO 这类世界级大会和国内的 CSCO 自不必多说。 更进一步，如果你对某一个细分领域感兴趣，不妨搜搜是否有更垂直的会议可以关注。虽然最近几年线下参加会议的机会少了，但对于和我一样的初级选手而言，即便不参加会议只是看看会议日程往往也能收获一些新知，乐在其中。 就在这两天，美帝那儿正召开一个为期两天的液体活检 summit，主题是「Surveillance &amp; Early Detection」。借这个机会，我们一起实践通过一份会议日程如何多了解一点液体活检。 在我看来，从产业（非学术）的角度了解一个细分领域，无非就是三个维度：厉害的人、活跃的公司和领域内的产品热点。学术角度其实也一样，三个维度对应的是厉害的 PI、活跃的实验室和科学期刊热点发文方向。关于这个话题之前录过一期播客，感兴趣可以再回头找找。 回到 Liquid Biopsy Surveillance &amp; Early Detection Summit。 人的维度 关于 Speaker 的信息，第一页 highlight 的 Expert Speakers 除了几家大药企的 Director，还有两位助理教授。 比如 Pashtoon Kasi 他主要的研究领域在胃肠道肿瘤，最近还刚在 Nature Medicine 发表了一篇讨论液体活检 TMB cutoff 的评论文章 Liquid biopsies and tumor mutational burden: the cutoff conundrum，而这篇文章评论的则是 BFAST 研究。如果你感兴趣不妨找来看看。 另外日程里还特别点了几个人以及他们会涉及的相关内容，比如 Aadel Chaudhuri 和 EMD Serono 的 Zheng Feng。 其中 Aadel Chaudhuri 课题组的研究方向本身就是通过 cfDNA 监控癌症的早期复发，2017 年 Cancer Discovery 发表的那篇使用 CAPP-seq 技术通过 ctDNA 监控肺癌 MRD 的文章，他就是第一作者；而后者作为 EMD Serono 的 Director 参与了众多 ctDNA 不同技术维度相关的临床药物研究。 公司维度 再从公司的层面看看。一般花真金白银支持这种细分领域会议的，抛开有相关预算的前提，多数或者是行业第一梯队「不得不花钱」的头部公司，或者是攒了些东西迫切想花点钱露露脸寻找一些机会的公司。这个会议的 Official Partners 有下面这几家。 其中 Personalis 和 KARIUS 是我们之前文章中尚未提过的两家。 Personalis 作为一家提供基因组测序和分析方案的公司，重点关注在肿瘤免疫治疗，它家核心产品 ImmunoID NeXT 可以一站式提供绝大多数目前免疫治疗所需要的相关 biomarker。读读官网的产品介绍就相当于看了一个 mini 版综述。 目前他们产品重心也转移到了 MRD，相关产品 NeXT Personal 在最新一季的财报中占据了很大篇幅。 KARIUS 和其它公司略有不同，虽然都是做液体活检，但他们关注在微生物领域。其核心产品 Karius Test 可以快速从血液样本中检测出 1000 多种导致感染的病原体微生物 ctDNA (microbial cell–free DNA, mcfDNA)，进而为医生的治疗提供决策帮助。 话题维度 最后，你还可以通过整个两天的会议内容来粗浅看看液体活检哪些话题获得了大家的关注。这里简单截一部分图。 如果里面有你感兴趣的话题就可以去搜搜报告人发表过的 paper 或者社交媒体，没准能有意外收获。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-11-24-learn-from-schedule/"},{"title":"找到一种和这个世界沟通的方式","content":"因为 9 月初写了 行业几家公司 2022 Q2 财报简读，最近又有小伙伴后台留言问 Q3 这几家财报陆续出来之后是不是更新一下近况，我瞅了瞅感觉不大有必要。 除了最新一季各家公司财报发布，接近年底公司们也陆续开始了财务人力评估。想必你最近看到更多的大概率是各种裁员新闻。 比如，国内外多家 biotech 公司过去一段时间密集宣布进行管线（人员）调整，国外多家 NGS 肿瘤诊断相关的公司也相继宣布进行人员优化。下游行业不容易，这股寒意自然会传递到 illumina 这样的龙头上游企业。 即便是进博会期间他们搭台，邀请诸多行业第一梯队公司的 CXO 来唱戏，给出了非常乐观的 2027 年行业预期和「基因组学时代已至」的结论。 但为了能活到 2027 年，illumina 还是宣布了 500 人的全球裁员计划。（下图是前几天看到的新闻） 其实，跳脱生物医药行业，最近从 10 月 28 日马斯克收购 Twitter 随后宣布裁员 50% 以来，加上 Meta 和亚马逊，这些宇宙超级大厂也陆续开启了涉及几万人的裁员计划。 之前那篇文章，我提到看起来 MRD 和早筛是多数公司拼命争取的第二增长曲线（或者说是面向投资人的第二故事曲线），结果很多人都问我有没有参与到这些第二增长曲线中去。 在这样的一个周期里，关注外部信息的同时，最近几天我反复想起其它行业一个朋友说的话：如今比参与到公司第二增长曲线中更重要的，也许是找到自己的第二增长曲线…… 为了一起缓解一下后台看到大伙留言中表现出的各种焦虑，从今天开始打算或长或短地持续更新一段时间专业向内容。 可能是一起读读最新的文献研究进展，可能是关注一些最新的行业动态，也可以一起聊聊你我关心和纠结的问题。 所以，特别欢迎大伙通过最近任意文章的留言功能进行留言，无论是发表自己最近一段时间的感想或者任何想讨论的问题，我会找一些力所能及的问题或请力所能及的朋友日后慢慢回答。 毕竟，不论如何，我们都还是要找到一种方式和这个世界沟通，不是么？ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-11-24-find-yourself/"},{"title":"跨越60年的癌症靶向治疗里程碑","content":"写在前面 在一年前，我曾经写过一篇 NGS 肿瘤研究可以学什么的文章，展示了一下规划的学习路径。 那个时候刚刚从生信涉及到癌症研究，我就寻思有没有一个类似于编年史的肿瘤重要研究进展。比如可以按照编年体的样子梳理重要的临床研究或癌症药物开发历史。 很可惜没有找到。 转眼一年时间过去，最近「网上冲浪」的时候我突然发现 ASCO 竟然把这个事情做了。或许是为了纪念他们的国家癌症法案颁布 50 周年，ASCO 官网专门建立了一个叫做 Cancer Progress Timeline 的页面。 这个抗击癌症里程碑的进展时间表提供了癌症主要进展的历史概述，记录了跨越 170 年的 400 多个里程碑。从 19 世纪中期全身麻醉的出现为癌症手术打开大门，到 2017 年 FDA 批准了第一个癌症基因疗法。 时间线内容突出了癌症治疗和研究领域的一些最重要的进展，几乎所有的里程碑都是严格进行的临床试验结果。我挑选其中靶向治疗相关内容进行学习梳理后有了今天这篇文章。 下面正文开始～ 1960-1999 1960 年，来自美国费城的研究人员发现了一种与许多白血病患者有关的染色体异常。直到十年后，研究人员发现，当 9 号和 22 号两条染色体的一部分发生易位时，就会产生这种异常。后来，它成为有史以来第一种靶向癌症治疗药物伊马替尼 (Imatinib) 的靶点，而伊马替尼 (Imatinib) 则改变了慢性粒细胞白血病和其他癌症的治疗方法。 距离白血病患者染色体异常被发现的 27 年之后的 1987 年，研究人员首次确定癌细胞上一种名为表皮生长因子受体（EGFR）的受体在非小细胞肺癌的生长和扩散中起着重要作用。正是这一发现为我们提供了一个新的治疗目标，并导致了之后几十年来多个靶向药物的开发，比如厄洛替尼（Erlotinib）。 又过了 10 年，1997 年，美国 FDA 批准了第一个癌症分子靶向药物利妥昔单抗（Rituximab），用于治疗其它治疗方法无效的 B 细胞来源非霍奇金淋巴瘤患者。利妥昔单抗（Rituximab）属于一类新的药物，如今被我们称为单克隆抗体，它针对免疫 B 细胞来干扰癌症的发展。日后，这类药物可以与其他癌症治疗方法相结合，从而提高患者的生存。 1999 年，人们在准备迎接千禧年的同时，大约 25%的乳腺癌患者则迎来了一种名为曲妥珠单抗（Trastuzumab）的靶向药物。在过度表达 HER2 蛋白质的乳腺癌，化疗中加入这种单克隆抗体可以极大的提高晚期乳腺癌的生存率。而曲妥珠单抗（Trastuzumab）的作用还远不止于此，2006 年，它被批准用于早期 HER2 阳性乳腺癌妇女术后辅助治疗，研究显示药物可以将复发的风险降低 50%以上，这是一个前所未有的结果。如今，曲妥珠单抗（Trastuzumab）也被 FDA 批准用于治疗有类似 HER2 过表达的胃癌患者。 2001 时间跨过千禧年，2001 年 FDA 仅仅在三个月的审查之后就批准了伊马替尼 (Imatinib)，研究数据显示该药物在大多数患者中可以阻止慢性骨髓性白血病（CML）的进展。伊马替尼 (Imatinib) 作为是第一种被证明能够对抗所谓 「费城染色体」分子缺陷的药物，在 1960 年首次被发现后，它已成为 CML 的标准治疗方法，其有效性和易于服用优势使大多数患者能够将 CML 作为一种可控的慢性疾病。 这一年可以说是伊马替尼 (Imatinib) 的高光年，在被批准用于治疗慢性骨髓性白血病仅数周后，靶向药物伊马替尼 (Imatinib) 就被证明对一种名为 GIST（胃肠道间质瘤）的罕见肿瘤有效。在伊马替尼 (Imatinib) 之前的药物治疗对 GIST 肿瘤几乎都没有效果。 2002 一年之后，2002 年，已于 1997 年被 FDA 批准的靶向药物利妥昔单抗（Rituximab）在加入标准的化疗方案（CHOP）后，被证明能够提高老年弥漫性 B 细胞淋巴瘤患者的生存率。随后试验则证实了其在所有年龄段患者中的结果，&quot;R-CHOP &quot;组合很快就成为这种类型的非霍奇金淋巴瘤的标准治疗方案。 话分两头，2002 年 8 月 1 日，Nature genetics 发表了一篇肝癌分子发病机制的研究进展。研究人员发现了调控肝癌细胞生长的遗传途径，表明肝癌的发展是由于多种途径的破坏进而导致了许多遗传上不同形式的肝癌。这些发现一方面解释了为什么基因靶向药物的开发在过去十年中被证明极具挑战性，另一方面也为研究人员提供了一些潜在的治疗目标来进行探索。 2003 2003 年是人类生物学研究进程中有重要纪念意义的一年，来自七个国家的研究人员宣布他们已经成功绘制了人类基因组中 30 亿个 DNA 地图。这项历时 13 年的人类基因组结果将免费提供给世界各地的科学家，而基因组序列如今是我们所有基于高通量测序肿瘤研究的基础。 同年 FDA 批准了首个非小细胞肺癌靶向治疗药物，来自于阿斯利康的吉非替尼（Gefitinib），此前的研究显示它能缩小一部分采用了其他疗法但仍进展的晚期癌症患者肿瘤，吉非替尼（Gefitinib）所靶向的，正是我们上文提到 1987 年就被科学家发现的 EGFR 基因。 然而，16 年的等待并没有立刻换来吉非替尼（Gefitinib）大显身手，仅仅 2 年之后，FDA 就限制了吉非替尼（Gefitinib）的使用场景。因为 2005 年的一项大型临床研究发现，和安慰剂相比吉非替尼（Gefitinib）治疗根本就没有延长患者的寿命，不过这项研究也提到从未吸烟的患者和亚裔患者可以从中受益。直到 2009 年和 2010 年，两篇先后发表在新英格兰医学的临床研究才有力的表明吉非替尼（Gefitinib）确实有作为一线治疗的价值，只不过它是在携带 EGFR 突变的患者中比化疗更有效。 2004 2004 年，一系列重要的研究表明，具有 EGFR 特定突变的肺癌肿瘤对 EGFR 靶向药物的反应很强。表皮生长因子受体是刺激癌细胞分裂的重要信号通路，这些发现为确定最有可能对吉非替尼（Gefitinib）产生反应的患者群体提供了关键信息。 于此同时，FDA 批准了第二个用于非小细胞肺癌的靶向药物厄洛替尼（Erlotinib）。来自于罗氏的厄洛替尼（Erlotinib）被批准用于接受至少一次化疗方案后病情恶化的晚期非小细胞肺癌患者。先前的研究数据显示厄洛替尼（Erlotinib）与安慰剂相比可提高两个月的生存。而后续分析显示，厄洛替尼（Erlotinib）还能改善患者的生活质量，减少疼痛和改善身体功能。 2004 年是罗氏风光的一年，除了厄洛替尼（Erlotinib），FDA 批准的首个 &quot;抗血管生成 &quot;药物贝伐珠单抗（Bevacizumab）同样来自于罗氏。被称为抗血管生成药物的贝伐珠单抗（Bevacizumab）是新一代靶向药，它通过阻断肿瘤生长所需的血管生长来攻击癌症。2004 年它首次被批准用于治疗结直肠癌，此后也成为晚期肺癌、卵巢癌和肾癌以及某些脑瘤患者的重要治疗手段。 此外，阿扎胞苷（Azacitidine）在这一年获准用于治疗骨髓增生异常综合征，作为一款表观遗传学药物，阿扎胞苷（Azacitidine）在低剂量时能够通过与 DNA 甲基化酶 DNMT 蛋白家族形成共价键抑制其酶活性，使细胞的 DNA 甲基化水平降低。阿扎胞苷（Azacitidine）的一种脱氧类似物地西他滨（Decitabine）在 2006 年同样获批。 2005 从 2005 年开始，靶向药物开始逐渐走上更多癌种治疗的历史舞台。但聊靶向药之前，还有一件事情不得不提。 2005 年 2 月，为了全面了解导致所有主要癌症的基因组变化，美国国家癌症咨询委员会下设的生物医学技术工作组，建议启动一个「人类癌症基因组计划」（Human Cancer Genome Project）。到了 6 月，美国国家癌症研究所和国家人类基因组研究所举办了题为「癌症的全面基因组分析」的研讨会，共同讨论如何实施人类癌症基因组计划的试点阶段。12 月 NIH 就启动了为期三年、耗资 1 亿美元的「癌症基因组图谱」试点项目。这就是后来在某些层面帮助了大量研究生博士生毕业的 TCGA。 伴随着 TCGA 项目启动，2005 年，厄洛替尼（Erlotinib）成为首个获准用于治疗胰腺癌的靶向药物。一项重要的临床试验发现与单独使用吉西他滨（Gemcitabine）化疗相比，将靶向药物厄洛替尼（Erlotinib） (Tarceva) 加入标准的吉西他滨（Gemcitabine）化疗能延长无法手术的胰腺癌患者寿命。这是自近十年前吉西他滨（Gemcitabine）问世以来，首次发现晚期胰腺癌患者使用新药存在生存益处的试验。 索拉非尼（Sorafenib）则在 12 月批准用于肾癌治疗，因为研究表明它能延缓晚期肾细胞癌患者的肿瘤进展。 西妥昔单抗（Cetuximab）和帕尼单抗（Panitumumab）也被批准用于治疗转移性结肠癌，他们同样是对抗表皮生长因子受体（EGFR）的单克隆抗体。不过后来的多项研究分析表明，西妥昔单抗（Cetuximab）和帕尼单抗（Panitumumab）只对 KRAS 野生型的患者有效，这一发现有助于医生确保药物只用于那些能够受益的患者，同时为不会受益的患者减少不必要的治疗和费用。 2006-2007 2006 年和 2007 年，在肾癌治疗领域舒尼替尼（Sunitinib）和另一种靶向药物 Temsirolimus 相继被 FDA 批准，研究表明前者与以前的标准治疗方法干扰素相比能够减慢疾病进展，而后者作为 mTOR 抑制剂可以将晚期肾癌患者的中位总生存期延长 3 个月以上。 这两年，在针对已有靶向药耐药的问题上，达沙替尼（Dasatinib）被证实可以帮助对伊马替尼 (Imatinib) 耐药的 CML 患者并随后进入一线治疗的行列；拉帕替尼（Lapatinib）被批准与卡培他滨联合用于肿瘤 HER2 过表达的晚期乳腺癌患者，可以减缓对曲妥珠单抗（Trastuzumab）耐药肿瘤的疾病进展，等到 2010 年又被批准与芳香化酶抑制剂来曲唑联合作为 HER2 阳性患者的首选疗法。 2007 年，贝伐珠单抗（Bevacizumab）适应症也向前迈进了一步。两项早期试验表明，单独或与化疗药物伊立替康连用，贝伐珠单抗（Bevacizumab）可能会使治疗后病情进展的胶质母细胞瘤患者的肿瘤缩小。基于这些发现，FDA 对贝伐珠单抗（Bevacizumab）治疗胶质母细胞瘤给予加速批准，使其成为十年来第一个被批准用于治疗脑瘤的新药。而此后很多年，贝伐珠单抗（Bevacizumab）也开启了各种联合用药之路。 2008 2008 年，因为可以延迟肿瘤生长，贝伐珠单抗（Bevacizumab）又被 FDA 加速批准与紫杉醇联合治疗新诊断的晚期乳腺癌患者。然而，后来的长期研究显示贝伐珠单抗（Bevacizumab）并不能延长生存期。关于这种药物用于乳腺癌的争论仍在继续，尽管它在治疗其他常见癌症，如肺癌和结直肠癌方面有既定作用。 这一年，普拉曲沙（Pralatrexate）成为首个获批专门用于 T 细胞淋巴瘤治疗的药物，一项研究显示它可以使近三分之一常规治疗后仍然存在或复发的外周 T 细胞淋巴瘤患者的肿瘤缩小，研究中超过 10%患者的肿瘤完全消失了。随后，FDA 加速批准其用于复发或对其他化疗反应不佳的外周 T 细胞淋巴瘤，这是第一个被专门批准用于治疗 T 细胞淋巴瘤的药物。 与此同时，除了药物本身的研发，实验室技术的最新进展使得利用简单的血液样本检测**已经脱离肿瘤的癌细胞（称为循环肿瘤细胞）**成为可能。同样在 2008 年，发表于新英格兰医学的一项表明跟踪这些循环肿瘤细胞的数量有助于评估非小细胞肺癌患者对治疗的反应。 尽管彼时使用的检测方法是 PCR，但这种所谓治疗过程中的使用血液检测进行动态监控的方法将在 10 年之后大放异彩。 2009 2009 年之前，我们看到值得纪念的里程碑大多数是少数几个药物在不同癌种或者条件下的应用突破。但 2009 年的 ASCO 大会，研究人员分享了一类新型靶向药物首个令人鼓舞的发现，代号为 AZD2281 的药物适用于难以治疗的 &quot;三阴性 &quot;乳腺癌和那些涉及到 BRCA1 BRCA2 基因突变的乳腺癌。这类药物就是如今我们所知的 PARP 抑制剂，而 AZD2281 的中文名字叫做奥拉帕利（Olaparib）。 PARP 抑制剂旨在使癌细胞用于修复 DNA 损伤的关键酶失效并促使癌细胞死亡。它们还可能使癌细胞对其他治疗如化疗药物更加敏感。当然，彼时还需要进一步长期随机临床试验来确定 PARP 抑制剂是否真正有益于乳腺癌患者，如果是的话，哪些特定类型的乳腺肿瘤最有可能对该药物产生反应呢？其它癌种效果如何？这些都是以后的故事。 2010 时间来到 2010 年，从 2010 年开始靶向药物抗击肿瘤的里程碑逐渐增多。旧的明星药物继续在其它领域开疆拓土，用于后线治疗的药物慢慢上位，新的靶点药物也在这一年问世。 大约 80%的转移性乳腺癌妇女经历了癌症扩散到骨骼，这种并发症会导致疼痛、骨骼变弱和其他影响生活质量的副作用。2010 年，一项大型研究显示名为地舒单抗（Denosumab）的靶向药物可以预防或明显推迟骨转移。 达沙替尼（Dasatinib）和尼罗替尼（Nilotinib）用于慢性骨髓性白血病的一线治疗可能比当时的标准药物伊马替尼 (Imatinib) 更有效，尽管这三种药物针对的都是 「费城染色体」上相同的活性遗传途径，但研究表明较新的药物可能会引起更快、更强的反应，并且比伊马替尼 (Imatinib) 引起的副作用更少。 一项大型长期试验确定，在标准药物氟达拉滨的初始治疗中加入靶向药物利妥昔单抗（Rituximab）可以减缓慢性淋巴细胞白血病的进展并改善患者生存。这是有史以来发现的第一个能明显延长该疾病患者生命的药物治疗方案。试验发现，超过 10%的接受这种方案治疗的病人在十年后没有出现疾病进展。 这一年的 ASCO 大会报道了一项研究，在一线化疗中加入靶向药物贝伐珠单抗（Bevacizumab），然后将其作长期的 &quot;维持 &quot;疗法，可以显著减缓卵巢和周围组织中患有癌症的妇女的疾病扩散速度。 对于新药，在一项 III 期研究中发现 BMS 研发的靶向药物伊匹木单抗（Ipilimumab）能够改善晚期黑色素瘤患者的生存期，并延迟疾病进展。该药物在 2011 年初被 FDA 批准。不久之后，第二个试验发现，与单独使用化疗相比使用伊匹木单抗（Ipilimumab）联合化疗的组合治疗也延长了患者生存期。 伊匹木单抗（Ipilimumab）是靶向 CTLA-4 的单克隆抗体，可促进 T 细胞活化及其随后的抗肿瘤免疫作用，日后其它不少免疫相关药物也都不约而同选择在黑色素瘤中和大家见面。 这一年的另一个重头戏，来自于针对钻石突变 ALK 的药物出现。 间变性淋巴瘤激酶（anaplastic lymphoma kinase, ALK）融合基因是非小细胞肺癌的驱动基因，其发生率 3%-7%，在从未吸烟的患者中更为常见。EML4 和 ALK 两个基因分别位于 2 号染色体的 p21 和 p23。两个基因片段的倒位融合能够使得组织表达新的融合蛋白 EML4-ALK，这种融合基因又能导致肿瘤发生。之所以被称为钻石突变，是后来研究发现具有这类突变的患者使用靶向药物后疗效往往都比较好。 克唑替尼（Crizotinib）就是由辉瑞研发的一款 ALK 抑制剂。在 2010 年发表于新英格兰医学的研究数据显示，在有 ALK 基因异常的癌症患者中有很高比例肿瘤会缩小。 2011 年，根据长期实验数据，该药物被 FDA 批准用于肿瘤携带 ALK 基因突变的晚期肺癌患者。 2011 2011 年，FDA 批准了靶向药物维罗非尼（Vemurafenib），对于 BRAF 基因中存在特定突变的患者而言，数据显示该药物可以缩小肿瘤并提高晚期黑色素瘤患者的生存率。在许多情况下，患者开始这种治疗的几天内就会出现疼痛的大幅减少和肿瘤缩小。不过似乎癌症通常在几个月后又会停止对这种新型药物的反应。 维罗非尼在黑色素瘤细胞系中可以引起程序性细胞凋亡。如果 BRAF 具有 V600E 突变，维罗非尼会中断 BRAF/MEK/ERK 通路上的 BRAF/MEK 步骤。 至于 Plexxikon 和 Genentech ，作为共同研发这款药背后的两家公司，后者于 2009 年已经被罗氏收购，前者则在 2011 年 4 月被日本制药公司第一三共 (Daiichi Sankyo) 收购。 2012 要在 2012 年挑一个癌种来讲，那应该是 HER2 阳性乳腺癌。同样在新英格兰医学杂志，2012 年初和 2012 年末先后发表了两项 HER2 阳性的乳腺癌研究。 在 2012 年初的研究结果中显示，培妥珠单抗（Pertuzumab）和曲妥珠单抗（Trastuzumab）两种针对 HER2 的药物与标准化疗一起进行治疗，可大幅减缓晚期 HER2 过表达的乳腺癌肿瘤生长速度。 这项研究的另一个意义在于为探索将两种或更多针对相同分子途径的药物结合的研究增添了新的思路和信心。 2012 年 11 月发表的文章又将开启一个新的靶向药物时代。恩美曲妥珠单抗（T-DM1）是一种抗体-药物偶联物，兼有曲妥珠单抗（Trastuzumab）靶向 HER2 抗肿瘤作用和微管抑制剂 DM1 的细胞毒性作用。抗体和细胞毒性药物通过稳定的连接物共价连接。该药物旨在与癌细胞上的 HER2 蛋白结合，并直接将这些药物输送到肿瘤中，最大限度地减少对体内健康组织的不良影响。 在一项研究中，将曾接受曲妥珠单抗（Trastuzumab）和紫杉醇治疗的 HER2 阳性晚期乳腺癌患者随机分配到 T-DM1 组和拉帕替尼（Lapatinib）联合卡培他滨组。T-DM1 组的中位无进展生存期为 9.6 个月，拉帕替尼（Lapatinib）联合卡培他滨组为 6.4 个月，且 T-DM1 组的客观有效率较高（43.6%对拉帕替尼联合卡培他滨组的 30.8%；P&lt;\\0.001）。 基于此，FDA 在 2013 年批准了 Genentech 研发的 T-DM1 用于晚期 HER2 阳性乳腺癌，而 9 年之后的 2022 年，第一三共和阿斯利康共同研发推广的 ADC 药物 T-DXd(Enhertu) 通过 DESTINY-Breast03 研究狂虐 T-DM1 又是另外一个故事。 2014 如果说 2012 年是乳腺癌备受关注的一年，那么到了 2014 年黑色素瘤又一次重新走到了前端。2014 年也是 PD-L1 和 PD-1 抑制剂正式走上历史舞台的一年，FDA 批准了帕博利珠单抗（Pembrolizumab）和纳武利尤单抗（Nivolumab）两种免疫疗法治疗黑色素瘤，也加速批准了曲美替尼（Trametinib）和达拉非尼（Dabrafenib）对携带某些 BRAF 基因突变的晚期或无法手术的黑色素瘤患者进行联合治疗。 2014 年 11 月，新英格兰医学发表了一项 BRAF 抑制剂和 MEK 抑制剂联用与单独使用 BRAF 抑制剂治疗黑色素瘤的比较研究，研究表明新方案能使大多数患者获得持久的反应。 2014 年 7 月的柳叶刀杂志，一项被称为 KEYNOTE-001 研究中的黑色素瘤相关结果发表，对于伊匹木单抗（Ipilimumab）治疗后进展的晚期黑色素瘤患者接受默沙东的帕博利珠单抗（Pembrolizumab）治疗表现出了一定的效果，ORR 为 26%。这对于那些几乎没有有效治疗选择的患者来说可能是一种有效的方法。 帕博利珠单抗（Pembrolizumab）作为一种「免疫检查点抑制剂」，通过阻断名为 PD-1 的途径发挥作用，该途径可以阻止身体的免疫系统攻击癌细胞。 同样也是免疫检查点抑制剂的纳武利尤单抗（Nivolumab）由 BMS 研发，在 2014 年和 2015 年先后发表了多篇文章。研究结果显示其可以在服用伊匹木单抗（Ipilimumab）和 BRAF 抑制剂后病情恶化的黑色素瘤患者中产生持久反应。对于没有 BRAF 突变的转移性黑色素瘤患者中，纳武利尤单抗（Nivolumab）与化疗相比，在总体存活率和无进展存活率方面有显著改善。 2015-2017 帕博利珠单抗（Pembrolizumab）和纳武利尤单抗（Nivolumab）的比赛，在 2014 年的黑色素瘤治疗中仅是一个开端。之后的三年时间，他们在不同癌种里的治疗竞赛全面展开，也彻底打开了肿瘤免疫检查点抑制剂的时代。当然，紧随其后入局的还有罗氏研发的 PD-L1 抑制剂阿替利珠单抗（Atezolizumab）。 2015 年到 2017 年这三年时间，上述三种免疫疗法被 FDA 批准用于化疗恶化的晚期非小细胞肺癌患者，纳武利尤单抗（Nivolumab）获批用于晚期肾细胞癌患者。 越来越多的研究表明，对于标准治疗没有反应的霍奇金淋巴瘤患者，使用 PD-1 抑制剂的免疫疗法也可以带来明显的好处，可以使以前接受过许多癌症治疗的患者得到缓解，这使得 FDA 分别在 2016 年和 2017 年对这两种药物的适应症给予加速批准。 BMS 眼看自己的伊匹木单抗（Ipilimumab）在免疫治疗道路上被后来的三个弟弟围起来打，就又开辟了另外一种新的免疫治疗角度。在 2015 年和 2016 年先后发表都结果证明术后使用伊匹木单抗（Ipilimumab）辅助治疗可以降低早期黑色素瘤的复发风险并延长生存时间。这也标志着首次研究显示伊匹木单抗（Ipilimumab）对早期黑色素瘤的有效性。 除了对一部分患者进行无差别的治疗外，2016 年的研究发现，对于晚期非小细胞肺癌中表达高水平 PD-L1 蛋白的患者来说，帕博利珠单抗（Pembrolizumab）可以提高生存率并比标准化疗引起的副作用更少。此后，这一研究为这种类型的肺癌建立了新的治疗模式，免疫疗法成为 PD-L1 阳性的首选疗法。 同样在 2016 年，一项早期临床试验中，阿替利珠单抗（Atezolizumab）迅速缩小了先前接受治疗的晚期尿路上皮癌患者的肿瘤，特别是 PD-L1 含量高的患者。基于此 FDA 批准阿替利珠单抗（Atezolizumab）用于治疗晚期尿路上皮癌，成为 30 年来第一个新的膀胱癌治疗方法。 虽说这三年抗击肿瘤都里程碑多数都来自免疫，但仍旧有一类新的乳腺癌治疗方法在此期间问世，那就是细胞周期蛋白依赖性激酶 (CDK) 抑制剂。 哌柏西利（Palbociclib）作为CDK抑制剂的首个药物，能阻止控制细胞分裂的关键蛋白。在临床试验中，标准激素疗法中加入哌柏西利（Palbociclib），将癌症恶化的时间在初治患者中延长了 11 个月，对于以前接受过治疗的患者则延长了约 5 个月。2015年，FDA加速批准哌柏西利（Palbociclib）联合来曲唑作为作为一线治疗用于激素受体阳性和 HER2 阴性的晚期乳腺癌患者。2016年，FDA加速批准哌柏西利（Palbociclib）与氟维司群用于治疗激素治疗后病情恶化的晚期乳腺癌。 阿贝西利（Abemaciclib）作为另一种CDK4/6抑制剂，2017年被批准为第一个用于先前接受内分泌治疗和化疗转移性患者的CDK4/6抑制剂单药治疗。 2018 时间来到 2018 年，肿瘤靶向治疗历史中的里程碑大年，这一样在多个癌种中的多种药物都有重大突破。 首先是免疫治疗领域。罗氏的阿替利珠单抗（Atezolizumab）为了应对 O 药和 K 药，开始在免疫联合治疗以及一些难治性肿瘤中发力。 2018 年发表的 IMpassion 130 试验结果中，表达 PD-L1 的肿瘤患者在接受联合治疗时无进展生存期得到了改善。阿替利珠单抗（Atezolizumab）联合化疗不仅成为了第一个被批准用于乳腺癌的免疫疗法，也是对预后极差的晚期三阴性乳腺癌患者的一个重要进展。 同样 2018 年发表，IMpower 133 的实验结果显示化疗基础上加用阿替利珠单抗（Atezolizumab），小细胞肺癌生存期明显延长。这种联合疗法于 2019 年被 FDA 批准，已成为小细胞肺癌的标准疗法。 接下来是我们在 2009 年就曾提到的 PARP 抑制剂。 2017 年一项针对晚期 BRCA 基因胚系突变相关的乳腺癌临床试验显示，与标准化疗相比，PARP 抑制剂奥拉帕利（Olaparib）能降低癌症进展风险且副作用更少。 大约 5% 未经选择的乳腺癌患者携带胚系 BRCA 突变。基于这些数据，2018 年初奥拉帕利（Olaparib）被 FDA 批准用于这一用途，也标志着首次有药物被批准用于治疗有胚系 BRCA 基因突变的转移性乳腺癌患者。 除了在乳腺癌里的应用，奥拉帕利（Olaparib）在新诊断晚期卵巢癌患者的维持治疗中也有了新的突破。 一项名为 SOLO 1 的三期试验在 2018 年底发表，结果说明患有新诊断的晚期 BRCA 突变卵巢癌患者，手术和化疗后接受 PARP 抑制剂奥拉帕利（Olaparib）的维持治疗与不接受维持治疗相比，疾病进展或死亡风险降低了 70%。这些结果不仅使 FDA 批准了奥拉帕利（Olaparib）用于这一适应症，而且代表着在治疗这种类型的癌症患者方面又向前迈出了一大步。 还记得 2004 年获批的厄洛替尼（Erlotinib）么？随后的 14 年时间里，EGFR-TKI 药物有了巨大发展。因为各种耐药情况的出现，已从一代走到三代，2018 年奥希替尼（Osimertinib）登场。由阿斯利康开发的奥希替尼（Osimertinib）是一种口服第三代 EGFR-TKI，它可选择性地抑制 EGFR T790M 耐药突变。 在 FLAURA 试验中，奥希替尼（Osimertinib）与两种标准的 EGFR-TKIs 相比，对以前未治疗的 EGFR 突变阳性晚期非小细胞肺癌患者的无进展生存期延长了近 80%，中位无进展生存期为 18.9 个月，疾病进展或死亡的风险比标准组低 54%。在 AURA3 试验中，与化疗相比奥希替尼（Osimertinib）也改善了患者的生活质量。 基于这些研究，奥希替尼（Osimertinib）在 2018 年被批准用于一线治疗转移性非小细胞肺癌且存在 EGFR 19del 或 21 号外显子 L858R 突变的患者。同时，它也成为确诊 EGFR T790M 阳性患者的新标准一线疗法，这些患者往往在使用其他 EGFR-TKIs 一线治疗后耐药并复发。 最后，还是 2018 年，一种名为拉罗替尼（Larotrectinib）的新药在两项临床试验中表现出了积极的结果。 拉罗替尼（Larotrectinib）可以择性地针对存在于各种实体瘤中的一类基因组异常 NTRK 融合。这种异常在常见癌症的发生频率为 0.5%至 1%，但在某些罕见难治癌症中，如唾液腺癌、儿童乳腺癌和婴儿型纤维肉瘤，它的发生率可以高达 90%。 一项早期临床试验中，拉罗替尼（Larotrectinib） 在包扩成人和儿童的多种类型的 NTRK 融合癌症中产生了强烈持久的效果。另一项只关注儿童癌症的实验中，发现该疗法几乎能使所有 NTRK 融合患者的肿瘤缩小。这也证明精准医学治疗可使儿童癌症患者受益。基于这些发现 FDA 加速批准拉罗替尼（Larotrectinib）用于患有 NTRK 融合的晚期或无法手术的实体瘤癌症患者。 2019 2019 年，再来关注一下 CDK4/6 抑制剂药物。 瑞博西利（Ribociclib）作为一种另一种 CDK4/6 抑制剂药物，与内分泌疗法联合可以为晚期 HR+ HER2- 乳腺癌绝经前和围绝经期的患者带来总体生存获益。这一年发表的 MONALEESA-7 试验结果显示，瑞博西利（Ribociclib）的 42 个月生存率为 70.2%，而接受安慰剂加标准内分泌治疗的妇女仅为 46%。这种治疗组合对于治疗患有这种疾病的年轻女性是一个重要步骤，因为她们的肿瘤往往更具侵略性，生存率比绝经后的患者更差。 写在最后 至此，根据文章开头提到的Cancer Progress Timeline，我们就梳理了癌症靶向治疗，从1960到2019年的一些重要里程碑。至于最近三年哪些是重要的靶向治疗相关里程碑，可能还需要一些时间的沉淀。 另外，为了便于阅读学习，我把Cancer Progress Timeline 的所有内容扒下来整理了一下，顺便也弄了个非常粗糙的翻译版本供你参考。 Cancer Progress Timeline 英文整理版 Cancer Progress Timeline 中文整理版 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-09-17-cancer-progress-timeline/"},{"title":"同样做肿瘤NGS检测，美股上市的9家公司近况如何","content":" 声明：本博客所有文章的专业/行业相关信息全部来源于公开资料，且所有内容和观点仅代表个人。 写在前面 很多东西，单独看一个点看不出什么，但相似的东西摆在一起还能耐住性子看过去，往往就比较有意思，比如文献，比如财报。 8 月 31 日，随着燃石 2022 Q2 财报的发布，除了计划私有化的泛生子，美股上市且主要业务包括肿瘤 NGS 检测的几家同类型又各有特点的公司，2022 Q2 财报已悉数发布。 本文涉及到的九家公司包括：Natera、Guardant、Exact Sciences、Myriad、Veracyte、Invitae、Oncocyte、GRAIL 和燃石医学。 其中，GRAIL 因为被 Illumina 收购，所以其营收内容展示在后者财报中。而除了燃石总部在中国，其它 8 家公司的全部位于美国。 如果说大家的财报有一个主旋律，那就是亏。但各有各的家底，各有各的亏法，也各有各的侧重。除了关注主要财务指标，还应该留意这些公司在财报中提到了哪些其它信息。 因为篇幅有限，本文提到的每家公司我们以后都可以详细展开聊聊他们的核心产品和产品背后的临床试验与应用方向。 Natera Natera 成立于 2004 年，在 2017 年如今行业最熟悉的 Signatera 面世之前，其核心业务集中在无创产前检测 NIPT 领域。 用创始人 MATTHEW RABINOWITZ 的话说：2004 年他姐姐生下了一个患有唐氏综合症的儿子，仅仅出生六天后就去世，创建 Natera 是因为相信所有家庭都应该获得能够及早发现遗传病的技术。 不过最近几年，他们的 MRD 产品 Signatera 像开了挂一样，迅速吸引了大家的目光。比如，2019 年 3 月，华大更是宣布和 Natera 合作完成 Signatera 在中国的商业化落地（中文名：华见微）。 这次合作华大花了多少钱呢，答案是 5000 万美元。 回到 Natera 2022 年第二季度财报。 主要受 Signatera 强劲增长的推动（特别是在结直肠和免疫治疗），其第二季度总收入增长了 40%，收入增加到 1.982 亿美元，去年同期为则 1.42 亿美元。 第二季度净亏损 1.452 亿美元，2021 年同期为 1.16 亿美元。 截至 2022 年 6 月 30 日，Natera 持有约 6.387 亿美元的现金、现金等价物、短期投资和限制性现金（其中现金和现金等价物 0.91 亿）。 比较有意思的是，他们也自信地在财报中写到：结合今年的发展，公司有信心在 2024 年中期实现现金流平衡。（flag 先立在这里，我们 2024 Q2 再来） 在 Earnings Pre 中，他们特别强调了 Signatera 医疗保险覆盖范围已经包括了肌肉浸润性膀胱癌（MIBC）。而 MIBC 的预估市场则可以达到每年 40 万的检测量。 目前其产品可覆盖的报销人群如下图所示。 关于 Signatera 在泛癌种的临床试验，可以看到已经涵盖结直肠癌、胃食管癌、胰腺癌、乳腺癌、卵巢癌和黑色素瘤。 Guardant Guardant 是一家从成立之初就专注于全周期跨癌种液体活检（血液检测）的公司，用他们自己的话说 Our goal from day one has been to provide blood tests that span all stages of cancer. 具体如何实现，大概是下图所示的几个方向。 第二季度财报显示，截至 2022 年 6 月 30 日的三个月收入 1.091 亿美元，比 2021 年同期的 9210 万美元增长 19%。其中受到临床检测量和生物制药公司样品量增加的推动，肿瘤业务收入增长 27%。 截至 2022 年 6 月 30 日，现金、现金等价物和有价证券为 12 亿美元，其中现金和现金等价物 2.15 亿美元（2021 年底为 4.92 亿美元）。第二季度净亏损 2.29 亿美元，而 2021 年同期为 0.97 亿美元。 在具体的细节内容中，Natera 一方面也是提到医保，另一方面强调了药企合作业务的增长。 而在全球化策略中，可以从上图看到他们特别提到中国的一家公司艾迪康，早前报道显示，Guardant 的 Guardant360 和 GuardantOMNIO 都已经完成了国内授权。 针对公司最重视的结直肠早筛监控，按照 Guardant 的说法正在释放出 20 个 billion 的市场机会。 更多的产品策略可以从下图略知一二。 多说一句，开头我们提到的这两家公司在 MRD 领域互相一直不对付。针对产品的性能没少搞事情，从 2021 年 5 月开始就一直在打官司，而同行只能静静地看他们表演。 Exact Sciences Exact Sciences 成立于 1995 年，2001 年进行首次公开募股。 纵观 Exact Sciences 的发展，能够进行结直肠癌粪便筛查的 Cologuard 可以说是其最核心的一款产品。依托于万人入组的大型临床研究 DeeP-C，Cologuard 的安全和有效性得到充分证实，并于 2014 年获得美国 FDA 批准用于结直肠癌检测。 除此以外，最近几年他们的液体活检产品 OncotypeDX 则是另外一项重要业务。OncotypeDX 目前已经在前列腺癌，乳腺癌和结直肠癌中有了不同方向的应用。 接下来看看他们的 2022 Q2 财报数据。 不同于其他几家 NGS 检测公司，Exact Sciences 在这波疫情中参与了 COVID-19 检测业务。 公司第二季度的总收入为 5.216 亿美元，比 2021 年同期的 4.348 亿美元增长 20%。在三块主要业务中，Screening 业务达到 3.54 亿美元，超过 67%，肿瘤相关的业务收入为 1.54 亿美元，同比增长约 12%。COVID-19 检测占了零头 0.14 亿美元。 Exact 整个第二季度的净亏损为 1.661 亿美元，而去年同期的净亏损为 1.769 亿美元。第二季度末的现金和现金等价物为 2.134 亿美元，有价证券还有 5.146 亿美元。 关注的主要内容和突破可以在下面两张图中一目了然：基本盘是结直肠癌筛查，还有多癌种早筛和 MRD 监控。 值得注意的是，在这次财报中宣布将放弃 Oncotype DX 在前列腺中的检测，以高达 1 亿美元的价格出售给 MDx Health。 Myriad 论资历，成立于 1991 年的 Myriad，是没有多长历史的历史长河里成立最早的基因组公司之一。1994 年他们的科学家在 Science 中发表论文发现了 BRCA1 基因与遗传性乳腺癌和卵巢癌有关。1995 年就已经正式在 NASDAQ 上市。 通读财报，几个关键数字。 Myriad 2022 年第二季度收入同比下降了 5%。该期间的总收入为 1.793 亿美元，低于去年第二季度的 1.894 亿美元。本季度净亏损 1410 万美元，去年同期亏损 470 万美元。第二季度末拥有 1.052 亿美元的现金和现金等价物。 看点细节。商业化的核心检测业务包括了三大部分，分别是心理健康检测业务（涵盖 64 种精神疾病检测能力的 GeneSight），女性健康检测业务（产前检测），以及我们最为熟悉的肿瘤检测业务。 其肿瘤业务在 2022 年第二季度收入 7610 万美元，同比下降 3%，但比第一季度连续增长 9%。 具体到肿瘤业务，Myriad 提供遗传性肿瘤检测，比如 MyRisk；还提供肿瘤诊断相关产品，如 myChoice CDx （HRD 检测）、Prolaris 前列腺癌检测和 EndoPredict 乳腺癌预后检测。 MyChoice CDx 2022 年第二季度在美国的季度交易量达到历史最高，同比增长 63%，比 2022 年第一季度则连续增长 10%。 前列腺癌预后检测产品 Prolaris 在 2022 年第二季度也实现最高季度销量，比之前的季度销量记录高出 6%。 Veracyte 成立于 2008 年的 Veracyte 是一家明确定位为肿瘤诊断的公司，诊断产品主要包括了如下图所示的 6 个。其中不少产品的主要用途是对单一癌种进行临床相关的分型。 2022 年第二季度总收入 7290 万美元，与 2021 年的 5510 万美元相比增长了 32%，同样包括了三个主要部分。 其中，检测收入为 5970 万美元，与 2021 年第二季度的 5080 万美元相比增长了 18%，主要是由泌尿科相关产品的增长推动；产品收入为 310 万美元，与 2021 年第二季度的 270 万美元相比增长了 16%；生物制药和其他收入为 1000 万美元，与 2021 年第二季度的 160 万美元相比增加了 840 万美元，主要是由收购 HalioDx 的贡献所推动。 Veracyte 第二季度的净亏损为 950 万美元，而去年同季度为 900 万美元。 本季度末拥有现金、现金等价物和短期投资 1.640 亿美元。预计 2022 年全年总收入将达到 2.72 亿美元至 2.8 亿美元，同比增长 24%至 28%。 公司的四个主要中长期增长策略。 在不同癌种中的产品布局。 Invitae Invitae 成立于 2010 年，根据最新的财报显示，其 Q2 收入 1.366 亿美元，与 2021 年第二季度的 1.163 亿美元相比增长了 17.5%。截至 2022 年 6 月 30 日，现金、现金等价物还有 3.03 亿美金。 Q2 净亏损 25 亿美元，在财报中特别给出了说明，之所以能亏这么多，主要是因为净亏损包括了 23 亿美元的商誉减值，这是由于股价和相关市值的持续大幅下跌以及低于预期的财务业绩的结果。 在财报中 Invitae highlight 了三点内容，分别对应医疗机构，药企合作和患者人数。 其中特别提到，超过 310 万的患者总人数中近 62%可用于数据共享。之所以关注数据共享，是因为 Invitae 把患者的真实世界数据管理，看做未来重要的增长方向。 关于烧钱速度，Invitae 也给出了一个比较乐观的预期。 预计 2023 年将从 6 亿美元下降到 3 亿以内，还专门强调，按照目前的现金储备烧到 2024 年底不成问题。（又是一个 flag，且看） Oncocyte Oncocyte 成立于 2009 年，最主要的产品是肺癌诊断相关的产品 DetermaRx。 Oncocyte 的财报显示，其第二季度的总收入为 210 万美元，2021 年第二季度为 200 万美元。净亏损 830 万美元。截至 2022 年 6 月 30 日现金和现金等价物还有 4480 万美元。 关于产品相关的细节披露中。与 2021 年第二季度相比，DetermaRx 的样本量增长了 66%。另外一项免疫治疗相关产品 DetermaIO，其临床合作伙伴在 ASCO 和 AACR 上供提交了五份摘要，扩大了 DetermaIO 与六种不同癌症类型决策的临床相关性的证据。其中独立前瞻性随机临床试验表明，DetermaIO 可以识别并扩大结直肠癌的免疫检查点抑制剂的患者。 此外，他们 highlight 了比较有意思的两点内容。 一是裁员。知道自己钱剩下的不多，他们表示组织结构调整预计每年将减少超过 450 万美元的人力成本，其它的成本削减算在一起，预计 2023 年的年运营成本将比 2022 年减少约 1200 万美元。 二是特别提到了国内的燃石。由于燃石引进了 Oncocyte 的 DetermaRx Lung Cancer Assay（中文名：朗迪瑞），Oncocyte 今年也因此获得了 100 万美元具有里程碑意义的付款。 GRAIL 作为一家专注于肿瘤早检的公司，GRAIL 2021 年 8 月被 Illumina 收购之后，其核心经营数据也纳入了母公司的财报。后者 2022 年 Q2 的财报就分成了两个部分，其中一部分是 Core Illumina，另一部分是 GRAIL。 关于 Core Illumina 不谈，我们仅仅捡出来 GRAIL 的部分看看。先说结论，一个季度亏了 1.87 亿美元。 在 PPT pre 上，Illumina 展示了 GRAIL 被收购之后的一些大动作。 比如： 在 NHS-Galleri 试验中招募了 14 万名参与者，这是多癌症早检队列最大的研究 与阿斯利康开展战略合作开发相关的诊断产品 与 Mercy Healty 和 Ochsner Health 展开合作将 Galleri 的服务范围扩大到全美 备受关注的 PATHFINDER 研究，在 2022 年马上就要召开的 ESMO 大会将发布最终研究结果 另外，PPT 里没写，但是财报里提到的。与 Fountain Health Insurance 合作，提供 Galleri 作为年度福利；另一方面，与美国退伍军人事务部和退伍军人健康基金会合作，在未来 3 年向全美 10,000 名退伍军人提供 Galleri。 这么多大动作，直接反映在钱上得多费钱呢？ Illumina 随后展示 GRAIL 营收 1200 万美元，支出 1.56 亿美元。烧钱主要还是在人力和临床试验，甚至这个数字由于他们 G&amp;A 费用控制，要比预期少了一些。 可以多说一句的是，Illumina 现在野心之大和头之铁。 一年前收购 Grail，案子本身就没有通过美国和欧盟的审查许可。在这个行业里的人都明白，你一个卖仪器的上游企业，收购一个用仪器的下游公司。这做法，越看有点越像大洋彼岸的……。 收购一年之后，Illumina 前一阵子刚刚表示公司已经拿出了接近 5 亿美元的预算，为欧盟可能征收的巨额罚款做好准备。 燃石医学 看完楼上 8 家公司，最后看看唯一的国内公司燃石。 燃石成立于 2014 年，相比于其他几家美国公司要更晚一些。不过依靠持续的研发投入如今也带来了产品能力的回报。 以早筛为例，自 2016 以来，燃石基于甲基化策略的早筛产品已经进行了多次迭代升级，完成了从 6 癌种到 9 癌种再到 22 癌种的监测和溯源。 在最新发布的财报中，燃石 highlight 三部分内容： 院内诊断和 MRD 推动增长，新产品占中心实验室收入的 7% 早筛 PROMISE 中国首个前瞻性、多癌种液体活检多组学验证性研究结果，和 GRAIL 一样也会在下个月的 ESMO 公布结果；PREVENT 万人前瞻性干预研究已经在 2022 Q2 启动 药企合作收入持续增长，2022 年上半年收入同比增长 166.6%，且新合同价值 1.58 亿人民币，同期也增长了 49%。 强调这三点，多少能看出一些东西。 比如入院和 MRD 产品是目前高度关注的两个趋势；早筛的两个研究体现了对于相关业务未来稍远几年的强烈预期；药企服务，在疫情持续不明朗，影响中心实验室和院端主要核心业务的几年，似乎成为了一个被愈发看重的业务营收增长点。 当然，这些具体内容也都可以在 Earnings Pre 中看到详细介绍。 关于具体营收。 截至 6 月 30 日，整个二季度收入为人民币 1.308 亿元（1950 万美元）, 毛利 8260 万元。三个核心板块中，中心实验室业务收入人民币 7860 万元（1170 万美元），院内业务收入人民币 3420 万元（510 万美元），药企服务收入人民币 1807 万元（270 万美元）。 过去一年半的中心实验室送检量如下图。 再来看看入院的情况，合作医院数量和 Q1 相比还有 3 家增长。 同时，在 Earnings Pre 中燃石也特别提醒了 COVID-19 对于业务的影响。 其中院内，全国除上海北京以外 60%的强劲增长被上海北京 49%的销量减少抵消。上海和北京的销量实在是太重要了。 钱花到哪里了呢？ 财报显示，研发费用人民币 9211 万元（1380 万美元），销售和营销费用为人民币 1.056 亿元（1580 万美元），一般和行政费用（G&amp;A）人民币 1.5 亿人民币（2240 万美元）。 截至 6 月 30 日的三个月，净亏损人民币 2.621 亿元（3,910 万美元），而 2021 年同期为人民币 2.037 亿元。还有现金和现金等价物 11.48 亿人民币（1.714 亿美元）。钱不缺，这点和上面我们提到的 Invitae 类似。 此外，对于 MRD 和早筛的重视，也在整个 Earnings Pre 中随处可见。 早筛内容里，他们特别介绍了自己的早筛技术和多癌种早筛优势以及深度合作的大佬们。 在 MRD 方向上则详细展示了自己的发展策略和临床试验进展。 写在后面 上市公司的好处（对于行业从业者）就是每季度发布的财报给了我等打工人一个更全面了解行业和公司的小窗口。 写到这里，我们就看完了这 9 家公司 Q2 的整体情况和未来的一些发展重心。 整体受到经济环境周期和 COVID-19 的影响，大家就是一起亏亏亏。面对这样的现实，不差钱的、有靠山的继续迈开步子向前，多数公司都需要重新思考，开始很难避免的人员架构调整和研发投入调整。 最后的最后，再来看一看这几家公司目前的市值吧。我们下次见。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-09-01-tumor-ngs-2022q2-financial-results/"},{"title":"30 岁，让我们成熟和改变的不是生日而是生活","content":"写在前面 30 岁，有人开始发现自己不再年轻，有人开始焦虑自己的目标、成功和失败，30 岁在 20 岁看来也许觉得好笑，在 40 岁看来也许又觉得矫情。不管怎么说，我的 30 岁还是来了。 发这篇文章时，已是我在 30 岁路上的第 4 天，此刻才有时间和你聊聊，同时感谢之前所有人的祝福。 伦写生日文，我最佩服《失控》的作者凯文凯利（KK）。68 岁生日，他写下 68 Bits of Unsolicited Advice，给出了自己 68 岁时的 68 条忠告。69 岁生日，他写下了 99 Additional Bits of Unsolicited Advice，给出了自己 69 岁的 99 条忠告。今年等来了他 70 岁生日主题文 103 Bits of Advice I Wish I Had Known。嚯，这次直接增加到了 103 条。 崇拜谁就模仿谁，所以很早之前我给自己定下了 30 岁写 30 条感悟的目标。嗯，如你所见，没写出来。还是熊言熊语，随便聊聊。 也许 29 岁最后一天和 30 岁第一天的我们不会有多少质的变化。真正让我们成熟的是那些生活和其中为数不多的经历，或让人恍然大悟，或让人追悔莫及，或让人晕头转向，也可能让人继续前行。 有些人 30 岁的经历你可能在 20 岁已经习得，有些人 30 岁的感受你可能要等到 40 岁才有所体会。 许久没联系的发小前几天微信问我作为三旬老汉有何感受。我这个发小本科毕业 7 年时间里先后换了三份工作，英年早婚，孩子已经能打酱油，如今安家在一个南方城市。我猜他不是真心求教，便说：开始感受社会的暴击。 他回复我：很好，那就不用我了，生活能教你做个人。 29 岁这一年，当我拿到一本建行绿色「个人住房抵押贷款合同」，翻开 X00 万贷款还款 30 年那一页时，脑子里突然冒出了万青的一句歌词：如此生活 30 年，直到大厦崩塌。 也许这就是 30 岁，开始需要抵押自己的生活。 29 岁这一年，是我开始工作的第一年。蛮幸运，在喜欢的行业喜欢的公司和一些厉害的人做一点喜欢的事。和多数刚开始工作的朋友类似，我对工作投入了巨大的精力和感情，有点像我第一次走进大学校园和第一次走进研究生课题组的实验室。做的每件事情都会有收获有遗憾，胖胖的脑袋里塞满了各种各样的问题。 也许这就是 30 岁，问题往往留给喜欢解决问题的人，不过「能者多劳」不等于「多劳多得」，前者 always 后者 just sometimes。 29 岁这一年，当我在魔都封闭的三个月里，因为行业寒冬和大环境，亲历公司组织架构优化的那一刻，一切都很平静又不平静。 也许这就是 30 岁，有人需要对企业和股东负责，而你和我需要对自己负责。 应该 珍惜可以做决策的机会 我不是一个擅长独立做决策的人，30 岁的我意外发现不少人和我一样，无论比我年轻 10 岁还是年长 10 岁。至于原因，我想无外乎是缺乏自信和害怕承担。 面对决策时，如果你心里已经有了一个答案，就没有必要再去关注别人的回答，不如可以刻意搁置几天之后再问问自己的答案。 我们会把罚点球的机会交给别人，不是因为相信别人更准，也可能是害怕承担没踢进的责任。放弃决策的机会就等于提前找了条退路：这件事不是我决定的，是综合考虑之后大家（多数人）的意思。 问题在于，只要你是最终决策者，无论大家的意思是不是你真实的意思，最后它都会变成你的意思呈现。有些事不是你的错也并不意味着不是你的责任。 此外，我们很少有机会直面重大决策，即便有些当下看起来迫在眉睫，但放在 3 年 5 年哪怕稍微长那么一点点的尺度上都会没多重要。大方向定了，一些小决定无论怎么下都不会差别太多，所以本身也不需要承担多大责任。 最后，不敢做决策还可能是由于我们主动限制了选择，我们习惯于根据已拥有的内部信息和容易看到的眼前影响做出决策。当我们在 A 还是 B 极度纠结时，也许稍微尝试下发现是可以选择 A 和 B 的。 当我们拥有独立决策机会的时候，不妨勇敢做出决策，然后承担这个决策带来的结果。 更多关注自我的感受 我是一个偏讨好型人格的人，从小到大想要做到足够好，让所有人都尽可能满意。如今到了 30 岁仍然会时常在意外部评价。我经常强调希望听到正负两面的完整评价，以为我们多数人都处在游戏规则中，在这个规则里人和人之间的评价与被评价构成了彼此的认知基础。 这一年的经历让我意识到，基于外部反馈构建的价值体系，把自我的认知体系依托于外部评价，是容易崩塌的。即便看起来已经是良好的评价体系也很难真正做到明晰、一致和开诚布公，你能听到的是可以听到的，我能讲出来的也只是愿意讲的。 在很多心理学的书籍中（比如《被讨厌的勇气》），都会提到「课题分离」的概念。「课题分离」概念是奥地利心理学家阿德勒提出，指的是要解决人际关系的烦恼就要区分哪些是你的课题，哪些是他人的课题。我们每个人只需要把自己负责的课题做好，而一件事情最终的结果由谁来承担就是谁的课题。比如，信任别人是你的课题，别人如何看待你的信任是别人的课题。 我们每个人都在路上，不要去开别人的车，也不要让别人我们的车，开好自己的车就可以了。我们因为不想被外界认为自己不好然后在意他人的感受，这不是对他人的关心而是对自我的执着，从课题分离的角度来思考，过分在意「他人怎么看」的生活方法其实反而是「以自我为中心」的生活方式。 因此，我们需要更多地去关注自我的感受，同时把对于自我执着转换为对别人真正的关心。 长时间的社会教育下，我们习惯把外部的认可和评价作为一个又一个里程碑，期待给二十岁三十岁的自己一点「交代」，但「交代」本身不是最终目的也非你能完全把控。我们要明确的，也许是阶段性可自我衡量的指标，然后一个阶段结束后去评估这些指标自己是否达到了，这是我们自己的课题。而基于此，他人是否给予了所谓的认可和评价，又变成了别人的课题。再进一步，面对呈现评价和结果，选择如何采取下一步行动，又是你自己的课题。 你真正能控制的就是自己的行动和态度。 学习如何面对失去 这篇文章在自己公众号初次发表的当天晚上，我在上海收到了老家爷爷去世的消息。 我的爷爷今年89岁，年轻的时候是个特别精神的帅小伙，工作之后因为工伤一只眼睛失明。虽然没上过什么学，但是极爱学习。 退休后，就用剩下的一只眼睛每天开始在家读字典，然后读杂志读报。好玩儿的是，杂志和报纸他从来不买，就每天去老家的河边和路边捡，为此天天被我奶奶唠叨。而这些捡回来的报纸和杂志，也成了我小学那几年难得的课外读物，有《读者》和《意林》这些，也有兵器相关的。印象尤为深刻的是有一段时间经常会捡回来《知音》和《家庭》这类杂志，每次我过去都看的津津有味。 后来，读研究生之后每年再回家，爷爷就很少能认出我来，奶奶说他老糊涂。 如今，爷爷走了，奶奶躺在床上不能下地，也糊涂了。而我，在离老家1400多公里的地方。 本来我想刻意避开「失去」这个话题，觉得时候不到，也没什么机缘思考生生死死。但让我成熟和改变的不是生日而是生活。没办法，不想面对什么，生活就给你点机会。 当我们30岁的时候，父母通常到了五六十的年纪，父母的父母也到了七八十岁。过年一年每次和家里通电话，我习惯了在最后要问一圈家里人的近况，爷爷奶奶怎么样，姥姥怎么样，大姨二姨家，我姐我哥呢。下次再打电话，已经没有机会问起爷爷了。 所以，到了30岁的年纪，终归要开始逐渐学习然后习惯面对失去。 失去的可能是一些我们试图努力争取的东西，也可能是我们习惯了感觉是理所应当的东西，比如，来自家人的照顾，甚至是家人。 写在最后 我那个发小在聊天最后说：即便社会的暴击拳拳到肉，作为胖子还好，借力打力，别伤了自己。我自然是没告诉他我在减肥，管住嘴不迈腿的方法最近瘦了 5 斤。祝所有思绪繁杂的胖子能变成波澜不惊的瘦子。 回到文章开头，关于高度抽象的道理和方法，读起来容易，但我以为只有活到那个岁数（或真有些经历了）才能有所体会。自己没炖出 30 岁的 30 条感悟这样的「鸡汤」，但还是从 KK 过去 3 年 270 条内容里随机地挑选了 10 条他的感悟分享，万一，有些内容你刚好就已经活到了呢。 You are what you do. Not what you say, not what you believe, not how you vote, but what you spend your time on. 你的所作所为将决定你是怎样的人。重要的不是说什么，信什么，或站在哪边，而是把时间花在什么上。 理解他人也一样 For a great payoff be especially curious about the things you are not interested in. 为了获得巨大回报，要对自己不感兴趣的事情特别好奇。 好奇是最好的动力 You are as big as the things that make you angry. 让你生气的事情有多大，你的心胸就有多大。 有一句类似的更火的中文版：人的胸怀是委屈撑大的。 Three things you need: The ability to not give up something till it works, the ability to give up something that does not work, and the trust in other people to help you distinguish between the two. 你需要三样东西：不奏效不放弃的毅力、不奏效敢放弃的魄力，以及对能够帮你分辨两者的人的信任。 敢于放弃敢于不放弃，明白什么时候做出选择。 Don’t be the smartest person in the room. Hangout with, and learn from, people smarter than yourself. Even better, find smart people who will disagree with you. 不要做房间里最聪明的人。和比你聪明的人在一起，并向他们学习，找到那些不同意你观点的聪明人更好。 Recipe for success: under-promise and over-deliver. 成功的秘诀在于谨慎承诺和超出预期。 Work to become, not to acquire. 工作是为了成为而不是获得。 Ignore what others may be thinking of you, because they aren’t. 忽略别人可能会怎么想你，因为他们没空想你。 If you can avoid seeking approval of others, your power is limitless. 如果你能避免寻求别人的认可，你的力量就是无限的。 Don’t be the best. Be the only. 不要做最好的。做唯一的。 The greatest rewards come from working on something that nobody has a name for. If you possibly can, work where there are no words for what you do. 最大的回报来自于人们还不知道叫什么的东西。如果可以的话去做那些人们还不知道怎么描述的事情。 扩展 凯文 · 凯利 70 岁生日的 103 条人生建议 https://kk.org/thetechnium/103-bits-of-advice-i-wish-i-had-known/ 69 岁生日99条人生建议 https://kk.org/thetechnium/99-additional-bits-of-unsolicited-advice/ 68 岁生日68条人生建议 https://kk.org/thetechnium/68-bits-of-unsolicited-advice/ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-08-13-thirty-years-old-what-i-know/"},{"title":"ctDNA系列之一：ctDNA的生物学特征、检测技术问题和临床应用方向","content":"写在前面 2022 年 6 月，中国抗癌协会肿瘤标志专业委员会（下文简称 CACA）在 中国癌症防治杂志 上发布了 ctDNA 高通量测序临床实践专家共识（2022 年版）。 2022 年 7 月，欧洲医学肿瘤学会（ESMO）精准医学工作组在 Annals of Oncology 发布了癌症患者 ctDNA 检测建议。 于此同时， 2022 年 7 月 20 日，Nature 发布了一篇高深度全基因组 ctDNA 测序在前列腺癌中的相关研究，从另一个维度揭示了 ctDNA 今后潜在的应用方向。 通过对 ctDNA 进行深度全基因组测序，可以揭示每个患者独有特征，帮助临床医生更有效地检测治疗耐药性，进而选择可以改善患者预后的个性化治疗。 随后，2022 年 8 月 1 日，Nature Reviews Clinical Oncology 发表了另一篇 ctDNA 综述：Circulating tumour DNA — looking beyond the blood，介绍了非血液样本类型中 ctDNA 的应用现状。 考虑到篇幅问题，我们将分三次完成这几篇系列文章的学习，第一篇是 ESMO 和 CACA 专家共识建议的整理学习；第二篇和第三篇是上文提到的两篇文献解读学习。 希望通过这三篇文章，可以对 ctDNA 目前的技术问题、应用方向和新的应用前景有一个相对综合的了解和把握。 说明：在这篇文章中，我们会弱化共识中具体的实验和技术细节，而是关注于两份共识中涉及到 ctDNA 生物学特征、技术分析问题和临床应用方向的内容。更完整的信息需要查阅原文档。本文整体结构基于 ESMO 临床应用建议展开，配合对应的 CACA 专家共识。 ctDNA 生物学特征 在健康人中，血浆 DNA 主要来自造血系统细胞，其浓度从可忽略的数量到高达 100ng DNA/ml，正常细胞产生的血浆 DNA 片段长度在 166bp 左右。肿瘤细胞主动分泌或在肿瘤细胞凋亡或坏死过程中释放入循环系统中的 DNA 片段（ctDNA）长度在 132~145 bp 左右，且半衰期较短（一般&lt;2 h） ctDNA 携带肿瘤细胞相关遗传特征，包括突变、甲基化、扩增重排等。ctDNA 长度、基因组位置和表观遗传标记等，可以提供信息来区分正常样本和癌症样本，并确定肿瘤的起源。ctDNA 代表了不同肿瘤亚克隆所释放的混合 DNA，可以反映特定肿瘤异质性，更好地描述肿瘤基因组特征。 血浆 DNA 的清除主要发生在肝脏，ctDNA 水平动态变化影响因素主要包括如下几项： 肿瘤病理组织类型、部位、分期、肿瘤负荷 其他来源的 DNA 干扰 克隆性造血细胞产生的 cfDNA 携带的基因突变信息 不同采样时间 药物治疗 ctDNA 是由肿瘤细胞主动分泌或肿瘤细胞在凋亡或坏死过程中释放入循环系统的 DNA 片段；其丰度受多种因素影响，波动较大，在内外因素特别是治疗压力下，其携带的生物信息可能会发生演变，且受正常细胞胚系变异或克隆性造血细胞体系突变干扰，在临床检测和报告解读过程中应特别注意。（CACA 共识） ctDNA 检测技术问题 在癌症患者中，ctDNA 根据肿瘤的不同特征而变化，其中包括肿瘤部位、疾病程度、增殖凋亡、坏死、炎症、肿瘤微环境等等。ctDNA 分析成功的关键是选择恰当的分析类型以解决特定的科学和临床问题。 目前，没有一种单一的 ctDNA 分析方法可以适用于所有目的（早检、MRD、基因突变鉴定和评估肿瘤遗传异质性、鉴定耐药分子机制等）。 在早检或 MRD 分析背景下，需要对有限数量的 ctDNA 进行超灵敏分析，而在识别与治疗耐药相关的突变和转移环境中的肿瘤遗传异质性时则需要不同的分析类型。不同的分析方法有不同的 LoD 度 LoQ，最终确定提供分析结果所需的血浆 DNA 和 ctDNA 量。 关于 ctDNA 的技术问题，需要着重从如下几个方面考虑 分析前的影响 ctDNA 的释放受到很多因素影响，比如患者特定的生理条件、炎症以及急性慢性疾病。ctDNA 的水平会受到包括化疗、靶向和免疫各种治疗方式的影响，可分为急性变化和长期变化两个阶段。 其中几天到几周范围内的急性变化受到治疗对肿瘤和正常细胞的直接影响，几周到几个月的长期动态变化与治疗对肿瘤的缩小有关。 此外，可供检测的血浆 DNA 数量与提取的血浆体积成正比，还要注意避免样品采集和处理过程中白细胞的裂解。 分析中的影响 分析过程中，假阳性和假阴性是两个主要问题。 即使是相对晚期的癌症患者，很多血浆中的 ctDNA 水平也可能很低。在 ctDNA 检测中无法检测到突变的原因可能是患者肿瘤中没有突变（真阴性）或 ctDNA 水平过低无法检测到突变（假阴性）。 在出现假阴性检测结果的原因方面，需要考虑多种技术因素，如分析的血浆 DNA 量以及不同类型突变之间可能存在的检测灵敏度差异。血浆中的 ctDNA 浓度与肿瘤分期和体积相关，一些临床和病理因素也与 ctDNA 水平相关。对 ctDNA 检测结果的解释必须考虑到血浆样本中的 ctDNA 含量不足以检测不同类型突变的可能性。 使用 CNAs、DNA 甲基化或血浆 DNA 片段分析时，需要通过确保有足够的肿瘤来源 DNA 存在增加给出真实阴性结果的可能性。下图展示了不同 ctDNA 含量可以进行的检测。 而对于假阳性结果，最大的问题来自于克隆性造血和胚系突变。 在整个细胞生命周期中，由于环境、化学因素或细胞分裂过程中的复制错误等原因，体细胞改变会在正常组织中积累。如果这些体细胞改变赋予了选择性的生长优势，它可能引起克隆性扩张并增加连续驱动突变的概率。血液中的血浆 DNA 主要来源于凋亡的造血细胞，因此这些细胞的克隆性扩张有可能造成 ctDNA 的假阳性结果。 在克隆性造血（CHIP）中突变的基因与实体瘤驱动基因有部分重叠。例如，对很大一部分晚期前列腺癌、肺癌和乳腺癌患者的基因突变检测中在血浆 DNA 出现克隆性造血相关基因（如 TP53、ATM）的假阳性。 这些假阳性在很大程度上可以通过白细胞（WBC）DNA 测序或者通过肿瘤组织样本的配对样本来尽可能排除。 因此需要留意，许多抑癌基因（如 TP53）或与 DNA 修复有关的基因（ATM 和 CHEK2）进行仅血浆 DNA 分析具有一定的挑战性，对于克隆性造血中常见的突变基因如 DNMT3A 和 TET2 尤其要小心。 针对这些问题，ESMO 的专家建议中，给出如下几点需要考虑的技术建议。 用于 ctDNA 分析的抽血时间应根据临床问题进行谨慎选择，不同的因素会影响 ctDNA 的释放（如治疗、并发炎症过程和手术等）。为了检测术后 MRD，最好在手术后至少 1 周内进行；对于愈合时间较长的大手术，可能需要 2 周或更长时间。为了进行晚期癌症基因分型，应避免在治疗响应或未进展的治疗期间进行采样，以尽量减少假阴性。 取决于处理时间和使用的检测方法，在选择血样采集管时应谨慎。 如在提取 DNA 前进行血样采集，应于-80℃ 下长期储存，尽可能减少连续的冻融过程。 假阴性（实际存在于肿瘤中的相关突变未被检测到）是 ctDNA 检测的一个重要问题，可能是由于所分析的血浆 DNA 水平低、检测灵敏度不足或&quot;非脱落&quot;（non-shedding）肿瘤造成。 当检测容易含有克隆性造血突变的基因时，克隆性造血是 ctDNA 检测中出现假阳性的常见原因。对于临床治疗可及的抑癌基因如 DNA 修复基因的检测，建议同时分析血浆 DNA 和白细胞 DNA。对于这种检测，建议从接受血浆 ctDNA 检测的患者身上常规收集富集白细胞的 Buffy coat ，以便在必要时有可用的材料排除相关影响。 在 ctDNA 中可能检测到肿瘤易感基因的致病胚系突变（如 BRCA1、BRCA2、PALB2），检测这种变异需要用验证过的检测方法判断体细还是胚系。 临床基因分型检测在今后应该适用于评估肿瘤纯度，以便有助于医生进行真阴性预测。 对于 ctDNA NGS 检测相关标准，与之相应的 CACA 共识如下。 ctDNA NGS 检测实验室质量管理需贯穿全程，ctDNA 收集、样本处理和自动化过程应按照标准化和临床验证程序进行，最大程度防范因操作差异而引发的假阴性可能。样本采集建议采用含细胞稳定剂的抗凝管，尽快完成血浆分离，提取的 cfDNA 建议在 24h 内进行后续检测，否则，置于-30°C 至-15°C 下储存并避免反复冻融。（CACA 共识） ctDNA NGS 检测应根据项目需求选择技术路线，可依据检测基因数量及覆盖范围大小选择不同测序策略。在进行基于 ctDNA 的超高灵敏度突变检测时，建议使用分子标签技术和优化对应的生物信息分析设置，以降低由于测序平台随机误差导致的假阳性结果；建议通过建立测序噪音和克隆性造血背景库的方法降低克隆性造血及背景噪音带来的影响。（CACA 共识） 检测报告信息 对于检测报告中应该包含哪些内容以及用词规范，ESMO 给出了如下建议。 CACA 共识中则提到： ctDNA NGS 临床检测报告应包含受检者基本信息、样本信息、实验室信息、检测项目、检测结果及变异解读、检测方法的实验室内部验证结果、检测局限性及不确定性以及进一步检测的建议等内容。实验室应建立报告 SOP，建议根据国内外文献、共识指南、临床试验证据和实践对检出的肿瘤基因突变进行分类或分级报告。（CACA 共识） 如果想了解更全面的内容，可以参考另外一份中文共识 肿瘤二代测序临床报告解读共识。 ctDNA 检测临床应用 针对 ctDNA 的临床应用，ESMO 给出了如下一段描述。 ctDNA 具有多种潜在的临床应用，包括用于筛查、描述早期疾病的特征、检测局部治疗后的分子残留疾病（MRD）、预测复发、对晚期肿瘤进行分型、治疗效果早期评估、响应监测和耐药机制鉴定。（如下图所示） ctDNA has multiple potential clinical applications, including its use for screening, characterisation of early disease, detection of molecular residual disease (MRD) after definitive local treatment, prediction of relapses, genotyping advanced cancer, early assessment of treatment efficacy, monitoring of response and identification of mechanisms of resistance to therapy 对于需要紧急治疗的患者，组织活检的延迟可能会限制治疗方案，而液体活检可以提供更快的结果。 空间和时间异质性是恶性肿瘤的既定特征，ctDNA 的优点是更容易连续获得，并且可以获得来自患者几个转移部位的&quot;基因组库&quot;。当组织检测只能在原发肿瘤中实施时，液体活检可以为有转移的患者提供更准确的基因分型。 ctDNA 的释放与肿瘤的生长成正比，而肿瘤的生长与细胞的死亡和更替有关，生长最快的肿瘤克隆脱落的 ctDNA 最多，理论上是最有临床意义的。多次液体活检可能允许检测获得性耐药突变，以便根据获得性耐药基因型最佳地选择后续治疗。 与组织检测相比，ctDNA 检测也有假阴性和假阳性率较高的局限性，而且样本中肿瘤占比较低，限制了对突变等位基因比例（VAF）的准确评估，并限制了拷贝数变异的分析。 晚期肿瘤基因分型 下表列出了针对液体活检的肿瘤特异性晚期肿瘤基因分型检测建议。 具体的内容可以参考原文和对应的治疗指南。 即便已经有了大量的证据表明液体活检可以用于晚期肿瘤基因分型，但是其仍然具有明显的局限性。 针对于不同突变类型，ctDNA 检测性能目前还有很大差别。例如 ctDNA 样本中的体细胞拷贝数变异只有在 ctDNA 比例较高的情况下才能被准确识别，只有在无法进行组织取材时才能取代组织评估。 此外，bTMB 与 ctDNA 的数量高度相关，因此需要最低数量的 ctDNA 来进行有效行评估（当肿瘤细胞含量低时这一问题同样适用于组织检测） 肿瘤检测部位的建议 ctDNA 检测敏感性在仅有中枢神经系统转移性疾病和原发性脑瘤中会降低，液体活检通常不适合对此类患者进行基因分型，但如果是基因分型的唯一样本来源则可以尝试。 有研究表明可从脑脊液分析中获得基因分型，但是再存在 oligometastasis 和仅有结节的疾病中，ctDNA 存在较高的假阴性，应特别考虑进行组织检测或在肿瘤体积较大时进行间隔性 ctDNA 检测。 晚期肿瘤基因分型应用建议 液体活检在晚期肿瘤中具有非常高的灵敏度和临床特异性，当其结果将影响标准治疗方案时可在常规实践中使用。同时也必须考虑到 ctDNA 检测的局限性。 建议将液体活检优先作为组织基因分型的替代选择，特别是对于临床上需要快速获得结果的侵袭性肿瘤，如晚期 NSCLC。这也适用于无法或不适合进行组织活检的情况。 用于基因分型的液体活检应在肿瘤进展时进行（不论是未接受治疗的还是后线治疗）。在肿瘤对治疗产生反应时收集样本，其敏感性会降低。 对于晚期肿瘤的基因分型，在临床实践中，RT-PCR、dPCR 和 NGS 检测之间的选择应根据可用性、报销情况和肿瘤特定情况下的 1 级可操作性基因变异的数量来确定。 在解释癌症易感基因（如 BRCA1、BRCA2、PALB2）的致病变异时应谨慎，需要进行有效的胚系检测以确认胚系或体细突变。 考虑到临床敏感性和阴性预测值，当液体活检未检测到可采取治疗的突变时，应建议进行组织检测。对于专家，如果能确认样本中存在足够 ctDNA，可能不需要进行组织检测。 ctDNA 检测对融合和拷贝数变异的敏感性较低，在有组织时应使用组织检测。 所有的肿瘤科医生都应该有机会接触 MTB，在使用 ctDNA 检测前期进行学习，以确保检测结果的正确解读，对疑难病例则应该进行讨论以确保做出合理决策。 晚期肿瘤动态监控 用于早期疗效评估的 ctDNA 动态分析 因为 ctDNA 的半衰期短且有可能进行无创重复采样，所以血液 ctDNA 可以在治疗过程中对疾病进行实时监测。 在治疗过程中监测肿瘤患者的研究表明，ctDNA 动态与治疗响应相关，并可能比临床/放射学检测更早发现。在多种不同的肿瘤类型和治疗类型（化疗、靶向和免疫）中，对治疗有响应的患者在开始治疗后几周内 ctDNA 水平会下降。 ctDNA 的早期下降可能反映了细胞周期停滞导致的 ctDNA 释放减少，后期则反映了肿瘤体积减小。需要注意的是，在开始细胞毒性药物治疗的几天后，ctDNA 水平可能会出现短时间上升。 越来越多的证据表明，对接受了免疫检查点抑制剂治疗的转移性肿瘤患者进行连续 ctDNA 水平变化的追踪，可以评估预后和治疗效果。 其中，监测 ctDNA 水平的一个临床用途就是区分真正的临床放射学进展和免疫治疗的假性进展（接受免疫治疗的患者中有 5%-10%的患者会出现这种情况）。 纵向监测用于发现耐药突变 ctDNA 分析也可用于评估临床进展前耐药性基因组机制的出现。在接受靶向治疗的不同类型肿瘤患者队列中进行的几项研究表明，纵向 ctDNA 分析能够在临床进展前检测到早期出现的耐药突变。 未来研究方向 今后，需要进一步研究确定 ctDNA 动态评估的最佳时机和预测反应的准确阈值。对于监测临床进展前出现的耐药突变还需要进一步研究监测的频率。 需要进行随机干预研究，以评估根据 ctDNA 的动态评估改变治疗是否能改善患者治疗结局，或着可以避免不必要的副作用和尽量减少经济成本改善生活质量。 晚期肿瘤监测建议 没有足够证据表明需要在治疗期间采用定期监测 ctDNA 的方法。虽然早期 ctDNA 动态监控与预后密切相关，并且在临床进展前的多个月可以发现耐药突变，但没有足够的证据表明根据这些发现采取的措施可以改善预后。需要进行随机干预的临床试验来评估 ctDNA 监测的效果。 早期肿瘤 MRD 和分子复发监测 大量证据表明，在可能的治愈性治疗后检测到 ctDNA 与未来的复发高风险有关，我们通常使用两个术语进行表述。MRD 是实体瘤中的一个术语，描述在用手术和/或放化疗对原发肿瘤进行治愈性治疗后不久出现的残留癌细胞的分子证据。 MRD 可只能通过分子技术（如 PCR 或 NGS 或 CTC 分析）来检测，但无法通过基于血液的蛋白质肿瘤标志物或常规成像检测进行。分子复发（molecular relapse，MR）是指在辅助治疗或监测期间，在较晚时间点上对隐性疾病进行分子检测。 多个病例-对照和队列研究的数据支持 ctDNA 分析用于 MRD 检测的临床有效性。早期乳腺癌、结直肠癌、肺癌和膀胱癌等许多研究中，在完成治疗后或监测期间立即检测 ctDNA 可以预测高风险复发。 ctDNA 检测表明，在没有进一步治疗的情况下预测复发的特异性往往超过 90%，然而在大多数研究中，在完成治疗后不久检测 MRD 的敏感性往往小于 50%。 此外，ctDNA 检测显示从 ctDNA 检测到临床复发的时间通常为 6 个月，也就是说现有的 ctDNA MRD 检测主要是检测那些注定要经历早期复发的患者（初治后第一年内复发），可能无法检测晚期复发的疾病。 除了临床有效性，ctDNA MRD 的临床实用性还有待确定，需要进行前瞻性随机试验。MRD 检测最明显的潜在应用是可以指导个性化的辅助治疗，即 MRD 阳性患者可能从额外的治疗中获益。另外从理论上讲，没有 MRD 的患者可以减少辅助治疗的力度。但目前可用的 ctDNA MRD 检测灵敏度不高，假阴性率高，使用这类检测指导降阶治疗需要谨慎。 基于 MRD 的降阶治疗策略，无论是在治愈性治疗后立即进行 ctDNA 检测还是在监测期间进行检测，都需要在非劣效设计的随机试验中与目前标准方法进行仔细比较，明确证明临床效用。 未来 MRD 临床试验的考虑内容 首先，证明辅助治疗中的临床效用（与不使用 ctDNA 检测相比，ctDNA 检测是否能改善临床结果并增加临床决策的价值）的证据应该是最高级别，可以通过如下实验完成。 前瞻性随机临床试验，主要目的是评估 ctDNA 检测结果用于指导辅助治疗或监测策略。 前瞻性-回顾性研究，使用主要目的不是为了评估 ctDNA 指导管理（通常作为探索性终点）而进行的前瞻性试验中收集的血样。需要两个或更多的独立研究产生类似的结果来确定临床效用。 值得注意的是，ctDNA 的临床应用在很大程度上依赖于疾病类型、分期、可有效根除 MRD 的现有治疗方法和预期用途。目前正在进行多项基于 ctDNA 的随机临床试验，以确定 ctDNA 在早期实体肿瘤中的临床应用。大体上，ctDNA 指导的试验可以在以下临床环境中进行。 确定性治疗几周后：研究 ctDNA 检测是否可以用于 ctDNA 阴性患者的降阶治疗和/或 ctDNA 阳性患者的强化治疗。可以使用非劣效性（用于降阶策略）和优效性（用于升阶策略）设计。 完成标准辅助治疗后不久：主要目的是研究额外 &quot;二线 &quot;或 &quot;辅助治疗后 &quot;的新疗法是否能提高可检测到 ctDNA 但影像学上没有疾病证据患者的治愈率。 监测期间：确定与标准监测方案相比，ctDNA 指导的监测是否可以更早发现复发，让更多患者接受根治性转移切除或改善患者生存。 早期肿瘤 MRD/MR 建议 对早期肿瘤进行治愈性治疗后使用有效检测方法进行 ctDNA 检测可以预测复发风险，多项研究已经表明了其临床有效性。 在常规实践中并没有足够前瞻性临床证据证明 MRD 指导下的治疗可以改善疗效或安全降阶治疗。 早期或晚期协助肿瘤初步诊断 ctDNA 检测可以作为诊断工作流程的一部分，为影像学判断疑似有肿瘤的患者提供服务。 对于难以进行组织活检的肿瘤患者，可以使用 ctDNA 检测基因分型来识别突变进而确认肿瘤存在。在这种情况下，克隆性造血突变不能与致病突变混淆，因此使用专业的检测方法至关重要。 对于侵袭性肿瘤患者，与组织活检相比 ctDNA 检测可能会使患者提早开始靶向治疗。对用于诊断的 ctDNA 检测，必须要考虑到假阴性问题。 对无症状人群进行筛查 ctDNA 在癌症治疗方面的最终应用可能是能够在无症状的人群中发现早期癌症和癌前病变，进而采取相关措施提高治愈率，甚至防止侵入性肿瘤的发展。 这一概念成为现实还需要大规模的人群研究提供足够证据，而标准化筛查工具在保持临床敏感度的同时实现高特异性是必要条件。 因为早期肿瘤的 ctDNA 含量很低，使用 ctDNA 在技术上仍然具有挑战性。此外，理想条件下以 ctDNA 为基础的筛查也应能提供癌症起源组织的信息，而这在现阶段也还远不成熟。 目前，在这一领域已经进行了大量的工作，研究表明，高灵敏度的测序方式可以与蛋白质生物标志物、片段长度特征和甲基化检测相结合。不过在筛查人群中进行的大型研究数据证实之前，ctDNA 检测作为多种癌症的筛查工具还不能被视为 ctDNA 检测的有效用途。 以上是 ESMO 提到的 ctDNA 几个应用场景，与之相对应的 CACA 给出了如下三点共识。 目前已有临床证据支持 ctDNA NGS 检测可应用于肺癌、乳腺癌、前列腺癌、卵巢癌等晚期实体肿瘤的伴随诊断，但涉及的驱动基因及其变异类型与相应分析体系均有严格限定，若超适应症应用时，建议与患者就检测必要性、检测费用以及局限性等内容进行充分知情。ctDNA NGS 检测已被国内外专家共识或指南建议作为多种晚期恶性肿瘤组织基因检测的替代方式，但依据其分析结果实时制定临床治疗策略时仍需高级别循证证据支持。（CACA 共识） 晚期实体肿瘤分子靶向或免疫检查点抑制剂治疗开始后，基于 NGS 检测的 ctDNA 水平定量和动态变化分析，有望成为新兴的疗效评估途径。ctDNA MRD 检测是全新的个性化技术应用领域，尚难以建立通用性技术标准，亟待通过大样本、多中心、前瞻性的临床试验验证其临床效用。ctDNA NGS 检测在临床上用于靶向或免疫治疗评估和分层时，建议就检测价值、局限性和费用等进行充分知情。（CACA 共识） 在临床环境中，ctDNA NGS 检测可用于识别分子靶向治疗的耐药机制，尤其对于疑难复杂的肿瘤患者，该结果有助于后续的治疗选择决策。免疫检查点抑制剂治疗获得性耐药机制复杂，治疗选择压力下的肿瘤亚克隆演进仅为其部分原因，ctDNA 靶向测序、全外显子和（或）全基因组检测仅作为其转化研究工具之一。（CACA 共识） 小结 液体活检，特别是 ctDNA 检测，正在越来越多地用于临床实践。 目前已有足够的证据表明其在晚期癌症基因分型可以用来指导治疗，特别是在组织活检不理想或时间至关重要的情况下。 在临床中使用 ctDNA 必须考虑到检测的敏感性，特别是对融合和拷贝数变异的敏感性较低。进一步开发更好的检测方法将真假阳性/阴性结果准确地区分开仍是未来基因分型检测的主要优先事项。 ctDNA 检测比组织测序能更准确地捕捉患者体内空间和时间上的肿瘤异质性，具有理论上的优势。现在需要进行更多重要的临床试验来评估检测这种异质性如何能够提供临床有用的信息来改善治疗。 由于缺乏有用的证据，尚不建议将 ctDNA 检测用于如早筛、MRD 评估和治疗反应早期评估的其他可能目的。基于甲基化、片段长度的测序或新型超敏感突变检测方法等目前正在开发的新技术有可能优化这些应用。正在进行中的多项临床实验，也可能为在多种临床情况下采用 ctDNA 检测进行决策提供证据基础。 以上就是 ctDNA 学习三部曲的第一部分内容，ESMO 和 CACA 专家共识建议的整理学习。下一篇文章，我们将学习高深度全基因组 ctDNA 测序在前列腺癌中的相关研究，一起看看高深度全基因组深度 ctDNA 检测的可行性和应用优势。 下次见。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-08-02-ctdna-esmo-caca-recommendation/"},{"title":"在《Google软件工程》里了解如何在团队内进行学习和分享","content":" 《Google软件工程》这本书朋友推荐给我的时候内心里是懵的，咱就是说就我这coding level可万万不敢看狗哥软件工程。结果对方表示可以「少量多次，温水送服，按需阅读，比如只看第二部分」。 本着看看又不吃亏的原则，在物流原因买不到中文版的情况下还是忍不住看了一小章英文。 先说结论：这书，得推荐。 就算你完全不写代码，只要所在的实验室、团队或者公司涉及到软件相关或者扩大到脑力劳动和知识管理相关的工作，这书都应该读（至少第二部分）。 为什么学习和分享会是挑战 比如，你可以在这本写软件工程的书里搞清楚为什么在一个组织内部学习和分享会变成一种挑战。 在第二部分的第三章「Knowledge Sharing」，首先写了Google总结出的6条为什么在一个组织内部学习和分享会变成一种挑战的原因，包括：缺乏心理安全、存在信息孤岛和存在有或无专长等等。 为了不剧透就稍微扩展一点。 信息孤岛的存在会客观上带来三个问题：信息碎片化（每个岛屿对于整体都有不完整的描述）、信息重复（每个岛屿都重新发明了自己的做事方式）和信息偏倚（每个岛屿做同一件事情的方法可能并不完全兼容）。 而所谓「有或无专长」，则是组织内部被分成两类成员，一派是“无所不知”的人，另一派则是菜鸟，但是很少有中间状态。 如果专家总是自己做每一件事，而不花时间通过指导或文档来培养新的专家，这个问题往往会加剧。在这种情况下，知识和责任继续积累在那些已经拥有专业知识的人身上，而新成员或新手只能自己照顾自己，并以缓慢的速度成长。 如何营造一个心理安全的空间 如何应对这些问题呢？仅举例如何营造一个相对心理安全的空间，书中提到了几种推荐模式和反对模式。 **推荐模式（合作）**包括： 基础问题或错误需要被引导到正确的方向上 解释的目的是为了帮助提出问题的人学习 回应是亲切的、耐心的、有帮助的 互动是通过共同讨论来寻找解决方案 **反对模式（对抗）**包括： 挑剔基础问题或错误，并责备提问的人 解释的目的是为了炫耀自己的知识 回应是居高临下、刻薄、没有建设性的 互动是有「赢家」和「输家」的争论 不过，需要注意的是，反对模式往往都是在无意中出现的：有人可能试图提供帮助，但却意外看起来不受欢迎。Google在实际操作中，发现Recurse中心提供的三条社交规则，在组织内部很有帮助。 不要假装惊讶。 不要说「什么，我不相信你不知道……」这样的话。当人们说他们不知道一些事情时，你不应该表现出惊讶的样子。因为假装惊讶通常是为了让自己感觉更好而让别人感觉更糟。即使这不是目的，也总是最终的效果。 不要轻易说「好吧，实际上」。 当对方说的内容几乎是正确的但又不完全正确时，不要轻易说「好吧，实际上是…」然后给出一个小更正。尤其是当纠正对实际对话不会产生影响时。 不在后座上开车。 无意中听到别人在解决问题时，不应该断断续续地半参与对话。打断现有讨论又不投入到对话中的行为就像是坐在后座上开车。提供帮助和建议以及加入对话，这些都是被提倡和鼓励的，只是想帮助他人或与他人合作时，应该全力以赴而不是偶尔插手。 另外，在这一部分里，还写到了如何在组织中学习和分享等一系列话题。粗粗浏览感觉就很受用，如果看了上述部分让你产生了一点兴趣，也不妨找到这本书来读读。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-07-16-book-software-engineering-at-google/"},{"title":"如何衡量个人在团队项目中的贡献","content":"身处一个团队（部门）中，合作是每一个项目顺利推进开展都必不可少的工作方式。但如何合理展示和评价每一个人的贡献，让每个人都能看到自己的价值，却不是一件容易的事。 这个问题在我过去一年的工作中，也碰到过好几次。有时候觉得自己的贡献没有被别人看到，有时候又觉得在最后show work的时候没有足够明确他人的贡献。 稍微想想，其实衡量个人在团队中项目的贡献是两个维度的事情。一是外部如何相对客观的评价，二是如何在项目中满足自我需求。 明确并清晰展示每个人的贡献 贡献者角色分类 CRediT 如果想要获得或者给予他人合理的评价，首先需要明确一个项目中可能存在的职责。 在科研项目合作中，特别是涉及到论文发表的，其实已经有了相对公认的贡献者角色分类（CRediT, Contributor Roles Taxonomy ）方法。 CRediT 2012年在哈佛大学和惠康基金会组织的一次合作研讨会上被提出，研究人员、国际医学期刊编辑委员会(ICMJE)和出版商均提出了各自的意见。 该分类下包括14个角色，可以用来表示科学产出贡献者通常扮演的角色。引入 CRediT 的目的就是认可个人作者的贡献，同时减少作者之间的争议并促进更好的协作。 Roles 角色 贡献 Conceptualization 论文构思 产生想法，制定或演绎扩展主要研究目的。 Data curation 数据管理 为数据最初使用和后续复进行注释，整理和维护（包括软件或程序）。 Formal analysis 形式分析 使用统计、数学、计算或其他形式的技术分析或合成研究数据。 Funding acquisition 获取资金 为了项目研究成果能够发表而去争取并获得资金。 Investigation 调查研究 实施研究和执行调查过程，特别是从事实验研究或收集数据和证据。 Methodology 方法学 开发或设计研究用的方法，建立模型。 Project administration 项目管理 为研究活动的计划和执行进行管理和协调。 Resources 资源 提供研究材料、试剂、病例、实验室样品、动物、仪器、计算设备资源或其他分析工具。 Software 软件 编程，研发软件，设计计算机程序，实施执行计算机程序及支持算法，测试已有的程序。 Supervision 指导 监督和领导研究活动的策划和执行，包括对核心成员以外的人进行指导。 Validation 验证 对研究结果、实验或其他研究输出内容的复制和重现进行验证，包括整体或部分的核实验证。 Visualization 可视化 对发表的内容进行准备、创作或展示，特别是内容或数据的可视化呈现。 Writing – original draft 初稿写作 对发表的内容进行准备、创建或表述，特别是撰写初稿，包括实质性翻译。 Writing –review &amp; editing 审核与编辑写作 对原始研究团队提出的发表内容进行准备、创建或表述，特别是评论、注释或修改，包括发表前和发表后所发生的这些工作。 有了明确的角色贡献，另一个问题是如何理清 authorship 和 contributorship的关系，或者说怎样判断哪些角色更重要（应该出现在作者名单中）。 在ICMJE关于定义作者和贡献者的角色 说明中，认为作者贡献应该基于四个原则。 对项目的构思或设计有实质性贡献；对项目数据进行获取、分析和解释 起草了项目内容或对重要的内容进行严格的修改 最终批准要发表的版本 同意对工作的所有方面负责，确保任何部分的准确性或完整性有关的问题得到适当的调查和解决。 公开展示的原则 在项目前期规划的过程中，就应该明确每个参与者的角色。在后期的每一次公开讨论或者分享时，都应该明确展示参与者的贡献。 所谓公开我的理解就是在有非项目实际参与人在场的情况下；所谓明确则是在展示环节（PPT对应页或者文字材料相关部分），都应该强调哪一部分工作由谁完成。 在项目中满足个人需求 除了外部认可以外，合作中的另一种收获取决于自我体验，即如何在项目中满足个人需求。 还得从经典的马斯洛需求层次理论谈起。 工作中最底层的需求是安全需求，也就是薪资待遇的保障，不会意外的裁员。 而实际参与项目，则是希望能带来顶部三层的满足： 与他人交流沟通获得连接的社交需求； 能够获得认可与尊重的需求； 自我价值得以实现的需求。 想有可能实现以上几个需求，就需要在项目开展过程中： 提供一个开放的心理安全的环境，让成员能够表达自己的观点和提出自己的问题； 经常进行有目的的沟通，让成员之间保持积极良好的关系； 保持高频率的有效反馈（可以是正反馈也可以是负反馈），在每一次例会中都去分享成员的贡献。 鼓励成员能多关注自我状态和个人发展。让成员的个人价值观、特点和使命感在工作中有机会展现 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-07-16-credit-a-team-member/"},{"title":"万字长文｜染色体不稳定性，凭什么2022年还能用TCGA数据发Nature","content":"写在前面 2022 年 6 月 15 日，Nature 在线发表了两篇染色体不稳定性泛癌研究。一篇题为：A pan-cancer compendium of chromosomal instability；另一篇题为：Signatures of copy number alterations in human cancer。 和我们常说的新闻「字儿越少事儿越大」一样，科学文献有一个潜在成立的标题定律，通常越重要越前沿的文章标题越短，比如 1953 年发表在 Nature 的 DNA 双螺旋结构 Molecular Structure of Nucleic Acids。 在肿瘤研究的很多方向上，如今我们只能通过不断增加限制条件和定语完成发表。所以如今看到10个单词以内的研究，不妨都可以多看两眼。这在我自己感兴趣的方向上，Nature一下online了两篇，那还了得。这此，我们先聊第一篇，剩下一篇有机会再说。 基因组（染色体）不稳定性作为肿瘤 20 年来人们已知的 hallmarks 之一，无论是单一癌种还是泛癌种，TCGA / PCAWG 前前后后都发过很多篇，如今用这些数据还能发表在 Nature 杂志上，而且还可以称之为泛癌种染色体不稳定性纲要（compendium），想必是有点东西。 而让我真正想仔细看看这篇文章的另一个原因是它波折的发表经历。文章的投稿时间是 2020 年 7 月 31 日，Nature接受时间是 2022 年 4 月 21 日，正式在线时间为 2022 年 6 月 15 日。一次投稿接近两年的修改时间，对于一篇没有湿试验的paper 来说，和 review 之间的拉扯不可谓不长。 前后经历了四轮修改的结果是文章一共68个figure，60页附件，90页Peer Review File。今天，我们就一起来学习这篇文献，同时试图聊聊其发表背后可能经历的波折和能学习到的经验。 或许能学到的 以下几点是我在阅读之后提炼的部分文献学习要点，你在阅读原文时可以作为参考。 染色体不稳定性相关的大量核心概念、指标和经典文献 染色体不稳定性相关的大量公开可用公共数据 基于生物信息学方法提出的新概念可以如何去验证 基于生物信息学提出的科研文章如何和临床研究进行关联 基于生物信息学使用公用数据发表CNS期刊究竟会面临哪些挑战 关于染色体不稳定性 染色体不稳定性（CIN，chromosomal instability）对于肿瘤具有非常复杂的影响，包括驱动基因的丢失或扩增、大片段重排、染色体外 DNA（ecDNA）、微核形成和先天免疫信号的激活等等。这导致其了与肿瘤的分期、转移、不良预后和耐药等均有关联。 造成 CIN 的原因也是多种多样的，其中包括有丝分裂错误、复制压力、同源重组缺陷（HRD）、端粒异常和断裂-融合-桥周期（Breakage-fusion-bridge cycle）等等。 由于这些原因和后果的多样性，在目前的研究中，CIN 通常被当作一个综合事件来看待。 CIN 的测量描述，通常来说，或者是将肿瘤分为高 CIN 或低 CIN 两类，或者局限于如 HRD 这一单一病因，有或者局限于如染色体臂变化这类特定的基因组特征，再或者只能对特定的癌症类型进行量化。 目前还没有一个系统性的框架来全面描述泛癌症的 CIN 的多样性、程度和起源，也没有定义肿瘤内不同类型的 CIN 与临床表型的关系。（嗯，文章开头提到的两篇文章就都是在回答这个问题）。 核心研究思路和方法 研究样本 为了解决上述提到的问题，作者首先使用来自癌症基因组图谱 (TCGA) 的SNP6 array数据，获得了 33 种肿瘤类型的 7880 个高质量绝对拷贝数图谱。使用的软件和筛选流程见下图。 特征选择 作者使用自己团队 2018 年发表在 Nat. Genet. 的一项卵巢癌 CIN 研究框架，对 6,335 个全基因组拷贝数结果计算了先前已经证明有效的五个拷贝数特征，这些特征可以代表拷贝数的变化模式（CIN 不同潜在原因）。 这五个特征包括： 相邻染色体片段之间的拷贝数变化 片段长度 每 10Mb 的断点数 每条染色体臂的断点数 拷贝数振荡状态的链长度 不理解的可以看原文method详细说明或者下面的示意图。 关于为什么没有把一些更容易理解的指标纳入考虑，作者也在附件方法中也给出了一些解释。 比如，排除绝对的拷贝数值是因为，多个拷贝数变化事件可能发生在同一基因组位置，因此该段的绝对拷贝数可能因各种变异事件的顺序而有很大的不同。 例如在全基因组复制 WGD 的背景下，一个单拷贝丢失导致拷贝数为 3，但在非全基因组复制的背景下则为 1，尽管它们可能是由导致缺失的同一突变过程引起的，但是会有两个不同的特征。 因为染色体倍性会对很多生物学特性有特殊的影响，不使用绝对数值作为特征可以纠正倍性的影响，避免出现在不同倍性背景下编码相同原因的冗余特征。（多说一句，其实这一特征在文章开头提到的另一篇同时发表的Nature文章是用到的） 对于不考虑杂合性缺失（LOH）状态，是因为作者大多数 LOH 事件是所谓的拷贝丢失事件，可以通过拷贝数变化来检测。在文章使用的数据集中，他们发现整个 TCGA 中的 LOH 事件中位长度为 3.6Mb，这表明大多数事件可以通过 SNP6 技术或者 WGS 检测到。但是随着科学研究越来越多的用到了 shallow WGS 和单细胞测序，它们尚不能提供准确的等位基因特异性分辨率，因此专门的 LOH 特征可能导致这个方法的应用受限。（再多说一句，其实这一特征在文章开头提到的另一篇同时发表的Nature文章也是用到的） 看到这里，我会有一个疑问：基于测序数据的这几个指标是否可以用来描述和区分生物学中常见的CIN相关事件。 如下图所示，这里作者也列出了经过充分研究后上述五个具体的拷贝数特征能够捕获哪些已知的拷贝数pattern。而正是这些这些促使作者选择了这五个基本特征来模拟已知的pattern，并有可能区分其突变过程。 Signature构建 有了这 5 个特征之后，作者应用混合模型来定义每个队列范围内特征分布的不同成分，最终在 5 个特征中共确定了 43 个混合成分。其中片段长度包含了 22 个成分，拷贝数变化包含了 10 个成分，如下图所示。 从理论上讲，这些43个成分就代表了定义 CIN 过程的基本模块。然后就可以利用这些混合成分对每个肿瘤基因组进行编码，通过概率计算将拷贝数事件分配给这些成分，形成一个 6,335×43 的矩阵。然后，应用非负矩阵因式分解的来识别拷贝数 signature。 主要结论 17个拷贝数 signature 作者首先使用完整矩阵，发现了 10 个泛癌症拷贝数 signature。然后使用矩阵子集，代表至少有 100 个样本的单个癌症类型进行分析，首先找到了 128 个癌种特异性 signature。 随后通过三步过滤，来避免 signature 冗余。 删除所有与任何泛癌 signature 的余弦相似度超过 0.74 的癌种特异性拷贝数 signature 从余弦相似度超过 0.74 的癌种特异性拷贝数 signature 中选择一个有代表性的 signature 删除构成泛癌 signature 组合的癌种特异性拷贝数 signature 最终找到了 17 个拷贝数 signature（10 个泛癌和 7 个癌种特异性），在下图中你可以看出这 17 个 signature 中不同拷贝数特征如片段长度和断点数等的 43 个成分的权重。 使用线性组合分解计算它们的活跃度，最终就可以得到一个泛癌的 17 个拷贝数 signature 和它们在 33 种癌症类型的样本活跃度。 推测不同 signature 成因 这篇文章的亮点在于不是讨论CIN之后会怎么样，而是解释哪些原因导致了CIN。因此就需要将 17 个 CIN 特征与产生 CNA 的推测原因联系起来。（思考题，如何用已知解释未知并且让人觉得可信，是生信最大的难点）。 关联的整体思路： 首先通过signature和CIN相关基因突变的关系，为每个signature赋予假设的对应原因 然后再通过不同维度的其它数据集进行交叉验证 然后根据验证结果给予评分。 使用数据 总体来说，为了完成这一步，如下图红框所示，他们用到了目前几乎所有可用的公共数据。 两个患者队列的数据及其临床数据 泛癌全基因组分析（PCAWG）项目的约 1900 名患者 自国际癌症基因组联盟（ICGC）项目的约 400 名患者 五种突变特征 单碱基替换（SBS）single-base substitution (SBS) 插入-删除（ID） insertion–deletion (ID) 双碱基替换 doublet base substitutions 早前卵巢癌研究拷贝数 ovarian copy number 重排 rearrangement 14 个分子特征 体细胞点突变 somatic point mutations 基因表达 gene expression 细胞周期评分 cell cycle score 非整倍体评分 aneuploidy score 全染色体拷贝数畸变（CNAs）whole-chromosome copy number aberrations 串联重复 tandem duplications 杂合缺失 loss of heterozygosity, 染色体破碎 chromothripsis 成簇突变 kataegis 全基因组复制状态 whole-genome duplication status 端粒长度 telomere length 延伸机械活动 elongation machinery activity 染色体外DNA extrachromosomal DNA 着丝粒扩增评分（CA20）centrosome amplification score 11 个 DNA 修复特异性特征 胚系 BRCA1 / BRCA2 突变 BRCA1 / RAD51C 超甲基化数据 HRDetect 评分 HRD 评分（Myriad myChoice） TP53 失活评分 端粒失衡评分 telomeric imbalances score 大规模状态转换评分 large-scale state transition score 杂合度丢失评分 loss of heterozygosity score DNA 修复能力评分 DNA repair proficiency score 23 个 DNA 损伤修复基因的蛋白表达评分 具有同源性的 PCAWG 结构变异 相关CIN基因鉴定 为了将 signature 活性和突变基因关联起来，作者进行了如下的筛选。首先通过 driver gene 的既往研究挑选出了 200 个肿瘤相关基因，根据 reactoma 数据库筛选出 1330 个 CIN 相关通路蛋白。对筛选后的 1179 个基因按照有无突变分为两组检测和17个CIN signature的相关性，找到788个至少和1个signature相关的基因。在这788个基因中通过qvalue和effect size进行过滤，保留了32个和signature高度相关的高可信度基因。 这32个基因是 AKT1, BRCA1, BRCA2, CCND1, CDK4, CDKN2C, CIC, CUL1, ERBB2, ERBB3, ERCC2, FBXW7, H3F3A, IDH1, IDH2, MAPK1, MYC, NFE2L2, RAC1, RPL22, PBRM1, PCBP1, PIK3R2, PMS1, PPP2R1A, PSMA4, SPOP, SOS1, SOX9, TP53, U2AF1, VHL。作者研究了围绕这些基因的文献，并整理了关于它们如何影响基因组稳定性的信息。 这些基因突变和拷贝数signature存在着如下关系 再上图你可以看到一些基因被红线划掉了。这是为什么呢？ 对于如上图所示显示出扩增模式的四个特征（CX8、CX9、CX11、CX13），作者研究了它们与染色体外DNA扩增子的关系。由于致癌基因容易被ecDNA扩增，作者假设通过ecDNA扩增的基因可能是产生这些扩增子过程的结果，因此可能与突变过程没有因果关系。用相关研究文章的数据测试了在ecDNA扩增子中扩增的高置信度基因的特征活性的变化情况，对于扩增相关signature中的每一个高置信度基因检验带有该基因扩增子的样本是否比没有扩增子样本具有明显的signature活性。因此额外删除了几个用于假设CIN成因的基因。 病因假设 根据signature和CIN相关联的病因假设逻辑如下图。 如果一个signature没有和它相关联的基因，那就没办法做出假设。如果一个signature不包括扩增但是有相关联的基因，查找这个基因和CIN相关的机制，如果有已知的机制就给出假设；如果一个signature包含了扩增且有基因关联，首先判断这个基因是否在ecDNA中也富集，如果富集了就假定不存在关联。然后还有剩余基因的，根据和CIN的相关功能进行假设。利用这样的分析共得到了11个signature可能的假定成因。 有了这些可能原因之后，再尽可能多的利用外部数据进行验证，给出打分。 如果高置信度的基因将某一特征与已知的CIN类型联系起来，加两颗星。如果有额外的数据支持该假定的原因，我们就增加第三颗星。 最终，八个signature（CX1-CX6，CX8，CX11）获得了三颗星。三个signature（CX10, CX14, CX17），即至少有一个高可信度基因与已知的CIN类型相关，但没有额外的数据支持。三个signature（CX9、CX13、CX16）被授予一颗星，这些特征没有高可信度基因，但一些额外数据验证使作者能够提出一个推测的病因。三个特征（CX7、CX12、CX15）为零星。 这里可以看一个具体的实例，比如在CX3中，本身的突变特征提出了假设，它具有LST可能和HRD相关；同时一个拷贝数的改变显示它可能是LOH事件和tandem duplications。 基于此，根据关联基因发现以下这些基因的功能确实和CIN的功能相关，首先给两颗星。那么是否有其它数据的支持呢？可以看到各种其它 HRD 相关的signature都存在，且还有生存数据的支持，最终三颗星。 经过这样一通复杂的验证，最后得到了下图这样一个核心结果。关于详细成因的解释还是看原文吧。 染色体异常与七个不同的特征有关，表明许多潜在的原因是这些复杂重排的基础。复制压力与八个signature相关，突出表明它是CIN的一个主要来源。不同的特征显示出在WGD之前（CX1、CX2、CX7和CX15）或WGD之后（CX3、CX5、CX6、CX8、CX9、CX13和CX17）发生的偏向，显示了WGD事件在调节CIN方面的重要性。APOBEC突变和kataegis特征与六个signature相关，强调了这些是CIN的一个共同特征。 药物反应与药物靶标识别 有了原因的解释，这些signature可以用来做什么呢？ 上述成因的探索结果暗示了典型的癌症相关同路是CIN的一些主要驱动因素。而这些途径中的许多基因都是靶向治疗的重点。 因此，鉴于这些signature可以很容易地在病人肿瘤中测量，作者接下来探讨了它们在治疗反应预测和药物靶点识别方面的效用。 作者整合了来自297个癌症细胞系的数据，结合通过CRISPR-Cas9或RNAi筛查确定的基因重要性以及对药物扰动的响应相关联，来发现相应的生物标记物和新的药物靶点，进而评估signature活性和基因以及药物敏感性之间的相关性。 分析结果如下图所示，作者确定了40个基因的拷贝数signature与靶点的遗传和药物扰动都有明显的相关性。 在这些基因中，CX5是HR相关的一个特征，预测了通过抑制PARP1对奥拉帕里的反应，又因为这一特征也与RNAi敲除PARP1相关，因此可能代表了一种生物标志物对常规蛋白功能的抑制而不是PARP的捕获。 CX9（复制压力有关）与针对参与主要有丝分裂途径的基因（EGFR、JAK1、MET、PRKCA和PIK3CA）的多种激酶抑制剂的反应相关，这表明多激酶抑制剂的方法可能适合复制压力相关的肿瘤。 同时，从CRISPR和RNAi扰动筛选中，找到了104个具有可药用结构的靶基因，这些基因目前在临床上没有靶向治疗方法。这些代表了预测的合成致死药物靶点，其中49个有证据表明与CIN相关的机制有牵连（如上图所示）。 预测铂敏感性 三种同源重组受（impaired homologous recombination，IHR）相关signature表明了CIN复杂性增加的一种模式。 即单独的IHR会产生CX2，它代表了串联复制的小拷贝数变化特征。IHR加上复制压力会导致CX5，它涉及较大的CNA。最后，IHR加上复制压力、NER受损和DNA损伤信号受损会产生CX3，其最大的CNAs与杂合度的丧失密切相关。不过研究结果没有说明这些不同层次的复杂性是以递进的方式发展的，还是由独立的过程发展。 HR和NER的损伤已知对铂化疗的敏感，鉴于只有CX3与NER的破坏有关，作者假设IHR特征可能表现出不同的铂敏感性预测能力。 由于卵巢癌患者经常接受以铂为基础的化疗，于是用Cox模型测试了三个特征预测总生存的能力，从而推断铂敏感性。可以看到，CX2与铂敏感性没有关系，CX5可以预测耐药性，CX3可以预测敏感性。 鉴于这些IHR特征能够预测铂化疗反应，作者进一步假设是否可以结合这些特征提供更好的铂敏感性预测指标呢？ 由于CX2不具有预测性，作者首先将其作为捕捉非预测性IHR相关基因组变化的参考，并要求预测性的CX3活性超过它才有可能赋予敏感性，即如果CX3活性大于CX2，则预测敏感性。 如下图所示，这种可解释的分类器能够区分BRCA1胚系突变的卵巢癌队列、TCGA队列中的卵巢癌队列和独立验证队列和也常规使用基铂化疗的食管癌队列的总生存期。其实此前也有不少基于机器学习的复杂模型进行预测，但是作者测试发现这种简单的分类也不必之前需要更多信息的方法差。 以上就是这篇文章的主要内容，因为60多幅图和60页的附件实在是太多了，我的梳理能力也有限，如果你读到这里产生了其他疑问还是得自己再去看看原文。 接下来我们聊点或许能让你感兴趣的。 和审稿人反复掰头 正如文章开头所讲，这篇paper从投稿到online用了接近两年的时间，对于一篇没有湿试验的 paper 来说和 review 的拉扯不可谓不长。 经历的四轮大修，我仅仅是读了一遍他们 92 页的交锋记录就感觉血压上来了好几次。如标题所言，2022年用TCGA数据研究染色体不稳定性还能发Nature，凭什么？ 这不是我的疑问，而是几位审稿人的质疑。 如果你真的想提高自己的科研思维，我以为或许读Peer Review File比读原文更有价值。 第一轮意见 首先，值得祝贺的一点是这篇文章一上来没有被editor直接拒掉，好在顺利到了三位审稿人手中。 通过阅读 Peer Review File，可以看到第一次投稿 review 后，三个人里，第一个提出了 8 大问题（Specific points）和 5 小问题（minor）；第二个提出了 6 点大修和 4 点小修；第三个则是直接给出了 5 点主要问题（major issues）。 好在，这一次应该又是editor手下留情，给了作者大修的机会。以下是我觉得比较有趣的部分内容。 审稿人1 他的第一次的评论很不客气，说白了就是拒稿的意思。他提到： 80%的肿瘤发生了CIN这件事情可能被高估了 一个特定的signature如何与给定的病因联系起来尚不清楚，文中主要是推测。 不清楚这样一个标志性数据库可能对癌症预防或治疗产生什么影响，也不清楚它是否有任何用处。 作者写的东西不太可能被非专业读者理解，因此它最适合一本更专业的期刊（这句话你是不是经常在自己的审稿意见中见到啊）。 而在8个Specific points中，审稿人主要质疑了如下几个问题。 这篇文章和作者2018年发表在Nature Genetics上有啥差别你给我解释解释 你们发现的一些结论在更多的队列中是否成立你给我测试测试 你这个signature和先前2018年发表结果一致性较弱，是否是因为这次的数据是TCGA snp6 array，而之前使用的是shallow WGS。 审稿人2 评论如下图。从第二个审稿人的回复中，可以看出来第一版的投稿作者似乎只解释了两个在所有癌种里最常见的signature，且这些对应的生物学过程目前已经研究的比较多，认为应该关注更多的其它signature解读。 他提到的主要质疑包括 希望作者能将CX2与其他基于拷贝数的HRD特征进行比较，如HRD score和HRDetect。 最近的WGS研究以比SNP阵列更高的分辨率对体细胞拷贝数的改变进行了非常详细的描述（其实就是说PCAWG）。作者能否与最近发表的结果进行比较？ 由于CIN特征的生物学解释是最重要的，那么如何根据WGS来识别这些CS呢？检测这些的能力是很棘手的，因为片段的数量和它们的大小都会不同。 signature推导的方法写的不清楚，也许可以用插图或流程图来说明。 审稿人3 在第一次掰头的时候，看起来评价的很克制，但其实他的质疑最大，也造成了后面几轮引入了第四位审稿人。 第三个审稿人认为尽管CNV特征可以为了解CIN提供信息的想法是有希望的，但作者所描述的方法不够新颖或信息量不够，而且这些发现缺乏坚实的支持证据。 他的主要质疑包括如下几个问题： 你很多结论是基于相关系数的。你肯定无疑知道当有许多数据时，即使是微弱的关系也会变得有统计学意义。例如，你自己说5年生存率和CIN之间存在着关联性，但从图1b可以清楚地看到，这种相关性是由少数离群值驱动的，我很惊讶你根据这个图声称CIN与生存率有关联。（看来第一版文章作者一开始放了一个生存和CIN的相关性，直接被审稿人diss，可以说伤害不大但是侮辱性极强） 该研究没有描述本文与同一主题的其他论文有什么不同和补充，特别是考虑到SNP数据是非常老的，而且以前已经分析过了（简单说就是你这个事情有啥意义呗）。 对于IHR特征，拷贝数段的长度（4.9-30.8Mb）似乎比SV特征（1-10kb）所报告的要大得多（Nik Zainal，Nature 2016），HR缺陷像本研究报告的那样普遍真是意料之外。你自己说九个不同的签名与同源重组缺陷有关，但又没有提供任何机制上的解释。反正我不相信。 完全不明白为什么你不把分析扩展到WGS，证明发现是可重复的，并与已有文献一致。 为了确定一个样本中是否存在CIN，作者使用了一个有点武断的20 CNA阈值，这可能夸大了具有实际基因组不稳定性的样本的比例。同样，以前也分析过同样的样本（不仅是SNP阵列，还有WGS），但没有对这些参数的结论的稳健性进行比较或检查。 应该再看看可能的过拟合和假阳性问题。你是测试了对两个signature应用最低阈值的必要性。然而这两个是与整个染色体或染色体臂拷贝数变化相关的，更容易被检测到。其它的会不会存在假阳性呢？ 我们这里小结一下，几个人最关键的就是两个终极拷问： 你这个东西是不是可以在多种测序方法中适用 你这个东西在临床上有什么用 作者更新了什么 投稿的时候大家都有经验，关于审稿人的问题需要逐个回复，感兴趣的话就自己读读，这里只说几个最关键的修改。 作者的原话是：这次修订包括重大改进和额外结果，我们完全改变了文章的内容。那翻译一下就是重写了一篇。 通过比较来自五个测序平台的相同患者的样本，验证了我们方法的稳健性。我们还定义了特定签名的噪声阈值，这使得低活性签名的检测更加稳健，避免了过度拟合。（其实这个问题读者也会提出来，不知道读前文的时候你有没有这个疑惑🤔） 通过结合与突变驱动基因、拷贝数pattern和多个外部数据集的关联，确定原因。更明确地说明了每个假设原因的多证据来源，包括星级评定。我们将所有的证据呈现在网络资源中，供读者探索。（完全重写了成因推测相关内容） 突出方法的临床影响：(a)使用我们的signature来识别药物靶点和预测药物反应；(b)开发基于signature的分类器来预测卵巢癌的铂敏感性。（原来这两部分在第一次投稿的时候是没有的） 大幅扩展我们整合的数据和资源，包括PCAWG和ICGC队列，额外的独立注释和变量，以及不同类型的CIN的测量指标。 虽然我们没办法看到第一版的文章，但是从这几个修改可以看出来，作者第一次敢直接投Nature也是挺勇的，大不了就是做一个被Nature拒稿的人。 关于稳健性测试这一块，其实最后的文章里作者在附件和附图中有了大量的分析来证实。为了验证这个 signature 模型的鲁棒性，作者在 TCGA 中筛选出了有 PCAWG WGS 数据的 478 个样本，对 WGS 数据进行基于 SNP6 芯片的下采样和 shallow WGS 下采样，将 WES 数据区分为 on-targets 和 off-targest，进行一致性评估。 还通过在人类基因组中引入拷贝数变化，模拟了如下五种染色体不稳定的活动： 通过有丝分裂错误引起的的染色体错位（CHR） 通过同源重组缺陷引起的大规模状态转换（LST） 通过 ecDNA 环化和扩增引起的大片段扩增（ecDNA） 通过细胞分裂失败导致的早期基因组复制（WGD early） 通过核内复制引起的晚期全基因组复制（WGD late） 然后再用自己的方法验证是否是不是能把这些内容还原出来。 临床应用价值这部分第一版看起来就是在fig1引入了一个CIN和生存的相关性，这次作者的回复是认怂，那我们就把这部分内容删掉。然后你要临床价值，那我就给你好好做做临床价值，才有了上文看到了药物预测和化疗敏感性预测。 第二次意见 作者一顿回复之后，迎来了第二波攻击。 审稿人1 第一个略被说服，重新提出了 6 个小问题 审稿人2 第二个人也表示肯定，但是表示因为你有重写了一篇文章，那我再根据你新写的文章接着追加 6 个小问题。 审稿人3 在前面两个审稿人态度转变之后，第三个审稿人开始发难了。 你可以感受一下他大概说了什么，以下为大致翻译。 自第一次提交以来，作者做了大量的工作，包括对另外几个人类癌症队列和细胞系模型的分析。他们在BRCA1突变的卵巢癌开发了一个基于CIN特征的分类器和一个预测铂化疗的模型。这是一个有趣的观察，但是由于WGS的病例数量较少，无法断定HRDetect是否能实现这一目标（难道他是HRDetect方法的作者么？）。 作者还比较了不同的测序平台，以评估他们的CIN特征方法的稳健性，但是这些比较是基于下采样的WGS/WES数据，不清楚当他们的方法应用于原始WGS/WES数据时，是否仍有相同程度的稳健性（这是不满意你没花钱测新的样本？）。 尽管做了大量的额外工作，我们认为新版本的主要结论并不令人信服。我们认为这篇文章存在着严重的方法学问题，而且我们发现signature的原因解释是推测性的。因此，我们认为这个文章不适合在Nature上发表。 关于为什么有严重的方法学问题，为什么不适合发表，他写了很长内容很多个问题，其中三个问题如下： signature设计方法存在缺陷，没有之前SNV signature的方法严谨，具体在于计算时一个CNV会同时贡献多个feature。 还是基于相关性讲故事，第一版你是单一维度的相关，现在你变成多个维度的相关，但还是相关性。比如例如CX2和CX5在同源重组通路突变的肿瘤中富集的并不意味着这些特征是特异性的或由于同源重组受损造成的。 关于HR相关的内容做了很多分析，但是这些都是矛盾的，比如CX5与PARPi的敏感性有关但同时也与铂耐药有关。 作者更新了什么 这一波操作，想必作者已经多了很多信心，没有再重写一遍文章，「只是」增加了7个figure，6张表。 这里我们重点挑几个对于审稿人3相关问题的回答看看： 对于CIN signature 和 HRDdetect 比较对于BRCA1胚系突变患者铂化疗敏感性的问题，作者说HRDdetect只有三例可用样本，你不是说是因为样本少看不出效果么，那我就直接从正文里拿掉了，顺便补个刀，HRDetect算法在训练的时候是把BRCA1/2突变当作正向label使用的，我们也不指望它能在突变组内部再有什么作为。 对于审稿人质疑CX2和CX5可能并不意味着这些特征是特异性的由于同源重组受损造成，而是一个副产物，作者里巧妙的使用CX2和CX5 CX3 这三个signature以及癌种在BRCA各种突变类型的样本之间做了一个多因素分析。证明，在多因素矫正后，CX2和CX5然后是显著在BRCA1突变的样本中有差异，因此表明CX2和CX5可能与BRCA突变状态直接相关，即是HR受损的结果。 对于审稿人质疑CX5与PARPi的敏感性有关但同时也与铂耐药有关互相矛盾时，作者则给出了如下答复。 这是一个有趣的观察（言外之意就是你看的好仔细），这确实似乎违反常识，因为公认铂敏感性也意味着 PARPi 敏感性。CX5似乎表明一些铂类耐药肿瘤也可能对 PARPi 敏感。这在文献中得到了一些支持，其中对铂耐药的胚系 BRCA 突变型卵巢癌对 PARPi 显示出敏感性。然而，我们认为我们没有足够的数据来进一步探讨这个问题，并没有在文章中强调它（我们的结果也有文献支持，你可以多查查文献）。 第三次意见 作者这一波回复之后，前两位审稿人已经表示可以了。 有趣的是，审稿人2甚至还回复了审稿人3的一些看法，顺便给作者出了主意，很可能是他也看不下去了吧。 审稿人3 压力来到第三位审稿人这里，这次他的评论可以看出来已经是「愤怒」了。 作者似乎没有意识到该领域以前的文献，也没有充分了解他们所采用的数学框架。 每次review我只是对文章中的问题举例说明，即便你回答了我的举例（比如从文章中删除原文）也不意味解决了问题。 作者一开始说他们仔细评估了所有相关关系，但是我们要求进一步验证的几个相关关系由于缺乏支持而被删除。我们的大部分问题导致论文中的陈述被删除，这与所说的相关关系得到很好支持的说法是矛盾的。（这个真的是神逻辑啊，你修改了我之前提出的问题，就说明你有问题） 有趣的是，在这次评论中，这位review做了两件事情。他首先引用了一篇2021年发表在预印本的CNA signature文章，说这篇文章就没有犯作者的错误。其实，他引用的这篇文章正是开头我们提到的一起背靠背发表的另一篇文章。 第二点，为了证明作者使用的模型真的有问题，他甚至自己做了一个模拟研究，以证明所提出的方法存在问题。而解决这个问题的可能方案就是使用另一篇背靠背发表的文章。 事已至此，最终压力给到了editor这边，三轮之后三位审稿人二比一，但是第三位态度非常强硬，那就不得不动用第四位审稿人来当一次裁判进入最终的第四轮修改。 作者更新了什么 这一次作者的回复是四轮答复中最有趣的。 为了让第四位审稿人吃瓜吃的明白一些，作者首先解释了一下前面三轮审稿发生了哪些事情。以下为作者的心路历程。 在整体回复的最后，作者还不忘说了这么一句话： 随着时间的推移，我们与审稿人讨论的主题变得更加详细和技术，但是重要的是不要忽视更大的问题。我们这个研究将大量和全面的基因组数据合成到一个连贯的框架中来衡量染色体不稳定性。这一框架为加深对CIN的理解提供了重要的一步变化，该领域在过去几十年中只取得了零星的进展！（哈哈哈，你们差不多行了）。 大局观归大局观，作者在这一轮用两个主要问题的回答，算是彻底结束和第三位审稿人的讨论了。 审稿人3的第一个问题是引用了一篇他认为没有在方法学上犯错误的同类型文章。 那作者就用第二位审稿人出的模拟基因组的主意，进行了一次模拟比较，设置了五种不同的突变过程，而另一篇文章只给出了3个正确的结果。 至于原因，作者解释为由于单特征编码使用了绝对拷贝数，同一个signature将在不同倍性背景下被人为地分割，这也是他们在多特征编码中删除拷贝数的原因。CHR、WGD-early和WGD-late三个过程被多特征编码所捕获是因为它们能够在整个特征空间中代表CNA的许多生物学特性。例如早期和晚期的WGD尽管有相似的拷贝数变化数，但可以通过片段大小的特征以及每10MB的断点数量区分。（写到这里，不知道另一篇背靠背的文章作者怎么看呢） 审稿人3的第二个问题是自己模拟了一个分析，使用NMF未能重现输入的signature，进而证明方法有严重问题。 作者表示，审稿人的模拟并不是我们方法的有效模拟而是存在一个致命的设计缺陷，人为地导致NMF过程失败。所以又给出了一个正确模拟的例子验证了结果。 至此，三轮掰头结束，整个的审稿过程基本也就要结束了。 第四轮意见 第四轮只有审稿人4发表了一些评论，认为作者已经很好的回答了之前几轮的问题，这是一篇会对相关领域产生有益补充的重要研究。而他也只是提出了一些文章表述上可能需要修改的问题。 审稿和修改过程 回顾一下四次审稿过程的经历，可以总结出作者的文章经历了如下变动。 最初提交的材料集中在signature的推导和它们的生物学解释上，其采用的方式是方法扩展了自己以前发表的一篇文章（Nature Genetics 2018），以及我们发现的17个signature 相关原因的证明。很明显这里缺乏更多的数据支持，稳健型证明和最重要的临床相关用处。有一位审稿人拒稿，另外两位需要大修。 .第二次提交的基本是按照editor的要求重写了一次，对原因证明增加了大量证据，增加了对药物靶点和治疗效果预测的重要部分。审稿人1和2非常认可，但审稿人3又对基本方法提出质疑（为啥不早说呢？）。审稿人3从以前的SNV/SV方法的角度来看待我们的方法，作为回应，作者指出了拷贝数分析的独特挑战。 增新增加了若干图表，在第三次提交后，审稿人3将他们的方法学质疑具体化为一项自己进行的模拟研究。同时提出了对于另外一篇文章方法的认可，明确表示拒稿。而作者则将两种方法进行了模拟数据的比较验证，又一次回答了审稿人3的模拟分析错误。 在第四次和第五次提交后，作者对文章的表述和细节做了大量修改，最终呈现出了我们现在看到的68个figure，60页附件方法描述。 做研究和讲故事 通过阅读四次大修的故事，也许你已经完全意识到了生物信息方法在公用数据中发表一篇Nature可能会经历哪些磨难，但不得不坦白讲，你我应该经历这种磨难都概率很小。 那明知如此，我为什么还有写上万字来记录这个过程呢？其实，我废了半天劲把90多页Peer Review File读完的真实用意，是想尝试搞清楚一个Nature级别的研究从执行到发表，故事性和逻辑性上会有怎样的提升。 幸运的是，在读完这折磨人的90多页文章修稿过程之后，我看到了通讯作者自己在社交媒体发布的文章主线介绍。也终于完成体会了，一个支离破碎修修补补科研项目，如何变成了一个严谨的激动人心的科学故事。 在本次推送的最后，你也来读读吧。以下内容来自于通讯作者的社交平台，我进行了大致翻译，大家重点体会此刻这个研究的呈现逻辑。括号里的内容是我的自行补充说明 一个好的科学故事 多年来，我们一直在与CIN肿瘤作斗争。我们经常看到TP53突变在CIN中出现，但很少看到其他驱动因素。一段时间后，我们开始在混乱中看到了规律，并开始意识到这些特征代表了CIN的不同原因。这些可以帮助我们更好地理解CIN吗？（提出问题） 我们的第一次成功是在卵巢癌研究方面，在那里我们发现了如何对DNA拷贝数（CN）模式进行编码以允许因果机制的识别。这包括片段长度、断点数量等等。作者从浅层全基因组测序的高级别浆液性卵巢癌（HGSOC）病例中确定了拷贝数特征。（介绍背景） 此后，我们改进了之前的编码方式，如不再包括片段的绝对拷贝数。这似乎与直觉相反，但却出奇地有效。现在，不同倍性背景下的相同CIN类型被一个单一的模式所捕获，而不是许多模式，这使我们能够实现泛癌的分析。（介绍方法改进） 我们从以前的研究中知道，每个肿瘤都会有多种类型的CIN，导致基因组中出现多种模式的重叠。因此，我们使用贝叶斯版本的NMF，用我们的新编码解开这些模式。 我们在泛癌种中应用NMF确定了10个特征。然后将其单独应用于每个大的癌症类型中又确定了7个泛癌特征。这使我们总共得到了17个泛癌CIN signature。 我们通过在模拟基因组中正确识别5种已知的CIN原因的组合，来测试编码和特征识别的稳健性。这五种特征包括 mitotic errors, cytokinesis failure, endoreduplication, homologous recombination deficiency and ecDNA circularisation/amplification。 我们的特征在不同的基因组分析技术中也是稳健的。无论是SNP芯片，深层和浅层全基因组，以及外显子组测序。（第二次修改才增加的内容） 至此，我们有信心拥有了一个强大的17 CIN signature，我们必须攀登下一个高峰：了解这些特征背后的生物学。（递进，介绍第二部分解释生物学原因） 第一个挑战：由于NMF产生了稀疏的signature定义，我们需要使它们更容易解释。为了做到这一点，我们把来自输入矩阵、活跃矩阵和定义矩阵的信息结合起来，生成了一个解释矩阵，其中每个signature都是在每个分解成分中被定义的。（第三次修改才增加的内容） 这个矩阵使我们能够开始理解我们的signature，在许多情况下，编码模式已经暗示了一种机制（例如，大长度片段+每条染色体未发生断裂=有丝分裂错误造成的染色体错位）。 第二个挑战：将signature与有缺陷的途径联系起来。为了做到这一点，我们测试了有突变驱动基因的病人的signature活跃度是否明显较高。这些联系，加上上面的矩阵使我们能够为12个siganture 提出推测的原因。（第二次修改完善） 第三个挑战。为假设的原因找到支持性证据。为了做到这一点，我们整合了大量的数据，以验证完善我们的推测。（第二次修改补充） 攀登了这座巨大的解释之山后，我们看到了山顶上的风景。3个有丝分裂错误的信号；3个同源重组受损的信号；4个复制压力的信号；1个NHEJ受损的信号；1个PI3K介导的WGD（星级=证据的强度）。5个未知数。 当我们考虑这个观点时，我们意识到许多被确定的缺陷因果途径包含正在被治疗的驱动因素。CIN特征能否预测对这些疗法的反应？或甚至确定新的药物目标？（你没意识到啊，第一稿根本没想到这个） 为了探索这一点，我们将297个癌症细胞系的signature与来自CancerDepMap的全基因组CRISPR、RNAi和药物筛选数据结合起来。我们发现我们的signature可以预测对44种靶向治疗的反应和49个CIN相关的可药用基因的扰动评估。 鉴于这些令人兴奋的体外结果，我们想知道......我们是否也能预测患者对CIN癌症的主要治疗方法之一的反应：基于铂的化疗？（这也是被审稿人diss才加上的） 以前，HRD已被证明可以预测对铂化疗的敏感性。但现在，我们有办法利用3个IHR特征来分解 &quot;HRD &quot;表型。 为了测试这一点，我们把重点放在了常规使用铂化疗的卵巢癌上。使用总生存期作为敏感性的替代物，我们发现CX2没有预测性，CX5预测抗性，而CX3则是敏感性！这已经非常棒了。但如果我们把它们结合起来呢？ 基于胚系BRCA1/2突变体可能有HR损伤，但不一定对铂化疗敏感的想法，我们想出了一个简单的分类规则，将 &quot;背景&quot; CIN（CX2）从预测性CIN（CX3）中剔除。一个简单的规则，如果CX3&gt;CX2，则为敏感，否则为耐药。 这个简单的分类器非常强大，能够对统一使用铂治疗的患者群体进行剖析。这包括BRCA1胚系突变的卵巢癌，以及其它卵巢癌、食管癌和乳腺癌的队列。其性能也可与更复杂的方法相媲美。 多么好的旅程啊，我们的signature提供了一个了解CIN的窗口，并提供了一个框架来评估泛癌症的染色体不稳定性的程度、多样性和起源。（升华主题，上价值） 为了更快地将这项技术带给病人，我们还成立了TailorBio。这家科技生物初创公司拥有将这项技术转化为精准医疗平台的独家权利，该平台用于改善患者分层并开发新的靶向治疗。 下一个研究前沿是研究CIN的动态变化。我们正在开发技术，利用来自早期病变、KO细胞系和药物处理过的器官进行单细胞基因组分析，识别正在进行中的CIN。欢迎你和我们联系。（介绍正在做的事情，占领地盘顺便招人） 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-06-26-tcga-pancan-cin-signature/"},{"title":"FDA发布ctDNA应用于早期实体瘤药物开发的指导意见","content":"这个月初，FDA发布了将ctDNA应用于早期实体瘤药物开发的指导意见稿。 对于相关公司而言，意见中的注意事项确实具有「指导」意义。对于相关从业者，等于得到了一份「ctDNA在早期实体瘤临床研究应用方向」的参考答案。 整个指南反映了FDA目前对在实体瘤早期临床试验中使用ctDNA作为生物标记物进行药物开发和临床试验设计看法，这部分内容没有涉及将ctDNA用于肿瘤早期检测筛查或在转移性肿瘤的使用。 以下为指导意见的意义非完整翻译版本。 背景 早期非转移性实体瘤的药物开发通常涉及到大型试验和多年随访的时间-事件终点。 某些早期实体瘤患者只需局部治疗(如手术、放疗或放化疗)即可治愈，部分患者则需要(新)辅助治疗才能治愈，而另一部分患者尽管接受了手术和/或系统治疗，仍可能发展为转移性疾病。 ctDNA 作为由肿瘤驱动产生的片段化 DNA，脱落进入患者的血液中，其数量取决于肿瘤的类型、部位、分期、肿瘤负担和治疗反应等。作为一种生物标志物，ctDNA 在早期阶段具有许多潜在的临床用途，可以帮助和加快药物开发。 在早期肿瘤环境中，ctDNA 可用于检测某种靶向性的改变，富集筛选试验中的高低风险人群，反映患者对治疗的反应，或可能作为疗效的早期标记。 支持ctDNA的临床有效性或临床用途的证据在不同的实体瘤、患者群体和测试模式中有所不同。然而多项小型研究表明，在手术或标准系统治疗后，ctDNA检测到分子残留病灶（MRD）会导致预后不良，筛选出高风险的复发人群。 因为ctDNA评估在不同的实验室和用于检测技术之间有所不同，有时会导致结果不一致。许多临床实验室自己制定的方案可能会影响ctDNA的定量检测。检测方法的进一步标准化将使ctDNA在监管环境中得到更好的使用。 应用方向 如果赞助商计划将ctDNA用于患者筛选或作为早期实体瘤临床试验终点，应向FDA进行咨询。以下是 ctDNA 的潜在用途。 ctDNA用于基于分子改变的患者筛选 在辅助治疗中，患者通常会接受治愈性的局部治疗，然后再接受全身治疗以防止复发。在这种情况下，对患者的血浆进行采样可以检测ctDNA，并有可能选择出存在遗传或表观遗传改变的患者群体，而这些改变则可能是研究中特定的药物靶标。 ctDNA 可以用作临床试验标准进行患者选择。 如果试验同时招收了标志物阳性和阴性人群，ctDNA也可作为分层因素。 应评估ctDNA检测肿瘤组织内包含的所有临床感兴趣的突变的灵敏度。如果在ctDNA中没有检测到突变，可能需要进行肿瘤检测以确认阴性结果。 ctDNA MRD 用于患者富集。 在手术后和/或（新）辅助治疗后，ctDNA可以作为MRD的标志物，进而富集临床试验中的高风险和增加复发或死亡事件的患者。 手术或（新）辅助治疗后的ctDNA检测可以确定生物标志物阳性人群。 基线ctDNA状态也可以作为研究中的分层因素，同时纳入ctDNA阴性和阳性患者。 顺序检验中可用于测试意向治疗的人群（包括ctDNA阳性和阴性），也可用于测试ctDNA阳性组。 设计方案可以包括升级实验设计（ctDNA阳性状态的高风险患者）或者基于ctDNA阴性状态的低风险人群进行降级实验设计，临床试验应该是随机的。 如果只给予辅助治疗主要终点应该是无病生存期（DFS），如给予新辅助治疗（有或没有辅助治疗）主要终点是无事件生存期（EFS），或者使用总生存期（OS）。 由于事件有限，不应对主要终点进行早期中期分析。可以考虑后期的中期分析，但这些分析应在试验开始前预先指定，根据多重检验进行调整并设置一个具有足够数据成熟度的节点。例如，在进行任何中期分析之前大多数患者预计应已完成了治疗。 ctDNA作为响应的衡量标准 ctDNA可用于早期临床试验以帮助发现药物活性信号，这可能帮助制定药物开发计划。 FDA鼓励开发关于新辅助治疗后ctDNA反应的有用性证据，证明ctDNA在新辅助治疗后病理完全响应之外的用途。 ctDNA作为临床试验的早期终点 虽然目前还没有验证使用，但ctDNA对药物的反应变化有可能被用作早期终点以支持早期肿瘤的药物审批。 需要进一步的数据支持将ctDNA作为有可能预测长期结果（DFS/EFS/OS）的终点。 在药物治疗前后收集ctDNA数据的试验也应收集长期的结果数据，以确定ctDNA阴性和结果之间的关联。 人们提出了各种验证终点的统计标准，并经常使用meta分析方法。在试验关联水平上验证 ctDNA 的meta分析应该只包括随机试验。赞助商应该讨论并向FDA提供meta分析计划的细节，以验证 ctDNA 在特定环境中的使用。 计划应包括试验设计、患者纳入和排除标准、ctDNA评估方法等细节。 临床试验应该包括一组能代表患者的人群，且实验终点将用于该人群。 应包括足够数量的具有足够随访时间的随机试验。 基于个体患者水平数据的分析应该允许对个体水平的关联进行准确性评估。 应提供基于试验水平和个体水平的相关性判定标准，包括预先确定的 ctDNA 评估时间点。 应包括长期临床终点如EFS、DFS和OS，这些终点在不同的研究中具有明确和一致的定义。 赞助商应探讨数据缺失对试验结果的影响。 注意事项 MRD检测的panel类型 MRD可以利用tumor-informed方法、tumor-naive方法或较少的候选基因panel，每种方法都有自己的优势和局限性。 Tumor-informed panels 是通过对肿瘤进行测序后选择一组突变进行检测。 这种方法的局限性包括肿瘤检测和ctDNA panel构建之间的滞后时间，灵敏度和特异性可能取决于临床时间点、产品分析灵敏度以及检测的突变数量。 Tumor-naive or tumor-agnostic panels 指那些没有对原发肿瘤进行测序的panel。 局限性包括ctDNA panel未涵盖某些肿瘤标志物，并且需要对队列进行额外的特征描述以了解有多少比例的患者可以用这种技术进行追踪。 全基因组测序（WGS）有可能在这种方式中被使用，WGS可以使用除突变、表观遗传学改变（如甲基化）或ctDNA的片段分析之外的其他生物标志物来捕获肿瘤驱动的ctDNA信号。 抽样考虑因素 几个与临床试验设计和预期入组病人群体有关的抽样因素应该被考虑在内。 ctDNA的脱落受肿瘤的组织学、分期分级和大小的影响，因此应与FDA讨论ctDNA测试的时间，并应以测试的性能特征、疾病特征和肿瘤生物学为依据。 应预先指定一个固定的时间点来加入研究。 如果赞助者希望使用多个ctDNA时间点来确定纳入标准（如评估早期检测复发时的干预是否会影响结果）应该有科学数据/理由支持。可以探讨基于不同时间点的敏感性分析（但应事先确定并讨论）。 各组的ctDNA检测时间应该是相同的。 应收集治疗前的基线样本，以考虑肿瘤脱落率的变化对检测性能的影响。此外，该样本将允许对治疗后的样本进行解释以利于研究入组。 研究中的所有地点都应遵循标准化的样品收集、储存、处理和处理方案。 市场应用检测的分析验证注意事项 验证研究应在检测的敏感性、特异性、准确性、精确性和其他相关性能特征方面使用指定的技术方案，其中可能涉及到标本的收集、处理和储存。 MRD检测验证应包括整个检测系统，从样品采集（如用特定的将用于最终上市的检测采集管采集血液）到检测结果输出，包括决定阳性与阴性患者的阈值。 应确定检测截止点，以优化临床使用的检测灵敏度和特异性。分析性能时应该可以准确和可重复地检测MRD阳性。 检测方法应具有高灵敏度和阴性预测值（NPV）以支持治疗降级；高特异性和阳性预测值（PPV）以支持治疗升级。 MRD检测的验证方法将取决于MRD检测类型。 推荐用来自临床试验的样本（临床标本）进行关键的检测验证研究，如确认检测极限（LOD）、检测精度和分析精度。在一些分析验证研究中，由于需要大量的样品临床样品可以用人造样品作为补充。在验证研究中使用人造样本时，应证明人造样本和临床样本之间具有功能等同性，如果在某些研究中使用人造样本来替代或补充临床样本需要提供理由。 对于固定化panel，携带特定突变的细胞系可作为人造样品。对于个性化panel，应根据早期临床研究数据，开发能代表突变数量和类型分布的细胞系。 应使用在检测范围内的样品来证明检测精确性。 应制定一套适当的参考材料以便在多种MRD检测中具有可比性。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-05-16-fda-ctDNA-for-early-stage-solid-tumor-drug-development/"},{"title":"单平台文章阅读量超过100万，我可能做对了三件事。","content":"把写作当作方法。 关于阅读量超过100万这个事 2018 年9月29日，我在少数派写下了第一篇文章，是科普书《基因传》的安利。 2021年6月27日，我在少数派写下了截至目前的最后一篇文章，自己6年硕博生活的6条心得。 在两篇文章之间的1002天里，我不是一个高产的写作者，只写了19篇文章；也不是一个称职的写作者，马上就要一年没有在少数派码字了。 不过最近我发现这19篇文章阅读量竟然也超过了100万，靠着苟活的本领走进了少数派百万阅读作者俱乐部。 借着这篇留念文章，我想简单安利一下写作，再介绍三件我可能做对了的事。 安利写作 写作是非常舒适的社交行为。你不用和别人寒暄，不用察言观色，适合社牛也适合社恐。坦率的讲，过去五年每到重要关头对我有帮助的人很多都是通过写作认识的。无论是学业、生活还是工作，我们从彼此的读者变成彼此的朋友。 写作是具有超级长尾效应的个人产品。5天写完一篇文章，5年后阅读量每天还在增长。有别于搬一天砖挣一天钱，还有什么是比写作更具有性价比的事情么。 写作是最好的逻辑训练。不知道从什么时候开始，「会说」好像变成了我的一个标签。我以为的「会说」是能把想说的事情说清楚，就当作一个优点慢慢接受了。说清楚就等于写清楚，每一篇文章都是一个逐字稿。如果你觉得自己一件事情都说不清楚，可以写下来试试。 我可能做对了三件事 至于为什么十几篇文章也能苟到100万的阅读量，自己可能做对了这样三件事，供你参考。 在可以被人看到的地方写。 想要让自己的文章有机会被人看到，就需要在可以被人看到的地方写。 按这个标准，文章只发布在公众号上就不合适，因为公众号的文章不具有「可及性」。 在绝大多数搜索引擎，公众号里都文章都不能被搜到，也就丢掉了获得长尾效应的机会。如果你不愿买域名搭博客，至少也应该发布在可以被公开检索的平台。具体到自己的做法，我会根据文章大概的受众选择在哪里发布，专业技术类的文章我会直接发布在自己的博客上，通识工具类的内容我就会发布在少数派。这两类以外的内容，多数就是一些临时随机的思考和情绪的记录，我才会发布在公众号方便转发朋友圈。 一篇文章解决一个问题。 想要让自己的文章有机会持续被人看到，就需要考虑面向搜索引擎写作，一篇文章解决一个问题。 第一个关键词是「问题」，构思一篇文章之初就要时刻问自己为什么动笔，想围绕什么需要解决的问题。 第二个关键词是「解决」，如果别人读完文章之后不能顺利解决你提出的问题，那就不是一篇值得写的文章，它会浪费每个人的时间。 第三个关键词是「一个」，我们可以给一个问题提供三个解决方案，但是不要尝试一次解决三个问题。 其实回顾少数派写的这19篇文章，阅读量最高的几篇文章都是做到了能够尽量用一篇文章解决一个问题。比如如何把VScode嵌入自己的工作学习场景，如何一篇文章里就可以学会Zotero 80%的高频操作。这三个关键词缺一不可。 为自己写就会有人读。 如果没人读还能做到持续写，就要为自己写。 写作可以有很多种目的，我以为最核心的目的一定是向内的，不然直接去X乎「谢邀」就好。而这种向内往往出于某种记录的需求，比如记录情绪或者想法。 我不是一个能闷声发大财的人。 写作是我的学习方法，像有些人读书必须出声，自己看一个东西如果想有所收获就得靠写点东西。基于这个原因，一篇文章的阅读量对我而言永远是意外惊喜。相比于呈现自己的学习成果，我更多地通过写作来呈现学习过程。 只要目的是为自己写，就不太会让阅读量高低影响心情。往往写给自己的东西，往往都能引起一些人的共鸣。或许大家都是普通人，遇到的困惑和问题也大同小异。比如我总结过去几年自己的成长经历，虽然是一篇完全个人化的内容，其实也收获了不少的共鸣和反馈。 最后，如果你和我一样不是一个做事情可以风雨无阻坚持不懈的人（也就是习惯性拖更），那还要认真对待自己写的每一篇文章，因为没人知道下一篇会什么时候写出来。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-04-10-about-writing/"},{"title":"Gitee图床被禁？云对象存储配合CDN方案以及图片批量迁移方法","content":"今天好几个小伙伴反馈Gitee不能再当作图床使用了，问有没有更好的markdown图床替代方案。 1 我最早一直用GitHub当图床，从2019年中开始改用腾讯云，用到现在感觉腾讯云对象存储配合腾讯云自己的CDN就是一个还蛮不错的图床方案。 首先腾讯云国内访问的速度绝对是快的，之所以建议配合CDN主要是基于两方面的原因，一是购买流量包的价格整体更划算，首次使用一般还会送半年的流量包，非流量大户妥妥的够用；二是相比于对象存储本身，CDN有着更加丰富的访问权限控制设置，可以防盗链以免被白嫖流量。 我的云存储的使用情况 用到现在大概是有5个G的存储量。 平均每个月的费用就是七八块钱。 你可能注意到今年2月和3月出现了两次异常，原因是我的域名被一个IP盯上了，每天都会遍历一遍域名下的所有图片。所以直接一个月干掉了我60多G的流量。 对象存储防盗链设置规则 这里就需要提到腾讯云对象存储的防盗链设置规则。 腾讯云对象存储本身只支持设置黑白名单二选一，对于大多数人都是设置为白名单更加合适，同时为了能够在本地编辑器（比如typora、VScode和Obsidian）中正常显示图床图片还需要允许空的referer。这就带来了一个很大的问题，如果一个垃圾IP利用空referer规则疯狂读图单纯靠这个规则就招架不住了。 CDN 访问控制设置防盗链 为了更好的配置防盗链规则，这里就推荐云存储结合CDN的配置方案。这样一个通过CDN访问的图片链接首先会遵守CDN自己的访问控制规则，通过之后会再去匹配对象存储的防盗链规则。 推荐的配置方案如下： 首先使用白名单指定可以访问的http地址，然后允许空referer使得本地可以正常显示图片。如果有明确的垃圾IP地址持续攻击，还可以在IP黑名单设置中输入对应的IP段进行过滤。 最后，为了应对可能存在的恶意访问，还可以设置单节点IP每秒钟的访问次数（15或者30基本都可以）。用这个方式就可以杜绝大多数持续性无差别的恶意访问了。 CDN使用效果监控 腾讯云的CDN数据分析后台上基本的数据都可以看到。 比如你可以通过TOP1000 URL 看到那个文件（图片）被访问的此时最多，通过TOP100 Referer 可以看到自己哪篇博客文章被访问的此时最多，通过TOP100客户端IP还能看到哪个IP地址访问的最多。这几个信息都还是蛮有用的。 批量迁移图床 好了，最后一个问题就是如何能够尽可能方便的批量迁移图片。这里推荐一个我曾经使用过的方案供参考。 目前我在使用的本地图床工具是PicGO，软件本身有不少插件可以配套使用，其中有一个插件叫做pic migrater 就是用来批量迁移图片的。 这个插件支持设置需要迁移图片链接的匹配方式，还可以选择需要操作的文件或者文件夹。 以及，如果你使用了CDN，记得把PicGo的配置地址也改成CDN的网址哈。 OK，这篇就写到这里，下次再见👋 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-03-26-tencent-cloud-cdn-setting/"},{"title":"别再用DEseq2和edgeR进行大样本差异表达基因分析了","content":" 如无必要，勿增实体。样本够多，无需预设。 读博那几年，闲着没事就喜欢做各种软件的测试对比。有时候几个转录组样本非得用两三个差异分析方法都做一遍。严谨起来就给它们之间求一个交集，狡猾起来就谁的结果「更好」用谁（想必你也是这么做的）。 2021年，从植物研究转到肿瘤领域后，对于处理TCGA这类大样本队列，我其实不少次也是通过对tumor和normal组直接进行Wilcoxon秩和检验来找差异基因，原因无它，唯快不破。当然，更多时候是两种方法混用，好处是样本量多了跑上DESeq2可以离开座位溜达两圈活动活动。 2022年，前几天发表在 Genome Biology 的一篇论文，算是比较严谨地论证了在大样本量RNA-seq差异分析时，今后即便不考虑速度因素，也应该抛弃DEseq2和edgeR转而使用朴实无华的Wilcoxon秩和检验。 先贴上paper链接，你可以直接读原文或者继续看完这篇文章。 Li, Yumei, Xinzhou Ge, Fanglue Peng, Wei Li, and Jingyi Jessica Li. “Exaggerated False Positives by Popular Differential Expression Methods When Analyzing Human Population Samples.” Genome Biology 23, no. 1 (March 15, 2022): 79. https://doi.org/10.1186/s13059-022-02648-4. RNA-seq实验应该有几个重复 RNA-seq问世以来，最基本也是最关键的应用一直是在2组（有时候也有多组）情况下识别差异表达基因(DEG)，比如肿瘤和正常组织样本，不同处理条件下的细胞系等等。 实际使用时，高通量的转录组数据我们通常只会测三个重复，这里的重复是指生物学重复而非技术重复。有的时候2个重复也能应付，甚至如果没有重复也有相关的软件可以处理。 为什么是3次重复呢？因为事不过三，以及材料有限和可以省钱。实际上，在不少早期专门研究应该有几次重复的论文中，大家的说法也不一，有说至少要6次才准的，也有说4次就够了，还有的说如果想把差异表达基因都找到至少需要12次个重复。 2016年，同样发表在Genome Biology的经典高引用RNA-seq分析综述则给出了如下表格和建议，简而言之，至少3次。 咱就是说，其实前期这些关于样本重复数量的分析，绝大多数都是在用DEseq和edgeR这些软件的基础上展开的。而今天却建议大样本量的分析不要再使用它们了，也蛮有趣。 DEseq2和edgeR不适用大样本 从以上关于样本量的讨论可以看出，转录组差异分析最大的挑战一直是希望三生万物（三次重复得到普适结论），检测的样本量太少。 为了解决这个问题，通过对RNA-seq数据进行各种参数分布假设的统计方法和软件应运而生。其中最流行的两种方法是DEseq2和edgeR，他们的核心假设都是测序数据符合负二项分布，再根据自己的一套逻辑对原始读数进行标准化。如果样本没有重复，负二项分布可能有噪声，可以考虑基于柏松分布的DEGseq。 另一个重要的问题是，对于DEseq2和edgeR这样的软件，为了让各种后续处理成立，一个需要接受的假设是两组样本之间没有绝对意义上的差别，或者说绝大多数基因在两组之间的表达都是一样的。 于是就带来了第一个疑问，一旦上升到大样本量的人群队列RNA-seq研究，样本规模已经是大几十或者几百上千个，绝大多数基因的表达水平没有差别的这个假设是否还成立呢？ 为了评估DESeq2和edgeR识别差异基因上的能力，这篇paper的作者测试了13个群体水平的RNA-seq数据集，总样本量从100到1376不等。分析后发现，DESeq2和edgeR在这些数据集上识别的DEG有很大的差异。 通过上图这个结果可以看出来在免疫治疗队列里，DESeq2和edgeR识别的DEG中只有8%一致。而在大多数大人群样本中，DESeq2都要相比edgeR找到的多不少。 事出反常必有妖，想看究竟问题出在哪里，就需要从FDR的角度进行深入的探索。测试FDR，在大样本的优势就体现出来了，它可以采取随机生成置换数据集的方法进行测试。 于是作者把队列中的两组样本进行混合，新的分组中每个都含有原来的两组样本。通过随机组合1000次置换，原始数据集就生成了1000次置换数据集。 结果很刺激。 首先，DESeq2和edgeR分别有84.88%和78.89%的概率从置换数据集识别出比原始数据集更多的DEG。 其次，DEseq2和edgeR分别从原始数据集中识别出的144个和319个DEG中，有22个（15.3%）和194个（60.8%）是从至少50%的置换数据集中识别出来的，而这些DEG其实都是假的。这个假阳性的结果实在是太高了。 最重要的是，它们还发现 fold change 越大的基因，越有可能从置换数据集中被鉴定出来。但在实际分析时，我们都会认为FC越大那基因的差异越大，它就越重要。而真实情况可能是这些基因本身并非差异表达基因。 这里多说一句，如果你好奇那些其实是假阳性的基因究竟是什么富集在什么功能呢？嗯……免疫相关。 DEseq2和edgeR为什么不灵了 为什么DESeq2和edgeR从这个免疫治疗数据集中发现了这么多假阳性？最直接的想法就是这些数据不再符合DESeq2和edgeR所假设的负二项分布。 为了验证这一假设，研究者选择了两组基因。其中一组是从≥20%的置换数据集中确定为DEG的基因；第二组是从≤0.1%的置换数据集中确定为DEG的基因。评估负二项式模型对每组基因的适应程度后可以发现确实第一组基因的模型拟合效果更差，这与这些基因是假阳性事实也一致。 进一步，为什么模型不适用了？作者检查了所有在至少10%的置换数据集中被误认为是DEG的基因，相对于假定的负二项模型，所有这些基因的实际测量值都存在异常值。 edgeR和DESeq2这样的参数检验中，假设是一个基因在两种条件下具有相同的平均表达量。所以分析结果会受到异常值存在的严重影响。相比之下，Wilcoxon秩和检验在有离群值存在时会表现的更好，因为它的假设是基因在一个条件下的表达量比它在另一个条件下的表达量高或低的可能相等。也就是Wilcoxon秩和检验更关注的是排序而非实际高低。 不止是DESeq2和edgeR，从上面的图可以看出作者还比较了其它几种代表性的分析方法，其中limma-voom和DESeq2、edgeR一样是参数估计；NOISeq和dearseq（最近发表的专门针对大样本量差异分析的工具）则和Wilcoxon秩和检验一样是非参数检验。 在比较谁能找到更少的假阳性差异基因时，DESeq2和edgeR明显败了，其它几个表现都还不错。如果比较它们找到更多真实的差异基因能力呢？ 研究者从12个GTEx和TCGA数据集中各产生了50个半合成数据集（有已知的真实DEG和假DEG）。如下图，只有Wilcoxon秩和检验能在0.001%至5%的FDR阈值范围内可以持续控制真实的FDR。此外，比较了这六种方法在实际FDR条件下的功效，Wilcoxon秩和检验要优于其他五种方法。下图蓝色线是Wilcoxon秩和检验，黄色和紫色虚线是DEseq2和edgeR。 什么时候使用Wilcoxon秩和检验 既然Wilcoxon秩和检验适合大样本的差异基因分析，关键问题就来到了多大样本量算大样本？ 为了研究样本量如何影响六种分析方法的效果，研究者对每个数据集进行了下采样，分别得到了从2到100个的样本量的不同数据集。 从下图结果可以看出。在1%的FDR阈值下，当每个条件的样本量小于8时Wilcoxon秩和检验作为一个非参数检验方法你就别用了。同时，只要当每个条件的样本量超过8个以后，Wilcoxon秩和检验取得了与三种参数检验方法（DESeq2、edgeR和limma-voom）或其他非参数检验方法相当或更好的表现。 考虑到DEG占所有基因比例也可能会对结果产生影响，他们还生成了5中差异基因比例（1%、3%、5%、9%和20%）的数据集，评估结果也显示Wilcoxon秩和检验的FDR和功效也不差。 所以，从这个分析结果来看，当每个条件的样本量大于8个以后，别犹豫，直接上Wilcoxon秩和检验。 怎么使用Wilcoxon秩和检验 懂的都懂，DESeq2、edgeR和limma这三种参数检验方法在转录组研究中长期占主导地位。基本上所有大型研究的差异分析结果都是用它们做出来。但是这三种方法最初都是为了解决小样本量分析的问题。 在群体水平的研究中具有更大样本量（至少几十个），因此往往就不再需要进行参数假设。同时，由于样本量越多越可能存在几个异常值，它们违反假设后会导致P值变得不稳定，进而导致FDR无效。 最后一个问题，就是在实际分析中应该怎样合理地使用Wilcoxon秩和检验进行差异表达分析呢？ 不同于DESeq2, edgeR和limma，作为一种非回归的方法，Wilcoxon秩和检验无法调整各种可能存在的混杂因素（比如测序深度的差别）。要想使用Wilcoxon秩和检验，研究者也推荐RNA-seq样本先进行标准化消除批次效应后再进行计算。 至于你是使用DESeq2的Relative Log Expression，还是使用edgeR的Trimmed Mean of M-values，或者是使用TPM，个人粗浅的认为问题不大（狡猾的你肯定会愿意都试试）。 最后是一段使用edgeR TMM + wilcox.test 分析的代码示例，来自于原文作者。 # read data readCount&lt;-read.table(file=&quot;examples/examples.countMatrix.tsv&quot;, header = T, row.names = 1, stringsAsFactors = F,check.names = F) conditions&lt;-read.table(file=&quot;examples/examples.conditions.tsv&quot;, header = F) conditions&lt;-factor(t(conditions)) # edger TMM normalize y &lt;- DGEList(counts=readCount,group=conditions) ##Remove rows conssitently have zero or very low counts keep &lt;- filterByExpr(y) y &lt;- y[keep,keep.lib.sizes=FALSE] ##Perform TMM normalization and transfer to CPM (Counts Per Million) y &lt;- calcNormFactors(y,method=&quot;TMM&quot;) count_norm=cpm(y) count_norm&lt;-as.data.frame(count_norm) # Run the Wilcoxon rank-sum test for each gene pvalues &lt;- sapply(1:nrow(count_norm),function(i){ data&lt;-cbind.data.frame(gene=as.numeric(t(count_norm[i,])),conditions) p=wilcox.test(gene~conditions, data)$p.value return(p) }) fdr=p.adjust(pvalues,method = &quot;fdr&quot;) # Calculate fold-change for each gene conditionsLevel&lt;-levels(conditions) dataCon1=count_norm[,c(which(conditions==conditionsLevel[1]))] dataCon2=count_norm[,c(which(conditions==conditionsLevel[2]))] foldChanges=log2(rowMeans(dataCon2)/rowMeans(dataCon1)) # Output results based on FDR threshold outRst&lt;-data.frame(log2foldChange=foldChanges, pValues=pvalues, FDR=fdr) rownames(outRst)=rownames(count_norm) outRst=na.omit(outRst) fdrThres=0.05 write.table(outRst[outRst$FDR&lt;fdrThres,], file=&quot;examples/examples.WilcoxonTest.rst.tsv&quot;,sep=&quot;\\t&quot;, quote=F,row.names = T,col.names = T) 写在最后 看到这里，个人感觉也没有必要对自己以前做过的事情产生太大自我怀疑，只是以后在做超过每组8个样本的差异分析时，别忘了也捎带试试Wilcoxon秩和检验。如果有人问你为啥有专门的DESseq2和edgeR不用，就把这篇paper丢过去。 当然，还有这个图。 reference https://genomebiology.biomedcentral.com/articles/10.1186/s13059-022-02648-4 https://rpubs.com/LiYumei/806213 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-03-20-donot-use-deseq2-edger-in-human-population-samples/"},{"title":"春天来了，但你得准备好继续过冬","content":" 面临行业的冬天，公司应该如何过冬，个人又能怎样过冬。 工作后第一次（线上）参加了公司范围的年会，虽然此时已是来年3月。 CEO分享的过程中聊了聊宏观和行业，反复提及的一个关键词是「过冬」。嗯，春天来了，却要做好整个行业开始（继续）过冬的准备。 冬天如此漫长 我们生活在一个又一个周期中，最近几年（前几年和今后几年）都会处在周期的波谷。国际环境和经济环境无需赘述，行业环境也惨不忍睹。看看行业内很有代表性的两家企业 Guardant 和 Veracyte 过去一年的股价变化。 再看看国内两家美股上市公司过去一年的股价变化。 除去股价的直观体现，出口上市和各种相关政策也不被看好或充满不确定性。几个周期波谷的叠加，行业和企业必然会面临寒冬。 企业如何过冬 关于一个企业能否过冬，CEO的分享里提到了四点，脱敏整理后大致总结如下。 充沛的资金。现金流决定一个企业过冬的能力，手上的钱够花几年意味着在恶劣的环境下能坚持多久。 用优势引领趋势。越是困难的时候越要能判断出公司优势和行业趋势。对于NGS检测行业，产品入院是避不开的趋势，如果这也是一个公司的优势，那就可以坚持的更久一些。 新产品的生命力。NGS检测是一个会持续推出新产品的行业，依托于前沿的科研转化，新产品不同于常规互联网产品，在技术和本质上往往都会有全新升级。有没有新产品，新产品在行业内有多久的领先窗口期，以及能不能在窗口期利用产品优势换来商业优势，是关键的问题。 公司的人。除了上面三个因素，最关键的一点就是有没有一群可以共同抵御寒冬的优秀的人。 个人如何过冬 听完上面的内容，这四点也适用于每个人自己如何过冬。 于个人而言，充沛的资金除了钱以外还可以代指各种层面的积累。刘玉玲曾经对「充沛的资金」有一个非常生动的解释。 用优势引领趋势，你能不能充分认识到自己的优势，然后尽可能的发挥这个优势。 个人层面的新产品则是你的技能和能力。在困难的环境下，你能不能生长出自己之前不具有的能力，是否可以承担之前没有承担过角色。 除了以上三点，还有就是你能不能找到彼此信任，愿意与你共同前进的人。 春天来了，但是要准备继续过冬。冬天会过去，春天依旧会到来。 关键是你打算如何过冬。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-03-11-getting-through-the-winter/"},{"title":"任务如何才能按时完成","content":" 工作不需要提前完成，但需要提前动手。小学时的寒假作业没有人会每天写点，要么是第一周写完，要么是最后一周写完。 2022年的第一篇读书笔记来了，这次要和大家分享的是2018年12月出版的《任务就要按时完成》，作者是UIEvolution公司创始人CEO，曾经深度参与开发了Windows95，IE浏览器3.0以及Windows98的日本工程师中岛聪。 整本书只有9万多字，买回来吃了很长时间灰之后终于用一个周末读完，险些因为拖延症而放弃了一本涉及拖延症内容的书。不过读完之后还有点收获和启发，与你分享。 读任务管理和时间管理这类内容，我一直比较谨慎，往往读的越多就越有「道理都懂但做不到」的体会。这本《任务就要按时完成》里「显而易见的道理」也不少，比如：工作要的是结果而不是过程；有工作拖延症的人大多害怕别人的评价等等。 我之所以还是想写这篇文章在于它的特别之处是让我学会了如何判断「任务不能按时完成」，以及书中的方法确实可以尝试执行。 面对分配到自己手里的工作，不能按时完成的原因多数不是拖延，而是不知道自己能否按时完成。这就带来了两个问题，一方面如果过分乐观，我们很可能会等到自己想象中的合理剩余时间才开始动手；如果过于悲观，往往表现的犹犹豫豫不能给出一个准确的答复。 就我个人而言，往往会乐观估计项目完成需要的时间而不能提前告知上级或者客户哪些地方存在风险。 如何才能准确地评估一项工作是否可以按时完成？答案是利用神奇的帕累托法则（也就是我们常说的二八法则）。 如何评估工作能否完成 想必你对二八法则应该不太陌生了，生活工作中方方面面的事情都可以归结为仅有20%的因素可以影响80%的结果，比如80％的销售额来自20％的客户，20％的代码包含了80％的bug，20%的人占有了80%的财富。 评估一项工作是否可以按时完成，同样可以应用二八法则。不妨回忆一下，做完一件事之后，是不是你往往需要总工作时长的20%就可以大致完成一项工作的80%。 在作者推荐和实践的「火箭发射式时间管理术」中，如果你接到了一项为期十天的任务，应该去和上级说明自己需要了解这项工作的大概情况，请给你两天时间来考虑工作规划。 虽然说名义上，我们是利用这两天时间对工作进行预估，但实际上就是实实在在地拼全力、赶进度。这两天需要高速推进工作，尽量做到基本完成。如果能够完成80%就可以答应这件事，如果做不到基本完成就要认识到情况不妙，并积极沟通考虑重新安排。 在时间绰绰有余时全力拼搏，在临近截止期限时从容推进。 接到任务后，在最初两天完成 80%的工作，这件事做起来的难度会超出你的想象。 在《龙珠》里，孙悟空从北界王那儿学了一招「界王拳」，所谓界王拳是一种在短时间内将自己战斗力提升数倍甚至数十倍的招式。这招不伤对手而是将自己身体的力量、速度、攻击力和防御力倍增，其问题在于对自己的身体有极大的负面影响，不能长期使用。 作者形容自己每次面临新项目的时候，都会在前20%的时间里尽可能拒绝一切干扰，使用出20倍界王拳（给自己心理暗示）来推进工作，这里的20倍不是指精确付出20倍的努力，而是让自己的身心进入最佳迎战状态。 在工作中坚决贯彻二八法则 用最初的2天完成8成的工作，在剩余的8天里从容不迫的收工，最大限度的争取余闲轻松工作。 如果想要能够达成这种状态，就需要在工作中的每一天都学习贯彻二八法则。这个比例关系在一天的工作安排中依然适用。在作者看来，一天的工作要在最初的2.5小时内完成 80%。为此，在这2.5小时中要割舍喝咖啡的时间，甚至上厕所的时间都最好省出来。你的身心只为工作服务，要有这样的意识。（下图为作者的每日作息表） 具体情况如何应对 在应用二八法则时，针对耗时较长的工作应该进行纵向分割，直到分割为十天到十五天一个单位。 针对多任务平行推进，要将一天横向分割，例如一天工作9小时，那么就分成3个3小时。 当工作有主次之分时，可以按照不同的重要程度进行划分。 在大任务中穿插小任务 除了上述场景，还有一个打工人更加常见的现实：我们通常会在一个大任务中穿插一个或多个小任务。 今天是周二，如果你做文献分享和项目交付的时间都是下周二。那准备文献的时间就不应该是下周一，因为你会发现项目在下周一到来的时候无论如何都做不完。 为了避免出现这样的狼狈，就要采用 「全速起跑」的二十倍界王拳。像下图这样，应该在周四准备文献分享。 虽说是「全速起跑」，但也不宜在周二周三就开始，因为你先可能需要一些时间准备主题，看看相关资料。确定主题固然非常关键，但也不需要使用太多功力。因此，在做项目的同时可以利用「顺势而行」的工作时间，去搜索合适的主题即可。做好相应准备工作后，便可以在周四顺畅地准备好内容。进而做到从容完工。 写在最后 总结一下： 无论什么工作，只要做到「全速起跑」，就能保证按时完工； 工作期限的最初20%的时间，名义上是「工作预估期」，实际上要完成任务的80%； 如果在最初的两成时间内，不能完成八成工作，就要考虑延长工期； 要提高工作效率，就要做到「合理休整」和「避免分心」。 写到这里，其实你会发现在工作中我们本身就都或多或少在应用二八法则了。不过绝大多数人都是在前80%的时间里完成了20%的工作，最后20%的时间完成80%的工作；只有极少数人可以在前20%的时间完成80%的工作罢了。 以及，整本书（包括这篇文章）的核心都是告诉你用前20%的来完成80%的工作这个非常简单的建议，更重要的还是你能否给自己建立这样一种心态：既然总是用20%的时间完成80%的工作，为什么不在项目开始时拿出两天时间好好「评估」一下呢？ 以及，做到这一点，又谈何容易啊。 补充： 文章发出来之后，很快有朋友给我留言：如果任务中有一些节点不在前20%的时间内呢？比如预计时间的70%采购才能完成，剩余的30%调试设备，也就是很明确的知道这件事情不会因为我的努力而在20%的时间里完成80%的时候这一原则似乎就不适用了。 关于这个问题我的回答如下： 这个规则涉及到两个核心的问题，在书中也没有给出绝对清晰的定义，写成文章就更是要选择性忽略了。一个是如何明确知道自己在一项工作里的指责或者说自己每天需要完成的事情是什么。另一个就是如何知道一项工作的前80%是什么？ 所谓的28分配不是要求我们站在一个过于全局的视角（领导者除外），而是应该细分到自己有明确把控权的部分。我们绝大多数细分到个人负责的部分都可以做28测试，至于在这之前需要谁来花多长的时间完成其他人的部分我们就没有太多的主动权了。 以及，很多时候别人的部分都会发生拖延，我们就做点其他更重要的事情吧。至于如何界定80%，主要是难度和长度，如果是复杂性的工作需要我们有能力拆解出对自己最有挑战性的部分，如果是有明确时长的工作反而更简单些。不过很多时候也都是难度和长度的叠加。 我其实很认同作者的方法，也希望自己能摸索出一个相对适合自己的二八测试方法。尽早投入，全速起跑，一气呵成，拥有闲余，顺势而行。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-03-06-finished-on-time/"},{"title":"从肿瘤突变列表到辅助临床决策","content":"如果你做了一份科研样本的 NGS 检测，绝大多数测序公司都会附上一份标准化的分析报告，当然，这份报告的实际可用性懂得都懂。但如果一位肿瘤患者进行了 NGS 检测，那出具的检测报告就需要慎之又慎，靠谱的公司往往会想尽办法提高报告的准确和严谨，每份报告也都需要进行人工审核和解读。医生们则会在拿到这份报告之后再结合病人的实际病情进行临床决策。 那如何根据突变数据进行临床决策呢？最近刚发表在 Nature Cancer 的文章详细介绍了 Cancer Core Europe（CCE）开发的一款临床决策支持系统(CDSS, Clinical decision support systems)：Molecular Tumor Board Portal（MTBP）。MTBP 为 CCE 的 7 个综合性癌症中心解读肿瘤患者测序结果提供了统一的框架和发布平台，并已经在 2019 年到 2020 年进行的一项 2 期临床实验中，为 500 个晚期实体瘤患者提供了分析结果。 通过阅读这篇文献，你一方面可以了解目前的生物标志物物相关高频基因和高频突变位点（有附件可下载），另一方面可以了解临床决策的基本逻辑和重要数据库，最后还能获得一个即刻可用的在线突变注释工具 MTBP。 肿瘤变异功能解读 解读 NGS 数据首先需要阐明在肿瘤中观察到的特定变异是否改变了癌症基因的野生型功能，因为并非所有变异都有一样的生物学影响。除了识别单个肿瘤基因组驱动因素外，这种分析还能将患者相关的生物标志物相匹配，如某一肿瘤基因的“激活”突变或某一肿瘤抑制因子的 “失活”突变。目前报道的近三分之一的癌症标志物依赖于对药物靶点中发现的变异解读，如下图。 在 MTBP 中，对于一个突变的解读以等位基因为中心的观点进行，包括功能、生物学背景和临床意义。例如一个已知会破坏野生型等位基因活性的特定 BRCA1 突变将总是被认为功能缺失，这里就不需要再考虑如第二等位基因的状态或癌症类型等肿瘤背景因素。 功能层面上，又包含了三个级别的证据。如下图所示：A 类证据首先根据多个数据库检查病人的肿瘤中观察到的突变是否有已报道的效果。需要注意的是，不同的数据库有各自定义的标准，且都在持续收集临床实验和人群遗传结果。 将这些信息进行整合将有利于更全面的使用，根据作者的统计，在被报道的突变中，1710 个有 2 个数据库支持，466 个有 3 个数据库支持，145 个有超过 3 个数据库支持。 B 类证据来自于大家公认的生物学假设，也就是我们通常认为可能会对基因功能产生重要影响的突变类型（如下图所示），C 类证据来自于计算估计。 基于以上标准，在前瞻队列的 500 个肿瘤测序样本中（检测基因数为 326-350）。MTBP 在每个肿瘤中发现了 3 个（中位数）功能相关的突变（单核苷酸变化和/或小差异）。总体而言，共有 26%的突变被归类为（推测）和功能相关，9%被归类为（推测）中性。其中四分之一的分类完全基于生物信息学预测（最低级别的支持证据）。即使有 MTBP 提供的全面功能注释，大多数（65%）在癌症基因中观察到的突变都被归类为未知的功能影响。这说明我们解释肿瘤细胞中发生的基因组改变的生物相关性能力仍然有限。下图详细展示了不同基因的分类情况。 肿瘤变异的临床解读 临床决策支持系统的最终目标是根据最先进的证据，将 NGS 的结果转化为最合适的治疗决策。 影响肿瘤药物反应（敏感性或耐药性）和具有诊断或预后价值的变异不断被报道。然而，这些资源遵循不同的数据模型，要准确地汇总非常困难，需要统一每个资源所使用的词汇和表示方法。MTBP 通过一个半自动的管道实现这一过程，该管道结合了一些生物信息学的映射工具（如 TransVar 和 VEP）和人工注释。 具体而言，MTBP 将知识库中的癌症生物标志物与在肿瘤中观察到的变异进行匹配，包括特定的核苷酸和/或蛋白质氨基酸变化（如 BRCA1:c.5468-1 G&gt;A 或 KIT:p.D572A）、变体类别（如 EGFR19 外显子缺失）或一个功能实体（如 FLT3 致癌突变）。此外，由于肿瘤的异质性，必须考虑到单纯变异之外的肿瘤背景因素，如生物标志物与患者的癌症类型（或其亚型）之间的一致性，是否存在可影响生物标志物效果的共突变，以及目前支持临床效用的证据水平）。下图是具体的示意图。 基于以上标准分类后，不同癌种中突变证据支持级别的分布，可以在下图中清晰的看出。 支持公开访问使用的 MTBP 版本 目前，MTBP 提供了一个供学术研究使用的公开版本 Karolinska - MTB。 你可以在网站上传 VCF 文件或者直接填写突变信息，选择对应的癌种后即可运行。 以一个具有 BRCA2、CDKN2A 和 AKT1 突变的浆液性卵巢癌为例，在线报告包括了如下几项内容。 首先，可以看到不同注释类型的突变，以及每个突变的具体信息，其中包括基因信息、突变信息、多个数据库中的功能相关证据和已经被报道过的生物标志物。 点击蓝色链接，可以看到具体的药物信息和相关证据链接。 此外，点击基因可以看到该基因的基本解读和在泛癌种研究中的高频突变位点，以及你上传突变信息的相对位置。 更多信息你可以阅读文献和网站的使用说明，下次再见 👋。 Tamborero, D., Dienstmann, R., Rachid, M.H. et al. The Molecular Tumor Board Portal supports clinical decisions and automated reporting for precision oncology. Nat Cancer 3, 251–261 (2022). https://doi.org/10.1038/s43018-022-00332-x https://mtbp.org/MTBfaqPublic.php 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-02-27-do-clinical-decisions/"},{"title":"半年毕业 半年工作 我的2021年度总结","content":"掐指一算，又到了每年向各位朋友进行年终汇报的时间，不过「年终」硬生生地让我从 1 月 1 号元旦拖到农历春节前夕（发出这篇文章的时候应该已是初二了）。 我怕大年三十的祝福太多，怕大年初一的鞭炮太响，干脆发一个「2021 年终总结」，愿读到这篇文章的你体会到一丝领导批复年终报告的感觉，顺祝来年继续牛皮。 按照往年惯例： 如果关心数据可以重点读前面部分； 想看思考心得可以重点读中间部分； 留意安利环节可以重点读后面部分 2021 年有 16 个月 个人总结的例行环节是统计过去一年和这个世界的交集。 2021 年，我们的主页（kaopubear.top）迎来了 2.1 万个用户的 3 万次会访问，按照平均会话时长 1 分 17 秒计算，我们彼此通过文字和网络沟通了 642 个小时，按照 8 小时工作量来计算，大致是完整的 4 个人月。 这意味着什么呢？ 用和这个世界的连接时间来计算，我的 2021 年有 16 个月。 播客和博客 「熊言熊语」播客 2021 年处于停播状态，不过后台数据还是让我小小震惊。在我们自己的服务器上，过去 12 个月「熊言熊语」播客共有 1 万 6 千多次的下载，再粗略加上其它几个第三方的平台还是有接近 3 万次的收听。计划播客在 2022 年重启来着，希望计划这次能赶得上变化。 2021 年前前后后一共写了 20 篇博客，写字手速确实大不如前（年），其中比较受欢迎的三篇是 你也可以在学术报告中讲好一个引人入胜的故事 、在陌生领域开始读文献，我劝你别读正文 和 6 年硕博生活的 6 条心得-生活成长篇，希望 2022 年能完成 30 篇的写作目标。 2021 年的 3 个关键词 2021 年发生了很多事情，以至于一件事还来不及消化和分享，另一件事就跟着来了。 如果用三个词总结 2021，我想到的是：转换、融入和成长。 转换 转换，包括身份也包括心态。 2021 年 5 月 8 日，和女票在一起 9 年之后终于领证。当天在民政局险些因为户籍证明的问题领证未遂，临下班前冲过去重新开证明，赶着下班时间才把手续办完。这一天，我们从情侣变成了家人，我在这段亲密关系中的身份也随之发生了改变。 2021 年 7 月 1 日，刚刚提交完毕业论文的我急匆匆入职，开始了工作后的第一个 Q3 和 Q4 季度。可以说过去半年我每一天经历的事情都是新的，同学变成了同事，老师变成了领导。这一天，我从象牙塔里的学生变成了社会人。 2021 年 9 月 23 日，6 月完成博士论文就跑去搬砖的我终于完成了博士论文答辩，当天线上参加的除了答辩老师以外还有我的家人。这一天，我正式结束了自己的全部硕博生活。 2022 年 10 月 2 日，从看房、办各种手续再到搬家，前前后后折腾了 5 个月终于告一段落。过户那一天开始，自己从交房租变成了还房贷，换了一种方式继续为房地产行业贡献绵薄之力。 身份转换总归没什么大问题，事情到了某个时间点自会发生，由不得你拒绝。但心态的转换则需要一个更加复杂且持久的过程。 用什么心态面对自己的伴侣，用什么心态面对自己的同事，用什么心态面对自己的工作，用什么心态面对甲方，用什么心态面对自己，都是需要持续修炼的话题。咱们今后慢慢聊吧。 融入 所谓融入，一方面是融入新的关系中，另一方面是融入到新的环境中。 有不少人和我聊过应该如何认识一个人或者融入一个团队。 我有这样一条准则可以和你分享：如果我（你）有哪里帮助到你（我），我希望你（我）也可以告诉我（你）一些我（你）不知道的事情。 工作场景下，我们和很多人的第一次交流往往从一次提问开始。 以前的结果不理解，祖传的代码看不懂，这个时候都需要你稍微鼓起勇气问问有经验的同事。请教之后事情只做完一半，我通常会再相对详细地介绍一下自己目前做什么，为什么需要对方帮助，以及后续可能会还会需要什么帮助，最后尽自己所能向对方分享一点或许感兴趣的信息。 别人没有义务花费自己的工作时间向你提供服务，如果别人这么做了，你理应为对方付出的时间提供些许价值。 多提问还有一个隐藏好处。人们往往会对自己帮助过的人带有一丢丢好感，因为人生来厌恶损失，而对方在你的身上已经付出了成本。所以珍惜每一次提问的机会并给予最真诚的反馈，如此几个来回，再见面难免会亲切些。 以及，提问开头最好不要说「刚才你讲的 XXX 我没有听懂」，改成「我对你刚才讲的 XXX 非常感兴趣」；提建议开头最好不要说「你为什么没有考虑到 XXX」，改成「想必你也想到了 XXX」。 至于建立信任感我没有什么好的方法，唯一能做的就是真诚。感恩每一个帮助自己的人，毫无保留地帮助需要帮助的人。如果可以，我希望把自己的任何经验分享给身边每一个需要的人，把自己的任何技能教会给身边每一个需要的人。 成长 2021 年的成长可以说都是在前文记录的几件事情发生时被动促成的。 比如，决定买房之后我才重新审视了自己过去的消费习惯，毕业答辩完成之后我才跟实际上用了 6 年多时间完成硕博连读的自己和解，工作之后我才发现自己的思维和习惯并不能轻松的胜任工作。 我是一个情绪相对敏感的人，好在硕博这几年下来已经基本学会了及时内化。即便如此，在过去半年的职场入门过程中还是发生了两次特别大的情绪波动。一次是入职 2 个月左右，做第一个项目时有过短暂的深度自我怀疑，另一次是入职 6 个月后做工作复盘那几天，发现自己在很多方面存在不小的差距。 工作半年，业务能力略有长进，更重要的是认知有一丢丢升级，比如以下几条感悟。 正确地做事非常重要，前提是能够做正确的事。 效率的提升在于复用，不要重复造轮子也不要怕造轮子 学会接受「只有……才……」不要认为「只要……就」 所有的倾听都是为了提问，利用一切机会提出自己关心的问题并及时给对方反馈 给看似无聊的事情找出可以学习的内容好过抵触做无聊的事情 理性看到「理想」和「现实」之间的差距，然后通过自身的行动去缩短差距。 不要太过于投入丰富的情绪，情深不寿，强极则辱。 成为一个有目标感的人，对自己负责，对结果负责。 2021 年的 8 个安利 如果把阅读或者摄取信息看作一项成本是时间的投资，这件事我们需要在意的是投资回报率，读什么东西划算，取决于我们花费的时间交换了作者多少时间。 我们读一篇博客大约需要 3 分钟，作者写一篇大约需要 2-3 天；读一篇深度报道往往需要 20 分钟，作者完成一篇大概需要 1-2 个月；读一本书通常需要 5 个小时，但写一本书往往需要耗费作者 2-3 年的时间和精力，很多经典甚至需要作者十几二十年的人生体验。 用 5 个小时的阅读时间获得作者几年甚至十几年的脑力和劳动投入，读书是一件投资回报率极高的活动。因此，今年的安利还是以书为主。 凤凰项目：一个 IT 运维的传奇故事 2021 年看过几本泛项目管理相关的书，我愿称《凤凰项目》为最佳。它带给我的冲击力有点类似于当初读《人月神话》。 《凤凰项目》描写了一个传统汽车配件制造商 IT 经理和公司各方神通从斗智斗勇到通力合作，最后拯救公司的故事。很多知识从小说中看似上帝视角的「董事」口中说出，让人印象深刻又容易接受。 另外这本书也讲清楚了传统工厂管理和现代化企业 IT 管理的共通之处。所以也给了我一些转行后的信心，更看到了知识迁移能力的重要。 可以说这是一本披着小说外衣的 DevOps 经典教科书，在阅读过程中因为小说描写的场景太过真实，自己经常读着读着忍不住笑出声。 程序员的思维修炼 这是一本教程序员如何学习和思考的书。彼时我刚进入公司，所有东西都要重新学又不清楚该学到什么程度。这本书很清楚地讲了所谓新手和专家的区别，以及一个人从新手出发进行实践需要哪些条件。 此外，这本书也提到作者认为如何看待学习和创造时间学习。学习就像投资，也应该采取「定投」策略。你需要定期投资最低限度的学习时间量，养成一种习惯，想尽办法躲在什么地方去完成学习。虽然并非每期学习都会有很大成效，但是只要定期安排学习，长期来看就会有收获。 为什么幸运的人总幸运倒霉的人老倒霉 这本书是我 2021 年读的一本相对轻松的书，作者 Spencer Johnson 曾写过「谁动了我的奶酪」和「一分钟经理人」。这本「为什么幸运的人总幸运倒霉的人老倒霉」也是他的作品，中文版 2007 年出版印刷 14 年之后我用几块钱买了二手书回来，又一次体会到了一点读纸质书的快乐。 这本书还是他的一贯风格，把简单的道理放进一个简单的故事里来解决一个实际的问题。书中他构造了一个最近状态不太好，不知道如何做决定的「年轻人」形象，然后全书通过为期两天的徒步活动，安排同行 7 个来自各行各业的人和他对话，针对他的困惑给出答案。最后把所有答案连接起来就是一个如何通往更好决定的思维导图。 金字塔原理 《金字塔原理》这本书实在太经典，经典到只要是最近 15 年出版的逻辑或者结构思考相关的书，每一本（几乎）都有它的影子；经典到所有写着「麦肯锡」名字的书归根结底核心内容也（几乎）都在讲金字塔原理。 也许正是因为经典，反而绝大多数需要提高自己逻辑和结构思考力的人都没有读过。不过，这本书的中文翻译感觉有改善空间，有能力的话推荐阅读原版噻。 百万富翁快车道 这是一本容易被标题误导的好书。 看似狂野吸睛的标题背后其实是作者的真实经历和一套容易把读者「洗脑」的完整逻辑。它不是一本「致富经」，因为致富是一个过程，这个过程中需要有想象力、正确的方向和正确的做法，还需要有一些耐力和坚持。 作者将我们绝大多数人的财富获取方法总结为三种路径：人行道、慢车道和快车道。包括我在内的绝大部分人，此刻都是行走在慢车道或者是人行道上，但我们需要培养自己走上快车道的思维和方法。 当有机会转换路径的时候要能抓住机会。路是有的，只是没有人保证结果。 一往无前+生生不息 范海涛是我比较喜欢的一位国内传记作家，先后写过李开复和周鸿祎，最近两年她先后又写了两本雷军相关的书。《一往无前》详细记录了雷军和小米这 10 年的起起伏伏（推荐配合小米十周年公开演讲服用），《生生不息》则描述了雷军重回金山后带领公司转型的过程。 通过这两本中的细节碎片，正面描写之外也可以看到雷军和团队成员背后有过的挣扎与不易。一个人可以先后重塑和建立两家如此优秀的公司，雷军的个人经历还值得一本更精彩的传记。 如果你是一个喜欢读传记文学的人或者也用过小米的产品，这两本书不妨读读看。 智能马桶圈和湿厕纸 哈哈哈哈，读到此处画风突变，书的推荐先告一段落。 2021 年除了书以外，我还想特别安利一下的实体就是智能马桶圈和湿厕纸。 如果你目前的居住条件允许，非常建议你考虑给自家的马桶装一个智能马桶圈。一方面在上海这样的冬天，加热功能让你坐下的时候会感受到春天般的温暖，另一方面，冲洗屁屁功能用上一段时间真的停不下来，关注个人卫生，用心呵护屁屁。 居住条件不允许或者出门在外的时候，则安利使用湿厕纸，温和不刺激。我试过不少牌子，目前交替使用的是舒洁和米特医生。 软件和订阅服务 2021 年我的个人主力工具又经历了一些迭代和优化，这里也一并向你汇报，供参考。 日常工作和学习笔记记录：Obsidian + Workflowy （彻底迁移了印象笔记和 RoamResearch，偶尔用用 Notion） 部分阅读摘抄和想法记录：Drafts + Flomo 思维导图工具：Xmind（使用 Xmind 已是第 5 个年头，工作以后发现似乎是人手必必备的工具） 读书：微信读书（50%）+ 得到电子书（20%）+ 京东读书（10%）+实体书（20%） 付费订阅：财新 App + 三联中读 App + 读库 音乐软件：Apple music（学生订阅） 2022 年的期望 2022 年我对自己的期望是投入。投入地做任何不得不做和想做的事情。 前不久，有同事在年终工作复盘时问到我的「自驱力」来自哪里。那个场景下我自然是乱语一通没有给出让自己满意的回答。 现在想来，可能自驱力更多的是来自于一种「投入」吧。投入地工作，投入的生活，甚至也投入地表演年会舞蹈。在这个过程中，投入进去就会感受到被一种力量推着向前。 如果你暂时不能给一件事找到说服自己做下去的理由，也许不妨先尝试投入做一段时间。投入之后，意义可能自然就会出现。 OK，以上就是我的 2021 年个人总结。汇报完毕，与你共勉。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2022-02-02-2021review/"},{"title":"你也可以在学术报告中讲好一个引人入胜的故事","content":" 科学是叙事过程，而叙事就是讲故事，所以科学需要讲故事。 在前一阵子写的短文中我建议大家在做项目分享之前准备两个版本的 PPT，文章发布之后有朋友问起：每次做学术报告（小到实验室组会，大到博士毕业答辩）感觉你都能讲的不让人犯困，有什么经验分享么？ 今天这篇文章就和你分享一些自己通过读书和实践得到的学术报告准备与练习心得，文章最后我也会推荐几本自己之前读过的相关书籍供你继续琢磨。 文章目录 人对什么感兴趣 把你的结论写在题目里 用多布然斯基模板找到故事的主题 多追问一次「然后呢」 围绕 ABT 结构通过「但是」引入冲突 讲故事可以从写故事开始 讲故事可以从听故事开始 不要做一个只会讲故事的人 安利环节 人对什么感兴趣 人们只会真正对两类事情表现出兴趣，一类是和自己息息相关的事情，比如关于春节（不）放假的通知；另一类是可以满足自己强烈好奇心的事情，比如好友和明星的八卦。 因此如果你想让自己的学术报告或者说任何一次公开发言让别人感兴趣，只能尽量向以上两个方向靠齐。科学（学术）报告多数情况都是无聊的，演讲者很容易过于关注技术和数据，反而不容易让听众理解研究的主要内容。 相信我，没有任何一次报告属于完全意义上的无障碍交流，只有你自己最清楚自己做了什么，所以不要指望别人天然带着强烈的兴趣来听你说话，也不要指望别人能听到你在说什么。 因此，了解人对什么感兴趣是讲故事的前提，嗯，再重复一次：人们只会真正对两类事情表现出兴趣，一类是和自己息息相关的事情；另一类是可以满足自己强烈好奇心的事情。 把你的结论写在题目里 「开门见山」是学术报告最实用的方法。针对一次报告，大到报告的题目，小到一页 PPT 的标题，都需要是一个「有方向」的结论。 报告的标题应该能够让听众知道你发现了什么以及将会在报告中分享什么。题目写的越清晰，就越有可能吸引更多人的兴趣。 「吸烟对于肺癌的影响」这样的题目就不是一个结论，因为它不包含影响的方向，「吸烟可以显著提高肺癌患病风险」才是。听报告的人会带着明确的结论进入到你的分享中，也就更容易在短时间内集中注意力。 具体到 PPT 中的每一页，结论（如果有）也应该体现在标题里。不要让听众自己从一堆密密麻麻的文字里去提炼，别人的每一次走神都会漏掉一页内容，漏掉了一页内容基本上就等于放弃了全部。 写文章的思路其实也一样，如果让你从以下三个标题中选择一个点开读，你更倾向于哪个呢？ 学术报告中引人入胜的故事 如何在学术报告中讲好一个引人入胜的故事 你也可以在学术报告中讲好一个引人入胜的故事 看到第一个题目，你甚至无法分辨我是要向你介绍几个故事还是要介绍如何讲故事；第二个题目你就能明确感知我要写的是讲故事的方法；看到第三个题目则是直接把「你」变成了这篇文章的一部分，点明一个有方向性的结论，即你也可以在学术报告中讲好一个引人入胜的故事。 用多布然斯基模板找到故事的主题 如果不从 XXX 的角度思考问题，XXX 的一切都毫无意义。 《遗传学和物种起源》的作者费奥多西·多布然斯基是有史以来最重要的遗传学家之一，他在 1964 年给《美国动物学家》杂志的文章中写下了这样一句话。 Nothing in Biology Makes Sense Except in the Light of Evolution. 如果不从进化论的角度思考问题，生物学的一切都毫无道理。 不论用「毫无」两个字本身是否科学，都不影响这句话对于我们准备学术报告的意义。如果你能把一次报告整理成类似上面的一句话，也就找到了整个故事的核心。 你的故事可以有很多个片段，但应该只有一个核心，也是在听众听完之后你最希望他们记住的内容。如果你自己在准备报告的时候都无法整理成这样一句话，更不要指望别人能记住你讲了什么。 如果不从剂量的角度思考问题，谈论毒性的一切都毫无意义。 如果不从克隆进化的角度思考问题，肿瘤研究的一切都毫无意义。 如果不从加班赶下周 deadline 的角度思路问题，谈论我周日对你放鸽子毫无意义。 布然斯基模板之所以重要还因为他可以给别人一个听你讲故事的理由。 我要和你讲讲 XXX 是如何起作用的，你需要了解这件事，因为如果不从 XXX 的角度思考问题，XXX 的一切都毫无意义。 多追问一次「然后呢」 因为 A 所以 B，然后 C；如果 A 那么 B，然后 C 谈到给别人一个听你讲故事的理由，就需要凡事多追问一次「然后呢」。 我们自己身上发生过的事情并不代表是有意思的事情，我们自己正在做的科研项目也不代表是有价值的研究。在进行学术报告时应该时刻提醒自己，坐在台下的人为什么要听这个东西？我们通过追问一次「然后呢」找到更深一层原因和意义。 标准的叙事逻辑是因为 A 所以 B 和如果 A 那么 B，但往往 B 都还是和你自己相关的一个延伸，只有扩展到 C 才可能引起别人的注意。 因为使用了这项技术，可以使得检测的灵敏度提升到万分之一，然后会让潜在的十万名患者从中获益。 如果你不借我 1000 万，那么我的公司马上就要破产，然后之前借的 1 个亿也不可能还了。（大公司和银行贷款的常用句式） 围绕 ABT 结构 通过「但是」引入冲突 没有叙事的 AAA 结构 讲故事的核心在于冲突，冲突的正反两面是推动一系列事件持续的原因。 理解上面这句话只需要一个最简单的例子。「猫坐在毯子上」不是一个故事，但「猫坐在狗的毯子上」就是一个故事了。 很多学术报告（无论规模和咖位）中，我们接受到的都是 And And And (AAA)结构。这样的报告没有故事，只是事实的罗列。 如果你在测序公司做过项目测序，他们送给你的标准化数据分析报告就是典型的 AAA 结构。分析报告等于：质量控制 And 定量分析 And 差异分析 And 通路分析 And 互作网络。 你明确知道这样的测序报告不等于发表论文，但还是把学术报告做成了一样的格式。 过度叙事的 DHY 结构 除了事实罗列的 AAA 结构，你要避免的另外一种结构是 DHY（Despite, However, Yet）。 所谓 DHY 就是让一个故事承载太多的走向。我曾经不只一次听到过这样的报告，报告人想要把每一件事情都扯上联系，他会说：尽管（Despite）A 事情很重要，但是（However）B 事情也需要考虑，然而（Yet）我们通过研究 C 发现…… 这样的报告，对于业内高手来说或许可以抓住事情的关键，但是对于大多数人而言留下的只能是听不懂的泪水。 故事的灵魂是 ABT 结构 XXX And XXX，But XXX，Therefore XXX。 如果看完这篇文章你只能记住一件事情，我希望就是上面这个 ABT 模板 所谓 ABT 结构就是用 And 将事实连接作为故事的开头，通过 But 改变叙事走向让故事得以推进，But 通常会抛出一个问题或冲突，带来一种紧张感。最后经过一系列寻找答案的过程，用 Therefore 走向故事的结尾。 如果你了解过一丢丢逻辑推理或者芭芭拉明托的金字塔原理，其实 ABT 就是一个经典的三段论式的结构，分别对应了金字塔原理中的状况、复杂性和解决方案。 对应到具体的学术报告类型，一个经典的 ABT 结构可以是如下一种展示形式： 这里我们整理了 XXX 数据和 XXX 数据，同时已有研究显示 XXX（2-3 张 PPT）；但是这些和我们初步的分析并不相符（1-2 张 PPT）；因此我们使用 XXX 方法，从 XXX 数据，开始分析 XXX（分析过程 3-4 张 PPT）；最后我们发现 XXX（1-2 张 PPT），通过以上的探究我们认为 XXX，这将有助于 XXX（1-2 张 PPT）。 落在纸面上，一篇论文摘要的 ABT 结构可以是如下一种形式： 已有研究者做了很多 XXX 工作 And 他们发现 XXXAnd 这些结果对我们有很深的启发，But 我们认为关于 XXX 的推论并不准确（完善），Therefore 我们希望我们的工作可以 XXX。 讲故事可以从写故事开始 学习讲故事的一个好方法是从写故事开始。 以自己举例，其实我发出来的每一篇博客都可以看作是一个讲稿。 有时你会察觉到我的文章非常粗略甚至像是一个大纲，那它很可能就是一次报告的大纲；有时候你会感觉我的文章读起来啰哩啰嗦字里行间都是「嗯嗯啊啊」，嗯，没错，那它很可能就是一次报告的逐字稿，我甚至会在写东西的时候留几个「气口」供未来的听众思考。 如果你对写故事感兴趣，有两本编剧相关的书可以推荐。一本是 1997 年出版的编剧圣经《故事》（罗伯特麦基），另一本是《故事写作大师班》（约翰特鲁比）。把这两本书读完再应用到自己的领域多加练习，你也一定可以是自己专业领域的好编剧。 讲故事可以从听故事开始 学习讲故事的另一个好方法是听故事。 抓住一切机会去听你的导师怎么做报告，去听你的老板怎么做报告，去听领域的大牛怎么做报告。在听内容的同时也去听他们的逻辑和讲法。 抓住一切机会去提问。如果你不敢在公开场合讲话，最好的练习方式就是从在公开场合提问开始。这里有几个关于如何提问的建议也供你参考。 如果知道对方要讲的主题，最好带着一个「想解决的问题」去听 在听的过程也如上文所述，可以时刻带着「然后呢」的疑问去思考 公开场合尽量不要提「反驳」和「确认」类的问题而是多提「展开」类的问题 尽量第一个提问，因为可能只有一个提问的机会 如果没有人提问，就主动问问讲者刚才他略过的内容 如果你对某一部分内容有疑问，不要说「我没有听懂你刚才讲的 XXX」而是说「我对你刚才讲的 XXX 非常感兴趣」 不要做一个只会讲故事的人 讲什么永远比怎么讲重要，上好的食材只需要最简单的烹饪，再漂亮的配色都拯救不了 0.5 的 P 值。 一个只会讲故事的人每次开头能说的都只是「我有一个朋友」。当别人提起你的时候，应该听到「而且 TA 是一个会讲故事的人」，而非「但是 TA 是一个会讲故事的人」。 做一个会讲故事的人，而不是一个只会讲故事的人。与君共勉～ 安利环节 进入文末的安利环节，以上关于 ABT 的内容就是我很早之前在读《科学需要讲故事》这本书学到的，而且屡试不爽。市面上教人讲故事的书有不少，但是告诉你科学为什么以及如何讲故事的书并不多，如果你对这部分内容感兴趣，推荐读读这本书。 这篇文章的主要内容其实集中在学术报告的结构部分，而没有着力于「演讲技巧」和「PPT 制作方法」。 如果你需要前者相关的内容，推荐读读《高效演讲》和《演讲的力量》，如果需要后者相关的内容，推荐读读《写给大家看到设计书》。 下次再见 👋 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-12-06-how-to-tell-a-story-in-presentation/"},{"title":"OncoSearch 肿瘤研究必备（自用）聚合搜索工具","content":"如果你目前的学习或者工作和「肿瘤研究」相关，面对日新月异的研究进展，想必总会在实际工作开会或者看文献的时候发现各种奇奇怪怪的基因和名次。问同事，有点不好意思，鼓起勇气问了很可能就也记不住。（好吧以上都是我目前的现状）。 基于以上原因，借助 Google CSE 的羊毛，我就整了这么一个叫做 OncoSearch 的小工具。开发成本可以说是没有，但着实解决了自己现在非常棘手的问题，于是也推荐给可能需要的你。 OncoSearch 利用 Google 搜索引擎 API 整合了肿瘤相关的接近 30 个常见网站对你的输入内容进行搜索。你可以尝试搜索基因名如 EGFR，突变位点如 BRAF V600E 或者是任何和肿瘤相关内容。 OncoSearch 不生产知识，只是 Google 搜索结果聚合的搬运工，所以这个工具使用的唯一前提就是能正常的打开 Google 搜索。根据自己的日常使用总结出来的高频需求，目前的 OncoSearch 和直接在搜索引擎里查询想必有如下几个特点。 接近 30 个肿瘤医学相关的网站（还会持续增加欢迎推荐），基本覆盖了肿瘤研究的方方面面，例如基因功能、基因表达、突变信息、药物信息和临床实验信息以及文献等。 我给最高频的一些关键网站添加了标签，方便一眼看到搜索结果的主要类型是变异相关、药物相关、临床实验相关还是常用综合性网站。 省去了很多每次搜索肉眼过滤的时间，如果按照相关性排序，OncoSearch 往往在第一页我都能找到自己想要的结果。 所有标签都被做成单独的 tab 可以进行过滤，比如搜索后按照时间排序，再点开文献标签页，你甚至也能一并大概了解这个东西目前的最新研究进展。 可扩展性，OncoSearch 本身就是一个简单的网页，但是也因此有了很多可扩展性。如果今后还有新的易于实现的想法，我也都可以在这里测试上线。 效果如下图所示 OncoSeach 已经推荐给了身边的一些朋友同事，大家都觉得还不错。因此如果你也在这个领域（且能用 Google），我非常认真地建议你把它作为一个常用搜索引擎收藏并用起来。 嗯，真的挺香。 访问地址 https://kaopubear.top/oncosearch 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-11-21-oncosearch/"},{"title":"读陌生领域文献，我劝你别读正文","content":"防杠声明： 如果以下内容你认为哪里不对，那一定是你的问题。emmm，说明你已经不是这个领域的新人啦，大佬喝橙汁，恭喜恭喜！ 迷途知返： 如果你想长期在某一个领域深耕，关注相关的研究文献进展。我推荐你像追剧一样读文献，关于这个话题我曾经录过一期单人播客，当时发布以后得到了不少反馈。如今的我依旧非常推荐你听一听这期播客，找一些追踪文献的思路喝灵感。 今天这篇小文则想与你讨论如何在一个陌生领域里开始读文献。进入新领域，最难的事情是什么？没有人脉没有资源还听不懂黑话。因此，以下21字箴言送给你。 读新番 读书和读文献究竟是应该多读经典还是读新？我的经验是读最新内容，经典永流传而会内化在新的研究结论中。 读作者 混圈子，尤其是混新圈子，「咱有银」永远是最重要的。读新领域的文献也是一样，看到一篇高分或者是合胃口的文章，记得多留意一下第一和最后一个作者。 外国友人可以盯住他的twitter，国内的就去微信里搜搜，赶上乐于分享的赶紧把人家blog和GitHub订阅一波。 然后呢？然后这些人读啥你就读啥，这些人干啥你就干啥，这些人吹谁你就跟着吹谁。以后和同行聊起来，就使用如下句式：你说他啊？熟！下次你用拼多多我喊他给你砍一刀。 读题目 拿出高考英语或者考研英语精读文章攻克长难句的架势，把一句话里的主谓宾定状补都圈出来。 然后干啥？然后就把每个句子成分都去查一遍，这是最快速的积累和学习专业名词的方法。 行业黑话一学会，和人聊天就起飞。 读摘要 新领域的文献，能把摘要读懂就是胜利。如果读不懂摘要，就大声地告诉自己：摘要读不懂不是我的问题，是作者的问题。 摘要里涵盖了最精简的背景、方法、结论和意义，就类似于我昨天文章里写到的5分钟PPT版本。如果你感兴趣，再像读题目那样再分析一下摘要里的英文长难句，接着继续练习名词解释。 看数据 看发文章的团队是什么实力主要就看他们用了什么数据。数据公开了么？哪里能下载类似的同类型数据？什么？文章里写了提出要求后可以提供数据？真不自信。 看方法 虽说读文献建议读新，但看方法要溯源。往往一个方法经过很多次使用以后，出现的地方就会从40分的杂志来到4分的杂志，如果你看到的刚好是4分那篇，最好要争取找回去。 攀关系 了解了文献里使用的数据和方法，接下来就是攀关系。虔诚地扪心自问：这数据要是给我，我能干点啥；就我手上这数据，那方法还灵么？ 再次强调，如果你觉得以上内容哪里说的不对，那一定是你的问题！你已经不是这个领域的新人了，那就转发给你身边的新人菜鸡。 预告 下周开始，我将相对频繁地更新相对精简的文献阅读笔记。我关注的领域主要是肿瘤NGS相关内容，如果你也是这个行业领域的朋友，欢迎多多交流。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-09-26-dont-read-full-text/"},{"title":"准备两个版本的PPT","content":"昨天发了一张图出来，配文是：不论你今天做什么，都祝你好远，顺祝自己。 其实今天是我博士学位论文答辩的日子，没错，工作快 3 个月之后的打工人回来「抽空」答辩。心里有点忐忑，不过好在讲的内容是最近两年断断续续主要做的东西。 前段时间我在完成一次面向客户的项目汇报前更是紧张的一匹，好在同桌铁子讲的一句话让我缓解了一点焦虑。他说： 你得知道，你要讲的东西全世界再没有人比你更熟悉了，不要慌。 这话我今天早晨又反复和自己讲了几次，下次你也可以试试。 准备两个版本的PPT 说到做项目分享，有不少人曾经和我讨论有没有什么心得，我其实经常会采取的方法是准备两个版本的 PPT。 如果时间允许，一个项目可以同时准备两个不同时长的版本，一个 40 分钟，一个 5 分钟。比如我这个项目 40 分钟的版本用来今天答辩，5 分钟版本之前用来申请了一个奖学金，也没浪费。 具体点说。 40 分钟的幻灯内容页大概三十多张；5 分钟的话内容页有六七张就够了。 40 分钟的每个层次内容可以扩展三点依次介绍；5 分钟的扩展三点就省了只讲「层次」。 40 分钟要讲清楚来龙去脉：背景，方法，结果，讨论；5 分钟只讲问题的严重性紧迫性以及解决问题的效果。 40 分钟的需要让评审记住你逻辑严密、思考充分、技术过硬；5 分钟的让评审记住你人还行或者想试试东西。 40 分钟的讲完之后听众最好觉得「无话可说」；5 分钟的讲完之后听众最好想「加个微信」。比如之前参加奖学金答辩的一位老师，今天和他的学生一起又来听了一次完整版，希望内容对他们的课题能有一点点用吧。 如果路子再野一些，可以考虑 40 分钟版本的分享前面也还是先讲 5 分钟版本。开门见山不够，直接翻过去。 以及 因为有两个答辩委员会老师人在北京，今天的答辩是线上线下同时进行的。结果线上热闹得很，后来得知除了自己的父母，他们携我的姨夫姥姥及若干家属同步观摩了答辩全过程。 如果你今后有机会参加线上的活动，也推荐你不妨把链接发给自己的家人。他们很大概率听不懂，但一定听得津津有味不亦乐乎。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-09-23-two-version-ppt/"},{"title":"通往更好的决定","content":"休息两天读完了这本一百页出头的小书，有感触也有收获。 先说说作者和这本书。Spencer Johnson 最出名的书应该是「谁动了我的奶酪」和「一分钟经理人」，是那种即使你没读过也会经常听到书名的那种。而今天要写的这本「为什么幸运的人总幸运倒霉的人老倒霉」也是他的作品，这是一本 2007 年出版的书，印刷 14 年之后我用几块钱买了二手书回来，然后又一次体会到了一点点读纸质书的快乐。 Spencer Johnson 应该是最会讲故事的医生了吧（没错，是医生）。这本书还是他的一贯风格，把简单的道理放进一个简单的故事里来解决一个实际的问题。在这本书中他构造了一个最近状态不太好，不知道如何做决定的「年轻人」形象，然后全书通过为期两天的一次徒步活动，安排同行的 7 个来自各行各业的人和他对话，针对他的困惑给出答案。最后把所有答案连接起来就是一个如何通往更好决定的思维导读。 只要读者能把自己带入到这个年轻人身上，整本书读起来就非常流畅。 外国人写书有一个特点，就是习惯给出一个问题的具体解决路径，会明确的告诉你把大象装进冰箱需要几步，这样一来可复制性就要更强些。而我们自己的文化更看重悟性，我给你讲一个事情一定不能讲明白咯，10 分的内容最多给你讲 3 分，剩下的 7 分你能领会到多少全看你我的缘分。这种做法的好处是能出真大师，但是对悟性不高的普通人就没那么友好了。 决定的重要性 幸运的人总幸运倒霉的人老倒霉，在于人能不能持续做出更好的决定。做出一个更好的决定比更正一个错误的决定要快得多，工作上效率最低的事情就是重复更正之前的结果。如果能完整应用一种可靠的系统方法来指导我们如何做出决定，那「幸运」的概率就会更高一些。 想要通往更好的决定，就需要我们避免在片面的事实基础上作出片面的决定。要不断作出更好的决定，既要保持头脑的冷静，又要保持内心的热情。每做一个决定之前，我们都应该问自己两个问题：运用头脑，问自己一个实际的问题；忠于内心，问自己一个私人的问题。 问自己一个实际的问题 实际的问题包括三部分内容：我是不是正在满足自己真正的需要，告诉自己所有可以选择的方法，并对事情深思熟虑？ 满足自己真正的需要 「满足自己真正的需要」首先要学会区分什么是想要和需要，问问自己这是我想要的还是我需要的。当我们努力追求欲望时经常会忽略掉自己真正的需要。我们想要的东西很多但是我们需要的东西很少。如果想要分辨想要和需要，不要思考当下想要什么，可以问自己「如果回过头来看，我希望自己怎么做」。想提高做事的效率，就把最重要的事情放在第一位。 在头脑中描绘出你满足自己真正需要时的情形，然后集中精力把这种情形描绘得尽可能具体、清晰，就好像你已经真的满足了自己的需要一样。我们对最后需要的结果越清楚，就越容易处理执行任务过程中可能出现的突发事件，就会变得更果断，也能更快地作出更好的决定。 告诉自己所有可以选择的方法 经常听别人或者自己说出这样一句话：我现在没有选择。但我们必须意识到在大多数情况下你我都有选择的余地。 从提问和收集必要的信息开始，必要信息是指为了做出更好的决策必须要知道的内容，所以也包括那些你不愿意知道的信息。 我们最终会选择对满足自己真正需要最有帮助的解决方法。信息是一系列事实和人们对这些事实的看法和感受。我们要反复和自己确认，我是否掌握了必要的信息，谁拥有这些信息，到哪里可以找到这些信息，获得这些信息的最好方法是什么，我有没有亲自去证实这些信息的准确性。 收集的有效信息越多，就会发现自己的选择越多。 对事情深思熟虑 「对事情深思熟虑」需要将可能得到的结果与我们真正的需要进行比较 ，判断这个结果的好坏。 什么结果才能满足我真正的需要？如果我按照某个决定去做，可能会发生什么，然后呢，再然后呢。 我害怕得到的最坏结果是什么，我能想到的最好结果是什么。如果面对这两种情况，我分别会怎样做。我对最有可能得到的结果有多么清晰的预想？对我来说，这个结果会是什么？对别人来说，这个结果又会是什么 对自己提出一个私人的问题 私人的问题也包括三部分内容：我做这个决定对自己是不是诚实，有没有相信我的直觉，我是不是还应该得到更好的？ 对自己是不是诚实 大多数人之所以会遇到问题，就是因为自欺欺人。现实是指任何一种真实的情况，真相则是对自己或他人所处现实的描述，对自己诚实就是要对自己说真话。 我们越早看清真相，就能越快作出更好的决定。要找出真相，就要先找出自己一直以来深信不疑的幻象，虽然我们希望美好的幻象是真的，但它实际上并不可靠。 人们往往更容易发现他人的错误，所以要经常问一问别人对我们有什么看法，留意其中有没有符合自己真实感受的东西。 记得问问自己：我有没有仔细审视我过去的决定并从中吸取经验教训，我有没有认真观察周围环境和自己真实的内心，我有没有注意到显而易见的事实，我有没有看清事情的真相，我是不是在对自己说真话。 有没有相信我的直觉 直觉就是你根据以往经验获得的深层认识，你会在某种程度上认为它对你来说是正确的。相信直觉需要把决定时的感受和决定带来的结果联系起来，反复思考，运用直觉并留意自己在做决定时候的感受。 情况可能比较庞杂，但是如果感觉复杂那肯定是自己一手造成的。情况庞杂指一件事情涉及许多方面，复杂意味着我们无法将各个方面区分开来。 我们对自己作决定的方式的感受常常会预示出将得到的结果。 任何时候都不应出于恐惧而决定做什么事，因为在恐惧的感受下就不会带来好的结果。体会做决定前自己的感觉是怎样的：压抑还是平静，清醒还是糊涂，筋疲力尽还是充满活力，心怀恐惧还是热情高涨，独立自主还是唯唯诺诺？这个决定是不是真的让我感觉舒服？像我看到最喜欢的颜色，邂逅要好的朋友，或是平静地散步那样舒服。 你可以尝试这样去向自己提问：如果对一件事情当你无所畏惧的时候我会怎样做。然后就去那样做。 我是不是应该得到更好的 一个人的观念，尤其是他真正相信自己应该得到什么的想法，会影响他的决定。 想要发现我们真正相信什么，必须认真反思自己经常性的行为。有时我们可能觉得自己应该得到更好的，行动却表明了并不是真的那么想。要不断作出更好的决定，关键在于要有意识地相信自己应该得到更好的，并采取行动去实现它。 记得问问自己：我有没有认真地反思自己过去的决定和行动，发现我真正相信自己应该得到什么？我有没有看到我的决定体现出的自己的信念？我是不是对自己的决定有足够的信心可以将其付诸行动？ 你可以尝试这样去向自己提问：如果你真的相信自己应该得到更好的，那么现在会怎样做？然后就去那样做。 如果你是一个经常不知道如何做出决定的人，我推荐你有机会可以读读这本书，然后把这两个通往更好决定的系列问题应用到自己的实践中。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-09-21-make-better-decision/"},{"title":"更多地写 但是写的更短","content":"前几天读到了一篇文章 Write 5x more but write 5x less，作者Mike Crittenden是一位Engineering Manager，也是一个日更博客的作者。 从题目，你应该就可以看出来作者认为每个人都应该更多的写作同时写的更短，他的建议是写作频率提高5倍但是平均长度应该缩短5倍。 The average person should write 5x more things than they do. The average written thing should be 5x shorter than it is. 之所以要更多地写，是因为：写作可以帮助人思考，练习可以让你变得更好，写作比演讲更容易分享传播，好记性不如烂笔头，以及把旧的想法从头脑里拿出来才能换来新的想法。 之所以应该写的更短，一方面是因为如今这个时代写的越短阅读的人很可能就越多；另一方面是因为二八法则（Pareto principle），即20%的因素就可以影响80%的结果。 其实，从今年6月分开，我就已经在践行「write more, but shorter」，但主要原因是希望通过尽可能的片段内容写作来降低自己的输出压力。我把每天的想法通过 Workflowy 进行分享，你可以在主页找到这个略显凌乱的想法碎片访问链接。 但是写成一篇blog还有更高的要求，它需要你能够学会简要地解释一个想法或概念，让内容更容易理解，即 「more briefly and digestible」。在我目前仅有的2个月工作体验中，这个能力非常重要。 于是，我想开始尝试恢复一下高频率但是低密度的写作输出，因为一旦人长时间放弃做一件事，就会放弃做一件事（真是听君一席话胜似一席话啊）。至于写什么内容，无非还是自己的专业内容和思考想法吧。 Write more, but shorter. More briefly and digestible. 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-09-19-write-more-but-shorter/"},{"title":"问题出现我再告诉大家","content":"过去两三个月有好有坏有不少事情，如果只能用一个词来形容就是「痛苦」。发现自己是一个能够熟练反向应用二八法则的人，用80%的时间做20%不重要的事情。 自己的问题，需要自己解决。 自己的问题 喜欢给自己找理由进行自我催眠 做A太忙了所以没有时间做B。 找不到做事重点目标感弱 为了证明做A而没有时间做B，会在A的细枝末节花费很多时间，导致A也很难推进，表现为只做事没结果。 制造恐惧又不能直面内心恐惧 因为上面两个问题，习惯了在潜意识里极度扩大一件事的完成难度，然后因为担心自己做不好就表现出拒绝开始。 不敢坦然面对能力不足。 不愿意承认自己很多事情目前只能做到60分甚至50分，处在严重的「能力陷阱」中，有能力上的「偶像包袱」。 需要自己解决 不给任何需要做的事情找理由进行自我麻痹 学习找到做一件事情的重点，抓大放小，要事优先。 培养目标感，做一件事情需要在有限时间内达成某个能够量化的目标。 先行动后思考，不要做思考问题的熊，要做解决问题的熊。 要做事情就要学会做错事情。学会坦然面对自己能力的欠缺和不足，以60分为一件事的阶段性目标。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-09-01-my-shortcoming/"},{"title":"重做新人 NGS肿瘤领域可以学些什么","content":"不出意外，很可能你将「重做新人」看成了「重新做人」，然后一脸问号的点进来。 前两天写了篇文章新手和专家的区别以及如何看待学习提到最近自己为什么重新陷入了知识焦虑和学习焦虑之中，其中有段关于新人进入一个领域之后的感受描述也想在这里单独拿出来与你分享一下。 在任何一个领域，当你作为菜鸡进入的时候通常都会面临着这样一种情景：抬眼望去你的面前是经验阅历丰富可能还比你年轻的同辈，你的身后是这个领域积累了几年甚至十几年的知识储备，你左顾右盼时到处似乎都是不应该错过的信息。你知道自己的的眼光应该放在这个领域的三五年之后，但又清楚自己的现状明显是多数人的三五年之前，头脑和思维则处于这种身体和眼光的脱节之中，无处安放无所适从。 所谓的新手和专家都不是针对所有事情，你只是处于某个特定技能领域中的某个水平阶段。因此，如果你也已经很久没有体会过新人的感受，那就把格局打开，可以像我一样尝试进入一个新的领域吧。 我有两种自我平复情绪的方式，读书和写东西，读书这事在自己，至于输出那就再开新坑吧。#熊说肿瘤 和 #熊读文献 。但凡你今后看到题目是「熊说肿瘤｜ XXXX」或者「熊读文献｜ XXXX」这类，那就可以放心地点进来看看我的学习内容，一起对抗焦虑 😂。 这系列文章最大的特点可能就是不会存在知识的诅咒，因为我本身就是菜鸟。「熊说肿瘤」系列内容将从肺癌开始，会重点关注 NGS 在肿瘤领域的全方面应用。每一部分内容都会涉及到大量文献，于是顺便也就有了「熊读文献」。 重做新人 NGS 肿瘤研究可以学什么呢？ 以肺癌为例，初步了解了肺癌是什么之后，从临床角度出发的几个方向就是肺癌的筛查、诊断和治疗和预后；每个角度又都可能涉及到类似于异质性和进化等等这类机制内容；如果考虑肺癌作为一种异质性疾病的病理特征，上面这些角度又可以按照非小细胞肺癌和小细胞肺癌分别讨论，当然，非小细胞肺癌又可以区分为腺癌和鳞癌。 NGS 作为一种成熟的技术手段，无论是生物标志物、分子检测还是辅助诊断指导治疗等等，在以上所有内容中都有着成熟或潜力巨大的应用，这些都是会逐步展开介绍和学习的。 当然，除了学术研究，我们不妨同样把目光投向现在的 NGS 肿瘤检测和肿瘤创新药研发行业，看看国内外这些产业的头部大公司都在做什么。 大致的内容已经整理成了下面这幅导图供你参考，也可以算作今后写作分享的主线和大纲。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-08-14-learn-lung-cancer/"},{"title":"新手和专家的区别以及如何看待学习","content":"又一次知识焦虑和学习焦虑 最近又一次出现了比较严重的信息焦虑、知识焦虑和学习焦虑。 这种感受上一次出现是研究室刚开始决定做生物信息方向，再上一次出现则是在大三决定准备读研。这三次的相似之处是处于不同阶段的转折点，想要开始做一件新的事情但尚且不能找到清晰的头绪；不同之处则在于自己已经从20岁来到了29岁，当时身边还都是同龄人，此时早已不然。 在任何一个领域，当你作为菜鸡进入的时候通常都会面临着这样一种情景：抬眼望去你的面前是经验阅历丰富可能还比你年轻的同辈，你的身后是这个领域积累了几年甚至十几年的知识储备，你左顾右盼时到处似乎都是不应该错过的信息。你知道自己的的眼光应该放在这个领域的三五年之后，但又清楚自己的现状明显是多数人的三五年之前，头脑和思维则处于这种身体和眼光的脱节之中，无处安放无所适从。 阅读是我平复情绪的一个主要方式，所以焦虑的直观体现就是自己最近一个多月的读书时长显著增加🤣，平均每周在微信读书的阅读就能超过10个小时，还没算进去纸质书。 我最近读到的书中，《程序员的思维修炼》虽然不厚但读完收获很多，其中尤其有两块内容启发最大，所以记录成文和你分享。 德雷福斯模型：新手和专家的区别 如何区分新手和专家这个话题之前在很多场合都聊过且每次讨论结果都不尽相同，比如在熊言熊语的播客节目中 对话|从编程学习心得聊到线上交友技巧。 从这本书中我第一次学到了德雷福斯模型（Dreyfus model of skill acquisition），从而理解了从新手到专家会发生哪些变化。这样的系统认知是此刻的我非常需要的。 首先说明专家和新手不针对所有事情，你只是处于某个特定技能领域中的某个水平阶段，比如虽然你可能只是做饭新手，但却是一个干饭专家。 德雷福斯模型将一个技能的学习程度划分为5个层次，由上而下分别是：专家、精通者、胜任者、高级新手和新手。 新手需要详细明确的指令清单，指令清单的问题则在于不能一五一十地将所有事情解释清楚，规则只能让你启程，不会让你走的更远。高级新手多少能够摆脱规定的规则独自尝试任务，但是他们还难以解决问题，同时因为没有全局思维所以无法认知工作的相关性。 胜任者能够建立问题域的概念模型并有效地使用它们，他们可以独立解决自己遇到的问题并开始考虑如何解决新的问题。不过他们的工作更多是基于谨慎的计划和过去的经验，如果没有更多的经验，在解决问题时将难以确定关注哪些细节。 精通者具有全局思维且能够自我纠正，他们会反思以前是如何做的，并修改其做法期望下一次表现得更好。精通者有足够的经验，知道下一步会发生什么，如果没有发生又需要改变什么。他们非常明确哪些计划需要取消，又应该采取什么行动。 至于专家，他们是各个领域知识和信息的主要来源。专家总是不断地寻找更好的方法和方式去做事。他们有丰富的经验，可以在恰当的情境中选取和应用这些经验。更重要的是专家根据直觉工作。他们可能会对如何得到结论完全说不清楚，但是知道应该关注哪些细节，可以放心地忽略哪些细节。专家非常擅长做有针对性的特征匹配。 从新手到专家的过程中最重要的三个变化￼如下。 从依赖规则向依赖直觉转变。 观念的改变，问题已不再是一个相关度等同的所有单元的集合体，而是一个完整和独特的整体，其中只有某些单元是相关的。 从问题的旁观者转变为问题涉及的系统本身的一部分。 不过研究似乎表明，大多数人的大多数技能从来没有高于第二阶段高级新手，执行他们需要做的任务并根据需求学习新任务，但是从来没有对任务环境获得更广泛的、概念上的理解。 在从新手出发的过程中，积极的实践需要四个条件。 一个明确定义的任务。 任务需要有适当难度但可行。 任务环境可以提供大量反馈，以便于采取行动。 提供重复犯错和纠正错误的机会。 作者在说中写到，稳步做这种实践十年，你就会达到目标。也是另一种对于一万小时定律的解释吧。 如何看待学习以及如何创造时间学习 这本书给我的第二点启发是对于学习的理解。 首先，只掌握知识的提纲并不会提高专业水平，虽然掌握它非常有用但对现实工作很难有所贡献。因此学习一定要有目标，然后通过SMART法则去实现它。在这里SMART代表具体的、可度量的、可实现的、相关的和时间可控的（Specific, Measurable, Achievable, Relevant, and Time-boxed）。 其次，我们常常陷入这样的学习计划：等到有空再花时间学习一门新语言或者新技能。但是把学习活动安排到「空闲时间」的做法一定等同于失败。 最近一个月的经历就让我深刻的体会到事实上我们没有任何“空闲”时间。时间不仅像海绵里的水，它更像是硬盘空间，总是会很快被填满。**为一件事情创造时间的说法用词不当，因为时间是无法创造和销毁，时间只能分配。**主动安排你的学习，分配合适的时间，合理地使用时间。 至于坚持学习有没有用，作者在书中作了一个让我看来挺恰当的类比。如果你有一些理财常识就一定听说过所谓成本平均法（dollar-cost averaging）或者定投。如果定期购买股票或者基金有时会大赔有时也会大赚，但长期看这些大波动往往互相抵消，最后整体上反而会获得一个不错的回报。 作者认为学习也是投资（这个观点不新鲜），所以我们也应该采取「定投」策略。你需要定期投资最低限度的学习时间量，养成一种习惯，想尽办法躲在什么地方去完成学习。虽然并非每期学习都会有很大成效，但是只要定期安排学习，长期来看就会有收获。即使你从来不会在工作中使用某项技术，它也会影响你思考和解决问题的方式。 最后，再次推荐一下这本比较好读的书，《程序员的思维修炼》。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-08-12-pragmatic-thinking-and-learning/"},{"title":"完成这个需要多长时间","content":"今天读到了一篇关于如何回答「完成这个需要多长时间」的blog，作者给出了4个分析步骤，简单记录和评论一下。 确定项目的范围和预期 一定要提前做好沟通。确定项目范围和预期的可交付成果，确定目标和有关上下游希望在此项目中解决的问题。搞清楚要做的事情目的是什么，是大致看看还是给一个准确答案，是不是要用于投入生产。 确认项目所需的数据可用性 完成预期目标现有的数据是不是够用，是不是可以直接用，是否需要其它人的协助。在估计项目时长的时候我们经常会默认上游的数据不存在问题，这有时候会带来很大的隐患。 定义高阶子任务并对每个任务的预估时间进行汇总 将项目进行一级子任务的拆分，任务越具体，时间估算相对就越准确。如果一个项目可以被拆解为3到5个子任务，一方面可以厘清工作头绪另一方面可以相对准确地对每个子任务进行评估，同时计算总时长。 对第3步的总时长应用模糊系数 所谓模糊系数就是根据过往的实际情况，计算完成时间和预估时间之间的差异倍数，以考虑到意外事件、会议等其它情况的发生。这个模糊系数通常可能在1.5～2之间。 原文：A 4-Step Process to Answer “How Long Will This Take?” 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-08-04-howlong/"},{"title":"从 MacBook Pro M1 安装编译 R 踩坑想到的","content":" 关键时刻要稳住，以及软件之间的不兼容和人与人之间很类似。 之前写过两篇 macOS 升级系统后安装升级 R 的博客，现在回看虽然解决了当时的问题但还是蛮混乱的。最近工作主力机切换到了 MBP M1 版本（感谢东家），再整理一点踩坑实录和引申出来的想法。 新 Mac 必备 新 Mac 上手，装好 Xcode command-line tools 和 homebrew 其实就已经解决了大部分后续软件安装问题，如果还需要在笔记本跑跑数据就装 miniconda。写这篇文章的时候 homebrew 在 M1 上基本不会碰到什么问题，可以放心安装。 想起来研二开始日常管理实验室服务器的时候，必学技能还是如何在几个不同的 Linux 版本环境中安装编译好大家需要的各种软件，如今 conda 和 docker 的成熟让软件安装早就不再是什么问题，管理员的最大作用似乎就是做好数据备份的同时提醒大家做好数据备份。 arm64 架构 R 的坑好多 我是一个忍受不了手机软件有更新而不升级的人，甚至经常通过 TestFlight 去找各种应用的测试版本（这种人被成为 TF boys）。拿到 M1 Mac 自然也是先找最新适配版本的软件。 以数据分析写代码常用的 VSCode 和 R 为例，目前很多软件已经有了专门针对 macOS arm64 的版本。你可以通过 R 官方的 mac 页面 找到下载链接。如图所示 4.1 版本 arm64 的安装包新鲜出炉。 下载安装一切顺利，往下翻翻就能看到针对 arm64 版本的说明。简单说为了防止不同架构的 R 打架，最新版本的 R 相关内容都保存在 /opt/R/arm64目录，包括进行 R 包编译必备的 GUN Fortran ，嗯你没有看错截图显示他们页面的这个单词拼错了。除了 gfortran 以外， XQuartz 则需要版本 2.8.0_rc1。gfortran 也有了 arm64 版本，可以通过 这个链接 下载安装。 正常情况下装好这几个就可以装 R 包了，但在安装几十个常用 R 的过程中发现了好几处 bug，其中最根源的问题是在 arm64 版本下（几乎）所有 R 包都需要通过编译才能使用。只要涉及到编译，各种不兼容和依赖问题就都来了。 edgeR 编译报错 这个 bug 最早是同事提出的，因为忙着搬砖所以我没有回答到点子上就甩了之前的文章链接。报错信息是library not found for -lgfortran，其实就是gfortran的位置找不到。这个问题如果仔细读了上面提到的官方页面应该有所准备。 It is assumed that /usr/local is unsafe as it may contain Intel binaries which don't mix, therefore R will not try to use /usr/local unless a manual flags override is issued. However, it also means that it is safe to use our arm binaries without affecting your legacy Intel ecosystem. 解决方案是需要正确安装最新版本的 gfortran，然后手动修改~/.R/Makevars编译用到的 FLIBS 信息 FLIBS = -L/usr/local/gfortran/lib/gcc/aarch64-apple-darwin20.2.0/11.0.0 -L/usr/local/gfortran/lib -lgfortran -lm 另外，网上其它软件也有提到把export PATH=/opt/R/arm64/bin:$PATH 写入系统配置文件，我并没有测试。 rgl 安装包错 rgl 是一个在 Mac 中有很多 R 包依赖的常用包，在安装报错的时候开发者良心地直接给出了讨论链接。macos catalina - Package rgl in R not loading in Mac OS - Stack Overflow Warning messages: 1: Loading rgl's DLL failed. This build of rgl depends on XQuartz, which failed to load. See the discussion in https://stackoverflow.com/a/66127391/2554330 2: Trying without OpenGL... 概括一下就是 rgl 和目前支持 M1 芯片的 Xquartz 版本不兼容，如果不想像链接中反复修改依赖软件的话，可以直接从 github 下载进行编译。 remotes::install_github(&quot;dmurdoch/rgl&quot;) maftools 编译报错 安装 maftools 需要提前安装 Rhtslib，而 Rhtslib 在编译时有如下问题。 # 'lzma.h' file not found 因为 Rhtslib 也是一个频繁被依赖的软件，所以我猜测这个问题应该有人已经在 issue 里问了，一搜 确实如此。结果翻着翻着看到这样一条回答。 Intel 架构的 R 真香 通过上面的截图可以看到最中肯的建议就是：别乱用什么 arm64 架构的 R…… 这是因为虽然 R 和 Rsutido 最新版本都已经支持 m1 芯片，但是 bioconductor 还没有支持，这样一来就无法直接安装编译好的 R 包版本。 不过，这个事情其实一开始苹果已经通过 Rosetta 2 解决了。为了在过渡阶段让 M1 同时兼容两种架构的软件，当使用 Intel 架构的软件时，macOS 可以直接通过 Rosetta2 去做转换。之前苹果官方介绍在大多数情况下需要使用 Rosetta 的 App 性能不会出现差异。 因此目前只需要使用 Intel 版本的 R，就可以避免编译以及随之而来的各种问题。所以，在果断重新安装这个版本的 R 之后，我只能说一句真香。 从 macOS M1 安装编译 R 想到的 在一开始读到 R 官网说明时，我就看到了下面这句话。 That said, our current Intel releases work just fine on the new Macs as well using Rosetta 2. 但追求走在更新前线的人怎么能如此委曲求全，结果就是浪费了不少因为编译 debug 的时间。所以生产环境求稳还是真理，只要没出错就不要乱改动，修改一下奥卡姆剃刀法则就是「如无必要，请勿升级」。 以及，使用 arm64 架构的 R 配合 Bioconductor 出现各种各样问题，原因在于它们没有保持住一致的节奏。软件如此，人和人之间也差不多。三五个人一起，要想成些事，彼此就不能出现太明显的「不兼容」。 一方面，如果有人走的太快但还要依赖他人的时候，这种自我升级本身没有太大价值，多数还是需要主动调低自己的版本。 另一方面，如果多数人都升级了，为了运行速度和后续更新，版本太低的人也不会被一直兼容。就像手机系统升级一样，手机公司总得逐渐放弃一些久远的型号，至于支持几代就要看不同公司的策略。 除了关键时刻果断决策，更重要的还是大家一起进步一起升级。想起来那句话：你就是你身边最常接触五个人的平均值。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-07-06-macos-arm64-R-tips/"},{"title":"6年硕博生活的6条心得-生活成长篇","content":"本科毕业时因为准备考研，我曾用前前后后一多年的时间整理了一本 30 多万字的文集，5 年多时间这个小册子如今还会被一些学弟学妹读到。随着进入 6 月下旬，自己 6 年的硕博生活也即将走入尾声，过去 6 年我能分享的东西并不多，但终究还是要写些东西作为总结和纪念。 于是，我整理了 12 条心得，有经验也有教训，6 条和生活成长相关 6 条和学术科研相关，这篇文章先把前 6 条与你分享。 所谓成长，是我们认识世界和世界相处的方式发生变化的过程。 与我而言过去 6 年有一半的时间生活在网络中，种种变化也更多的来自于在网络中的分享和表达。 从最简单的事情开始 从真实发生的事情开始 我经常在不同场合被不同的人问同一个问题：熊，我也想向你一样分享，但我不知道自己能分享什么。 我开始持续分享的时间是 2015 年寒假，我把每天自己精读的英语新闻做成长图分享到当时还在使用的微博，原因是我希望在那段空闲时间可以维持规律的学习；我把自己的各种复习经验整理分享在公众号，原因是我希望能够记录曾经真实发生在我复习期间的生活。 所以我对于这个问题的答案就是从最简单的事情开始，从真实发生的事情开始。 并不是你有了一个宏大的计划才开始行动，而是随着行动的累积开始逐渐呈现出一个计划。你想成为什么样的人，就开始分享什么样的内容； 你想过上什么样的生活，就开始分享什么样的生活。 只要你分享的一切都是真实发生的和你向往的理想生活，一段时间之后就能发现有人会关注你，然后推荐你给他身边的人。 在我当年早期逐渐积累的一万多个微博关注者中，他们中的很多人每天和我一起精读英语新闻，和曾经的我一样过着规律的复习生活。与其说是别人发现了我，不如说是别人在寻找他们自己的过程中顺便找到了我；与其说是别人在推荐我，不如说是别人在推荐自己。 我用分享营造了一种真实而理想的生活，我的同类则通过我把自己也代入了这种真实之中。你也可以。 做有长期收益的事情 输出是高效的信任货币 这几年经历的绝大多数让我成长的事情，其实都是从写作衍生而来，所以我也愿意把写作这件事安利给你。 写作是一件有长期收益且收益不受时间禁锢的事。这个世界上多数收益都和时间成正比，你耗费一份时间得到一份对应的收益，但写作不是。你今天写完的文章，无论明天明年都可以被人们看到。一篇文章被 1 个人看到和被 1000 个人看到所付出的时间成本也没有差别。 很多人因为自己写的内容不会被别人看到而拒绝输出，但我想说输出其实是一种最高效的信任货币。人与人的交流本质上是利益交换，如果你觉得这句话太残忍，那就改成人与人的交流本质是信任交换。 想一下什么情况你会信任一个人，初次见面恐怕不会，你需要先接收到来自对方的信号才能进行判断。这也是为什么以前多数城市的火车站是最混乱的地方，在这里相遇的两个人可能一生只见一次。 只有两个人交流达到一定密度，他们之间的信任才可能积累。输出就是这样，我们每次输出都是在释放一种信号，这个信号可能一开始并没有明确的接收者，但它可以无限传播。每一次信号释放都是在积累自己的信任货币，只要信号传播的足够远，只要信号没有中断，就会有人接受的到。 回到我的例子，这几年通过写作输出认识的朋友，我发现他们大多数人都对我有一种天然的信任，在一些事情中体现的信任程度甚至超过了现实中有血缘关系的亲属。这种信任肯定不是天然的，我们的第一次交流很可能建立在看过对方上百篇文章的基础上，我们之间默认已经交换了大量的信任货币，通过输出早就建立了对彼此的了解。 做一个生产者，一个积极影响别人的人 **绝大多数人都是消费者，只有很小一部分是生产者。**这几年影响最大的一个改变就是学习把自己的视角从消费者转向生产者，先进行生产再进行消费。 当拥有了生产者视角后，你会发现整个世界都改变了。不要只读文章，去写文章；不要只看短视频，去做短视频；不要只去培训班听课，去培训班讲课。做一个生产者并不是让你放弃消费，而是在看待事物的时候转变立场。看到一个具有煽动性的广告不是立刻下单而是要审视一下为什么它能让人们花钱；听了一次非常精彩的讲座不是立刻去加微信，你要思考这个讲座为什么会受欢迎。 无论是分享还是写作，当你坚持做这些事情的时候就已经不知不觉发生了转变。我非常希望身边每个人都可以是生产者。 作为生产者，你需要在某种程度上放下自己学习去观察别人的需求。没人关心你做了什么，大家都只关心你做的事情对他有什么好处。所以，想一想你要做的事情能如何帮到别人，能够解决什么问题，你的言行是否可以影响别人。 **尽可能多的从任何层面去影响更多的人，先作为一个生产者去给予再作为一个消费者去索取。**你的成就和价值（或者说挣多少钱）其实都和你能影响到多少人相关。 作一个能影响别人的人还需要我们大方承认别人对我们的影响。不要等到需要谁的时候再去社交，要在不同场合不同时间反复感谢那些帮助过你和影响过你的人，主动为那些影响过你的人们建立连接。 做一个积极影响别人的人是幸福的，我曾经因为一门 2 个小时的课程被一位朋友反复学习了 26 个小时而幸福；曾经因为我的一句话和做的一件事让对方也开始尝试写作而幸福。很多六七年前因为一篇文章相识的人我们现在已经变成了非常好的朋友。 有两三个可以交心的朋友 我的硕博生活经历过几次不小的困难，有一段时间还有过退学的想法，这些经历让我明白即便平日里我们影响了很多人建立了很多连接，还是需要两三个可以交心的朋友。 一个听起来很残酷的事实，我们接触到的人或者说朋友圈好友 90%（甚至更多）应该都是旁观者，大家彼此存在的意义主要是凑凑热闹。不要因为别人的夸奖和吐槽而受到太多影响，因为很可能他就是路过的时候给你加把劲或者朝你翻个白眼，你对于大多数人都不重要。 你需要学习和两三个朋友经营一些长久稳定的关系，如何定义交心呢？我以为是可以向彼此坦诚暴露自己的弱点。这又回到了前面提到的信任货币，我把自己的黑历史和阴暗面暴露给你，就是向你释放我最大的诚意。 有一个属于自己的产品 说完人和人之间的关系，这一条心得是希望你在研究生期间可以至少有一个属于自己的产品。 你可能在研究生期间发过论文，也参与过不少项目，但这些算是属于你的产品么？很大概率并不是。比如你发表的一篇论文究竟参与了多少工作，假设你是第一作者那这个课题的 idea 和你有关么，开展过程中的一些重大进展是你推动的么，项目完成后它的影响力是通过你扩大的么？ 所谓属于自己的产品，就是它的产生发展甚至结束都完全由你自己掌控。你要负责构思，负责开发，负责推广，如果可能的话还要负责盈利，甚至你还要负责亲手把它暂停或结束。 作为少数派的高级作者，我在少数派发布的十几篇文章目前已经有 80 多万阅读量，但这很难说是属于我的产品，因为我只产出了这些文章但无法左右它的阅读量。我在 B 站上传的一个转录组入门课程目前也有接近 5 万次播放了，但我清楚的知道这也很难说是属于自己的产品，因为它随时可以被别人下架。 如果让我说一个属于自己的产品，从去年疫情期间开始做的音频播客「熊言熊语」（以及配套的会员邮件通讯）应该算是。它起源于我当时整个人低迷的状态，我希望通过这档播客和那些我欣赏的好奇的人深入沟通。我需要负责它整体风格的把握，需要负责每一期节目的走向，需要和每一位嘉宾沟通，需要面对听众的反馈，需要学习音频剪辑，需要对播客进行推广，更需要学习如何弥补节目制作和服务器的成本花销。从一千次播放到一万次播放再到目前全网累计十万次播放，我参与了这个产品的所有过程。 如果在研究生期间你放弃了拥有一个属于自己产品的机会，那工作以后这件事可能就更难了。 收获可能不会立刻发生，但它确实会发生 我犹豫了很久要不要把这条心得写进来，它有点类似劝别人要做「时间的朋友」。这句鸡汤我不能接受，我从来不认为时间会平等的把每个人当朋友。之所以决定写进来是因为我想给现在或许正在「煎熬」的你一点鼓励。 每个人在研究生期间的困难各不相同，其中的纠结、自卑、焦虑甚至绝望对于外人来说都很难体会。你在思维最活跃，体力最好，精力最旺盛的年纪选择坐在实验室里拿着可怜的补助面对经常阴性的结果。以前的同学不少已经事业小成或家庭美满，身边的同学不少也产出不断。你很可能完全看不到自己继续坚持的意义，但我还是希望你不要放弃，比如返回去再读一读前面 5 条心得建议。 过去 6 年，除了学习科研以外，我花费了大量时间做着很多看起来完全没收获的事情。我几乎放弃了所有节假日和空闲时间。我不停地写文章不停地分享，我愿意把我自己知道的东西通过尽可能多的途径告诉尽可能多的人，我组织各种没有收益的活动。不少亲近的人都对此表示过不理解，多做一些「正经事」不好么？ 我没有奢求过这些付出能给我带来什么及时回报，可是随着时间累积一些收获反而自然发生了，比如工作的面试官有人是我的读者，一些合作者看中的是我的可迁移技能。 只要是你认为正确的事情，只要是对你认识这个世界和人能产生正向影响的事情，就可以再坚持一下。因为收获可能不会立刻发生，但它确实会发生。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-06-26-6tipsforphdlife/"},{"title":"面对职业教育缺失，在科研行业的我们能做什么","content":"最近有两件事让我感触比较深，一件发生在自己身上，是之前找工作初期的迷茫与局促；另一件是公共事件，最近发生在复旦大学的教师杀人案件。关于公共事件，目前官方披露的实际细节并不全面，当事人双方我也完全不了解，这里无意讨论。但这两件事让我联想到了一个国内长久以来存在的问题：针对高校学生和科研工作者的职业教育缺失。 职业教育（Career education/Vocational education）的目标是获得和提高从事某种职业所必需的知识以及技能。在我的理解中它应当包括毕业生的职业规划和求职相关教育，自然也应当包括对即将从事科研工作学生的职业发展指导和教育。 大多数学生（硕士博士尤其如此）埋头苦读，在实验室搬砖几载。进入职场之前很多人连怎样找一份工作，如何准备一次面试和谈薪资都不清楚，更遑论保护自己打工人的权益。对于读完博士甚至是博士后想要进入学术界的人来说，辛辛苦苦当上青椒（青年教师），面对各种竞争和社会机制时无法调整好心态和无法及时融入的情况也很常见。 过去一年，我因为做一个关注研究生科研生活的播客「熊言熊语」有机会接触到很多不同专业的同学。大家对于科研学习最高频的吐槽已经变成「能够在一个正常实验室过几年就已经很不错了」。有一个行为思维正常的导师和身边是一群行为思维正常的同学似乎都变得有点奢侈。也许有人说只有偏执狂才能有伟大的发现和成就伟大的事业，但绝大多数投身科研的也都是普通人而已，科学家少有，科研工作者常在。 可迁移技能 每每聊到相关的话题，我们总喜欢把科研中的这些问题归结于某个人的「低情商」或者「心理素质不过硬」，但这个锅情商不能全背。在硕博士研究生阶段除了科研培训，重视培养学生的可迁移技能（transferable skills）同样是不可或缺的部分。无论选择留在学术领域还是转到其它领域，可迁移技能对他们未来的职业道路都至关重要，这些技能将会更好地支撑个人的研究和专业发展。 明尼苏达大学职业与实习服务平台将毕业生的可迁移技能分成了 5 大类共 60 多个小类，并鼓励学生在进行职业选择和求职前先按照 1 到 3 级对自己的每一项可迁移能力进行评估。这 5 大类能力分别是： 沟通能力：用来巧妙地表达、传递和解释知识与思想。 研究与规划能力：寻找具体知识，以及将未来的需求和满足这些需求的解决方案进行概念化的能力。 人际关系能力：使用人际交往技能来解决与人有关的冲突并帮助他人的能力。 组织、管理和领导能力：监督、指导和引导个人和团体完成任务和实现目标的能力。 工作生存能力：有助于促进有效生产和提高工作满意度的日常技能。 我们现在面对的绝大多数问题都能在某类能力的严重缺失中找到身影。如果你想继续从事科研相关的工作，关注科研人员职业发展的非盈利项目 Vitae 整理了一个针对科研人员更为详细的技能说明和实例。你可以对应其中的技能找到欠缺部分，根据提供的实例有意识的提高自身能力。 研究人员发展框架 关于科研工作者的职业教育，Vitae 也提出过一个被很多高校广泛借鉴和采用 RDF 研究人员发展框架（Researcher Development Framework）。RDF 是一个针对科研人员的专业发展架构，旨在规划促进研究人员的个人、专业和职业发展。如果你正在攻读博士学位或是一名研究人员，正在追求自己的学术生涯或考虑将博士期间培养的技能应用到其它职业，RDF 就是你值得学习的内容。 这个框架有 4 个模块，包括了研究人员从事研究相关工作所需要的知识和行为能力。它规定了从事研究工作所需的知识、智力、技术和专业标准，也包括与他人合作并确保研究能够产生影响了所需的个人素质、知识和技能。 模块 A 知识和能力：从事研究需要的知识、智力和技术。 模块 B 个人效能：成为一名高效研究人员需要的个人素质和方法。 模块 C 研究管理和组织：了解做研究的专业标准和要求。 模块 D 参与度和影响力：与他人合作以确保研究能产生更广泛影响的知识和技能 从哪里获取更多信息和资料 如果你想通过网络了解一些非学术层面的职业技能介绍与资料，大致有以下三个途径。 国外高校的职业发展中心 The Princeton Review 每年会通过各种形式的调研对美国的高校进行排名，其中有一项叫做 Best Career Services 的评选依据是学生对于「如何评价学校的职业/就业介绍服务」的回答。在这份榜单中提到的高校网站多数都可以找到不错的资料。很多针对性的课程和服务仅对本校学生开放，但资料往往可以直接浏览下载。 这里列举几个内容比较丰富的访问地址，其中包括职业技能介绍和各种求职面试资料。 本特利大學 (Bentley University)：Resources – Bentley CareerEdge 东北大学 (Northeastern University)：Career Development for PhDs 西南大学 (Southwestern University)：Resources Career &amp; Professional Development 宾夕法尼亚大学 (University of Pennsylvania)： Resources – Career Services 克莱门森大学 (Clemson University)：Resources - Clemson Center for Career and Professional Development 耶鲁大学 (Yale University): PhDs &amp; Postdocs – Office of Career Strategy 在整理相关资料的时候，很遗憾我没有在国内几家 top 高校中找到类似于国外这些大学的内容。就业指导中心主要是用来发布就业手续办理通知，招聘会通知和提供各种表格的下载功能。如果你的学校有相关培训资料或者课程，欢迎留言分享给大家。 非盈利项目 上文被反复提及的Vitae是一个关注科研人员职业发展的非盈利项目，很多大学的公开资料最后都指向了他们的网站。部分完整资料只对会员单位开放，我之前偶然从 UPenn 官网的跳转链接注册了一个账号，注册成功后显示 Access provided by University of Pennsylvania，如果你有这个需求不妨也试试看。 学术期刊的职业板块 科研领域的顶级学术期刊（CNS）都有职业相关板块，这些非学术研究文章更多会关注科研人员发展现状和热门问题的讨论，作者多数来自科研一线，读完之后或许会给你些启发。 Science: Science Careers Nature: Career Column Cell: Cell Mentor: 除了 CNS 三本顶级期刊，还有一些其它杂志非常出名的系列内容可以参考，比如来自 PLOS COMPUTATIONAL BIOLOGY 杂志的Ten Simple Rules系列文章。这些文章会针对一个科研问题给出 10 条简单建议，有一篇套娃文章很有趣 Ten Simple Rules for Writing a PLOS Ten Simple Rules Article。如果你还知道类似杂志，也欢迎通过留言向大家推荐。 以及，学术科研本质也是一份工作，任何行业存在的问题它都存在。希望围观的人可以正确看待它，也希望身处其中的人可以掌握这份工作应该具备的各种技能，提升自己保护自己。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-06-11-researcher-career/"},{"title":"全球顶尖科学家榜单","content":"全球前 2%顶尖科学家榜单是由斯坦福大学 John P. A. Ioannidis 教授团队与 Elsevier 旗下 Mendeley Data 发布的一个科研人员「内卷」清单。 榜单以 Scopus 数据库为依据，基于引用次数、H 因子、HM 因子等指标，按照生涯影响力和年度影响力从近 700 万名科学家中选出世界排名前 2%的科学家，共有 22 个领域和 176 个细分子领域。 趁着高考的热度（并不能蹭上），如果你在考虑读研或者读博选导师，或许这个榜单可能会有一些帮助和参考。 如果你把科研作为自己读博的目标，找到一个领域内优秀的导师非常重要，如果你只是为了要一个不错的学历，或许更重要的是考虑去一个名气更大的学校。 关于这个榜单，直接放一点原文解释： Citation metrics are widely used and misused. We have created a publicly available database of 100,000 top-scientists that provides standardized information on citations, h-index, co-authorship adjusted hm-index, citations to papers in different authorship positions and a composite indicator. Separate data are shown for career-long and single year impact. Metrics with and without self-citations and ratio of citations to citing papers are given. Scientists are classified into 22 scientific fields and 176 sub-fields. Field- and subfield-specific percentiles are also provided for all scientists who have published at least 5 papers. Career-long data are updated to end-of-2019. 数据表格下载地址 https://data.mendeley.com/datasets/btchxktzyw/2 文献地址 https://doi.org/10.1371/journal.pbio.3000918 附上这 22 个大的领域列表 Agriculture, Fisheries &amp; Forestry Built Environment &amp; Design Enabling &amp; Strategic Technologies Engineering Information &amp; Communication Technologies Communication &amp; Textual Studies Historical Studies Philosophy &amp; Theology Visual &amp; Performing Arts Economics &amp; Business Social Sciences Biomedical Research Clinical Medicine Psychology &amp; Cognitive Sciences Public Health &amp; Health Services Biology Chemistry Earth &amp; Environmental Sciences Mathematics &amp; Statistics Physics &amp; Astronomy 如果从生涯影响力来看，共有 5272 位所在单位是中国的科学家入围，如果从年度影响力来看，共有 12948 位所在单位是中国的科学家入围。 我把所在单位是中国的所有相关详细名单拿出来做成了一个表格，如果需要可以可以直接访问，通过 filed 和 subfiled 过滤你感兴趣的领域。 ​ 彩蛋：附躺平和内卷的动作示范供你学习。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-06-05-topauthor/"},{"title":"构建自己的数字花园-工具篇","content":"逐渐感觉博客并不是一个很好的分享方式…… 什么是数字花园 Digital Gardon 嗯，不是本文的重点，附上几个链接供阅读学习。 What is a digital garden? by Chris Biscardi You and your mind garden by Anne-Laure Le Cunff A Brief History &amp; Ethos of the Digital Garden by Maggie Appleton 数字花园应该满足什么 我头脑中的数字花园应该可以实现如下功能。 支持双向或 wiki 链接的阅读方式：可以让自己和读者在花园中自由漫步，有尽可能好的阅读体验。 良好的笔记管理方式：笔记最好是通用格式或者可以全部且自由的导出为通用格式，能够在移动端相对轻松的完成记录，有尽可能好的编辑体验。 轻松地进行公开分享：可以变成公开网站进行分享也很重要。或者是工具自带分享功能或者是容易配合其它工具进行部署。 有哪些工具可以考虑 基于阅读体验，编辑体验和部署维护这三个维度，目前有如下几个主要的实现思路。 支持公开分享的现有笔记工具 Roam Research：从已经很长时间的使用体验来看，我愿称其为最纯粹的新一代知识管理工具，我的两篇大论文都是通过它整理的。从使用成本来看，我在内测期建了两个可以一直免费用的 graph，其中一个可以用作公开分享。从使用频率来看这也是我目前最高频的笔记工具。 Craft：从不重度但时间不短的使用体验来看，我愿意称其为最新颖的新一代写作工具。从使用成本来看，内测结束后赠送了一年免费订阅，之后每年 248¥ 。从使用体验来看它是几个工具里移动端使用体验最好的，而且公开分享呈现的形式天然适合做数字花园。以及更重要的是，作为一个靠原生应用赢得一大波好感的工具，Craft 马上就要推出正式的网页版了。 Notion：Notion 的用法类似于几年前的印象笔记，是我的核心资料库。虽然不像 RoamR，并没有太多笔记在里面，但是使用频率也非常高。日常使用定位里我没有把它定义为笔记工具也没有打算用它 All in One，我愿意称其为最强大的新一代个人建站工具。从使用成本来看，目前自己是教育账号也无需付费。 Obsidian：我之前基于 VScode 管理的所有本地 markdown 笔记已经全部迁移到了 Obsidian，配合上丰富的插件系统，我愿称其为最好用的新一代本地笔记管理工具。不过因为 RoamR 和 Notion 的存在，我的 Obsidian 使用频率略低。从使用成本来看，如果想直接使用 Obisidian 自带的发布服务需要每月支付 8$。 静态网站框架+本地笔记管理工具 静态网站的开发工具简直不要太多，目前有数字花园现成可用模板的是主要是 Jekyll 和 Gatsby。基本思路就是本地开发管理+GitHub 同步+Netlify 或者 Vercel 进行部署发布。本地的文本管理可以借助 Obsidian 或者 VScode 完成。这种方法的缺点就和自建博客一样，还是需要稍微折腾一下环境和部署。 Gatsby 相关模板 gatsby-theme-brain: gatsby-theme-andy: A Gatsby theme to build Andy style websites gatsby-digital-garden: Create a digital garden with Gatsby Jekyll 相关模板 Simply Jekyll digital-garden-jekyll-template 现有笔记工具+第三方部署服务 这种思路介于前两者之间。有很多开发者会针对 RoamR 和 Notion 这样使用量很大的工具进行二次开发，方便将这些内容直接转化可以通过更好的形式呈现的公开网站。如基于 Notion 可以使用免费的 React Notion X，基于 RoamR 有付费的 roam garden。 我的选择 先上结论就是我会从 Notion 和 Craft 中选择一个作为公开呈现的数字花园。 首先 RoamResearch 里记录的东西太多，各种关联和链接很难从中抽离出一部分作为公开发布的内容，以及它的移动端使用体验很差。 过了折腾框架改模板的年纪，我最看重的是不折腾，最好是这边只管写其它的完全不操心。这一步排除了静态网站框架的所有方案。 另外我需要一个好的移动端编辑体验，因为会大量记录随时生长的思考和想法所以很多输入都会在移动端完成。这一步 Craft 的使用体验比 Notion 占优。 如果再有一点进阶要求，我希望可以通过自己域名进行发布。这个需求通过 React Notion X 加 Vercel 可以轻松实现，Craft 则还没有什么工具可以实现自定义域名。 从呈现效果上来说，目前 Craft 自带的发布功能还没人做二次定制，但胜在简洁清晰；Notion 本身高度可定制，同时配合若干开源的二次开发模板可以呈现出非常丰富的样式。两者各有千秋。 以及 至于最终用什么来呈现，再过一段时间我会直接拿出一个 beta 版本和大家分享，到时候可以详细聊聊。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-04-14-digital-garden-tools/"},{"title":"使用R语言分析上海地铁好位置周边的二手房价格","content":"昨天看到有朋友分享了一篇关于北京地铁和二手房市场价格相关内容分析的文章。 打开一看作者是刘思喆大神，如今他是 51Talk 的首席数据科学家。那我的第一步操作当然是订阅好大神的博客，第二步就是用文章里提供的 R 语言脚本稍加修改，顺手看看上海是个什么情况。 关于具体分析内容不再赘述，主要提炼下知识点和注意事项。 关于地铁站评级的分析在思喆更早（2013 年）的博客中有所提及，他引入了三个 Closeness、Betweenness和 PageRank 指标分别表示一个地铁站和其它地铁站之间的距离关系、被经过次数和该节点的重要性。 使用高德地图上海地铁图网页版调取 json 文件的时候，可以在网页点击 F12 打开调试模式，切换到 network 面板后刷新一下后就可以看到 json 文件的地址 https://map.amap.com/service/subway?_1613660591830&amp;srhdata=3100_drw_shanghai.json。 使用贝壳网的二手房数据查询上海价格时，API 中对应的 CityID 是 310000。在实际分析过程中，原文按照步行十分钟到达地铁站设置的经纬度范围，我把这个范围稍微扩大了一点，不然有些地铁站附近会因为没有房源而报错。至于哪一站不行 10 分钟没有地铁呢？答案是虹桥二号航站楼。 整体分析下来，上海的所有地铁站被我聚成了 7 类，按照 Closeness、Betweenness和 PageRank 三个指标筛选后，分出来的第 3 类和第 6 类是比较不错的地段，尤其是第 3 类中的 14 个地铁站可以说是指定指标下的最优选择。直接看地铁站名很多也是肉眼可见的厉害。 结合二手房价格平均值，可以得到下面的二手房数量和价格关系图。不过这个平均价格和从各种 app 上看到的多少有些出入，似乎比实际情况整体要偏低一些，可能和选择的经纬度范围有关，关注的还还需仔细了解。 这个图比较说明问题，比如像长清路，东明路，成山路和耀华路都是 7 号线和 13 号线相对集中的一片区域，这里离浦东和浦江很远的几个工业园区和徐汇长宁几个区域也相对位置居中，到哪个地方上班无论是地铁还是自驾都不会耗时过长。 如果想了解更多关于城市地铁其它的分析指标，可以参考下面几篇文献进行深入了解。 Oldham S, Fulcher B, Parkes L, et al. Consistency and differences between centrality measures across distinct classes of networks[J]. PloS one, 2019, 14(7): e0220061. Derrible S. Network centrality of metro systems[J]. PloS one, 2012, 7(7): e40575. To W M. Centrality of an urban rail system[J]. Urban Rail Transit, 2015, 1(4): 249-256. 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-02-19-shanghai-subway/"},{"title":"熊言熊语会员通讯 4321X 第5期","content":" 你现在看到的是熊言熊语会员通讯 4321X 的第 5 期试读版本，今后我们会不定期的将部分会员通讯内容发布到公开平台，如果想稳定的阅读每期内容欢迎通过邮件订阅这份免费的会员通讯服务。 Hi, 见信好： 我是思考问题的熊，你现在正在阅读的是熊言熊语会员通讯「4321X」第 5 期。 截至本期通讯，「4321X」订阅人数为：529。 刊首语 上一期会员通讯聊到了确定性和不确定性问题，我提到希望这封会员通讯可以给你在充满不确定性的生活中带来一些确定感。But，如你所见，这一期还是没能在确定的时间和你见面。 我发现自己陷入了一点迷思，这期刊首语就聊聊关于预期和输出的困惑吧。 在第 0 期介绍这份邮件通讯的时候，我提到过「4321X」名字的来历：在每期通讯中推荐 4 篇生物信息/医学相关文献，分享 3 个过去一段时间的思考，推荐 2 个喜欢的工具，同时提出 1 个问题供交流，而 X 则代表不固定的 one more thing。 实际操作下来这几期，我发现在一个固定的时间段内凑齐 4+3+2+1 这 10 个内容还真不容易。本以为按照自己的素材储备和阅读量，一周找出 4 篇文献，浮现出 3 个思考这些硬性指标问题不大，但常常陷入 4 缺 2 或者 3 缺 1 的尴尬局面。比如本期内容 5 天以前已经是 2+3+2+1 的状态，但为了完成 4 篇文献的指标一直拖着没有推送。 所以困惑之一是写作的终极问题，应该面向自己还是面向读者写作呢。 如果写博客，我的观点一定是面向自己写作，这些文章写出来是等着被发现，大家通过搜索带着明确的目的找到你写的文章，所以不需要考虑其他人是不是感兴趣，关键在于把想写的东西写清楚，带着目的来的人看完不会太失望即可。但 newsletter 这种形式是一种主动出击，你明确的知道它会被一部分看到，愿意把邮箱告诉你的人一定会对接受到的内容带有信任感和期待，这时就难免会想我写的内容他看到感不感兴趣。 困惑之二是预期管理时，时间上的确定性重要还是内容的确定性更重要。 作为这份通讯的订阅读者，如果二选一你更在意哪一个呢？是希望每周固定的时间都可以看到一封邮件，还是希望打开邮件看到的一定是 4+3+2+1 足量内容。可能你当然是希望看到固定时间且足量的内容，但这又回到了开头写到的，在一个固定的时间里我就是没有找到那么多愿意分享给你的内容。这个时候该怎么选择呢？我作为读者的感受是更希望看到定时推送，至于内容篇幅没什么执念。 亦或者，作为读者这两者你都不在意，而是更希望时不时能通过「熊言熊语」公众号或者我们 Telegram 的「熊言熊语」频道看到一些短篇幅高频率的分享？因为我最近有在梳理 2021 年的分享方式和渠道，希望你可以回复这封邮件或者直接写信告诉我一些你的想法，邮箱是 hi@kaopubear.top 困惑之三是关于输出的意义。 在我关注的很多作者中，发现极少有人能够长期稳定且高质量的输出，如果不是不得不做，坚持的确是太难了。这就带来了一个悖论：所有决定 follow 你的人其实都是基于之前的内容，但从他（她）开始关注你的那一刻起在乎的又只是你以后的内容。所以，输出这件事一旦停下来就等于前功尽弃，留下的最多剩下一个念想。读的人可能来来往往，写的人必须一直向前。不过，能够坚持下来的少数人会逐渐积累输出带来的复利，随着时间推移看到越来越大的变化。我们现在做的每一件事，都是在为今后某一刻作准备。 抱着这些困惑，我咨询了丁香园的产品经理少楠，他同时还经营着一个已经 4 年之久的付费邮件通讯，也是想法记录工具 flomo 的开发者（我们曾经在第 0 期会员通讯有过推荐）。他的建议是适当减少数量且不要限制主题，但是要保证质量和持续更新。嗯，我觉得他说的对，所以以后「4321X」偶尔货不对板你也不要太惊讶，保证东西都是好东西，更重要的是要时常见面才好。 文献 Accurate and efficient detection of gene fusions from RNA sequencing data We developed Arriba, a novel fusion detection algorithm with high sensitivity and short runtime. These results demonstrate Arriba's utility in both basic cancer research and clinical translation. DOI: https://doi.org/10.1101/gr.257246.119 基因融合与各种疾病特别是癌症的发生发展紧密相关，甚至是一些癌症的直接诱因， 检测基因融合这件事很重要，但也已经有了很多分析方案。最近发表在 Genome Research 的这篇文章强调，他们推出的命令行工具专门为了临床研究而开发，特点是那叫一个快和那叫一个准。使用 STAR 比对后的结果进行后续分析只需要 2 分钟左右就能得到结果，而且准度更好。如果你有这个需求可以测试一下。这个软件还是 DREAM SMC-RNA 挑战赛的冠军，这个比赛由 ICGC、 TCGA、 IBM 和 Sage Bionetworks 联合组织，目的是确定当前从 RNA-Seq 数据中检测基因融合的黄金标准。 IGD: high-performance search for large-scale genomic interval datasets we introduce the integrated genome database (IGD), a method and tool for searching genome interval datasets more than three orders of magnitude faster than existing approaches, while using only one hundredth of the memory. DOI：https://doi.org/10/ghmqdt 在会员通讯第 1 期我曾经谈过自己对于生物信息打工人的理解，其中很大一部分日常就是找各种基因组区间的交并集。bedtools 是最常用的工具，但它对极大数据集就不灵了。因此，2018 年针对超大数据集的工具 Giggle 发表在 Nature Methods，前不久又出一个工具叫做 Varnote。这次推荐的文章则是又一款同类型新工具，发表在 Bioinformatics，文章里主要和 Giggle 进行了比较。尤其推荐在使用小内存机器的朋友看看。 tidybulk: an R tidy framework for modular transcriptomic data analysis Tidybulk decreases coding burden, facilitates reproducibility, increases efficiency for expert users, lowers the learning curve for inexperienced users, and bridges transcriptional data analysis with the tidyverse. DOI: https://doi.org/10.1186/s13059-020-02233-7 转录组分析流程是绝大部分接触生信的人最先开始了解学习的内容，这里首先推荐一个真不戳的免费转录组分析实战视频教程。基于转录组分析流程的文章大大小小得有十几个了，敢问这类型的文章还能发出来，还敢再多一些么？答案是：还能。 只要思路够巧妙，本质是一样的东西还可以反复做，这篇发表在 Genome Biology 的文章就是一个很好的例子。开发者引入了 tidyverse 这个知名系列 R 包中「tidy」的概念，用整洁的数据结构和模块化的框架实现了转录组分析的各个流程，整合成了 R 包 tidybulk，意义是啥呢？作者的原话是提高了老手的效率，降低了新手的学习曲线。至于是不是，你可以去了解一下。 思考 文章是写给自己也是写过读者的，很多时候还是写给搜索引擎的。 写博客以来，时常会有人问我有什么写作技巧可以分享，让更多人看到自己的文章。我会给出三个建议：对内容要有完全自主权；在主阵地之外要选择一个合适的推广平台；要确保人人都有机会看到自己的文章。 自主权是指随时可以增删内容且不会被别人莫名其妙的删除（微信公众号出局），合适的平台是为了让一部分内容更容易被人看到（比如我也在少数派写作），以上两点以后再展开说。至于确保人人都有机会看到，就需要了解一些基本的 SEO 规则。 最近阅读了一篇文章讲如何同时面向人和搜索引擎写作，总结了一些面向搜索引擎的写作心得和你分享。 Google 喜欢长文章，所以文章的覆盖面尽量要全一些，比如尝试把关键词搜索出的前几页主题都覆盖到。 Google 喜欢回答问题的文章，所以文章结构尽量清晰：是什么，为什么，怎么做。这是最稳妥的写作方法。 要开门见山，要围绕关键词展开内容。这里有意识的点题不等于反复堆砌同一个词，因为搜索引擎会自己使用语义分析。 使用正确的语义化元素，比如正确的使用引用，列表和代码块，一个页面只有一个 H1 标题，正文标题可以从 H2 开始。 要正确的使用链接，关键是一定要写清楚链接的 title 部分，保证内容完整和可被识别。「点击这里查看」这类标题就是反例。 生产高质量内容是 SEO 的根本。大家喜欢你的文章，搜索引擎就会索引你的网站，以后其它文章就容易被收录。搜索引擎只会推荐人们希望看到的内容。 关联阅读：如何写一篇同时面向人和搜索引擎的文章 创业者需要同时判断好技术、产品、市场三个要素，只有技术上可实现、需求真实存在、市场能形成盈利，这三者同时满足时，创业成功概率才能最高。 我曾经在会员通讯第 2 期推荐过一个陆奇的专访，这次他又来讲东西了。虽然主题是创业，但知识点可以在诸多领域进行迁移，比如关于科研项目的选择和职业方向的选择等等。 在关于创业的定义上，陆奇说在任何一个历史环境下，创业的核心是永远不变的，即优秀的创业者用技术打造产品，用产品试探市场，满足人们需求，从而创造商业价值和社会价值。创业者需要同时判断好技术、产品、市场三个要素，只有技术上可实现、需求真实存在、市场能形成盈利，这三者同时满足时，创业成功概率才能最高。 关于技术，我们需要判断某个技术在今天处于什么状态，以及五年后可能的发展状态，尤其要注意对技术发展拐点的判断。关于需求同样要判断现在的需求和未来的潜在需求。关于市场则要参考产业链和上下游这类结构化的因素，还要看政策环境、国际环境、国内环境这些市场所处环境。 技术、市场和需求也应该是我们科研和工作时的三个标准。你想做的课题需要的技术是不是成熟，有没有实际研究意义，是不是大家普遍关注的核心科学问题，研究成果能不能在所处领域有用武之地。 关联阅读 陆奇演讲：世界新格局下的创业创新机会 判断未来的能力，沟通的能力，行动导向解决问题的能力，长期的内在驱动力，触达用户的能力，这些都是创业的人(团队)需要具备的能力 依旧是在这次演讲中，陆奇提到了创始人或者创始团队需要具备哪些能力。 总结下来一共有五条，分别是：判断未来的能力、沟通的能力、行动导向解决问题的能力、长期内在驱动力和触达用户的能力。 我想这分明就是每一个追求上进的人都需要的能力啊，其中个别的可能更靠天赋，但多数都可以锻炼和积累。即便我们很难同时拥有这五项能力，也要清楚的分析自己的优势和短板，然后找到能够和你取长补短的合作者或者合伙人。 关联阅读 陆奇演讲：世界新格局下的创业创新机会 推荐 Unsplash Unsplash可能是世界上最知名的免费无版权图片下载网站，图片使用权限如下： All photos can be downloaded and used for free Commercial and non-commercial purposes No permission needed (though attribution is appreciated!) 我多数文章配图都来自于它，最近这个网站上线了「以图搜图」功能，虽然这个概念不新鲜但是对于一个图片网站来说这意味着今后可以用很多有版权的图片来搜索类似的免费无版权图片了。我尝试搜了一下正在使用的 MacBook Pro 自带壁纸，嗯，效果不错。 此外，Unsplash 的年度总结姗姗来迟，看下他们的主要成绩就知道有多厉害。2020 年，共有 208,696,224,047 张图片被观看，有 1,200,251,738 张图片被下载，累计一共有 20 万贡献者在这个网站分享了 200 万张图片，此外他们也用图片整理了几个年度热点。如果你感兴趣可以点击前面的链接查看。 足够简单的博客写作工具 Gridea 上期会员通讯中鼓励大家都来写东西，有读者写信来问：有没有推荐的部署个人博客的方式呢？ 确实，对于想写博客的人来说最大的问题就是如何搭建个人博客，第二大的问题就是搭建好了之后写什么。我看过好几个博客只有一两篇文章，内容想必你猜到了：如何搭建一个博客。 开始写博客以来，我前后用过 Hexo 和 Halo，其中 Hexo 折腾一下可以上手，Halo 基本无需配置但要有个服务器。最近一年半我一直在用的博客工具是 Gridea，它是一个有 Windows 和 Mac 版本的静态博客写作客户端，客户端免费使用，开发者会上架一些可以付费购买的网站主题（最近他们好像也推出了在线版付费部署服务）。 Gridea 配置非常简单，根据官方上手教程配合 GitHub 一步一步来基本不会遇到问题，如果你有开一个博客的想法，不妨试试。 上面提到的几个工具因为本质上都是部署在 GitHub 或服务器上，虽然写作起来相对自由但多多少少都有些学习成本。如果你只想简单写写，我更推荐用那些支持公开分享的笔记类工具，如果以后真有搭建个人博客的需求再迁移也不迟。我曾经写过一篇 如何使用语雀快速发表自己的博客 就提到了这样一个思路。不过这篇文章是一年多前写的，迭代升级后的语雀现在有了不小的变化，如果你需要可以自行探索。 讨论 一人份过年必备指南，你有什么推荐？ 响应就地过年的号召，今年应该不少人都是生平第一次不回家过年了(比如我）。这些年我们一直反复热议的话题是「春节回家生存指南」，比如怎样合理应对亲戚的各种盘问。不知道有没有独在异乡的过年指南呢？ 如果今年过年刚好你也不回家了，有什么计划或者独自过年的必备技能，欢迎写邮件分享给我。期待你的来信。 one more thing 第一财经杂志旗下的新一线城市研究所发布了一个研究项目，他们用大数据分析 348 个地铁站后找出了上海的“超级核心区”，这种用地铁展示一个城市的发展的思路还是挺有趣的，如果你人在上海不妨点击上面的链接看看，好为买(zu)房做功课。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-02-02-4321x-5/"},{"title":"关于 wolai 这款工具的观察与困惑","content":"本文首发于少数派 我不是产品经理也没有什么关于产品的深刻研究，但是我用过的笔记类工具时长和数量还算不少。这次说说对一个国内笔记类工具新秀的观察和思考。嗯，也不用藏着掖着，就是 wolai。 首先说明这个短文的出发点不吹也不黑。一方面我从去年 6 月 wolai 刚上线开始就参加内测，邀请获得的积分也接近上限，且现在依旧持续观察和轻度使用；另一方面，重度用 Notion 一年多和 Roam Research 近半年后，再看 wolai 的更新日志，反而对于它的后续有很大困惑。因此，本文仅仅是表达一些个人的观察思考和困惑。 我理解的工具类产品大致有两类，一类在诞生之初就带着一个方法论，比如 Anki，比如基于 GTD 的待办清单。这类产品无论后续怎么迭代，只要不严重跑偏就能给用户一种确定感，也会降低上手学习的恐惧，即便不使用了可能还时不时有些怀念。像我用了多年的 workflowy，它始于一个单页面大纲笔记，更新到现在即便丰富了很多功能依旧还是一个单页面大纲笔记。转向 Roam Research 之后我对它依依不舍，因为移动客户端和网页端对于各种时间节点输入的极度友好，又因为整体设计的极度简洁且支持了图片上传功能，如今被我用来美滋滋地写 Daily Log。更优秀的付费订阅制日记软件能省则省吧。 另一类产品是诞生之初就参考着一个或几个产品的模子来，采取跟随策略力求在某些体验上更优秀。wolai 应该是属于第二种，其实国内绝大多数工具都属于第二种。wolai 一直表达出来的开发思路是想做一个中文友好高颜值完美支持双链的类似于 Notion 的工具。我对它的更新和迭代速度非常惊喜，但这半年观察下来逐渐觉得很多地方不太对。wolai 似乎做的每一个功能都有一个明确的比较对象，比如 Roam Research 的界面有些丑，Roam Research 的网络图在节点多了之后很难用，Notion 竟然一直没有悬浮大纲，Notion 对于多文件导入的处理非常缓慢，Notion 竟然不官方支持动态图标…… 为什么工具类产品自身可以溯源的方法论或者设计思路尤其重要呢，因为工具在创造之初被赋予的属性很大程度上决定了以后用户的使用习惯，而且反过来会塑造用户对于某类方法或理念的认知。 看 wolai 最近的更新日志，我突然感觉一个工具类产品如果不带着明确的方法论去开发，要么很容易陷入跟随，要么就会容易纠结于细碎（这里对是否有核心理念的判断仅基于个人对产品的观察）。比如对中文友好的一个重要体现是用拼音首字母进行快速调取，这个思路当然是好的且也有类似案例。但是，最近更新里类似用/tb来调用 Font Awesome 图标，用/wyyyy来插入网易云音乐音频的功能，让我在实际使用中有些困惑。此外，图标更新在日志里强调「独家」，这样的独家对于工具类应用的核心竞争力是否有很大意义我还是画一个问号。 与我而言，想插入页面第一反映是/page，很难会先想到/ym 。更大的问题是，这样的中文拼音首字母输入习惯一旦养成就很危险，因为中文在翻译层面具有很多可替代的词汇。比如我想插入一首歌的时候，我是输入yy(音乐)还是输入gq（歌曲）呢？调用 Font Awesome 图标使用的缩写是tb，我一开始理解为淘宝的缩写，之后被提示是图标的缩写，那如果一个用户想插入表格时他的第一反映词汇是图表，又该用什么缩写呢？所以这究竟是中文友好还是会增加用户的负担。这个观点只是我一家之言，或许我并不是这种中文友好的目标用户，换个角度如果开发团队愿意把这件事情做到极致，那想同义词也是不小的工作量吧。 再说说核心功能的开发。因为给很多用户的印象是 wolai 要做一个带有双链功能的类 Notion 工具，用户在文档双链之后就催块双链，在块双链出来之后现在催 database。对于用户而言，有多少人是真的重度使用过 Notion 和 Roam Research 之后发出的催促，亦或者只是因为 wolai 给他们的感觉如此，用户永不满足；对于开发团队而言，是有强大的理论或者调研在背后支撑，是有明确开发计划或对最终呈现形式的设想，还是隐约想摆脱掉那些关于「模仿」的质疑，不得而知。Notion 没有的双链有了，Roam Research 没有的 database 有了，然后呢，1+1 有没有可能小于 1。 把 Notion 所谓的 database 和基于块的双向链接放在一起真的是好选择或者有必要么？先不提 Notion 前一段时间更新的姿态远大于实际作用的「反向链接」，也不提什么可溯源的方法论。单单就从我自己过去一年的 Notion 加 Roam Research 使用情况和侧重来看，自己完全不在乎 Notion 要不要跟进基于块的双链功能，也不在乎 Roam Research 要不要加一个 database 或者类似于 Notion 的若干视图。 话说到这里，如果 wolai 兢兢业业打磨 database 也没问题（当然这句话的意思并不是臆测团队没有同步开发 database 功能），但是我今天看到更新计划又要上线「脑图」，所以忍不住想写文章表达这些困惑。 一个基于文档的双链笔记工具，快马加鞭做脑图功能究竟是为了什么？是因为用户呼声、难度较低还是早有安排，或者是认为脑图是这个工具的重要功能。 也许是一种偏见（没有影射任何其它工具），我一直不认为思维导图和大纲笔记之间的切换除了让部分人看到哇一声以外还有什么重要价值，也不理解为什么还有人做主打 markdown 笔记切换成思维导图的文本编辑器。看似只是不同的呈现形式，但文章、大纲和思维导图本就是不一样的思维方式。 双链的魅力在于无需明确目标而带来的漫游和随机，大纲的魅力在于思路有基本框架后的逻辑和层级扩展，脑图的魅力在于仅有核心出发点后没有束缚的发散思维。那么，wolai 想给用户呈现的究竟是什么，想培养的用户认知和习惯又是什么呢。 最后，希望不要让用户的呼声去塑造一个产品，也希望不要用看似独家的功能去堆砌一个产品。这之间有没有可以平衡的方案呢？开发团队专注核心功能，高阶用户开发各类插件，带动普通用户构建方法社区，这条路 Roam Research 和 Obsidian 目前似乎都走得不错。 以及，疯狂添加功能的笔记工具不是没有先例，如今面临的境况也无需多言，作为多年的重度用户我还是时常会感到可惜。wolai，作为一个新产品才刚刚开始，希望越来越好。 更新：本文发布三小时后，wolai 更新日志页面已经去掉了关于脑图和 database 的更新计划说明，也去掉了关于 Font Awesome 图标更新的「独家」字样。作者浏览时间为 2020 年 1 月 21 日 20:59 再更新：今天在少数派看到了另一篇介绍 wolai的文章，因为看起来和我的这篇文章意见相左利益相关，我还是想在自己再补充一点想法。 这篇文章详细的介绍了 wolai 的中文优化，我想说的是这些中文优化大部分都是我喜欢的。但是文章最后引述了创始人的一段化。这段话是否为原话我没有考证，那就以这篇文章说的为准，如果是真的，我自己感觉更加加深了在上文里我提到的困惑。 1.「这个产品融合了自己使用过的同类产品的所有优点」。 即便真的可以融合使用过的同类产品的所有优点，又是好的么？如果这样的开发逻辑成立，所有新软件就多数都是之前同类产品的优点加和，但显然并不是这样。Notion、RoamResearch 和 Wordpress 在我有限的认识里也不认为他们是同类工具。 2.「充分研究中文用户的使用习惯，即便 Notion 进入中国，Notion 也很难达到这样的程度」。 考虑中文用户使用习惯一定是好的。但是不论 Notion 有没有意愿研究中文用户的使用习惯，按照这个逻辑，国际化产品都应该使劲研究每个市场的用户习惯，这对于很多快消产品是有道理的，比如快餐和化妆品，出针对国内市场的味道和色号。但是生产力工具，很大程度上并不需要做太多国际化适配（多语言支持通常就够了）。一个生产力工具，尤其是 to C 的生产力工具，只要有扎实且被认证过的理论基础或者底层逻辑，那对于哪个国家的人都应该是有效的，人和人的认知没有什么本质区别。换个角度，wolai 有一天在国内做到最大最强，它用什么出海开疆扩土呢，核心一定不是中文优化。飞书先是用 lark 在国外上线了很久，Xmind 一直被很多人认为由国外团队开发。 如果最大的优势在于中文优化和写作体验优化，再加上国内访问速度稳定的先天优势，我想也很好。我更愿意把它当作一个很不错的中文写作工具继续使用。但是优化可以是一个亮点，但不是一个生产力工具的核心。 回看 wolai 官网，第一个介绍是让「信息通过层级和链接方式关联」，本质其实就是大纲+双向链接。在关于 wolai 的知乎回答中，有写到「但可能只有我自己知道，我们未来绝不会是 Notion + Roam，我们也不会亦步亦趋做一个没有灵魂的 copycat」。这当然是包括我在内的每一个喜欢折腾工具的爱好者愿意看到的。只是，相比于不会是什么，每一个和这个工具一起成长的使用者，都很想知道它会是什么。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-01-23-aboutwolai/"},{"title":"关于个人的认知不确定性","content":"这篇文章是熊言熊语会员通讯 4321X 的刊首语和部分内容，主要谈了谈关于不确定性和写作的问题。完整内容可以通过会员通讯邮件进行查看。 小到个人，再到团队和公司，大到国家，都存在着如何应对不确定性的问题。所谓不确定性，通俗的理解是无法根据过去的经验来推断事件未来发生的概率。在深度学习中关于不确定性有两种解释：一种是偶然不确定性（Aleatoric Uncertainty），是由于观测数据中固有噪声导致的，这种不确定性增加实验数量也无法被消除，但可以更准确的给出结果变异的概率分布；第二种是认知不确定性（Epistemic Uncertainty），它与模型相关，主要是由于缺乏知识引起的，如果我们获得了有关研究对象足够的知识，理论上就可以消除这种不确定性。 这里我们主要谈的是基于个人的认知不确定性。 不确定性会带来什么问题呢？不确定性带来的最大问题是焦虑，如果既成事实摆在面前我们可能会恐惧，但是如果不确定的事情存在我们就会焦虑。最简单的例子是等待体检结果和拿到体检结果后的两种体验。恐惧是人面对现实危险的正常反应，焦虑就是面对潜在想象中危险的过度反应。 当然，如果生活中完全都是确定性也不行，在一个极度安全的舒适区所有事情都可以被预测，多数创意或者想法其实都是在适度不确定性中产生的。**我们能做的首先是认识到这种不确定性的存在，然后主动增加一些不确定性的同时还得给自己营造一些固定的仪式感。 ** 所谓认识到不确定性的存在，就是能够区分能力和运气，信号和噪音，还要能够区分因果。人的抗击打能力很强，有一种非常火的锻炼方法叫做高强度间歇性训练（HIIT)，我的理解这就是给确定的身体机能偶然来一些强度逐渐提高的不确定性，生病也是一个道理，平时有个偶尔的头疼脑热其实也是不确定性的体现。 主动增加一些不确定性，从个人角度来说可以是主动学一些专业外的内容，做一些本专业之外的事情。面对未知的内容，人很容易增加斗志和好奇心，这样才容易看到自己更多的可能性。换个角度想，多做一些出人意料的事情，也是给这个世界多增加一些不确定性。如何最简单的践行呢？你可以每周有两三天选择不同的路线回家，甚至「不经意」的坐过一站然后再走回家。很多人都不知道自己家的下一站路上有些什么东西。 所谓营造固定的仪式感，就是刻意的给自己一点确定的感觉。比如很多人都有一件在重要场合才会穿的衣服，在做重要事情之间都会做的个人癖好。这件衣服和某个爱好不一定真能带来好运，但会让你明显感受到一种状态转换和积极的心理暗示。实践起来，比如你可以每天坐到工位上之后先固定浏览 10 分钟某一个杂志网站的信息，然后再开始工作，每天睡觉之前都读 20 页书。 对我来说，写作就是一个主动选择不确定性的行为，每天我会把看到的各种内容记录整理，播客也是一个主动选择不确定性的行为，不同的嘉宾会给我带来不同的思考。写会员通讯和制作播客虽然于我是不确定性大于确定性的过程，但希望它们对于你来说能变成一种确定性。 其实这件事儿也没有那么难，写不出来 3 千字的内容我可以写 300 字。因此我会尽快稳定找到一个固定的时间和频率进行更新，无论我这边出现了什么不确定，争取到了固定的时间它就会出现的你的生活里，让你多一点安心。 谈到写作，李笑来曾经在他的一本书里总结过人生的商业模式主要有三种：同一份时间出售一次，重复出售同一份时间，购买他人的时间再出售。绝大部分人都是第一类，创业公司和大公司的领导们做的是第三类。我们这种普通人还可以在第二类稍微尝试尝试，比如写作就是重复出售同一份时间的最好示例。 一个小例子，5 年前我曾经写过一本关于考研相关的文集「聊聊考研复习这件事」，包含随笔文章、不同科目复习心得、英语真题解读和英文新闻精读几个部分，文笔稚嫩但是绝大部分内容如今看来也没有过时。我从后台粗略统计，去年它的访问量依旧有 8000 多，这还不算流传在民间的几个 PDF 版本。嗯～如果你身边还有准备考研的朋友不妨把这个文集推荐他。 2020 年有 1.5 万人访问了我的个人网站，有效访问会话数有 2.1 万，平局会话时长是 2 分钟，这么算下来就是 700 个小时或者 30 天的时间。 最感动的是，过去一年有三位朋友和我的交流次数超过了 100 次，虽热从未谋面但绝对是很深的交情了。其中最多的一位访问了 363 次，会话时常超过了 38 个小时，希望你我的文章有帮助你解决一点问题。 2020 年 5 月 18 日，一位朋友在网站上停留了 1 小时 40 分钟，是单次停留最长的，希望你现在已经顺利的用上了 Zotero。 我也鼓励每位看到这篇文章的你从 2021 年开始写作吧。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-01-17-uncertaintyandwriting/"},{"title":"需要时刻留心的24个生物信息学提示","content":" 前几天读到一篇英文博客深以为然，所以翻译一下和大家分享。以下 24 个提示不仅适用于生物信息而是适用于所有科学研究，看似简单但需要我们时刻留心。 保持简单 如果你刚开始接触生物信息学，务必保持简单。设定几个明确的目标然后专注于它们，不要偏离方向，也不要试图一下子做太多。 寻求帮助 有许多资源可以帮你解决生物信息学问题。无论是线上论坛还是与身边的同事同学交谈，你都可以获得编程语言或其它技术的支持。 用熟悉的例子 熟能生巧。在学习新概念或使用新工具时，尽量找一些自己熟悉的例子上手。当你能将学习内容与自己的课题联系起来时学习就会更容易。 养成好习惯 从长远来看，养成良好的习惯可以节省时间。确保自己有详细的记录文档，这将使你和你的代码都更有效率，并有助于提高可重复性。 做好计划 从一开始就想清楚要从数据分析中获得什么，并在实验设计和执行阶段牢记这些目标。一个精心设计和执行的实验可以最大限度提高准确得出你想要结论的可能性。 不重复造轮子 无论开始一个项目还是在当前项目卡住了，在创建新项目前先看看已经有哪些方法可以使用。GitHub 和 SourceForge 都是大型软件仓库，它们可以帮你节省时间并提供代码支持。 质量、质量、质量 怎么强调质量都不过分，从原始数据质量到生物信息学分析流程中的质量控制，数据质量在研究每个阶段都很重要。使用公共数据集并将其整合到分析中时尤其如此。 投入什么就会产出什么 如果你的数据质量不好，这对你的生物信息学分析意味着什么呢？当实验设计导致质量问题时，下游质量控制能做的很有限。 管理范围和期望 范围蔓延、范围蠕变都是生物信息学项目面临的主要挑战。项目起始就要制定好分析计划，不要突然或大幅度改变项目范围和期望，不要浪费资源，确保项目范围是可控的，同时也要管理好分析的期望。 注：范围蔓延 scope creep 和范围蠕变 scope grope 都是项目管理中的概念。范围蔓延是指未得到控制的变更，随着项目需求的不断增强而产生。泛围蔓延通常被认为对项目成功有害，因为它增加了成本并延长了进度，每一次增加的功能所带来的范围改变看似不大但是积少成多量变最终有可能引起质变。范围蠕变是指在产品或项目开发期间需求驱动发生变化，带来一些开始没有计划的产品特点，对产品质量或时间表产生影响，特征蠕变来自于客户增长的需求列表或者是开发者本身发现了提升产品的机会。 再注：我目前的项目就是没有做好范围和期望管理，深受其苦。 寻找合适的工具 理想的生物信息学分析可被重复也可以复用。要做到这一点关键在于你使用的工具。要考虑的因素有很多，比如工具是否被广泛使用，是否能得到开发者的支持，是否开源，是否有版本控制，是否容易安装等等。总之要制定出一个决定使用新工具的标准。 方法应该能够回答问题 你的研究目标是什么？你生成的数据会产生什么潜在问题？要回答你研究的科学问题而不仅仅是将某种方法用于某种类型的数据，使用的方法应该可以帮助你找到数据中的潜在模型。 背景至关重要 生物信息学是生物学、统计学和计算机科学的交叉。研究背后的背景非常重要，由生物学主导和数据驱动的结论有助于将你的研究置于更广泛的背景中。 追踪变动 追踪变动有助于确保数据分析期间的质量控制，还可以使你的研究具有可重复性。工作流程会随着时间的推移而变化，追踪可以验证和确认这些变化。 数据再利用 无论是从你之前生成的数据还是公共数据库中的数据，你总能从中获得新的信息。在药物开发中，来自试验的数据可以探索药物在未来如何被重新利用。 存储原始数据 存储图表背后的原始数据有很多好处。它可以让你快速对图表进行修改，也可以退回到之前的图表以确保一致性。此外，存储用于制作图表的代码也是必须的。 好图胜过千言万语 海报、报告和论文里的图都可以帮助你有效地将研究结果传达给别人，这是别人理解分析结果的关键。 有效使用颜色 色彩丰富的科学图表可以突出特定特征或直观显示差异，但是过犹不及。要警惕太过相似的颜色和只是为了颜色而颜色。 不要误导 保持你的图表清晰简单，使用能以最简单的形式表达数据的图表，让读者清楚地了解图表含义。 你的图是为了什么 对论文有用的图和对演讲有用的图是不一样的。演讲报告需要简单的图去讲述一个简单的故事，但是论文可以用更复杂更详细的图让读者了解的更加深入。 吸引别人 不要以封面来判断一本书，也不要以标题来判断一个报告。掌握好演讲或论文标题的长度和亮点是一种艺术，但要确保你的主题依旧明确。 好的格式 好的幻灯片的格式布局可以帮助你传达研究成果并确保观众能够真正理解。拥有易读的文字和清晰的布局可以帮助读者有逻辑地浏览你的研究。 内容简明扼要 有时很难将所有成果浓缩成一个清晰简洁的总结，尤其是在有限的海报或幻灯片里。清晰的措辞和排列整齐的图会让听众保持兴趣，从而让你的故事被更多人听到。 简洁胜过复杂 从基本的和简单的方法开始，然后根据需要再增加分析的复杂性。通常对于大型生物信息学项目来说，分析本身就具有内在的复杂性并需要复杂的模型，但不要以为所有项目都如此。 做就对了 最后的建议是现在就开始。第一步总是最难的，在编程时犯错也是学习曲线的一部分。 做就对了。 原文地址 https://www.fiosgenomics.com/bioinformatics-hints-tips/ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-01-12-bioinformatics-tips/"},{"title":"要不要读博（答读者信）","content":"最近收到了一个朋友的来信。 信很长，简单来说这位朋友： 2020年上半年抱着不能「延期丢人」的信念挣扎毕业之后最近半年各种不顺利，申请国外和国内的几个学校纷纷失败，有科研助理的机会也不太想去。毕业半年目前没有工作而且2021年已经读博无望，28岁的年纪也让他很挣扎要不要继续读博。 以下是我的回信： 你好，感谢你的来信。 首先说说毕业时间这个问题。研究生（尤其是博士）的毕业时间某种程度上是和导师协商以及和自己协商的结果。涉及到比如课题进度、文章进度，工作机会，下一步发展和当下的整体环境等很多问题。 按时毕业还是推迟半年一年，我想并不是研究生毕业这件事情的重心和中心，单就时间节点而言无论怎样都不值得骄傲也不需要感觉丢人，重点是毕业前你得到了什么和毕业后你会去做什么。按时毕业反而gap了一年和延后一年毕业但是发了一篇文章哪个好是见仁见智的事情。 2020年的疫情（这个事情可能持续两三年）打乱了很多人的计划，无论是毕业还是出国，但是从你的信里更多看到的是一种不知道为什么的执念以及些许不甘。我没办法替你做选择，也很难从一封信里了解更多东西，只能给一些提醒吧。 读博不是因为赌气，也不是因为执念，我也不建议把读博理解为继续硕士毕业后的继续上学。不要为了取悦别人（比如父母）而读博，这样今后遇到的各种不顺心都容易归结给对方；不要因为别人（比如导师）的热情鼓励而读博，形势变化的速度很快，很多东西今时和往昔差别极大，也不要因为毕业前不知道还能做什么而读博。 从我这几年的经历和身边的例子来看，读博有非常大的不确定性，一小部分人走上了很好的学术生涯，也有一小部分人非常挫败，大部分人得过且过。 在权衡是否读博的时候，首先要想想因为读博可能错失的职业发展机会和需要付出的职业成本，比如在三年或更长的时间里如果投入工作，你很大概率会攒些钱，获得些工作经验然后得到一两次晋升，如今在大部分行业里（比如互联网）这比一个博士学位来的更直接更实际。读博会让你在某个领域有深入的研究，但无形中也会缩小今后工作选择的范围。 读博并不是推迟工作的方法，因为它本身就是一个职业选择和一次职业培训，这些职业又大多数局限于高校或者高度专业化的相关领域。如果你想从事研究和教学类工作，或者想在专业的细分领域工作，读博是不错的选择。如果你非常不善于处理人际关系，那么读博整体的工作环境来说也相对简单。 另外，从很多与研究生相关的热点事件看，如果一个人经常需要表扬或者习惯于接受肯定，也要对读博慎重考虑。博士阶段接受到的反馈，坏的一定比好的多（阴性结果一定比阳性多）；反馈并不频繁（一个实验经常需要十天半月）且非常滞后（一个课题文章发表往往要两三年）；以及日常还会面对各种拒绝，比如评比落选、文章拒稿和导师责备。 如果你权衡了很多还想读博，就尽快做决定吧。至于你信中还提到的选择国外还是国内读博，坚持什么方向，以及毕业后的职业道路，我目前都很难给出更多回答。一是因为每个人都差别很大，我看来不错的选择可能完全不适合你；二是我还没有丰富的经历去做什么判断，比如我也尚未毕业也没有出国读书的经历。 其实科研助理也是你实际感受要不要继续读博的一个机会。无论怎样还是先把一件事情做起来才会增加后续的各种可能性。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-01-07-phdornot/"},{"title":"熊言熊语会员通讯 4321X 第3期","content":" 你现在看到的是熊言熊语会员通讯 4321X 的第 3 期试读版本，今后我们会不定期的将部分会员通讯内容发布到公开平台，如果想稳定的阅读每期内容欢迎通过邮件订阅这份免费的会员通讯服务。 Hi, 见信好： 我是思考问题的熊，你现在正在阅读的是熊言熊语会员通讯「4321X」第 3 期。 截至本期通讯，「4321X」订阅人数为：451。 刊首语 本期会员通讯刊首语想和大家聊聊生病。 最近一周多的时间一直在生病，我以为像感冒咳嗽这样的日常病，就是给身体一个信号，告诉你需要刹车需要休息，是身体默默的反抗。这几年只要自己坚持一段高强度的生活之后就会病一次，这种高强度有时候是身体层面有时候是指心理。生病了人总归要停下来，各种药的最大作用给我的感觉也是「催眠」让人犯困，强迫自己睡几天再重新开始另一段高强度的生活。 之前几期通讯都是在周末推送，我看了后台的打开率并不理想（略高于 50%），难道是因为周末大家对打开邮箱这件事比较抗拒？借着这次延后发布，再试试把推送时间改到周中下午时段是否会好些，希望用 10 期左右的时间我们可以达成一个固定推送时间的默契。 上次想测试拆分一次通讯多次发布的计划还没试行就被我又否定了，至于原因，我没有想出来该怎么给多出来的一封邮件命名。 文献 The relationship between genome structure and function DOI：10.1038/s41576-020-00303-x Precise patterns of gene expression in metazoans are controlled by three classes of regulatory elements: promoters, enhancers and boundary elements. During differentiation and development, these elements form specific interactions in dynamic higher-order chromatin structures. 基因表达会受到启动子、增强子和边界元件这三类调控元件控制。在分化和发育过程中，这些元件在动态的高阶染色质结构中可以形成特定的相互作用。然而，基因组结构与基因调控功能之间的关系尚不完全清楚。这篇综述从基因组的调控元件、基因组结构和 3D 基因组调控几个方面进行了介绍。 Cross-Site Concordance Evaluation of Tumor DNA and RNA Sequencing Platforms for the CIMAC-CIDC Network. DOI: 10.1158/1078-0432.CCR-20-3251 The CIMAC collaborating laboratory platforms effectively generated consistent WES and RNA-seq data and enable robust cross-trial comparisons and meta-analyses of highly complex immuno-oncology biomarker data across the NCI CIMAC-CIDC Network. 全外显子组(WES)和转录组测序(RNA-SEQ)是肿瘤基因组分析的重要组成部分。越来越多的分析需求需要将不同中心的数据整合起来进行分析，CIMACs 和 CIDC 共同发起了一项关于这两类数据在不同中心平台分析一致性的研究。其中 WES 的一致性比较好，RNAseq 数据在满足 DV200&gt;24% 和 MedTIN&gt;30 的情况下可以进行后续的 HLA 配型、免疫浸润和免疫谱系推断。 The landscape of long noncoding RNA-involved and tumor-specific fusions across various cancers DOI 10.1093/nar/gkaa1119 Here, we present a systematic study of the lncRNA fusion landscape across cancer types and identify &gt;30 000 high-confidence tumor-specific lncRNA fusions (using 8284 tumor and 6946 normal samples). Fusions positively correlated with DNA damage and cancer stemness and were specifically low in microsatellite instable (MSI)-High or virus-infected tumors. 基因融合与各种疾病特别是癌症的发生发展紧密相关，甚至是一些癌症的直接诱因。本文使用大量的癌症与正常样本分析了 lncRNA 相关的融合现象。融合与 DNA 损伤和癌症干性呈正相关，在高 MSI 或病毒感染的肿瘤中呈负相关。且作者研究发现 eRNAs 可能介导一种新型的复杂融合机制 Alternative splicing: Human disease and quantitative analysis from high-throughput sequencing DOI：10.1016/j.csbj.2020.12.009 In this mini-review, we aim to illustrate I) mechanisms and regulation of alternative splicing, II) alternative splicing associated human disease, III) computational tools for the quantification of isoforms and alternative splicing from RNA-seq. 可变剪接可以使一个基因产生多个不同亚型从而增加蛋白质的多样性，同时也是一种重要的表达调控机制。95%的人类多外显子基因可以通过可变剪接编码具有不同功能的蛋白质。同时大约 15%的人类遗传性疾病和癌症与可变剪接有关。这篇综述介绍了可变剪接机制和调控方式、可变剪接与人类疾病的关系以及如何从 RNA-seq 中进行可变剪接分析。 思考 每时每刻我们都是幸运的，因为任何灾难的前面都可能再加一个「更」字。 史铁生是我最喜欢的国内作家（或许没有之一），他的「病隙碎笔」曾陪我度过了高中特别重要的一段时光。直到今天，每次生病我都会想起下面这段他关于「生病」的描写。 生病也是生活体验之一种，甚或算得一项别开生面的游历。这游历当然是有风险，但去大河上漂流就安全吗？不同的是，漂流可以事先做些准备，生病通常猝不及防；漂流是自觉的勇猛，生病是被迫的抵抗；漂流，成败都有一份光荣，生病却始终不便夸耀。不过，但凡游历总有酬报：异地他乡增长见识，名山大川陶冶性情，激流险阻锤炼意志，生病的经验是一步步懂得满足。发烧了，才知道不发烧的日子多么清爽。咳嗽了，才体会不咳嗽的嗓子多么安详。刚坐上轮椅时，我老想，不能直立行走岂非把人的特点搞丢了？便觉天昏地暗。等到又生出褥疮，一连数日只能歪七扭八地躺着，才看见端坐的日子其实多么晴朗。后来又患尿毒症，经常昏昏然不能思想，就更加怀恋起往日时光。终于醒悟：其实每时每刻我们都是幸运的，因为任何灾难的前面都可能再加一个「更」字。 每时每刻我们都是幸运的，因为任何灾难的前面都可能再加一个「更」字，上面这段话除了适合送给生病的自己，也适合送给每一个走过 2020 年的你。 推荐阅读书籍 病隙碎笔 史铁生 别把时间排太满，冗余和空闲反而可以提高抗风险的能力 本来上周末安排了播客录音、会员通讯的写作和几篇文献的整理，因为生病无精打采睡了两天之后才发现自己抵抗风险的能力很低。一旦哪一部分停下来，就像多米诺骨牌一系列事情都无法按照计划完成。 很多人已经习惯了追求高效紧凑的时间安排，事情一件接一件，待办事项和日历填写的井井有条，看似充实反而降低了抗风险和反脆弱的能力。时间安排的太满，计划做的太好，整个系统就会很脆弱，这个观点在「反脆弱」和「稀缺」这些书中都有介绍。 如何提高抗风险的能力呢？有两个看起来非常低效的方法：冗余和空闲。 冗余在数字领域可以理解为备份，在之前一期通讯中刚好有提到这个问题，在生物体内也存在大量的冗余基因，看起来没用但就是为关键时刻准备着。对于「3421X」通讯而言，最理想的情况是有三四期存货，现在写的内容在一个月之后发布。但因为我总想把最新的想法和你分享，所以还需要摸索一下如何平衡。 我们通常会大大低估完成一件工作的难度和时间，空闲的作用之一就是给计划预留出缓冲的时间。空闲的作用之二是给尚未出现的机会预留时间，我曾听一个非常厉害的 freelancer 讲他一周只给自己安排 3 天的固定时间工作，因为这样有更重要的事情找到他就不会因为没时间而错过，如果没有更重要的工作就读书和学习。 对于你我来说，我们可以把每天的某一段时间作为空闲时间，当然前提是非空闲时间没摸鱼～ 推荐阅读书籍 反脆弱 告知对方你希望提供帮助，让他很难拒绝你的好友添加请求 因为在网络上发布过一些教程我常会收到各种各样的好友请求，多数是提问或者索取资料也有一小部分是表示感谢。因为我取消了微信好友验证，所以大家可以直接给我发消息，但我可以选择是否把对方也添加为好友。 对于大部分提问和索取资料的读者我会尽力回复但很少把对方添加为好友，但有一类人我无法拒绝，就是那些有意愿想要为我提供帮助的人。如下图所示： 一个人首先对你表示感谢，然后进行自我介绍，最后表达向你提供帮助的意愿，这真是一个极好的社交破冰范本，值得借鉴和学习。有求于人和有助于人构成了人与人之间的联系，向自己在意的人表达给予帮助的意愿总是没错的，无论对方是否需要。 推荐 ListenNotes 播客栏目越来越多，听播客的人越来越多，如何找到感兴趣的内容？订阅自己感兴趣的播客追更是一种不错的方法，如果想知道自己感兴趣的话题有没有人在播客中讨论过该怎么办。ListenNotes 就是一个专门针对播客（Podcast）的搜索引擎。 ListenNotes 自称是播客界的 Google，可以通过标题和 shownotes 搜索内容。截至本期通讯推送，网站已经收录了超过 9000 万期节目，英文为主也包括中文内容。 我曾在少数派写过一篇详细介绍 ListenNotes 的文章：Listen Notes：最好的播客搜索引擎岂止于搜索，如果感兴趣可以进一步阅读。) 定制简单的搜索引擎 学会搜索是数字一代的基本技能，这次推荐的技巧是定制简单的个性化搜索引擎。大部分基于 Chromium 内容的浏览器都可以参考，这里用的是最新版本的 Edge 浏览器。 在设置「隐私搜索服务」中选择「地址栏和搜索」，然后选择「管理搜索引擎」，再选择「添加」。 以上文提到的 ListenNotes 的网站配置为例，搜索引擎可以随意命名，这里命名为「listennotes」，关键字则是唤起方式，这里我们设置为「ln」。第三步是将搜索 URL 中的搜索内容使用 %s 进行替换。如果你不知道对应的 URL 是什么，只需要在网站里随便搜一个内容然后复制网址就可以，这里我们设置为https://www.listennotes.com/search/?q=%s。最后保存就可以。 今后只需要在浏览器的地址栏输入ln 然后按下 tab 键，输入检索内容再回车就可以直接看到 linstennotes 的结果。 按照这个思路，你还可以把 Wikipedia、豆瓣和京东等任何常用的网站进行配置，从而一键直达提高效率。还有一些常用的搜索小技巧可以继续了解。 讨论 你坚持最久的一件事是什么，并因此得到了哪些意外收获呢？ 最近在爱发电平台一位发电的朋友给我留言了这样一句「鸡汤」：成功的路上并不拥挤，因为能坚持的是少数。) 鸡汤想要有效关键是需要得到验证。成功的标准很难定义，这里就不讨论了，但能够坚持的确实是少数，而且可能比你以为的少还要少，以下是两个例子。 我曾经重度使用的一款笔记应用最近做了一个年度回顾，我感兴趣的一个统计是一年新建笔记数量 700 多条超过了 90%的人，根据其他人反馈不到 400 条新建笔记数量就可以超过 80%的人。也就是说，你只要平均每天写一条笔记，基本就能达到前 20%的水平。 Substack 是一个非常火的 newsletter 发布平台，有人统计了 Substack 的newsletter 更新数据后发现 40.14%的 newsletter 在最近 90 天内没有更新，推送数量少于 10 篇的占 65.5%。也就是说，只要我们的会员通讯可以保证一定频率的稳定更新或能够坚持 10 期以上就已经超过了一半的人。) 本周的讨论内容想听你讲讲自己坚持最久的一件事是什么，因此得到了什么意外收获。期待你直接回复邮件我和分享，静候回信。 one more thing 对未来的憧憬固然让人心动，但更重要的是接纳过去的自己。 上一期会员通讯我们尝试了一次共创协作活动，大家一起通过三个问题回顾自己的 2020。三个问题分别是：今年我最大的收获是；今年我最大的遗憾是；我想对去年此时的自己说什么。 通过大家的评分，2020 年的平均分是 6.36，一个及格的成绩。 我整理汇总了大家的回答，通读下来发现「课题」、「论文」和「毕业」是非常高频的词汇，此外「女朋友」和「男朋友」也多次出现。同一个话题对于有的人来说是收获对于另外一些人来说却是遗憾，各有欣喜和忧愁，无需羡慕谁。 问卷发布以后，有人留言提了一个问题：为什么不是想对明年的自己而是对去年此时的自己说些什么呢？因为对未来的憧憬固然让人心动，但更重要的是接纳过去的自己吧。 从大家的年度收获和遗憾中你又可以读出什么呢？如果想阅读完整内容，可以点此查看。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2021-01-02-4321x-3/"},{"title":"用三个问题回顾 2020（全员协作版）","content":" 2020 年 12 月我在会员通讯发布了第一次「熊言熊语全员协作」活动。大家一起通过三个问题回顾自己的 2020 年。三个问题分别是：今年我最大的收获是；今年我最大的遗憾是；我想对去年此时的自己说什么。 我整理汇总了大家的回答内容，通读下来发现课题、论文和毕业是非常高频的词汇，此外女朋友和男朋友出现的频率也很高。同一个话题对于有的人来说是收获对于另外一些人来说却是遗憾，反之亦然。各有欣喜和忧愁，无需羡慕谁。对未来的憧憬固然让人心动，但更重要的是接纳过去的自己。 通过大家的评分，2020 年的平均分是 6.36，一个及格的成绩。 下文是四十位小伙伴的分享，隐去了个人信息。 这一年我的最大收获 做了一件以前不敢做也没能力做的事情，投入了一些钱和时间，但真的非常非常开心。 在家体验了一段前所未有的时光，对无所事事有了更加深刻的理解。 加强了和新朋友的联系，巩固了和老朋友的关系，对于出现在生命中的人和事有了更深的感悟，治疗了一下自己的强迫症，进一步理解了顺其自然的含义。 拿到了法律和证券的资格证，又锻炼了一次填鸭式学习的能力，发现学习还是有乐趣的，无所事事最难受。 成功拿到了一段时间的国外学校入场券 硕士毕业 成功四证合一 最大的收获是与自己对话的时间变多了，观察社会、关系的视角也不同了，以前并不觉得自己幸福，时常会迷茫人生的意义，现在好多了，有些事情想得开了，我觉得是很大的进步。还有，保研成功了，这半年很自我，虽然并未有所成就，但是也试过了目前来说的极大自由。 首先，在上半年很庆幸自己的论文被接收，代表着自己研究生阶段取得了些许成绩，也为自己以后的成长奠定了基础，可以凭借此朝着更高的地方走一走。 受疫情影响，我度过了一个记忆中许久没有过的这么长时间的在家里的时光。 最大的收获是毕业后看到曾老师招实习生，虽然自己才刚入门不知哪来的勇气。可能考研失败了，也没有什么可以失去了，即使被拒绝起码也尝试过！ 现在，一方面是导师安排的任务，还有学生信和看视频。每天安排的任务比本科都很多，但...第一次发现自己很喜欢这种忙碌且充实的生活！！ 心态发生了改变。真的要坚定自己的目标，不要放弃，不管环境多么艰难旁人如何嘲笑，不留遗憾！ 投出我学术生涯的第一篇 paper！ 或许是赶在疫情爆发之前拿到了驾照？ 工作方面来讲，对自己的一项业务有了更深层次的认识与掌握，从全国来讲，本系统内对于这项业务我算是掌握的比较好的。对于 python 使用有了一定的掌握，今年开始学习使用 python 写爬虫，也因此收入了一点钱，还是比较开心的。 暑假学会了游泳 找到一个会做饭的男朋友并组成了一个小家 最大的收获大概就是陪女友找到我俩都认为很好的工作吧 当然，是在我的坚持下，没有让女友对其他工作动心，坚守到 10 月份才有了工作。 感谢女友对我的信任 学会了新的技能 应该算是在想法上发生了一些改变，尤其是吕思勉的中国通史。 只要活着就还有希望 凡事最好最坏的准备，要做好反脆弱管理 注意心理健康，不要等到抑郁症再来注意 除了顺利毕业，和读博士，还在实习期间遇到了男票。今年完成了太多事。最重要的是，疫情在家陪爸妈待了很久，他俩很开心，慢慢走出来了，陪伴是良药。 勾勒出理想的生活，知道自己追求的未来需要现在的自己付出什么；重新捡起了读书习惯，开始尝试稳定的每周作息；第一篇 SCI 被接收；心灵上与自己的家庭和解；储蓄真香；降噪耳机满分。 意外收获保研名额，9，10 月是这一年最幸运的两个月，真的是满足了天时地利人和才得到这个结局。 认识多的人 充满意外的一年。由于疫情，本身在焦虑和紧张中赶实验的我停了下来。 疫情期间开始做了心理咨询同伴支持的志愿者，在助人自助的过程中找到了自己的兴趣点，原来我最喜欢的事情是与人沟通，对心理学的东西，对人的身体和精神的健康都充满好奇心。也更加认识了自己，接纳了自己。 疫情期间开始科学系统健身，获得了强壮有型的肌肉。还在坚持。 疫情期间教我妈妈做饭，让她学会了用下厨房软件，做任何想要学习的美食，她也津津乐道，很有成就感。 疫情期间参加人生孵化器，开始关注自己的微情绪和成长，对自己的好与不好更加接纳和自洽，也对自己的职业发展有了新的认识。 明年毕业，目前获得了华为的 offer，最近刚完成了西湖大学博士面试。二选一我可能要去挣钱了。但是我有认真考虑过这个选择。这两个都不错的选择是对我莫大的肯定，我自己是很缺乏正反馈的一个人，总会觉得自己不好，但是这一点正在悄悄发生改变。 一两句话说不清楚最大的收获，但是以上列出的五件事是我多年之后回头看 2020 都会津津乐道的改变，它本不应该出现，但因为疫情我偶然接触到了正常轨道之外的事物并如梦初醒，2020 对我来说意义太重大了，一下子像睡醒了一样，开始向外探索自己的好奇和兴趣，愿意去试错，向内去自省和了解自己，接纳自己，不对自己苛责而且更多 be present. 这是非常大的成长。 在压力的催促下，勉强完成部分实验 我是 20 届考研人，由于疫情原因，20 年的 4 分之 3 的时间是呆着家里的。上半年准备了毕业论文，考研复试，找调剂。然后就在家闲着，以及之后去学校开启研究生生活。也许最大的收获是调剂上岸吧。 硕士第一年将近一年时间投了三家期刊，最后在年终的时候终于被接受了，一方面可以保证毕业要求，另一方面在整个研究的过程中让我认识到在这个领域里面自己擅长做什么，不擅长做什么，喜欢做什么，讨厌做什么。和这里的本科生比，最终还是认识到作为一个普通人的平庸所在，接受自己在某些方面的思考问题的缺陷，以及未来会在多大的程度上选择继续做学术或者转行，也是 10 月份左右的时候才意识到，“如果一个硕博士的培养过程结束后只能够进入高校或者研究所做研究就白读了”的意义所在，哈哈 😄 加入了 Robin 师兄的科研小组后对学习、科研和未来人生方向的认知上升到了一个新的台阶，知道自己在面对生活中的每一件不同的事应该持有什么样不同的心态，每一天都过得很开心！ 生病住院的时候，有一帮好友照顾。认识到身体健康的重要以及要去爱那么值得爱的人。 克服万难的实习经历，认识了倾盖如故的好朋友，学到了很多新东西 开始进入博士生涯正轨了，开始好好学习了，开始安心下来努力了，开始认识到更多的优秀的人，开始养成阅读的习惯，开始用哲学的思维去思考问题，继续了爱情的甜美，继续了友情的顺遂。 接触到了生信！从生信技能树到生信星球到小丫画图到熊言熊语，神奇的发现大佬们都认识！ 心态上注意到了自己的小学生心态，依旧对荣誉称号很看重，得不到心情会低落，但是和以往不同的是，现在学会了自我和解，之前的话绝对是心理上会郁闷很久，必须要到心理老师那里咨询才能够释然一下，还时常焦虑的睡不着觉，但是今年也认识到那些东西并不是很重要，没有那些，我也是我，我的价值不需要荣誉证书来证明。 参与疫情抗击。换到了一个令人激动的初创平台。 攀升到人生另外一个阶段，心态和能力上都有很大的改变。经历了抉择转博还是工作，投递简历面试，选择什么样的工作和城市，对外合作课题，多任务工作方式等。 认识了一位在工作中值得学习的带教老师 按部就班的生活，学业还算顺利，对新年的期许基本完成（其实就是考试通过啦）。 还意外在疫情期间收获了男盆友，焦躁的心态真的有被他安慰到，做事没那么心浮气躁了。和好朋友都能经常联络，在我不开心的时候听我倾诉，给我支持。 换了新手机，哈哈哈哈之前的 ip7 竟然用了四年，我可真棒！ 去了南法，把小时候看的偶像剧一帘幽梦的景点基本打完卡了，满足了我的少女心。家人真是最最坚实的后盾，他们的爱不特别但踏实。 厨艺有所提升，还培养了听播客的新爱好！ 除了集团项目以外的各级别课题都拿了，得到了领导和同事等人很大认可。 思维拓宽了，不局限于书生气，学会多分享多交流，合作共赢。 工作两年多，第一篇 sci 被接收，投稿投了快两年，但结果是好的。 开始真正给本科生上医学遗传学课程，实现了作为一名教师的基本素养。 加入我课题组的本科生越来越多，希望大家都可以学到东西。 核医学科的科研小队基本成型，具有可预见性的成长空间。 保送研究生了 感觉一点写不完（都是最大收获，并列吧） 科研方面 工科研二，在全组只有我一个人学的是导师最初专业研究方向（偏理论，其他人偏工程实践、做项目），导师开公司很忙，我被放养学习的情况下，下半年他让一个年轻负责、温柔体贴的新老师（他师弟）带我，感觉瞬间看到了希望，甚至在逐渐规划继续读博（以前是想都不会想的）； 社交方面 通过 L 先生的写作课和智识营接触到一些认知心理学的内容，并且加入了付费社群，接触了很多同频率的人或者不同频率的人，深受启发，更愿意静下心来深度思考了 通过 Struggle with me 的播客节目知道了熊言熊语，两个很棒的良心社群啊，简直宝藏！！！从中接触到了一些科研效率工具和新的做笔记思维、方法，并也在不断实践中，还有和科研生活很贴切的其他人的真实经历，有所思考，有所收获。过段时间（不太忙的时候）互动我也愿意分享，并且会一直关注和支持滴 通过做打卡返学费的兼职班长了解到很多社会上形形色色的、爱学习或者只为了钱而学习的人，他们都或多或少教会了我一些做人、做事的方法，和几位同龄小伙伴、几位身居外国的学员（中青年）成了神交的好友，也拓宽了自己的一些见闻 3、下半年坚持健身 4 个月，为了增肌，从 115 斤的“瘦”子变成了目前肌肉明显的 130 斤的“中等”子 收获了很多好朋友。疫情结束后回到单位开始实验，但我没有实验基础，从养细胞开始陆续认识师兄师姐，其中一部分已成为无话不谈的知己，让我在实验出现 bug 时总有依靠。 开始接触冥想，开始了解自己。虽然是一段坎坷的旅程，但是慢慢尝试建立欲望与需求的关系。 在繁忙之余抽空来了一次说走就走的旅行 明白了自己很适合在家躺着 涨工资 哈哈哈哈 2020 年没想到录制了二十多期播客节目，和很多朋友有了深度的交流，也给更多的朋友带来了一些陪伴。而且一个重要的人生大事有了比较关键的进展。 这一年我的最大遗憾 浪费了太多时间去维持一个表面的和平假象。 没啥可遗憾的，因为遗憾也回不去。总觉得收获经验，得到教训，人生就是这样走过的。心情时好时坏，但整体向好，已经是最大的不易了。但是，有时候又想，不知道遗憾可能是最大的遗憾了。算了算了，正能量要告罄的时候还是不想负能量的词了。 和女朋友在一起的时间太短啦 最大的遗憾是执行力不够，高估了自己的自律力，尤其是上半年，处于心情低谷，好似没有了灵魂，不过，总的来说，今年还是挺好的，想明白了一些事，尝到了真正自由的滋味（虽然也没有想象的潇洒） 遗憾同样来自于这么长时间的假期，即使也会有一定的任务，不过自己清楚内心还是懈怠的，返校一段时间后状态调整仍然还存在问题，课题进展没有进一步的突破进展。还有的遗憾是没能找到一个女朋友，哈哈哈哈哈 研究生没有考上我梦想的大学！！！ 我觉得应该成为我一生的遗憾，太多无可奈何和泪水... 最后，从南方调剂到了北方，从开学到现在一直很纠结究竟选择是否正确，应该再坚持一年呢还是在异地好好坚持？ 可能毕业后才有答案... 因为太难合作，放弃了我第一个入手并主导的课题 没能和好朋友毕业旅行 减肥失败！个人工作方面，理论上应该能够更进一步的，自己也是这么设想的，但是疫情严重的那几个月看了几本书之后，忙碌了几个月的工作，期间没有再读一些有价值的东西，网络小说到时看了两本。从而耽误了业务水平的提高。自己分析，可能是一段时间太忙，之后就不想再给大脑输入东西了吧。 论文没有认真写 课题普遍进展不顺 最遗憾的就是，没有尝试考考其他学校的博士，糊里糊涂在师姐老师三番四次的劝导下直博了 😭 分手了。 立 flag 没有全部实现 太相信导师，没有自己做好另外的准备 疫情刚开始的时候，没有预计到今年回不了国，导致后面各种麻烦，甚至断粮 自己不拖延的话，文章会早接受，就可以评选优秀毕业论文，拿一等奖学金。（害，就是这么世俗） 没有因为疫情就放了假（年初二就回学校），但是也没有抓住这段时间有什么实验成果；新的课题兜兜转转，没有什么实质性进展；没有把控好自己的情绪；毕业忧愁。 这一年没有认真学习的长时间段，计划完成的事情没有做到，荒废了大把时光； 科研不顺，进展缓慢，文章还挺遥远。这一块算是我的心病了哈哈，耿耿于怀，但是呢，有时候环境给到的支持太少了，一个人真的很难。 依然单身。还没遇到那个让我想要主动的人。 变胖了。自省仍旧欠缺。 最大遗憾就是今年复试落选了吧。 基本上都被科研和上课包裹住了，一年时间很快就结束了，很少时间跳出来回顾自己做出来的东西以及思考为什么要这么做，找了很多自己想做的方向都没有沉下心来哪怕做一个初步的结果也好，基本上都是一个文献调研就结束了，然后在自己业余时间一些感兴趣的东西都没有做，导致某个周期的科研结束了，会完全一种完全的无力和空虚的疲惫感中。 在理财上至今没有迈出第一步，依然在败家乱花钱 555~ 跟一个女孩，约好了见面的，最终却没能相见。 和妈妈在一起的时候对她不够温柔有耐心 没能把文章写出来，还没有能够真真正正的 100%投入科研，没能对自己有个规划。 在家的时间没有安排好自己的学习计划，本来想提高一下大二的绩点，没想到还拉低了呜呜 没能让自己满意地用好时间 没有利用好疫情期间的时间充实自己，没有对自己的课题有一个很好的规划，只能被别人规划。 没能考完驾照 秋招竟然一个都没过，想找自己没有尽力的借口，但感觉自己做不了更好了。 夏天的一个很好的实习机会错过了。 生活有被疫情打乱一些，留了个假学。 被导师婉拒了读博的请求，只能继续套瓷了。 没拿到集团项目，少了好多科研经费，如果之后这个项目存在，我要继续争取。 没有照顾好自己的身体，工作拼命是一方面，我觉得最大的原因是把借口推脱到工作上，给自己找理由，有时间玩手机，没时间吃饭运动，实际就是懒，不自律。 没有安排出时间来学习，两种学习内容，一是和工作无关的任何学习，二是自己感兴趣但和工作技能相关的学习。 日记质量不足，总是去补前几天的日记，而且思考深度不够。 没能画出来我的“树屋”。 知道很多道理，依然没有很好地落实，最头疼的问题：时间管理 现在还是不能做到早睡早起啊，好纠结，感觉每天都在混日子浪费时间 最大的遗憾是疫情期间的工作，还没有发表出文章。 在工作上还欠缺很多，效率比较低。同时因为个人饮食习惯的改变少了很多和同学们一起交流的机会，希望能够找到更多的机会，与他们进行沟通。工作上的效率也还不够高，很多年初制定的工作计划到头来没有完成。 生信学习太差劲了，学啥学不会。对实验室的研究方向不感兴趣，想硕士毕业。 2 个课题没有 balance 好 flag 没有全部完成 上半年自己状态很差，很多事情比年初的计划都有巨大改变，比如毕业的问题，加快进度吧。 想对去年此时的自己说 不要选择你认为别人认为更好的那条路，你不会开心。 努力是个好词，应该时时贯彻才是。保持积极向上的心态，养成良好的习惯才是能够让自己终身受用的呀。压力太大了其实可以换个解压方式的，记得多总结&amp;要把锻炼践行到底呀。 论文写快点啊，要固定目标和方向，别总是看一些其他的论文 不用太焦虑，要有自信，其实你做的挺好的，不要老是攀比别人做的怎样，自己的人生路还是得自己走，有了目标，其实过程应该美好，别人做的好，不应该嫉妒，应该欣赏、应该学习、应该替他高兴。 去年上半年由于课题方向的问题，一度自己心情很低落，感谢一些人的陪伴能很快走出来。感谢师兄和老师的指导，能在研究生阶段取得一些结果。也感谢自己付出了努力，接下来希望自己可以改掉一些不好的习惯，加油。 加油，一直朝着目标前进吧！不要放弃！ 记得好好爱惜身体，早睡早起！ 浇水，接花，成果，每一个明天都会因为昨天而有所成就或付出代价！ 之后会有很大一波疫情！记得买口罩！ 2020 年应该是生命中比较特殊的一年，可能这一年会永久改变我们的生活习惯。年初二开始，家里一位逆行者就开始工作了，面对未知的新冠病毒，当时真有一种生离死别的感受。庆幸的是一步一步的走过来，大环境也逐渐趋于稳定，感谢国家强有力的抗疫措施。自己这一年中也或多或少的参与到抗疫工作中去，也算是做了一分贡献吧。这一年又过去了，真快！减肥又失败了，连续失败十年了，很是尴尬。刚跳槽入行的时候，给自己定了个 5 年目标，如今已经过去三年了，虽然有进步，但是感觉差距还是比较大的。来年要更加努力了。这一年不好不坏，有努力过，也有不少缺憾，总体来说，有收获。遗憾的事情明年去弥补吧！ 每一天都要全力以赴，认真，你就赢了！ 科研和工作不是生活的全部，希望你花多一些时间照顾好自己，做自己想要去做的事情。喜不喜欢做甚至都是次要的，顺着那突然而来的冲动往往也是极其有趣的。 相信未来，无论此刻你认为有多难，未来都是光明的 如果当初不选择这个地方，如果可以忘掉今年的记忆，那是多么美好的事情呀！ 少立点 flag，多干事 PS：觉得增加一个问题：对明年的自己留一句话会不会挺有意思的？ 开心点 谢谢你当初的坚持，所有的努力和坚持在正确的方向下都是有意义的。可能当时也错过了一些，但想做什么时候都不晚。 认清形势，放弃幻想。 每天都有个小目标，认真而谨慎地做好现在能做的事情，认真过好此时此刻。 加油 阿臻，不要怕呀，你没想到吧，那个曾经焦虑的你，长大了，可能还是会有很多的 struggle.但是现在你更强了呢，不管对于自己还是家庭，你都是值得骄傲的存在。去向外扩展吧，这是你的天赋，认识有趣的人，做不同的事，向内接纳吧，你自己多的是你不知道的事。 有时候需要记录才知道自己到底走了多远 熊之前在群里说的，仰望星空，脚踏实地吧。 真的不要把科研看作自己生活的全部，选择做不做科研都是一种生活方式，即使最后转行也不是一件丢人的事情，在所有领域都能找到你感兴趣的方向，在主业上专注的同时也不要放弃保持开放的心态，做自己擅长和感兴趣的事情才会长久才能带来快乐和持续的动力。 不要关注得失，问题都会自然而然解决的~ 对去年的自己，总觉得没有什么好说的，因为不管说什么，都是无法改变的。如果是反思的话，希望自己能学会放下，不管不顾的付出和骚扰并没有什么区别，你做得越多，对方反而越想逃开。学会和解，你要意识到你天资愚钝，也许付出两倍的努力也达不到别人的高度，不要抱怨，不要气馁，多思考，多总结，两倍的努力不行，那就付出十倍，无需责备自己为何如此愚笨，世上本就不公平，竭尽全力，投入地去做就行。 人生就是一个接着一个的历险记，但最后都会变成奇遇记，坚持住 今年的自己进步很大，也希望明年能够阅读更多的书，跟着 B 站学习更多刚兴趣的课程，生信终于算是入门了，未来可期！ 在家也要执行学习计划呀！ 保持自律，留有余闲 很多时候你觉得自己真要不行了，但回头看看，那些真的不算什么，并且都是弥足珍贵的经历。 别害怕 科二真的不难 每一次练到位就可以了 保持心态 你很棒 好像没什么好说的，心态和去年差不多，还是像个没头苍蝇一样不知道自己想要什么。很完美主义，给自己期待过高，反而手边的事情处理不好，目标定低一点，完成就好啦，不需要多么尽力，坦然看待。虽然事情有很多，但都会一件一件一件做完哒！ 不要着急，脚踏实地。 制定目标任务要实际，不可能除了吃饭睡觉的时间都在工作，而且不可能 100%效率工作，人的精气神是有限的。 我才工作没多久，不能追求自己太有能力，有缺陷才是对的，没有人一口吃成胖子。 多爱自己一点。 最好不要去做牙齿矫正，接受并喜欢你本来的样子。 呀，时间真的不多，别荒废时间，好好打牢基础，明年的你就不会这么挣扎了 去年的你大约有 2/3 的时间在家里度过了，实属难得。虽然不管在哪里，家或学校，你都爱熬夜(主要是自己太慢了，活完成不了)，希望未来一年尽量生活规律。这一年的十月，你因为傻到被网络诈骗，导致自己背负了债务，在家人及警方帮助下，已经妥善解决了。希望你无论何时，在有颗清醒的头脑前提下保有善良。还有继续爱家人，爱那些关心你的人。学业上还请抓抓紧，该准备的东西要提前准备，这一年你没有选择转博，要及时确立目标去寻找自己想要的未来。 这是坎坷的一年，是接触新事物的一年。但是去经历，去痛苦，去体验。因为人生就是要不断的 To be。去做，去尝试。 你马上将会有一个 4 个月的假期，在这个假期里我知道你没有浑浑噩噩，但没想到最终你几乎一无所获。 不要虚度光阴，虽然虚度光阴真的很爽 少熬夜 在 2020 年你对很多事情依然抱有好奇心，这是很好的。你愿意在不同的地方进行尝试，但是也应该考虑清楚自己想要什么。此外，你要记住，坚持做一件事情最简单的方法就是让这件事情可以尽可能简单的进行。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-12-30-our2020/"},{"title":"熊言熊语会员通讯 4321X 第2期 ","content":" 你现在看到的是熊言熊语会员通讯 4321X 的第 2 期试读版本，今后我们会不定期的将部分会员通讯内容发布到公开平台，如果想稳定的阅读每期内容欢迎通过邮件订阅这份免费的会员通讯服务。 Hi, 见信好 我是思考问题的熊，你现在正在阅读的是熊言熊语会员通讯「4321X」 截至本期通讯「4321X」订阅人数为：323 有几位订阅读者和我反馈如果一次全部认真读完一期通讯压力很大，需要很长时间。我们会用之后几期通讯来测试将一期通讯拆分为两次发送，例如本期通讯的文献部分将在几天后发布。 刊首语 本次通讯的主题是记忆与遗忘。 每到年底，各大媒体的各种年终总结都会接踵而至，今年我们的「熊言熊语」也未能免俗，在最新一期熊言熊语播客中，我和嘉宾担担面一起回顾了各自从听播客到录制播客的心路历程，各种欢喜与悲伤历历在目。当然，这一期是播客回顾系列的上集，稍晚时间我们会放送下集，各自推荐喜欢的播客。 如果你对这一期聊播客的内容感兴趣，可以到官网或者你喜欢的播客平台搜索「熊言熊语」进行收听。 同时我也为你整理了一些推荐阅读的 2020 回顾系列文章，看看过去一年都发生了什么。 纽约时报汇总了 2020 年第一次发生的 18 件事（18 Things That Happened for the First Time in 2020），同时也整理了 2020 拍摄的大量摄影作品，这篇「照片中的 2020」（A Year Like No Other）推荐你阅读，感受优秀摄影作品带给人的冲击。 在线杂志 Voicer 在微信公众号用可以交互的方式整理了今年国内曾经火热过的 20 个关键词，可以看看哪些是你不那么熟悉或者已经忘记的。Viocer 2020 年，20 个词 专注于数据可视化的网站 visual capitalist 从数据可视化的角度用 20 张图回顾了 2020 年，好的图表像照片一样可以给人带来冲击和享受，这篇文章非常推荐阅读。 求职平台领英发布了年度行家来信，他们找来了平台上各行各业的行家，例如职场、互联网、创投等，分享自身信念及行业思考，精炼出 2020 行家年度信。你可以点此处阅读。 Nature 和 Science 两大媒体也于近期推出了科学相关的 2020 回顾，其中 Nature 整理了除 COVID 以外的其它科学成就（2020 beyond COVID: the other science events that shaped the year），也列举了 2020 年参与重大科学事件的人物（Nature’s 10: ten people who helped shape science in 2020）；Science 按照传统评出了年度 10 大科学进展特刊，这里有一份简单的中文介绍。 如果你喜欢科技产品，The Verge、Engadget 和 PCMag 等科技媒体都纷纷推出了自己的年度产品推荐，可以通过下面的链接阅读原文。 2020: BAD YEAR, GOOD GADGETS What we bought: Our favorite gadgets of 2020 The Best Tech Products of 2020 思考 人们回忆的价值是什么，如果没有记忆又怎么样呢？ 看完这么多和回顾/回忆相关的内容，我突然产生了关于「回忆」的困惑，**人们回忆的价值是什么，如果没有记忆又怎么样呢？**这两天刚好看了几篇和记忆相关的文章，也一并分享给你。 神经现实公众号：记忆特刊 记忆从何而来，为了记忆的忘却，没有失忆，但记不起过去的自己有多可怕？ 此外，我还找到了两本和「记忆」主题相关且评价不错的书正在阅读，如果你感兴趣欢迎可以和我一起。 追寻记忆的痕迹 记忆的风景 一件值得去做、长期有价值的事，不被人理解是必然的。如果被所有人理解，你肯定做不大，因为所有人都想做一样的事情，那他们将全是你的竞争对手。 这句话来自于 2019 年 12 月晚点团队对陆奇的一次专访，彼时他回国三年，已经离开了百度又从 YC 离职创办了奇绩创坛。陆奇 1998 年前往美国卡内基梅隆大学（CMU）进修博士学位，37 岁第一次进入企业工作，用十年普通工程师做到了雅虎高级执行副总裁，后加入微软并任职全球执行副总裁，成为美国科技行业担任最高管理职位的华人。如今再读这篇文章，他的很多回答 1 年后会给人更多启发。 不过，我还有个困惑，我们如何才能找到一件值得去做且长期有价值的事呢？除了不被人理解还有哪些可以判断的标准。 推荐阅读 对话陆奇：做一件长期有价值的事，不被人理解是必然的 任何智能体系要真正学会知识，这三者都分不开——感知（观察系统）、思考（智力系统）、行动（活动系统）。人、一个企业、一个国家都是这样。 这句话依旧来自于上文提到的陆奇采访。记者问到「你被认为是一个非常勤奋的人，对你而言，最有效的学习方法是什么」这个问题时，他给出上面这个答案。感知，思考和行动真的是一个非常精炼且准确的学习方法总结。 不过据我的观察，如果有人能很好的做到这三点中的两个，就已经非常厉害了。这里的厉害不是特指某一项技能，而是可以快速的学习很多技能的能力。观察系统需要我们保持足够的敏感和好奇心，智力系统能够让我们想清楚可能的行动方向，而活动系统则是一个事情能否做成的最关键一步。 某种程度上，你现在读到的「熊言熊语会员通讯」就是一次关于感知、思考和行动的练习，即我看到了什么，我想到了什么，我分享了什么。 推荐 GitHub Student Developer Pack 如果你是学生且有可以通过高校认证的教育邮箱同时还在使用 GitHub，那 GitHub Student Developer Pack 绝对是一个微软送给你的超值「巨硬」大礼包。 Student Developer Pack 包含了大量高质量的付费课程网站，多数会提供半年到一年的免费学习时间。例如，可以通过文本交互式学习到 educative，可免费获得 6 个月学习时长，涵盖 Web 开发、Python、Java 和机器学习等热门主题；以 30 天为学习周期，可以学习 HTML、CSS、JavaScript 和 Python 的 One Month，免费订阅 30 天。 Pack 中还有几个非常高质量（同时也非常贵）的应用，海报制作工具 Canva，macOS 和 iOS 上非常强悍的终端 Termius，适用于 iPhone 和 iPad 功能强大的 Git 客户端 Working Copy，适用于 Mac 和 Windows 非常强大的 Git 客户端 Tower。 学生可以 点此进行申请 Canva Canva 是全球领先的在线设计平台，创建于 2013 年，用户遍及全球 190 个国家，月活跃用户有 3000 万，平均每秒就有 80 个设计在 Canva 上产生。 我最早使用的是 Canva 国际版，也是上面 GitHub Student Developer Pack 提供的版本，2018 年他们针对中国市场推出了中国版，从今年开始中国版又推出了付费服务，一年的费用真心不低。 不过对比了其他几家同类型网站之后，只有它的整体设计风格比较符合我个人的审美。其实大家看到的绝大部分熊言熊语播客相关的 logo 和海报以及大量公众号文章题图，都是我使用这个网站做出来的。如果你有类似需求，不妨尝试一下。 讨论 2020 年就要过去了，不妨一起用三个简单的问题回顾一下。 借这期通讯，我们发起第一次「熊言熊语全员协作」活动。你可以分享自己的想法给其他熊言熊语的朋友，也可以看其他朋友写了什么。 这里准备了一个表单，无需注册即可直接填写，填写之后即可看到大家的总结。 三个问题如下： 今年我最大的收获是 今年我最大的遗憾是 我想对去年此时的自己说什么 我们鼓励共同创作，如果你不愿意参与，也可以直接通过总结汇总页面进行查看，希望看过大家的分享后你会愿意再回来写点东西。 填写地址： 熊言熊语全员协作：用 3 个问题回顾 2020 欢迎你回复邮件到 hi@kaopubear.top，和我分享你的其它想法。 one more thing 最近几周持续被赛博朋克刷屏，那什么是赛博朋克呢，这里给你推荐几篇文章。 赛博朋克 | 中文科幻数据库 你们口中的“赛博朋克”，究竟是个什么意思？ 赛博朋克简史 此外，我很喜欢的一档播客也聊了一期相关节目，不妨听听：您那是赛博春晚，不是赛博朋克。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-12-20-4321x-2/"},{"title":"熊言熊语会员通讯 4321X 第1期","content":" 你现在看到的是熊言熊语会员通讯 4321X 的第 1 期试读版本，今后我们会不定期的将部分会员通讯内容发布到公开平台，如果想稳定的阅读每期内容欢迎通过邮件订阅这份免费的会员通讯服务。 Hi, 见信好： 我是思考问题的熊，你现在正在阅读的是熊言熊语会员通讯「4321X」第 1 期。 截至本期通讯，「4321X」订阅人数为：304。 刊首语 2020 年就要过去了，在未来两三周我们的会员通讯和熊言熊语播客会推出若干期回顾内容，包括播客和书籍 rewind &amp; recommendation 等等，敬请期待。 本期刊首语我们延续上期讨论的问题再聊一聊。上一期我发起的讨论是「读者和作者应该保持一种怎样的关系」。因为上周收到了一封听友来信，这次想用播客主播和听友的关系略加展开。 听友来信的一段内容如下： 听完这期节目，我想把这个节目介绍给我朋友圈所有的人，但是好像我们实验室只有我一个人在努力开创生信的领域，无人分享这种快乐。听了你们的思考，我甚至觉得我可以把你们当做我的朋友，一个向我传输观点，我只需要静静聆听即可的朋友了。 播客是少有的可以在闭屏环境下接受信息的渠道，文章和视频都需要我们开着屏幕阅读和观看。闭屏场景又通常发生在通勤、做家务和睡前等时段，是一个相对私密的时间，因此听友和主播也更容易建立起信任感，像来信里提到的「可以当做朋友」。 这个优势带来一个问题是不少听友会有一种想要「私藏」播客的感觉，像邮件里提到只是静静聆听，其实每一个内容创作者都需要也希望内容可以被更多人看到。还有一种情况是不少人觉得这节目收听的人不少，肯定也不缺我一个留言不缺我一个转发，但真相是你的一次留言和推荐很可能就是作者坚持更新的动力和鼓励。 推荐带来的是整体收听量和阅读量的增加，也就是内容整体影响的感知；留言带来的是明确的信息传达结果的反馈。这两点对于内容创作者实在是太重要了，所以如果你有喜欢的博客播客或者作者，尽可能地去和他们沟通，也把你喜欢的内容推荐给朋友。 他们缺的，就是你的一次留言和一次推荐。 文献 Seq-ing answers: Current data integration approaches to uncover mechanisms of transcriptional regulation We describe popular multi-omics data integration approaches used to identify target genes and co-factors, and we discuss how machine learning techniques may predict transcriptional regulators and gene expression. DOI：https://doi.org/10/gg9zxf 转录调控是一个经久不衰的研究话题，如果归结到测序技术使用最多的就是 RNA-seq 和 ChIP-seq，他们也是学习生物信息分析的基本路径。这两个技术结合可以涉及到大量相关研究问题，例如鉴定相互作用的调控因子和表观调控因子，鉴定靶基因、预测基因表达还可以预测转录因子结合。这篇综述就从这些层面进行了介绍，比较适合想大致了解一个相关框架的情况下阅读。 Tutorial: guidelines for the computational analysis of single-cell RNA sequencing data Here we present an overview of the computational workflow involved in processing scRNA-seq data. We discuss some of the most common tasks and the tools available for addressing central biological questions. In this article and our companion website (https://scrnaseq-course.cog.sanger.ac.uk/website/index.html), we provide guidelines regarding best practices for performing computational analyses. DOI：https://doi.org/10/ghn48p 谈到转录组分析学习，颇有几篇值得参考的经典文献。Nature Protocols 最近发布的这篇单细胞测序分析指南颇有几分类似的潜质，感觉有可能成为单细胞分析学习必读的一篇经典文献，和文章配套的还有一个更加详细的在线教程。如果你正在学习单细胞数据分析，这篇文献推荐给你。 Ultrafast and scalable variant annotation and prioritization with big functional genomics data Here, we develop VarNote to rapidly annotate genome-scale variants in large and complex functional annotation resources. Equipped with a novel index system and a parallel random-sweep searching algorithm, VarNote shows substantial performance improvements (two to three orders of magnitude) over existing algorithms at different scales. It supports both region-based and allele-specific annotations, and introduces advanced functions for the flexible extraction of annotations. DOI：https://doi.org/10/ghmqdt 如果问生物信息的日常工作是什么，我目前能想到两个层面：一个是进行各种文件格式的转换，一个就是求各种区间的交并集。变异注释归根结底还是一个求区间交并集的问题，这个事情看起来简单，但处理大量数据集的时候就会变得异常缓慢，常用的 bedtools 很难解决问题，特别是集成到网站服务的时候让别人等个七八分钟很不合时。这篇文章作者开发了一个针对大数据集进行变异数据的工具，并且和其它工具进行了准确度和速度的比较。如果你有被类似的速度问题所困惑，推荐使用。 GREEN-DB: a framework for the annotation and prioritization of non-coding regulatory variants in whole-genome sequencing We integrated 24 data sources to develop a standardized collection of 2.4 million regulatory elements in the human genome, transcription factor binding sites, DNase peaks, ultra-conserved non-coding elements, and super-enhancers. Information on controlled gene(s), tissue(s) and associated phenotype(s) are provided for regulatory elements when possible. We also calculated a variation constraint metric for regulatory regions and showed that genes controlled by constrained regions are more likely to be disease-associated genes and essential genes from mouse knock-out screenings. DOI：https://doi.org/10.1101/2020.09.17.301960 各种调控和表观相关的数据如何应用到突变注释已经有了一些相关的文献报道，这篇最近发布在预印本上的文章同样是关注的这个问题。作者们把人类表观调控相关的数据能整合的全部整合了，在构建一个数据库的基础上也开发了一个注释工具。如果你想看看自己的突变数据和这些表观调控元件之间的关系，这篇文章推荐给你。 思考 我们应该如何保护或者管理自己的数字资产，以及我们应该如何理解自己的数字权利呢？ 上周我收到了一封 Google 的邮件，他们更新了数据存储政策。邮件开头的一句话是「我们近期公布了关于存储空间的新政策，以确保符合行业惯例」，言外之意就是「同行都这么做」。 存储新政策主要内容有两点： 如果您连续 2 年（24 个月）未使用 Gmail、Drive 或 Google 相册，我们可能会删除上述处于闲置状态的产品中的内容。 如果您的用量连续 2 年超出存储空间上限，我们可能会删除您在 Gmail、Drive 和 Google 相册中的内容。 这封邮件引发了我的一些思考，因为我并不仅使用 Apple 的设备，所以近 5 年的照片全都存储在 Google Photos，他们的存储政策经历过几次变化，从之前的高清图（略有压缩）无限存储到所有图片都不会无限存储，再到如今的不活跃账户或者超限额内容将会直接删除。你有没有想过什么情况下会连续 2 年不使用某一个产品呢？其实每个人都会遇到的一个情况，就是当我们离开这个世界以后。 或许很快，数字遗产会和实体一样成为每个人都必须要面对的议题。谈遗产有点远，你有没有考虑过自己的数字资产问题呢？很多看不见摸不着的东西对我们越来越重要，比如你的各种社交平台账号，写的文章，录制的播客和上传的视频，以及在你电脑里各种各样的文件。没有这样的意识就很可能会经历硬盘损坏和数据丢失的悲剧，吊诡的是通常只有经历过刻骨铭心的数字资产丢失，才能理解备份的重要。 安全意识的增强使越来越多的人开始接触和使用云存储，不过云存储依旧是等于你租了一块在千里之外的硬盘用来保存自己的数字资产。云存储并不是绝对安全的，这样的例子发生过不少，有的人相信云存储，有的人不相信。此外，有些东西一旦被存储到云上可能就不属于你或者不仅仅属于你了，它可能随时被删除或者永远也不会被删除。 如果你认为购买过的软件和数据是属于你的，那也有些天真，如今我们通常只拥有很多东西的读取资格而没有操作资格。 靠谱的云服务是看来相对安全的选择，因为你已经使用了很多年的云笔记和云存储服务，但时间尺度如果拉长到十年二十年，这些公司可能会倒闭可能变得越来越难用，我们又该怎么办呢。 对了，关于备份数据有一个3-2-1 原则，你可以参考。 3：保留至少三个数据副本 2：并将两个备份副本存储在不同的存储介质上 1：其中一个副本应该位于异地。 扩展阅读 data backup options 价格很大程度上不取决于工作成本，而是取决于购买的东西对你多有用。 这个思考的来由还是和数据存储有关，一个朋友用了很久的硬盘突然坏了然后问我的建议，只能让他找一家数据修复的公司去碰碰运气。几天后他和我说：公司可以恢复 99%的数据，但是要价 2600，以你的经验，这个可以讲价到低一点，因为总感觉他们没有这么高的工作成本。 我给出的回复是：2600 要比较的不是我们推断的公司工作成本，而是自己的数据值不值 2600。即便他们就是用 1 秒钟点了下某个一键恢复软件，如果这些数据是你急需且重要的，那 2600 也得花啊。 当然，上面的回答并不符合标准的经济学对于成本的解释，还需要考虑显性成本隐形成本沉默成本和机会成本以及所谓的稀缺性。成本是复杂的，不仅仅是购买生产要素的货币支出或者提供服务的人付出了多少工作，而是在于被多少人需要或对够买的人多么重要。我们可以坦然的接受便利店的东西比大型超市稍微贵一些，iPhone 的定价远高于所有物料价格的总和，很多非实体的服务同样如此。 产品价格与成本无关，价供求关系决定了商品的价格，甚至这个价格反过来决定了原材料的成本，比如 2020 年的口罩价格变化。 只关注两类人的情绪和感受，一类是给你爱的人，一类是给你钱的人。 我是一个情绪比较容易受外界影响的人，也总是努力让更多人对我的所作所为感到满意。但最近播客听友群里一个听友的催更行为让我感到冒犯和不舒服，也开始反思更应该关注哪些人的情绪和感受。 我不反对催更，很多时候就是善意的调侃同时告诉你有人在等着听节目，但单纯的催更绝对不会成为更新的动力，参与和讨论才是。他在群里参与互动的唯一形式就是催更，同一句话反复催更。节目更新前的催促和节目更新后的沉默形成了鲜明的对比，或许催更才是他最大的乐趣吧。 我尝试用戏谑的方式和他「正面交锋」，比如他的 ID 是催更小助手，我就改成反催更，更新了群公告，准备了最新回复话术，类似反问实验做了么文章发了么论文写了么工作找了么结婚了么等等。甚至，我计划连续七天每天更新一分钟的音频，专门反问那些无聊的问题发给他听。 在脑海中反复交战几个回合平静以后，我把自己逗笑了。何必呢，倘若催更能让他开心一些，也挺好。我们需要做的就是尽量只关注两类人的情绪和感受，一类是给你爱的人，一类是给你钱的人。前者包括父母家人和最紧密的朋友，因为他们难受你也难受；后者包括你的老板导师客户以及其他购买了你时间和生产力的人，因为他们难受你就饿肚子。如果还有剩余精力就多多关注自己。 推荐 翻译软件 Bob 上一期工具推荐提到了 Mac 上的一个小工具 PopClip，这次推荐一个可以配合 PopClip 使用的翻译工具 Bob。 Bob 是一款 Mac 端翻译软件，支持划词翻译、截图翻译以及手动输入翻译。可以进行翻译多开和自定义若干翻译插件，可以通过 AppleScript 调用和 PopClip 调用。 Bob 本身是不收费的，但使用某些服务可能需要给服务商支付一定的费用。经过测试，我目前保留的是腾讯翻译君和彩云小译的翻译 API，前者每月有 500 万字符的免费额度后者则有 100 万字符的免费额度，正常使用应该足够。OCR 识别用的是腾讯云通用 OCR，每个月有 1000 次免费额度。 服务需要配置但难度并不大，尤其是当你还在使用腾讯云的其他产品时，翻译和 OCR 服务只需开启然后在 Bob 配置秘钥即可。 使用效果如下图，详细的配置教程可以访问官网。 保存万物的文献管理工具 Zotero Zotero 一直我最推荐的文献管理工具，关于 Zotero 的基本用法可以参考我曾经发在少数派的Zotero 上手指南，目前这篇文章的阅读量已经超过了 11 万。其实跳脱出文献管理，Zotero 配合浏览器插件基本可以用来保存万物，然后可以对万物添加标签和笔记进行管理。例如如果你单纯保存一个网页，Zotero 可以对网页内容生成快照在本地保存一个 HTML 文件。 关于 Zotero 的优点，曾经整理过如下几个： 软件本身完全免费并且开源，不存在盗版问题 注册后本身只包括 300M 空间同步，但支持 WebDAV 同步，例如 Dropbox 和坚果云等 官方的反馈论坛比较活跃，有问题可以快速得到反馈 从网站和期刊文章等提取保存出版物数据检索 拖入 PDF 的出版物数据准确率高 可以和 Word，LibreOffice 集成，方便文献进一步的使用管理 强大的第三方插件系统 每个条目下可以添加任意数量和格式的附件 我曾经修改过一个支持 markdown 格式笔记的插件，最近又用上了一个很棒的 Zotero markdown 相关插件zotero-mdnotes，它可以把文献条目的元信息和已有笔记都转换为 markdown 格式文件，方便进一步整理，如果你有类似的需求，推荐使用。 讨论 本期通讯，我想和你讨论的话题是：有什么事情你曾经会刻意做但现在不会了，又是为什么呢？ 我可以先分享一个。 之前通勤坐地铁我会刻意避开早高峰，比如要求自己 7 点半之前必须出门，起晚了就 9 点再出门，但是现在不会了。我发现永远不知道哪个时间是真的高峰，有时在最拥挤的时间段会来一辆人并没有那么多的车，而且，看起来已经满了的地铁到了下一站永远都可以再挤进来几个人。 欢迎回复邮件 hi@kaopubear.top one more thing 2020 年接近尾声，真是复杂而疯狂的一年。端传媒近日发布了一篇题为「2020 年，网络流行语里的中国」回顾文章。作者盘点了 2020 年 14 个互联网流行语，借此回看这颠簸的一年，并试图理解流行语背后的社会脉络。因为是一篇有付费墙的文章所以我只把关键词贴在这里，希望可以帮你回忆一些很快就又会被遗忘的事情。 新冠肺炎 抄作业 不能，不明白 江山娇与红旗漫 方方日记 后浪 入关学 小镇做题家 网抑云 社会性死亡 月经贫困 最美逆行者 内卷 打工人 凡尔赛文学 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-12-13-4321x-1/"},{"title":"熊言熊语会员通讯 4321X 第0期 阅读与分享","content":" 你现在看到的是熊言熊语会员通讯 4321X 的第 0 期试读版本，今后我们会不定期的将部分会员通讯内容发布到公开平台，如果想稳定的阅读每期内容欢迎通过邮件订阅这份免费的会员通讯服务。 Hi, 见信好： 我是思考问题的熊，你现在正在阅读的是熊言熊语会员通讯「4321X」第 0 期。 截至本期通讯，「4321X」订阅人数为：143。 写在前面 从这一封信开始，你我之间多了一个连接的方式，就是你此刻正在阅读的会员通讯：4321X。本周是这份通讯的第 0 期，感谢你也祝贺你成为首批读者之一。 在本周的会员通讯中，我想和你聊一个关于阅读和分享的话题，也顺便聊聊我们这份会员通讯。 我不是一个重度阅读者，读过的书和文章（严肃阅读）远不及我认识的一些优秀的朋友，我也不是一个重度分享者，我认识的不少朋友可以做到每天都有高质量的输出。不过我是一个相对比较重度的阅读者兼分享者，这两个身份的叠加会让我时常反思自己应该阅读和分享怎样的内容。 一个人看到的学到的越多，对一个领域的积累就越多，在阅读的过程中对相关知识密度的要求就越高。 比如在数字工具这个细分领域，三四年前我接触到的内容很少也没有自己的认知体系，随便看到一个相关主题的文章就感觉满篇都是不了解的内容。如今再看到这类主题的文章，十有八九我都能快速的将其归类到自己的认知体系中，然后迅速判断这篇文章的优劣以及能给我带来多少信息增量。 我的阅读目前遵循两个策略，就主题而言尽量在我相对熟悉的大方向上做小范围的延伸；就内容而言尽量多阅读经典内容都同时了解更厉害的人在阅读什么。 在熟悉的大方向做小范围的延伸，可以给我带来持续的新鲜感也不至于失去安全感。阅读更多经典的书和文章是因为我发现很多现在听起来特别 tricky 的概念和问题其实是几年甚至是十几年前已经被系统讨论过的内容，不过是重新套壳包装。了解大佬阅读什么也并不是一个新鲜事，不然比尔盖茨怎么会成为每年最大的带书 KOL 呢，人们都想知道他的书单。我这里建议的是去了解一下那些真实对你产生过影响的人都在读写什么。 分享的内容如何才能为读者带来一点价值？ 其实很简单，在读者感兴趣的领域讲一个对方或许还不知道的东西，如果是熟悉的东西就讲一个对方可能还不了解的用法。除此之外最稳妥的是讲一点你自己的思考，因为这是仅属于你的东西，我们总是好奇别人的脑子里究竟在想些什么。如果以上三点都做不到，或许真的就没有什么写出来的必要了。 关于这份你读到的熊言熊语会员通讯 4321X，首先它的诞生离不开已经上线半年多的音频播客节目熊言熊语，这份通讯可以看作是这档播客节目的补充（嗯，主要是给那些一直催更的朋友），此外，如果你还没有听过我们的播客反而是先看到了这份 Newsletter，有空的话去听听。 之所以叫 4321X，还是会对应到上文关于分享内容的思考。在每期通讯中我会为你推荐 4 篇生物信息或者医学相关文献，分享 3 个我过去一周的思考，介绍 2 个我喜欢的工具，同时提出 1 个问题供我们交流，而 X 则代表不固定的 one more thing。 思考 信息不对称是真实存在的，所以不要害怕你说出来的东西别人知道，也不要担心你提供的信息是陈旧的。 最近发生在熊言熊语听友群的一个小事让我有了这个思考，前几天我在群里发了一张已经没有时效性的截图，截图里的事件发生在今年 6 月。但是五六分钟之后我就在朋友圈里看到了五个配有这张截图的内容。别人愿意把截图发出来，很大程度是因为这个内容他感兴趣同时认为自己的朋友也会感兴趣，即便事情的热度已经过去只要他是第一次看到对于他来说这个内容就是新的。 所以无需事先预判你传递的信息是不是真的过时了，不妨先抛出来让别人去判断。 学会坦然接受 1 个人干活 19 个人看 最近几年陆陆续续组织过一些小的协作项目，大多数实际效果都不是我最开始设想的样子。最直观的反差就是很多时候一开始参与进来的人慢慢没了消息，很多事情只要组织者不牵头很快就会陷入停滞。我一度对于这个问题十分困惑，但是最近读到一篇文章让我释怀了不少。 万维钢在他的付费阅读内容的一篇文章中提到了 GitHub 的一个现状。有人对 GitHub 上 275 个项目统计的结果表明，所有参与者之中，有一半人只提交过一次代码，他们加起来的总贡献还不到 2%。另有一个研究发现 GitHub 上绝大多数（超过 85%）开源项目中，不到 5% 的开发者贡献了超过 95% 的代码。 Bootstrap 这个前端框架 2017 年这一年各个程序员向这个编程项目提交代码的次数如下图所示： 排名第一的人贡献了将近 700 次，第二名 200 次，第三名大概 180 次，这三个人的贡献占全部工作的 73%，其余几十人，有的只提交了一两次代码。从 GitHub 的统计结果来看。如果把一份工作分成 20 份，那就是约等于 1 个人干活 19 个人看，剩下 19 个人干 1 个人的活。接下来的角度我们可以探讨如何避免这样的局面，但不如我们就坦然接受这个现状。 科技博主 Alex 最近写了一篇博客，说编程工作现在已经成了一个节目，程序现在只是副产品，程序就相当于内容创作，程序本身并不稀缺。稀缺的是写程序的人，是那些真正参与创造的优秀团队。开源编程其实是一种娱乐表演，只不过这里的粉丝更喜欢互动。 其实那 19 个人并不是来干活就是来围观的，围观说明了项目的价值，在某种程度上这可能就足够了。这也是我把这份叫做「会员通讯」的内容做成可以免费订阅的重要原因之一，欢迎围观。 推荐阅读：Making is Show Business now 提问和提需求的时候永远不要先说很简单和不麻烦 这个思考来源身边最近发生的几次合作和提问。很多社交本质上就是相互「麻烦」的过程，今天我请你帮我做个什么，明天你找我做个什么。这里就会出现提问和回答两个角色，作为提问的人我不知道你有没有使用过下面类似的开头句式。 「你好，我有一个小问题想请教你一下」 「Hello，在忙么，我现在有个事情需要你帮忙，很简单的」 看上去两个开场都很客气，又是请教又是询问。但是面对类似的表达能拒绝的我都会直接拒绝，客观原因无法拒绝的心里也会嘀咕上一阵。 原因很简单，作为一个提问和提需求的人，不应该主观上给一件事情定性。要么是作为一个纯外行你不知道完成这件事情的复杂程度在哪里，只是看起来很简单；要么是作为一个内行觉得这件事简单到不愿意自己上手，但你怎么能判断对方是不是和你一样的水平。 如果你觉得一件事情很简单，直接自己做了就好。如果是向别人提问或者提需求，只需要客观描述问题，告知对方在这件事上你前期花费的精力以及做过哪些准备，然后说明需要对方帮助完成的原因。至于难度，应该留给对方去评估，如果他给出的难度系数和你预估不一致，要么是你把事情想错了，要么是你找错了人。总之问题不在对方。 如果一上来就告诉我这件事情「很简单」，我是该做还是不该做呢？真要是简单感觉我做了也没什么太大价值；要是真不简单，还得需要花费我大量的精力时间。即便真的是举手之劳，别人又凭什么好端端要为你举手呢？ 工具 flomo flomo 是一款还在内测中的想法记录工具，主要开发者是目前在丁香医生任职的产品经理少楠。我们第一次有正式的交集是在少数派（SSPAI）的一次圆桌讨论上，当期主题是关于网状笔记工具的使用心得和看法，大家提到的无非是 RoamR、 Obsidian 和 Notion 这些，不过他当时就提到自己正在使用一款还没有上线的自己开发的记录工具。开始内测后不久我就进行了试用，到今天已经过去了三个多月，并在开放 Pro 会员时第一时间充值表示支持。 flomo 的名字来自于 flow + memo 的组会，从 memo 可以看出它并不是一个主打笔记方向的工具，而更多的像是一个备忘录。 你可以通过网页或者微信（移动端正在开发中）非常方便的记录自己任何的思考疑问和小灵感，虽然目前还是开发的早期阶段不过已经上线的几个功能我都非常喜欢。 支持多层级的标签管理，可以非常方便的管理每一个记录卡片 支持通过微信快速输入，可以直接保存并同步 每日回顾功能，支持设置多种回顾规则，会通过微信每天定时随你发送你以前的灵感记录供你回顾 随机漫步，当你有了一定量的输入，系统会尝试帮你建立不同记录之间的关联，通过算法提取关键词推荐标签 这个工具我目前的用法也确实和笔记工具进行了区分，只记录我的想法和灵感，如果有的话还会配套上产生思考的来源链接。本期通讯的三个思考内容就都是我从 flomo 里挑出来的。 如果你也刚好需要一个这样记录想法的工具，不妨试试。通过这个链接进行注册可以获得 15 天的高级会员，体验上述提到的所有功能。 注册体验可以点击这里。 PopClip 本期通讯推荐的第二个工具是在 Mac 上使用的 PopClip。PopClip 的核心功能类似于 iOS 上选中文本然后弹出快捷菜单进行下一步操作。自 2011 年发布以来持续迭代更新至今已经有了超过 180 个可以使用的插件（快捷菜单功能）。 这款小工具有很多日常高频用途，从类别上看包括文字编辑、文字转换、文字统计和 markdown 以及各种搜索和翻译等等。例如我常用的选中文字后直接跳转到指定搜索引擎进行查询，或者跳转到 PubMed 查询文献，还可以直接把选中的网页内容富文本复制为 markdown 格式。 更厉害的地方在于 PopClip 还有非常多针对其它知名软件开发的集成插件，例如我现在在用的写作工具 Drafts，更多的支持列表可以在官网查看。 虽说有不少功能都可以通过其它软件或者实现方式进行替换，但这种省心的操作真的是用了就回不去，如果足够硬核还可以写自己专属的插件。Popclip 支持下载试用，也可以在 App Store 进行购买，售价为 12.99$。 讨论 本期通讯我想和你讨论的内容还是和阅读与分享有些关系，即读者和作者（或者说创作者和接收者）应该维持一个怎样的关系？ 你可能本身是一个作者也可能只是一个读者，或者两者皆有。你感觉读者应该和作者建立更加深入的关系还是应该仅仅维持一个你写我读或我写你读的关系呢。 有一个故事我们从小就听过，钱钟书先生曾经婉言拒绝想拜访他的读者，拒绝的理由是「假如你吃了个鸡蛋，觉得不错何必要认识那下蛋的母鸡呢？」。但是如今读者和作者的关系和以前已经大不一样，我也并不怎么认同这个故事通常的解读版本。 我目前关于这个问题的想法是如果你想和我交流想告诉我一些我不知道的事情，那么我非常愿意进一步的沟通；如果你只是猎奇或者想再看看是不是还能多得到些什么，那这样的关系大可不必。 期待你直接回复邮件我和分享你的经历和想法，静候回信。邮箱 hi@kaopubear.top one more thing 和猫学习，找到家里最暖和的地方。 猫真是一个神奇的存在，它总能找到最暖和的地方。家里的柜顶之前对它没有任何吸引力，但是现在只要空调一开就想尽一切办法去柜顶放空自己。一个朋友和我说，他家以前还在用有显像管电视的时候，冬天猫就会常驻在电视机上。 空调一直开着经济实力不允许而且也很干燥，于是不开空调的时候我就像猫学习看看哪里是最暖和的地方。嗯，就是它的肚子下面，暖手暖脚都非常方便。猫吸热，我吸猫，热量就循环起来了。 注：因为是第 0 期的试读版本，考虑到篇幅过长删减掉了文献推荐部分，下一期正刊我们再见。欢迎你把熊言熊语会员通讯 4321X 转发给你在意的朋友，我们下期再见。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-12-06-4321x-0/"},{"title":"有备而来的 4321X","content":"在最新一期的熊言熊语播客中，我提到了一个思考：组织一个社群的目的是为了找到愿意互相分享和交流的同好，而不是单纯「输出」或者「售卖」组织者的信息和资源。 基于这样的想法，从 2021 年开始我将会调整一下自己的分享和沟通思路，简单说就是让更多人可以更容易看到我自己的分享和思考，同时也让真正想要交流的小伙伴更容易互相认识和沟通。 此外，因为可以预见的明年就要改变到另外一种工作的生活状态，我也需要在工作、生活和分享之间找到一个新的平衡。而且还有几个老坑需要陆续完成。 这期节目上线之后收到了一些听友的反馈，我也又有了一点后续规划，和各位分享。 分享途径和组织活动 梳理了一下最近几年自己的分享途径。 博客，完全是基于个人的文字内容分享 熊言熊语播客，和其他主播与嘉宾进行分享 熊言熊语配套的公众号、微博和更少人知道的 TG 群和 TG 频道 知识星球，个人运行了三年的付费小圈子 目前还在组织且人数较多的小组。 学习素材分享小组，基于学习素材分享的线上小组已经运行两年，目前主要依托于 Trello 和语雀，内容呈现方式为素材看板和语雀知识库。 生产力工具群，早期在生信菜鸟团发起的生产力工具讨论群，最初的目的是和大家一起学习分享日常碰到的好工具。运行了一段时间之后因为我的时间问题，发现仅仅依靠我自己输出很难坚持下去。当时内容呈现方式主要是腾讯文档，后来我把内容整理迁移到了Notion。 熊言熊语播客听友群，收听熊言熊语播客且想要和大家交流的不少听友目前加入了播客的听友群。不过还并没有实际的群内活动，更多的是自发交流。 后续计划 让更多人可以更容易看到我自己的分享和思考，同时也让真正想交流的小伙伴更容易互相认识和沟通。从这个目的出发，后续会进行的一些变动如下。 关闭知识星球新成员加入关闭续费通道 建立知识星球的初衷是为了回答大家的提，不过从第二年开始问题就越来越少，曾经尝试过一些方法增加星球的活跃度，比如发一些小福利群红包，抽奖送书和发布「作业」等等，但收效甚微。 很感谢近期刚刚加入或者已经续费了三年的小伙伴。如果单纯是想看我输出，知识星球本身并不是一个好途径。不谈高额手续费，没有固定使用习惯的人也很难时常打开，同时我个人的单向输出也鲜有反馈互动。 因此，我关闭了知识星球的付费加入通道，也关闭了续费通道。最后一位星球成员到期的时间大致是明年此刻，期间我还是会正常在星球发布内容也会优先回答大家的任何问题。 所有后续活动将依托于「熊言熊语」播客展开 在开头列出的事情中如果只挑选出一个保留，我想会是已经上线半年有余的播客。这件事情我暂时的目标是 100 期节目（已经完成超过五分之一）。音频内容的分享让我感受到声音似乎可以更好的让大家产生信任感，当信任感积累到一定程度就会增加深度参与的可能性。 考虑到受众，我们播客涉及的范围比较广，涵盖了生物信息相关的访谈介绍、硕博生日常学习生活、医学相关的知识科普、读书心得和各种工具使用分享心得等等。所以，目前已经开展的多数活动都可以依托于熊言熊语播客进行后续开展。当然，这么做的另一个目的也算是我的小心愿，「熊言熊语」不应该仅仅是音频形式的播客，它可以有更多可能性。 当然，如何具体整合还没空认真思考，但今后所有的纳新通知和进展都会通过播客同步，我也会尝试打通几个不同小组之间的连接。 发布「熊言熊语」会员通讯和筹备播客会员计划 整合输出内容和社群小组之后，如何让大家可以方便且及时的看到我们输出的内容呢？筹划了接近一年的每周通讯（Newsletter）即将在 2021 年初和大家见面。 之所以说筹划了接近一年，是因为我其实已经坚持写了 40 周。 之所以叫「熊言熊语」会员通讯，我希望它可以给那些愿意在早期通过爱发电等等方式支持我们播客听友提供更多一点声音陪伴以外的价值，这份每周通讯就是因你们而产生的。 区别于付费才能阅读的「会员」服务，这份会员通讯将面向所有人开放订阅。但是，注意，今后只有我们的会员才可以在上面发布和分享内容，你可以介绍自己的项目，介绍自己的工作，甚至单纯介绍自己；也只有我们的会员才能参加未来线上和线下的活动。 谁需要成为会员呢？如果说免费的 Newsletter 可以让更多人更容易看到我们的分享和思考，会员就是为了让真正想交流的小伙伴更容易互相认识和沟通。 在播客上线超过 50 期内容之前，我们不会考虑推出付费会员计划，目前大家在爱放电的赞赏已经够我们承担一阵子服务器和硬件花费；如果我们没有做好线上线下活动的准备，也不会考虑推出付费会员计划，因为这些费用将主要用来覆盖活动花销。 关于 4321X 关于这份即将推出的每周会员通讯再多说几句，其实我还给它起好了另外一个名字：4321X。 其中：4 代表推荐 4 篇生物信息或者医学相关的文献（专业相关）；3 代表分享 3 个过去一周我的思考或想法（专业无关）；2 代表介绍 2 个我喜欢的工具或资源（工具相关）；1 代表提出 1 个问题供大家讨论（留言互动）；X 则代表不固定的 one more thing。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-11-26-newsletter/"},{"title":"macOS big sur 升级后编译 R 的问题","content":"macOS 发布新系统以来有一段时间虽然手痒但是不敢升级，前几天实在忍不住点了更新。目前使用下来基本一切平稳，新系统新 UI，就像换了一个新电脑（并没有）。使用下来，日常用到的大多数软件都没有问题，比如 conda 和 brew 等等，虽然 brew 还没有正式支持。 使用 R 和 Rstudio，如果不涉及到编译也没什么问题。那如果需要编译呢？ 关于 R 的版本，目前使用的最新版 4.0.3。macOS 版本为 Big Sur。 &gt; sessionInfo() R version 4.0.3 (2020-10-10) Platform: x86_64-apple-darwin17.0 (64-bit) Running under: macOS Big Sur 10.16 Matrix products: default BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib locale: [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 关于如何解决 R 编译的问题，自 R 进入到 4.0 开始，在 macOS 上的配置就不需要像之前那么复杂了。目前只需要保证两个东西可以正常在 macOS 对应版本运行即可。 首先是最新版本的 Xcode command-line tool，针对 Big Sur 目前最新版本是 12.3 beta，选择 12.2 正式版本亦可，可以从官网下载。 然后是安装好配套的 gfortran，我是从官网页面下载的针对最新版系统的 gfortran 11 然后可以在系统路径配置文件或者.Renviron中指定路径。 PATH=&quot;/usr/local/gfortran/bin:${PATH}&quot; 之前那些旧的配置，目前应该是都不需要了，如果你参考过我以前的文章，这里需要特别注意一下。 配置完之后，可以装个 R 包测试，比如。 install.packages(c(&quot;Rcpp&quot;, &quot;data.table&quot;), type = &quot;source&quot;) 比较有趣的是，虽然在电脑里显示的版本号是 11 ，如果你通过 R 的sessionInfo() 查看就能看到内部版本号依旧是 10.16。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-11-25-bigsurupdater/"},{"title":"你的实验伴侣摸鱼首选和通勤第一品牌","content":"如果你有听点东西的习惯，欢迎订阅这档播客，如果没有也可以用这档播客来培养一下。订阅方式可以查看本文的结尾部分。 最近半年博客的更新速度说不上快，一方面是因为事情比较多，没有太多系统可以拿出来分享的成文，另一方面是随着「熊言熊语」播客 (Podcast) 上线，很多表达的出口也转移到了这档播客中。首期节目于 2020 年 3 月 4 日上线。相比于文字，声音和对话会让我们情绪与内容的表达更加真实立体。 截止目前（2020 年 11 月），通过我们自己的官网 RSS 渠道分发的播放量累计达到 3.2 万，在喜马拉雅这个单一平台的播放量累计达到 2.5 万。加上 B 站等其它平台，目前我们的播客全网累计播放量已经超过 6 万。「熊言熊语」当仁不让应该成为广大学子的实验伴侣、摸鱼首选和通勤第一品牌。(逃…… 以下是已经上线的节目内容盘点，可以直接到官网查看收听。 访谈 | 生信技能树创始人 Jimmy 的成长与蜕变 小镇青年休学穷游险些丧命，转专业只为证明自己是专业前几名，靠百度答案找到第一份工作迅速进阶为高级生信工程师，换三个工作后又决定继续读博，面对他人的误解自己为何习以为常。本期节目我邀请到了 4 年好友，生信技能树的创始人 Jimmy，听他聊聊自己的经历和目前的状态。 访谈 | 出国留学的苦与乐听听萌新和老司机怎么说 本期「熊言熊语」邀请到了两位正在国外读博士的朋友，他们一位刚刚到德国 2 个月，一位已经在澳大利亚学习生活了 7 年时间。从两个国家目前的疫情状况开始，我们聊到了出国留学的缘由、留学生活成本、留学早期阶段的感受和问题，也聊到了国内外工作生活的差别、今后要留下还是回国，最后他们也给出了出国留学的建议。 闲聊 | 关于播客、表达和协作 本期「熊言熊语」是一个人的闲聊放送，前几期有听众留言问道我是谁以及播客的录制形式，那就借这期节目再聊聊我们的播客如何制作以及如何收听。最近关于如何表达和如何协作有一点小感触，也分享给各位供大家参考和讨论。 对话 | 从编程学习心得聊到线上交友技巧 本期「熊言熊语」邀请到了洲更和果子两位好朋友。本着跑题的宗旨，我们从生物信息聊到了编程语言，从编程入门进阶又聊到了如何线上交友，甚至还提供了勾搭生信技能树创始人的两种思路。更奇葩的是主咖嘉宾不知不觉沦落到「补充一句」。 访谈 | 硕士工作两年又离职我有些话想说 本期「熊言熊语」我们请来了一位刚从前公司离职的嘉宾。她分享了自己在本科和硕士的学习经历和两年来工作的感受，同时也总结了自己每个时间点做不同选择的原因和给准毕业生们的工作建议。 访谈 | 宝藏女孩の东瀛学医漂流记 本期「熊言熊语」我们请到了一个宝藏女孩，正在日本京都大学攻读医学博士的斯佳。这次连线也是我们第一次详细交流，感叹她丰富的经历和各种技能。我们从医生培养制度聊到中医药大学学中医的经历，又从公派留学聊到了她在日本的生活和感受。疫情让她开始进行医学科普，也成为熊言熊语第一位正式客座主播。 读书 | 一朵后浪的深度数位大扫除 作为一朵后浪，从节日出发聊聊最近在读的「深度数位大扫除」这本书。随着数位工具和服务越来越多，社交平台逐渐侵蚀日常生活，很多时候我发现自己被裹挟在信息的洪流中，生活和感受都被各种 APP 所支配。这种失控的感觉令人不安，于是也就有了这期读书分享和正在进行的 30 天深度数位大扫除。 科普 | 姗姗来迟的疫苗是否值得等待 本期「熊言熊语」是我们科普系列的第一期节目，听日本京都大学的医学博士斯佳聊聊疫苗那些事儿。我们从童年的记忆聊到了疫苗的类型和作用原理，从宝宝出生后为什么要打疫苗聊到了育儿建议，通过介绍疫苗的研发流程和环节引出了当前新冠疫苗研究的进展和困难，当然也谈了常见的狂犬疫苗、流感疫苗和近一两年很火的 HPV 疫苗。 访谈 | 硕士毕业 3 年 3 次转行，在不确定性中野蛮成长 「熊言熊语」迎来了职场系列节目的一次随机更新。本期嘉宾毕业于一所 985 农业院校，硕士研究水果采后方向，毕业转行工作 3 年先后在 3 家不同的公司任职，如今已作为高级经理带领团队独立开展项目。她和我们分享了自己从学生到职场的转变，总结了自己关于转行和工作的思考，也给出了简历和面试的实用建议。 访谈 | 新加坡癌症中心研究员海涛，平凡之路的不平凡 「熊言熊语」本期迎来了目前在新加坡癌症中心工作的海涛，作为我的好友和生信技能树创始人健明的前同事，我们三个人进行了一次三个半小时的长谈。本想分成两集，但为了保证内容流畅还是忍痛割爱整理成一个多小时的节目和大家分享。 海涛说自己是个很平凡的人，但是丰富的个人经历又让我们感受到他的不平凡。他详细介绍了自己四段或主动或被动的跳圈经历，分享了每个阶段自己的感受，更是详细总结了关于生物信息学习与科研的思考。 分享 | 像追剧一样追踪文献和前 10 期小回顾 「熊言熊语」最近收到了好几个听友和文献相关的留言与提问。不少硕博新生都有文献焦虑，既然大家有问题有需求，那我们就借着节目先聊聊文献趴的第一部分：如何像追剧一样追踪文献。给大家提供几种或许用得上的思路和工具，希望对你有帮助，也期待你的评论和分享。另外，关于前 10 期节目我们做了一个小小的回顾，感谢有你。 访谈 | 小丫画图，除了画图更想和你聊聊副业 「熊言熊语」本期迎来了第一位妈妈身份的嘉宾，小丫画图的创始人小丫。可能有一些听友参与过小丫画图的众筹，但对小丫却鲜有了解，本期节目带你走近小丫，听她讲讲小丫画图运营两年背后的故事。如果你有意发展一项副业，还可以来听听小丫关于副业的思考和建议。小丫说自己是个后知后觉的人，但我感觉很多事情她都想的很清楚。 访谈 | 临床医生做生物信息，我是认真的 「熊言熊语」本期请来了上海某大型三甲医院即将结束规培的临床医生 Jack Wang。他讲了自己硕博期间入门生物信息的经历与感悟，从前期漫长的冷板凳到成为香饽饽，从自己艰难摸索到给师弟师妹提供学习建议。此外，他还从临床医生的角度，介绍了生物信息在临床中的具体使用场景、研究思路和发展方向，毫无保留的分享了自己在做项目和投稿中遇到的困难与反思。 无论你是想从零开始认真学习生物信息，还是想结合生物信息让自己平稳完成学业，作为一名医学生或者临床医生都不难从本期节目中获得收获。 科普 | 我还小但是肩颈和腰都不太好 「熊言熊语」科普系列第二期节目终于上架了，嘉宾是中山大学康复医学硕士一楠和复旦大学在读医学硕士旭东，当然还有负责科普系列节目的客座主播日本京都大学在读医学博士斯佳。 本期节目整体感觉就是三位医生从各种维度为我会诊答疑。从各自的生活状态开始，我们聊到了日常学习办公不良坐姿站姿带来的危害以及科学坐站和缓解肩颈腰痛的方法。他们也解答了我关于翘二郎腿、过劳肥和肥宅如何开始运动的种种困惑。 分享 | 学习新工具的思路以及播客近况 本期节目是我一个人的单口分享，先讲讲我们的播客近况以及近期会推出的节目，然后和大家聊聊关于如何学习新工具的问题。从研究生阶段开始一直到工作，我们会碰到各种新问题，要求学习新工具去解决，但很多时候关于如何学习一个新的工具都没有相对清晰的框架。 对话 | 乘风破浪的青年中医，学习工作大揭秘 中医药大学在全国很多省市都存在，但中医专业对很多人来说却非常神秘。一说到中医，不知道你最先想到的是什么？本期「熊言熊语」我们请来了在某省中医院工作的青年医生，一方面帮大家揭秘中医药大学的学习生活，一方面聊聊一个中医院医生的工作日常。当然，我们也谈了一些关于中医的看法和思考。 对话 | 无惧退学与放养，过来人的博士申请走心总结 「熊言熊语」本期请来了即将到澳门大学再次开启博士生活的春卷和即将到美国留学但目前只能远程上课的卖萌哥。春卷曾经有过一次短暂且失败的读博经历，那一次挫折让她有了明显的成长；卖萌哥放养的研究生生活让他有机会接触到更多老师，也让他有了明确的读博申请选择标准。 两位嘉宾在节目中分享了博士申请遇到的各种问题和经历，也从自身经历出发谈到了选择导师和申请博士的具体建议，当然还有关于要不要读博的思考。更多内容，欢迎收听本期节目。 对话 | 和留美博士萌新 up 主聊聊知识分享 「熊言熊语」本期迎来了一位反客为主的嘉宾，正在美国读化学博士的萌新 up 主担担面。当担担面提议想要对我进行采访的时候一开始我是拒绝的，不过没等我说出口她就直接发过来了若干个让我感到惊讶的问题。我惊讶于一个完全不认识的人竟然对我的分享历程一清二楚。 看了她在 B 站发布的奇葩视频之后，我更惊讶于这个人分享的视频和音频教程虽然完全听不懂但还是听的挺有趣。本期内容我们聊到了自己知识分享的历程，以及和知识分享相关各种问题的看法，比如分享动机、平台和付费等等。更多内容，欢迎收听本期节目。 麦驰来了|养成系读博系列节目开篇 本期节目我们请来了刚刚开始博士生活的麦驰姐姐，因为硕士毕业后有几年工作经历她自称要假装萌新的科研「老阿姨」。在本期节目中她回答了很多我好奇的问题，比如工作之后为什么还要重新读博，重新准备读博的过程中遇到了哪些困难，重回校园之后自己的心态和状态发生了什么改变。同时麦驰也坦露心声分享了她对于代沟问题以及如何和导师相处的看法。 另外，本期内容本身还是一个关于系列节目的重大发表，不容错过；另另外，本期内容并没有人为加速，只有 30 分钟的原因很大程度是因为麦驰异于常人的语速。最后，本期又是充满了「哈哈哈」的节目。 麦驰来了|妈妈朋友圈屏蔽了我但我不怪她 「麦驰来了」系列节目时隔三周迎来第二期，本来是一次关于近况的闲聊节目但是熊却迎来了他节目开播以来的首次哽咽。在本期节目中我们谈了谈播客停播疑云，也就是最近三周大概发生了什么。麦驰在节目中爆料了「熊言熊语」首位妈妈粉真实身份，就这个话题我们又认真聊了聊现在应该如何与父母相处以及如何感知父母的变化。当然，不忘初心的麦驰还谈了最近博士生活的一些焦虑感受，不过这依旧是充满了「哈哈哈」的一期节目。 对话|所谓生活工作平衡或许只是一种取舍 在这一期节目中，担担面、小也和我一起聊了聊各自目前的工作和生活状态。担担面已经在美国学习工作了五年，目前也面临着即将毕业的问题；小也硕士毕业后已经工作了满一年。 Work-life balance 这个话题最初由担担面提起，其实在录制节目的时间点之前我并没有什么详细的思考，也没做什么准备。起初目的就是想听担担面聊聊美国博士生活，听小也聊聊萌新社畜生活。 随着交流的深入，我们意外地又聊到了关于朋友关于社交以及如何理解所谓的生活工作平衡。在播客录制结束之后反而让我又思考了很久。 或许会更新一篇文章在我们的播客微信公众号，欢迎大家在微信搜索「熊言熊语」然后关注起来。也欢迎你和我们交流讨论自己关于工作生活平衡的困境或者想法。 对话|硕博生困境逃离指南：街头迎风痛哭还是家里买菜洗碗 和 Struggle With Me 的三位主播神交已久，终于迎来了一次串台。 这期节目话题来由本身很沉重，2020 年 10 月 13 日大连理工大学一位化工专业的研究生在实验室结束了自己的生命，同时网络中也流传出一封可能是这位同学留下的遗书。硕博学生的生存现状又一次成了人们讨论的热点，两三周时间过去和其它热点一样又毫不意外的回归平静。 舆论归于平静，但正身处这个群体中的我们可能很难真正平静下来。在本期节目中，四位主播聊到了硕博学生的生存现状和自己遇到的种种困难，提到了有没有所谓适合科研这类反复被讨论的问题，重点交流了各自面对困难时的解决方法以及如何逃离负面情绪和困境。心理学专业的嘉宾正正更是从心理学角度分享了自己的想法和建议。 话题沉重但是节目本身并不沉重，展现出了我们新时代高素质学生良好的精神面貌和积极乐观的心态，更多内容欢迎收听本期节目。 分享|组织一个小活动两年之后的反思 原本计划中的一期访谈因为录音事故不得已延期，于是又有了一期一个人的真「熊言熊语」。 那就聊聊已经组织了两年在昨天刚刚收官的一个活动：学习素材共享小组。发起这个活动的起因是小时候交换小霸王游戏机卡带的回忆，但是真做起来却困难重重。回顾之后我有些关于社群的感受和反思与你分享，关于播客后期如何做其实也是最近困扰我的问题。 麦驰来了|从与导师沟通聊到换课题侧重的纠结 不少听友很喜欢的「麦驰来了」系列节目终于又更新了。 麦驰在往期节目里聊到的问题和困惑很多听友都纷纷反馈很有共鸣。这次回归的麦驰又带来了她最近一个多月更新的感受和疑问，比如如何看待组会，应该如何和导师进行沟通。这次节目主要内容是我们讨论了关于麦驰要不要调整课题侧重方向的纠结，录制过程中两个人情绪起伏很大，一度感觉要吵起来。不过至于是哪里起了冲突欢迎收听本期详细内容，如果你有什么类似的经历想和我们分享也欢迎在收听节目的平台或者通过邮件给我们留言。 联系 如果你想作为嘉宾出现在我们的节目中或者想推荐嘉宾参与我们的节目，亦或者你有任何的想法和问题都可以通过邮箱和我们联系。大家提出的问题都有机会在后续的节目中得到解答。 邮箱：hi@kaopubear.top 如何收听 官网收听 如果你不想多下载一个 APP，那么通过官网收听节目是非常好的选择。目前我们的官网已经支持了倍速播放、快进快退和章节功能。 https://podcast.kaopubear.top 苹果播客 苹果播客（PodCast）是 iOS 自带的一个 APP，是使用苹果手机听友最简单的收听选择。只需要在应用内搜索「熊言熊语」即可。 因为它仅仅是一个播放平台，直接使用我们提交的 RSS 源，本质上目前不会对节目做任何干预或者插播广告，同时章节功能和倍速功能都可以使用。 小宇宙播客 APP 安卓用户推荐下载「小宇宙播客 app」，和苹果播客类似，它也是一个泛用型播客客户端，适合使用安卓手机的听友。目前他们不会对节目做任何干预或者插播广告，还有时间轴和评论功能。在主页也可以看到编辑推荐的优质播客节目。 更多泛用型播客客户端 由于国内托管平台存在着审查下架节目和私自插播广告等问题，我们的播客除了中国版外还托管在独立服务器，因此推荐大家使用 RSS 订阅的方式进行收听，从而获得包括完整「shownotes」和「章节功能」等更好的收听体验。 播客 RSS 地址：https://podcast.kaopubear.top/episodes/feed.xml 如果你想获得最好的收听体验，比如使用我们精心准备的章节功能，可以使用第三方泛用型播客客户端，如 Pocket Casts 搜索我们的节目进行收听。 其它平台 此外你也可以到喜马拉雅、B 站和网易云音乐搜索订阅这档播客。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-09-18-kaopubeartalk/"},{"title":"如何帮助别人","content":"会提问也要会回答啊。 之前我写过，很多人也都写过关于「如何提问」的相关文章，今天读到了一篇博客讲的是「如何回答提问」，这个角度确实以前没有仔细考虑过，于是我就着这篇文章整理了一个图，大概就是下面这些内容，详细的内容可以直接阅读原文。配套之前整理的如何提问的思维导图，这块内容就比较完整了。 先答问题 只有帮助了别人才更容易和他们讨论你看到的其它问题 专注问题 别人的代码习惯可能和你不一样 不要吐槽哪些你看不惯但是和问题无关的东西 不要插话 如果已经有人帮忙你不应该插话 你的新思路可能会给初学者带来更多困惑 匹配水平 初级问题不要直接提供高级解法 能理解的次优方案要好于不能理解的最佳方案 多是少否 尽量多说「是的」少说「不对」 你的目的是为了帮助别人而不是责备别人 找到问题本质并用积极的语气回答 避免绝对 过于绝对的语气和立场容易让人反感甚至对抗 「以我的经验」是个不错的开头 学会让步 互动可能很糟糕，误解可能越来越深 尝试解决误会或者退出讨论 承担责任 和预期不符通常会认为是对方没有努力 把「你听不懂么」改为「也许我解释的不好」 评价自己永远好过评价别人 多说几句 简练的回答固然好，但也容易产生误解 多说几句鼓励的话 了解动机 帮助别人的动机有很多，其中也包括否定别人的快感 不要把帮助别人作为自己负能量的出口 尽量谦虚 知道答案的感觉固然很好，但是你也并不是什么都知道 尽量谦虚的帮助别人和回答问题 建立联系 与人建立联系比掌握对话技巧更重要 有了融洽的关系更容易传达信息 这些很难 做到上面所有这些很难，但是面对一个好的提问者你要努力去做 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-09-16-howtobehelpful/"},{"title":"21天日记挑战-5分钟日记法","content":" 很久没有记过日记了，打算来个 21 天日记挑战，然后录制一期播客。好吧，是不是看出来了播客选题荒。 为什么要记日记呢 想要开始记日记的缘起来自最近听了一期播客，初看题目觉得平平无奇「一年过半，我开始接受生活的随机」。但是两位主播回顾的形式让我有点没有想到，她们拿出自己的手帐，随机翻到哪一页就讲那一天她们记录下的生活。 于是我问自己，如果现在让我回忆过去六个月，我能记住哪些日子，在哪一天又发生了什么，很难。每天在混乱忙碌和浑浑噩噩中过去，但是又无法记住每天都经历了写什么，那么就尝试记下来吧。 我其实从小就没有记日记的习惯，不都说 21 天可以养成一个习惯么，我用前面 20 多年养成了不记日记的习惯，那就趁着这次机会来个 21 天日记挑战吧。 我希望如果哪天我想要回忆的时候，我就知道自己可以回忆些什么。如果说写博客录播客是和别人对话是输出自己的想法，那么记日记就是和自己对话，是缓解负面情绪的一个好方法。 此外，最近想比较正式的实践一下所谓的[[Zettelkasten]]（卡片笔记法），那么每天随手记的习惯也是需要培养的。 日记应用 Diarly 虽然我很喜欢随机翻开手帐回顾过去某一天经历的感觉，但我当然还是得选择电子工具啊。日记类应用最牛的应该是 Day One，在我派有不少重度用户，我很喜欢的 Hum 就是一个。 Day One 提供的元数据，对图片和地理位置的处理，各种模版，以及 macOS 客户端都是我需要的。但是目前一年接近 250 的价格是我暂时无法承受的，嗯，最近换房子我感觉自己遭到了社会的毒打。 如果用一直在用的 Drafts 或者印象笔记这些，又没有一种记日记的仪式感，如今没有仪式感的事情如果不是已经养成习惯感觉会更加降低坚持下去的可能性。 好在订阅了 setapp，去里面看看有没有类似的工具，于是就发现了 Diarly，首先一年 100 的订阅价格能让我的 setapp 更加值回票价一些。同时 Diarly 的功能也基本满足我的需求。 iOS+macOS 同步 方便的插入时间地点天气和图片 markdown 语法良好的支持 设置日记字数目标 自定义模板 有日历和地图查看模式 方便的导入和导出 每天记录些什么 关于每天记录什么，自然不可能要求一天一篇 800 字的小作文。这里计划采用[[5分钟笔记法]]也推荐给大家。 所谓5 分钟笔记法，在[[巨人的工匠]]这本书里就有所提及，其实是一套比较知名的笔记模版，每天只需要花费 5-10 分钟就可以完成早晨 3 个晚上 2 个共 5 个题目。 这 5 个题目早上的目的是感恩以及设定目标，晚上的目的是回顾与反思总结。 早晨的 3 个问题 I am greatful for…（三件令我感恩的事情）：不分大小，不分人或者物，学会观察，意识到生活的美好，要有积极的心态。 What would make today great？（三件会让今天更美好的事情）：本质是待办事项，要写做了会感觉美好轻松的事情。只写比较有希望完成的三件事，要具体。 Daily affirmations. I am…（我是谁，三个自我设定） ：本质是想清楚自己是谁，明白自己的指责，明确身份才能明确做什么，因此身份也需要具体。身份会影响目标，目标会影响计划，计划会影响行动。 晚上的 2 个问题 Amazing things that happened today…（三件今天发生的美妙事情）：和第二题对应，也可以写一些意外的小惊喜和收获，无论大小，有一个瞬间让你开心或者触动你就可以，这里可以配一两张照片。 How could I have made today even better？（我如何能让今天过的更好） ：一道温柔的反思题，一个「更好」既是对一天还不错的小总结，也是反思有哪些可以改进的地方。 补充一个关于 5 分钟笔记的 英文解读。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-08-06-21day5minjournal/"},{"title":"使用 Zotero 在 Markdown 中优雅地处理参考文献","content":"需求 兵马未动粮草先行，写毕业论文需要做很多思想建设，有一个顺手的写作工具和一个方便的文献管理工具可以给人一些动力和勇气。 我目前的需求很明确，就是用自己中意的 Markdwon 编辑器来写论文初稿，使用 Zotero 来管理大量参考文献，然后论文转换成 office Word 文档让老师们查看。 如果选择 office Word 来写，直接用 Zotero 插件处理参考文献没有任何问题，但作为 Markdown 的重度用户，用 Word 写上百页的文档实在是太难受。 于是，这篇文章就分享一下如何尽量优雅地借助 Zotero 用纯文本方式完成论文中参考文献的引用和管理。所谓优雅是指当 Markdown 内容并转换成 Word 格式后，所有引用都需要被 Zotero 插件正确识别且可以随时在 Word 中进行修改更新，而常用的 Bibtex 加 Pandoc 方法并不能实现这个需求。 准备 工具 Markdown 编辑器：Ulysses 奔着 Ulysses 在高价位上了 setAPP 的车，如果能用它把论文写完，这车费就没有白花。当然，用 Markdown 写论文最自由的就是对写作工具的选择，这里使用任何一个你顺手的编辑器都可以，比如 Typora, MWeb 甚至是 VSCode 都么得问题。 文献管理工具：Zotero 硕博这几年时间，我先后使用了目前国内使用率最高的三款文献管理工具，从 Endnote 转向 Mendeley 是因为当时觉得 Mendeley 没有 Endnote 那么「重」；从 Mendeley 转到 Zotero 是因为后者的免费和插件。关于如何上手 Zotero 之前也有写过详细的介绍。 辅助 使用 Zotero 又不借助 Word 来管理参考文献，安装 Better BibTeX 插件是必选项，它为参考文献的引用和管理提供了一站式解决方案。 同时，把 Markdown 格式的文本用高度可定制的方法转换为 PDF 或者 Word 格式文档，绕不开 Pandoc 这个工具。我们熟悉的大量文本编辑器在生成其他格式文档时往往调用的都是 Pandoc。 概念 CITATION KEYS 所谓 Citation Keys(Citekey)，可以理解为 Better BibTeX 给文献生成的一个 ID，当我们在文档中需要插入文献的位置按照一定格式输入 Citekey 后就等于告诉 Zotero 要在这里引用对应的文献了。 由于 Citekey 是纯文本格式，不同编辑器对文章本身的影响可以降到最低。在 Endnote 中同样有类似的引用方式，这个概念被称作 Temporary citation。 通用的 Citekey 格式为 [auth:lower][year]，前半部分表示文章第一作者的小写姓氏，后半部分为文献年份，如果出现了重复，就会在后面添加 a b c 或者数字进行区分。 下图是 Zotero 中关于 Citekey 的展示。 CITE AS YOU WRITE 在写作过程中，如果仅将 Zotero 对应的文献 Citekey 复制到文本并没有什么难度，无非就是方便和效率的问题，即随写随引。 在 Word 插件中的 Zotero 的引用效果如下图所示。 类似的效果只有同时在我们使用的编辑器中实现，才能做到 CITE AS YOU WRITE。 自动操作 如果你在使用 macOS，或许还不知道它也有类似于 iOS 中快捷指令的功能，叫做 Automator（自动操作）。这个应用可以设定在什么情况下进行何种操作，本文将会涉及到一个脚本自动执行的问题，就会用到 Automator。 如果对它感兴趣，具体使用介绍可以查看苹果 官方说明。 设置 Zotero CITATION KEYS 我目前的配置如下图，所示。这里主要是修改了引用格式。 Pandoc filter Better BibTeX 的作者写了一个 lua 脚本zotero.lua，用来实现从 Markdown 到 Word 实时引用的格式转换。我们可以在 Markdown 文本中写入相关元数据，或者在 pandoc 命令行中进行相关参数设置。 --- # all the regular stuff you have here Zotero: library: &lt;group name&gt; # omitted to use your personal library scannable-cite: false # only relevant when your compiling to scannable-cite .odt client: &lt;Zotero or jurism&gt; # defaults to Zotero author-in-text: false # when true, enabled fake author-name-only cites by replacing it with the text of the last names of the authors ... 如果是 Zotero 个人 library , 没有什么特殊情况使用默认参数即可，直接运行如下命令： pandoc input.md -s --lua-filter=zotero.lua -o output.docx zotpick-applescript Better BibTeX 在实现随写随引的问题上给出了多种实现方法。如果你是把 Atom 或者 VSCode 作为编辑器可以直接安装它们相关的扩展插件，具体可以查看 官方说明。 除此以外，还可以利用插件的提供的 URL 自行设置在其他编辑器内的调用。例如 http://127.0.0.1:23119/better-bibtex/cayw?format=mmd&amp;clipboard=yes 这个地址就表示会把选择的 Citekey 按照 MultiMarkdown 的格式 [#adams2001][] 进行引用，同时把内容保存在粘贴板中。 当然，无需我们自己写，已经有前人造好的轮子 zotpick-applescript。 这里我们只需要下载 zotpick-pandoc.applescript。 为了快速调用这个脚本，我们可以设置一个自动操作的 workflow，配置如下图所示。选择「没有输入」和位于「任何应用程序」，然后在左侧选择「运行 AppleScript」，在右侧弹出的编辑器中复制 zotpick-pandoc.applescript 的代码即可。随后保存命名并保存该 workflow。 快捷键 为了快速调用这个 workflow，我们还可以在快捷键的设置中为它指定一个快捷键。 此外，因为 workflow 插入的格式为 @adams2001 而 Pandoc 转化时在 Markdown 中识别的格式为 [@adams2001]，所以有了另一个小需求：快速输入 [] 并且把光标置于两个括号间。 这个需求可以利用 TextExpander 和 Keyboard Maestro 等工具实现，为了让 setAPP 只会票价，在这里我选择了和 TextExpander 同类型的应用 Rocket Typist。设置方式如下： 同时我给这个动作也自定义了缩写，方便快速输入。最终的实现效果如下： 如果使用 VSCode 来编辑，插件用起来非常方便，就无需上面这些设置了。 效果 接下来展示一下 Markdown 源文档示例，和转换成 word 文档之后的样子。 最后一步，就是在 Zotero 的 Word 插件中选择引用格式，点击「OK」，然后再点击「Refresh」就可以展示正常的引用格式了。如果想插入参考文献的详细信息，点击「Add Bibliography」即可。 扩展阅读 Better BibTeX 的官方文档是非常好的学习材料，可以了解更多的相关知识，推荐阅读。 From Markdown to live citations CITE AS YOU WRITE 此外，如果你感觉这些配置过于繁琐，可以尝试 Zettlr 这款直接支持文献管理的开源 Mardown 编辑器。我曾经使用过一小段时间，不过还是因为没有 MWeb 和 Ulysess 用起来顺手而放弃了。 如果你是 Windows 用户，则非常推荐使用 Zotero + VSCode + VSCode Zotero 插件的组合。 2009021117 更新 文章发表在少数派之后有不少有价值的评论。其中有朋友提到了 markdown 文本可以使用 docdown 来直接进行转换。关于 docdown 可以直接参考学习它的GitHub 主页。后面有空了可以就 docdown 做一个详细的补充。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-06-04-markdownzotero/"},{"title":"三个 Linux 文件高频小操作","content":"去除文件名后缀 在 Linux 中跑各种任务或者循环命令的时候，有一个高频的需求是截取一部分文件名。例如有文件 XXX_aaa.bb 和 YYY_aaa.bb ，很可能我们需要提取出 XXX 和 YYY 来给后续的文件进行命名。 实现这个需求的方法有不少。 利用变量中的 % 号。在 Linux 中使用百分号将变量的内容从变量的尾部删除。 一个%号可以从尾部最近位置进行匹配删除，两个%%从尾部最远位置匹配删除。同时支持使用通配符。例如id=XXX_aaa.bb 可以使用 ${id％％_*} 第二种方式是使用 cut cut -d ‘_’ -f 1。使用 _ 作为分隔符，输出第一列，也是可以得到 XXX 第三种是使用 awk，和 cut 类似也是指定分隔符输出第一列 ls *.bb| awk -F &quot;_&quot; '{print $1 }' 为了让脚本使用率更高一些，我通常会使用绝对路径来指定文件位置。为了更快的获取文件名，会使用命令 basename。basename 本身就有一个非常好用的功能，可以剔除指定的文件名结尾部分。如下所示，我觉得这个应该是最优雅的方式。 basename /a/b/c/XXXX_aaa.bb _aaa.bb XXXX 批量重命名 场景如下，现在有好几百个文件需要重命名。类似于 A1.txt A1.md A1.pdf B2.txt B2.md B2.pdf ... 其中 A1 要全部替换为 C3 ,B2 要全部替换为 D4 变为，即 C3.txt C3.md C3.pdf D4.txt ... 已经有一个两列的文件是对应信息。 A1 C3 B2 D4 昨天在知识星球抛出这个问题之后有几个小伙伴给出了自己的建议，其中给我最大冲击的是一个小伙伴提出的 Excel 批量法，思路是用 Excel 对字符段组合出新的命令。 这个需求或许可以拆解为两个问题，一个是重命名，一个是批量。 重命名的方法 mv 或者 rename 都可以，批量很容易想到 for 循环，因为对应的一对变量已经在文件的一行了，所以只要把它们分别保存为两个变量就好了。这个需求更好的完成是方式是配合 while 和 read 来完成循环。 read 可以从标准输入或者管道以及文件描述符读取内容，而且非常方便的可以直接定义多个变量。 因此可以写为： while read old new do echo $old $new; rename &quot;s/${old}/${new}/&quot; ${old}* done&lt;changename.txt 如果把这个小小的命令变成一个 rename.sh 脚本，可以写成。 #!/bin/bash FILE=$1 while read old new do echo $old $new; rename &quot;s/${old}/${new}/&quot; ${old}* done &lt; $FILE 多说一句，关于理解 read 的用法，有一个小的测试题。 echo '1 2 3 4 5 6' | while read a b c do echo $c $b $a done 上面这个命令，请问输出的结果是什么？是 3 2 1 6 5 4 么？如果不是又会是什么呢？如果能直接说出 3 4 5 6 2 1 这个结果，应该就是理解了。 同文件名文件拷贝 这个需求也比较常见，在 Linux 中，不能的目录下都有可能存在相同的文件名，例如有些生信分析软件跑多套数据，通常只会在目录层面进行区分，而不会在文件名层面进行区分。可能的目录结果如下： a: xx.txt yy.json zz.bam b: xx.txt yy.json zz.bam 为了方便处理，我们通常习惯把同一个类型的文件放在一起，但是如果直接拷贝源文件，会因为文件名重复的问题带来灾难。这时就有了一个重命名再拷贝的问题。 重命的一个基本思路就是把需要的目录名加到源文件名字的前面或者后面。首先拿到实际的文件名可以使用 basename 命令，如果想拿到目录名则可以使用 dirname 命令。 for i in `ls */*.bam` do cp $i ./bamfile/$(dirname $i)_$(basename $i) done 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-05-30-linuxfile3tips/"},{"title":"VS Code 代码编辑器入门指南下篇-场景化应用介绍","content":" 本文首发于「少数派」 写在前面 如果当电脑只能装一个软件还需要尽量不影响日常学习工作时，不知道你的选择会是什么。我把这个看似「荒诞」的问题理解为「All-in-One」的升级版拷问。 这个问题陪伴了我很久，每用一个软件我都会想想它对我究竟有多不可代替，然后决定是否继续用下去；当决定深度使用后，我就会问自己它能在多大程度上帮助我完成日常的学习和工作。截至这篇文章完稿，如果我的电脑只能装一个软件还要做到基本不影响日常学习工作，我的选择是 VS Code。 参考之前写过的 文献管理工具 Zotero 入门指南，本入门指南将从 VS Code 特点出发，介绍入门 VS Code 必须了解的核心概念和组件（上篇）以及 5 个 VS Code 实际使用场景（下篇）。希望对想了解和学习 VS Code 的读者能有一点帮助和启发。 在 VS Code 编辑器入门指南上篇，我们了解了什么是代码编辑器、为什么选择 VS Code 、从 0 到 1 开始使用 VS Code 以及上手 VS Code 需要了解的核心概念与组件。提到的组件包括资源管理器、跨文件搜索、源代码管理、启动调试和扩展管理，涉及到的核心概念包括插件、命令面板、工作区和语言支持。 有了这些基础的知识储备再打开 VS Code 就不会恐惧和陌生，不过，学习一个工具更好的方式是找到具体应用场景。VS Code 编辑器入门指南下篇将从五个可能会用到的实际场景出发介绍一些 VS Code 特性和好用的插件。因为文章篇幅所限很难详细展开，如果有需要可以后续再分别介绍，不过我会为每个插件附上链接和尽可能多的官方相关介绍方便大家进一步了解。 码字工具 如果你是一个重度的 Markdown 写作者，VS Code 经过简单配置后作为文本编辑器其体验不会逊于市面上大部分文本编辑器。 图片 首先通过两个插件来解决图片处理这个老大难问题，如果经常使用截图功能且喜欢直接把图片存放在本地可以使用 Paste Image 插件，如果喜欢把图片直接上传至图床则推荐使用优秀的 PicGo VS Code 插件。 因为我日常会把所有图都放在腾讯云中保存，这里以此为例简单介绍 PicGo 在 VS Code 的配置和使用。 在设置面板中搜索 picgo 就可以看到相关的配置选项，需要的配置参数和 PicGo 客户端一致，例如使用腾讯云时需要填写 APPID、存储空间名和自定义域名等信息。因为平时使用的目录和文件名都可能包括中文，我设置为仅按照时间命名。 在使用时，picgo 利用快捷键可以方便的将剪贴板图片（option+command+u) 或者本地图片 (option+command+e) 上传至图床，并直接在光标处插入图片链接。 目录功能 打开一个 Markdown 文本后在资源管理器组件中可以通过 outline 查看文档目录，点击对应章节标题直接跳转至相应位置。 如果你没有忘记上文提到的命令面板，我们还可以利用命令面板的符号跳转功能实现章节定位。符号跳转本身是针对代码设计的，可以快速跳转到一些函数定义和类定义，其实在 markdown 中也十分好用，只需要按下 Command+shift+o 或者按下command+p后输入@, 就可以看到各级标题了。 这个操作在什么时候最有用呢？或许是按下 ctrl+k z 开启禅模式的时候。 编辑体验 如果需要获得更好的 Markdown 编辑体验可以考虑安装如下几个插件 Markdown All in One：基本支持了 Markdown 所需的各种操作，例如快捷键、生成 TOC 和导出 HTML 等，如果没有特殊需求无需安装下面三个插件。 Markdown Footnotes：让系统默认的 Markdown 支持脚注。 Markdown+Math：非常完善的数学公式支持。 Pangu-Markdown：盘古之白，在需要的时候给中文和英语数字之间增加空格。你懂的，关键时刻这个功能非常重要。 笔记模板 模板是所有笔记类工具的标准配置，在 VS Code 中可以通过代码片段（Snippets）针对不同类型的文档设置模板。 如果想配置自己的代码片段，在命令面板中输入 Configure User Snippets 后会看到语言选项，这里我们以 Markdown 为例，配置内容本身为 json 格式。 一个典型的代码片段如下所示： &quot;Print to console&quot;: { &quot;prefix&quot;: &quot;log&quot;, &quot;body&quot;: [ &quot;console.log('$1');&quot;, &quot;$2&quot; ], &quot;description&quot;: &quot;Log output to console&quot; Print to console 为片段名，对象的值包含：prefix、body 和 description 三个属性。分别表示调用名、插入内容和代码描述。 我把自己一些常用的 Markdown 模板做成代码片段并打包成了一个 插件。例如当我输入debug的时候就可以方便的调用 debug 记录模板。 查找替换与精确定位 如果你是一个每天需要处理很多稿件的编辑往往会有一些重复性工作，比如需要把十几篇投稿中的「ios」修改为「iOS」。这类涉及到搜索替换的问题，使用 VS Code 强大的搜索组件都可以轻松搞定。 VS Code 支持单文件和多文件的搜索替换，这里以多文件常见的需求作为介绍。 搜索支持三种模式，分别是区分大小写、全字匹配和正则表达式，例如 iOS 这类大小写的替换需要选择「区分大小写」。进行多文件搜索替换时，有时只希望限制所在目录的部分文件，这时就可以设置在哪些子文件夹进行搜索或者过 2020-04* 会匹配所有以它开头的文件。 除了使用搜索功能进行替换以外，它还可以实现「精确定位」。 很多人在使用一些笔记工具时都有精确定位的需求得不到满足，即快速找到某个 tag 或者关键词所在的具体位置。VS Code 则可以帮你在所有需要的文档中进行精确定位和跳转。 如下图所示，我在一个文件夹内搜索「模板」，它会在结果中显示每个文档中的搜索结果，鼠标放在某一行时会用浮窗形式展示详细内容，点击后会直接打开对应文档并定位在所在行。 预览导出 Markdown 文档的预览在不借助第三方插件的情况下基本可以满足需求，我们可以在配置中设置引用自己中意的 CSS 样式以达到更好的效果。如果需要非常强大的导出功能，可以借助插件 Markdown Preview Enhanced。 该插件应该可以满足所有的 Markdown 文档的预览和导出需求，官方有详细 中文文档 可以查看了解。 项目管理 如果你有很多个笔记本（文件夹）在码字的过程中需要经常切换，这里推荐的插件是 Project Manage。 它支持将目录和工作区 Workspaces 保存为项目并进行快速切换，很好地弥补了 VS Code 自身项目切换的不足。如果你对工作区这个概念很陌生，可以阅读 VS Code 编辑器入门指南上篇-核心概念与组件。 管理协作 如果你的项目需要协作，VS Code 也可以成为你不错的项目管理和协作工具。 从需要的地方即刻开始 从 VS Code 的搜索功能角度出发，如果我们在文档内部做一些固定的埋点并赋予特殊含义，那么就可以在需要的时候直接找到这些特殊内容。todo 类型插件就是这样的思路，我们可以设定一些特殊的标记，然后在工作目录下自动搜索匹配这些标记再以形象的方式展示在组件中。 以比较常用的 TODO 插件 Todo Tree 为例，在设置中我们可以指定哪些内容作为标记以及这些标记如何被展示。 2020-04-17-19-43-55 &quot;todo-tree.highlights.customHighlight&quot;: { &quot;TODO&quot;: { &quot;icon&quot;: &quot;tasklist&quot;, &quot;iconColour&quot;: &quot;red&quot; }, &quot;REVIEW&quot;: { &quot;icon&quot;: &quot;eye&quot;, &quot;iconColour&quot;: &quot;green&quot;, }, &quot;FIXME&quot;: { &quot;icon&quot;: &quot;thumbsdown&quot;, &quot;iconColour&quot;: &quot;yellow&quot; } } 随后当我们在任意文档的任意位置插入相关标签后，它们就会在组件中展示出来，点击标签即可直接跳转到对应位置。 用 KanBan 管理素材 只有 TODO 功能或许不够过瘾，如果能做成看板的形式就更好了。嗯，一个插件 Kanban 基本满足需求。 在自己的稿件目录下添加一个「稿不完」看板，该写什么一目了然。看板内容本身会存储在 json 格式的文本文件中。 在 VS Code 中使用 Trello 如果你的团队正在使用 Trello， 那么你也可以在 VS Code 借助插件 Trello Viewer 及时查看大家的 Trello 动态。 完成 token 配置后，在侧边栏将会出现一个 Trello Viewer 组件，Trello boards 下会显示所有看板，你还可以把某个常用的 list 添加到 favorite list。 如果仅仅是想查看卡片内容只需要点击即可，这时插件会生成一个 Markdwon 格式文件并自动打开预览模式。如果你想对卡片进行简单编辑，可以在组件中右键点击某个卡片然后选择要进行的后续操作。 让 Git 更容易一些 版本管理是个人和团队项目开发中非常重要的一环，源代码管理也是仅有的几个被内置到 VS Code 中组件，无需任何插件和设置即可在 VS Code 中使用 Git。很多人在学习 Git 时都会被各种各样的命令搞晕，在提交代码时也会因为要输入各种命令而烦躁。 如果想更轻松使用 Git 和 GitHub，你可能会选择 GitHub 官方客户端或第三方付费客户端，实际上借助 VS Code 自身对 Git 的支持以及 GitLens、Git History 和 RemoteHub 这三款插件，就可以获得极佳的使用体验。 如果你是一个经常使用 git 的人，应该可以感受到 gitlen 提供的组件非常贴心。 2020-04-17-20-45-15 前两个插件的安装数基本说明它们是绝大多数 Git 用户的必选项，而 RemoteHub 是 GitLens 开发者还处在预览版的新作品。它支持在命令面板中直接搜索 GitHub 上的项目，在不需要 clone 的情况下通过 VS Code 查看项目代码。当需要编辑操作时对应的文件才会从 GitHub 按需下载。不过该插件目前需要开启一些 VS Code 默认关闭的功能，如果想尝试可以阅读插件使用说明。 网站开发 说完目前最火的轻量标记语言 Markdown ，就不得不提和它对应的超文本编辑语言 HTML 和前端开发了。 可能写一个小网页或者个人博客是很多人的 todo 事项，使用 VS Code 做前端开发对于初学者来说非常友好。 格式化与折叠 代码格式化是指让各种不规范的代码瞬间按照要求好看起来，VS Code 借助语言插件目前对绝大多数语言都有很好的支持。在设置中我们可以选择何时对代码进行格式化，包括输入粘贴和保存。此外每种语言都可以进一步进行个性化设置。 关于代码格式化的插件，你也可以尝试 Prettier。 除了代码格式化以外，VS Code 还可以基于语言定义进行代码折叠，即根据语言特性来自动区分哪些部分可以折叠，因此 Markdown 文档同样可以使用代码折叠功能。当鼠标位于行号旁边时，可以被折叠的位置会自动显示向下箭头。 使用快捷键command+shift+[ 进行快速折叠时，会从所在位置处可折叠的最内层代码开始折叠。展开的快捷键则是command+shift+]。 对于较长的代码，如果不习惯使用代码折叠可以开启 minimap 功能。当前页面在小地图中会呈现为灰色，光标所在位置为白色。如果进行文件内搜索时，对应位置会以黄色高亮显示。 多光标 多光标特性是 VS Code 高效使用的必备技能，官方文档 有详细介绍，这里简单提一下我常用的三种方式。 有时候我们需要在一个文件内多个没有明显特征的位置添加相同的内容，此时如果配合鼠标操作，只需要按住 option 键，在需要添加光标的位置单击即可。 还有些时候，我们统一需要在多行的行末添加一些内容，或者需要从行末开始删除一些内容。这时只需选中要修改的内容，按 option+shift+i 就可以在行末添加光标。 最后一个比较高频的需求有些类似于查找替换，比如我们需要把文档中一些相同的内容统一选中进行某些修改，这时可以先选中一个内容，然后按下 command+d 就会自动选中下一个相同的内容。 颜色设置 在编写 CSS 时常见的一个需求就是修改元素颜色，在 VS Code 中可以直接使用取色器进行修改。 当遇到颜色时，我们会在编码前看到效果色块，鼠标浮于颜色上会自动显示颜色编辑器。在这个窗口中可以调整颜色的饱和度、透明度和色相，也可以切换不同的颜色代码。同时，只要点击右上角就可以轻松退回之前的颜色值。 Emmet Emmet 是一个可以大幅提高前端代码编写效率的工具，可以让我们用尽量简洁的输入来实现复杂的内容。借助 Emmet 可以摆脱频繁写 &lt; &gt; 的尴尬，而在 VS Code 中可以非常方便的调用 Emmet。 当输入任意内容后，如果有可以和输入匹配的 Emmet 缩写，相关建议就会实时展示出来供选择。 如果写的语法比较复杂它也可以实时帮你展示转换后的效果，非常实用。 除了在编辑时进行代码展开，借助命令面板还可以是实现 Emmet 的很多其他操作，例如缩写包围、删除和更新标签等等。你可以在官方文档中查看更多信息。 实时预览 VS Code 本身不支持实时预览 HTML 文件，不过已经有很多插件实现了这一功能，例如 Live Server。 数据分析 查看 Excel 和 PDF 在日常工作中，我有很大一部分时间都在和各种格式的数据和文档打交道，其中 Excel 和 PDF 文档是最常见的两种格式。在没有使用 VS Code 之前如果一个项目中有这些文件就需要在 office 和 PDF 阅读器中打开，但是借助 Data Preview 和 VS Code-pdf 可以轻松查看这些文件，用起来挺过瘾。 VS Code 中直接查看 Excel 并进行基本操作。 VS Code 中直接查看 PDF 文档。 Python 与 R 语言支持 目前数据科学相关领域有 Python 和 R 两种常用编程语言。如果你习惯使用 python ,VS Code 本身对 Python 和 juypter 都有非常完善的支持，可以查看官方文档的 详细说明，使用起来比较简单。 如果你习惯使用 R 语言，随着 R Language Server 后端加持以及 VS Code-R 插件在前端的重大迭代，现在使用 VS Code 愉快地进行 R 语言编程不仅成为了一种可能，而且还挺香。使用体验上基本不输 Rstudio，而且很多小细节上更贴心。 因为 R 语言配置相对复杂，所以稍加介绍。 安装 R，建议使用默认路径即可。 安装 R 包 languageserver ，命令如下install.packages(&quot;languageserver&quot;) 在 VS Code 中安装两个和 R 相关的插件 R support for Visual Studio Code 这个插件是 VS Code 中 R 的核心插件，具有语法高亮，基础代码片段和代码执行等功能。例如你可以在编辑器中选择某几行内容，然后使用 ctrl+enter 将代码发送到终端执行。 R LSP Client 有了它就可以进行代码补全、查看函数定义以及参数预览等功能。 安装插件后需要在配置文件中进行两个对应设置。通过 ctrl+, 进入设置页面，在搜索页面首先搜索 rterm，在对应操作系统位置处输入你的 R 路径，然后找到 rlsp path 对应设置处也输入 R 安装路径。 打开一个包含 R 脚本的文件夹（单独打开一个 R 脚本无效）就可以正常使用了。 一些基本特性如鼠标悬停显示函数定义和帮助文档（无论包是否加载）、鼠标悬停在变量直接展示类型信息、自动高亮文档内所有同一变量和函数自动补全等都非常好用。 R session watcher VS Code-R 插件近期更新中新增了 Session Watcher 功能，即便还在测试阶段这个功能也足以让人激动。它实现了在 VS Code 中实时展示各种变量图表等需求，不会再有单独弹窗。 如果要正确使用 session watcher 功能，首先需要在设置中开启 session watcher 选项，然后需要在 R 的 .Rprofile 配置文件中添加一行代码： source(file.path(Sys.getenv(if (.Platform$OS.type == &quot;windows&quot;) &quot;HOMEPATH&quot; else &quot;HOME&quot;), &quot;.VS Code-R&quot;, &quot;init.R&quot;)) 开发利器 对于程序员来说，终端和服务器的使用频率极高，如果代码编辑器可以和这两者非常好的结合将会大大提高工作效率。 配置终端 VS Code 的设计理念之一就是让 VS Code 和终端紧密联系在一起。 例如，我们可以在终端某个目录中通过 code 命令以命令行的形式打开 VS Code，也可以在资源管理器中通过右键直接通过终端打开一个目录。 VS Code 终端放进了工作台从而避免在编辑器和终端间切换，集成终端支持同时打开多个终端操作并以多种方式排列。 由于把终端做到了工作台当中，所以我们能把终端的输入输出与快捷键、资源管理器和搜索等各个功能组合到一起。例如无需多次 cd 到某一个目录直接在资源管理器打开；在终端中点击文件直接在 VS Code 中编辑；当终端输出内容（例如报错信息）包括链接或者文档路径时，VS Code 会自动识别并可以直接点击打开链接和文件。 远程模式 一些小型的计算和开发可以在本机完成，如果涉及到大型计算或者部署就需要在服务器上操作。VS Code 提供的远程模式可以让我们在本机轻松连接其它开发环境，目前官方的远程模式支持包括容器、SSH 和 WSL 在内的三种方式。 本部分内容以 SSH 为例进行简要介绍，我们默认需要远程连接的服务器已经开通了 ssh 服务，使用 Windows 时需要首先在 PC 正确安装 Windows OpenSSH Client。 安装 Remote-SSH 插件后，打开命令面板搜索remote ssh。然后找到 Remote-SSH 相关命令，即可以直接选择链接服务器，也可以选择打开配置文件。这里，我们选择打开配置文件进行简单的配置。 在配置文件中可以输入相应服务器名称、 IP 地址、用户名以及端口等信息。写法如下图所示，写好保存即可。 需要连接终端可以在命令面板中执行命令，也可以点击状态栏左下角的连接标志。连接成功后左下角将会显示此前设置的服务器名称。 需要注意的是，插件组件会分别显示在本地和远程中安装的插件，两者是独立的。如果需要在服务端使用 VS Code 要重新安装需要的插件。资源管理器展示的则是服务器中的目录结构，得益于 VS Code 全平台特性，使用起来基本感受不到差异。 代码调试 VS Code 内置支持 node.js ，可以对 JavaScript, TypeScript 进行调试，其它语言则通过第三方插件实现。目前对 PHP, Ruby, Go, C#, Python, C++, PowerShell 等都有很好的支持。 如果想进入调试模式，首先需要点击侧边栏的调制组件打开调试视图，会看到提示打开一个需要被调试的文件。我们以简单的 Python 脚本举例，打开脚本后会自动生成一个名为 launch.json 的调试配置文件。这个文件可以随时修改，定义不同的内容应该如何加载调试。典型的配置如下图所示。 下图为调试界面的主要内容，其中包括当前变量、堆栈和断点等，顶部为执行控制工具栏。 和 IDE 相比，复杂项目的调试是 VS Code 的弱点。由于调试本身由其它插件完成，不同调试器在调试代码时需要的信息各不相同，要自行使用配置文件进行配置。如果你真的对代码调试有更高的需求，可以查阅官方更加详细的说明文档。 或许有用 最后，列举几个可能会让 VS Code 更加顺手的设置。 渲染空格符制表符 通过设置 editor.renderWhitespace: all 可以将所有的空格符、制表符等全部显示出来。有时候空白的地方就是坑。 修改新建文件默认格式 默认配置时，command+n 快捷键可以在编辑器里创建一个新的普通文本文件。如果你是一个把 VS Code 当做文本编辑器用的人，不妨通过 files.defaultLanguage 把新建文档格式设置成 Markdown。 前后光标处跳转 这个功能有些向在 Linux 中快速回到之前目录的操作。ctrl+- 跳转回上一次光标所在位置，ctrl+shift+- 则相反。 自定义快捷键 如果你是从其它 IDE 迁移过来，可能会面临快捷键冲突和缺失的问题。这时可以通过自定义快捷键解决。 例如 R 语言用户在 RStudio 中可以使用 alt+- 一气呵成输入赋值符号 &lt;-，在 VS Code 中必须也可以。 打开 Keyboard Shortcuts 会看到这个快捷键已经被绑定，可以在 json 文件中设置不同情境下新的含义。 点开快捷键配置文件之后不要管左边的内容，直接去右边设置就好，配置方法如图。以后在 R 或者 Rmd 文件里 alt+- 就变成了和 RStudio 一样的快捷键。 关于快捷键自定义的语法，可以查看对应官方文档。 写在最后 以上，结合 VS Code 编辑器入门指南上篇-核心概念与组件 就是对 VS Code 这款代码编辑器的入门介绍。 当我借助这篇两文章再一次梳理了 VS Code 使用场景后突然多了点感慨。在热衷于讨论和标榜 All-in-One 工具的今天，VS Code 轻量快速的软件本体加上开放丰富的插件生态代表了另一种思路，似乎正从某个层面朝着这个方向大步前进。 如果本文没有涉及到你的领域，不妨去插件市场探索一番，万一找到什么有趣的摸鱼神器呢？ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-04-21-usevscodepart2/"},{"title":"VS Code 编辑器入门指南上篇-核心概念与组件","content":" 本文收发于「少数派」 写在前面 如果当电脑只能装一个软件还需要尽量不影响日常学习工作时，不知道你的选择会是什么。我把这个看似「荒诞」的问题理解为「All-in-One」的升级版拷问。 这个问题陪伴了我很久，每用一个软件我都会想想它对我究竟有多不可代替，然后决定是否继续用下去；当决定深度使用后，我就会问自己它能在多大程度上帮助我完成日常的学习和工作。截至这篇文章完稿，如果我的电脑只能装一个软件还要做到基本不影响日常学习工作，我的选择是 VS Code。 参考之前写过的 文献管理工具 Zotero 入门指南，本入门指南将从 VS Code 特点出发，介绍入门 VS Code 必须了解的核心概念和组件（上篇）以及 5 个 VS Code 实际使用场景（下篇）。希望对想了解和学习 VS Code 的读者能有一点帮助和启发，下文是该入门指南的上篇。 什么是代码编辑器 如果此前对「代码编辑器」没有任何概念，我们可以和文本编辑器（写作工具）进行类比，就是为了更好更方便进行代码编写开发的工具。 提到代码编辑器，不少「工龄」较长的程序员第一反应都会是 Notepad++，这款代码编辑器发布于 2003 年并更新至今，非常经典。因为使用惯性和轻量的特点它目前依旧很受欢迎。不过在 2020 年的今天，有更多好用的代码编辑器值得向你推荐。目前比较受欢迎的代码编辑器主要有 VS Code、Atom 和 Sublime text 。它们各有特点也都有不少死忠粉，新手在初期都可以尝试。 另外你或许还经常人提起 IDE(Intergreated Development Environment)，和代码编辑器相比 IDE 更关注开箱即用的体验、对代码的智能理解和对大型项目的支持，因此相对「笨重」；代码编辑器则更加轻量，侧重于文件，对于语言和工作流的支持也更自由。 为什么选择 VS Code Visual Studio Code（简称 VS Code）是一个由微软开发，同时支持 Windows 、 Linux 和 macOS 等操作系统且开放源代码的代码编辑器，它支持测试，并内置了 Git 版本控制功能，同时也具有开发环境功能，例如代码补全（类似于 IntelliSense）、代码片段和代码重构等。该编辑器支持用户个性化配置，例如改变主题颜色、键盘快捷方式等各种属性和参数，同时还在编辑器中内置了扩展程序管理的功能。 ——维基百科 瑞士计算机科学家 Erich Gamma （《设计模式》作者、 Eclipse 主要开发者之一） 2011 年从 IBM 来到微软后起初负责组建团队开发一款线上开发工具（Manaco），后来他们在这个工具的基础上开发了如今的 VS Code 并于 2015 年发布。VS Code 定位为一个 高性能轻量级的编辑器，为了保证主进程的稳定，插件系统运行在主进程之外，所有个性化功能都由插件系统完成，在 IDE 和编辑器之间找到一个比较理想的平衡。 在微软所有开源项目中，VS Code 是目前最受欢迎的一个。经过不同工具之间的比较，我最终选择 VS Code 的原因包括： 完全免费且开源，更新迭代稳定 跨平台编辑器，满足日常在不同系统中的使用 占用系统资源比较少，大文件打开速度快 插件丰富，扩展性极强 使用人数多且社区活跃，碰到问题和需求容易找到解决方案 从 0 到 1 开始使用 VS Code 下载与安装 VS Code 有两个不同版本：稳定版（Stable）每月更新；预览版（Insiders）每个工作日更新。两个版本可同时安装互不影响，在 官网 即可选择自己需要的平台和版本，本文使用的版本为稳定版 1.44.1。 客户端安装完成后，如希望通过终端启动 VS Code，可以按下 shift+command+p 调出命令面板，在搜索框内输入shell command 后找到并点击「Shell Command: Install 'code' command in PATH」即可。 VS Code 默认是英文界面，这里并不建议把默认语言修改为中文，因为在学习大量英文相关教程和说明时使用英文界面或许更容易操作。另外，VS Code 绝大多数插件都没有汉化，使用起来会中英混杂。 如果需要使用中文，依旧可以通过 shift+command+p 调取命令面板，然后在搜索框中输入 display 找到并点击「Configure Display Language」，这时会显示目前可以选择的语言或者安装其它语言。选择「Install additional languages...」后会跳转到相关语言插件，选择中文语言包安装并进行安装。安装完成后再次找到「Configure Display Language」后选择「zh-cn」后重启即可。 欢迎界面 打开 VS Code 后，未修改默认配置的情况下首先会看到「欢迎页面」。如下图，欢迎页面有五部分内容。首次使用不妨先花点时间浏览「学习」部分内容，其中交互式演练场（interactive playground）是新手了解 VS Code 好资料。 VS Code 主题与图标 在个性化设置部分点击「Color theme」可以选择一个你喜欢的主题。 除了主题之外，你还可以为 VS Code 选择一套自己喜欢的文件图标。点击左下角的「设置」图标，选择「file icon theme」。 然后选择「Install additional File icon theme...」会弹出可以安装的 icon 插件列表，例如 Material Icom Theme，点击安装后选择使用即可。 核心概念与组件 上面这张图展示了默认配置情况下 VS Code 的基本界面。 编辑器：在这里码字写代码 侧边栏：可以类比为 macOS 的扩展坞，姑且称为「组件坞」，这里会展示各种组件和插件图标。 组件内容：击侧边栏不同的组件后这里会展示相应显示组件内容。 面板：包括问题显示、输出、调试控制台和终端四个组件。问题面板会显示代码中的警告和问题，输出面板会呈现命令和插件的运行结果，调试控制台用来进行代码调试，终端则可以帮助我们直接在 VS Code 中进行命令行操作。 状态栏：可以类比为 macOS 的菜单栏 + 通知中心，这里会展示和文档及项目相关的简单信息以及部分插件提供的信息。 侧边栏及常用组件 默认情况下，侧边栏显示的五个组件分别是：资源管理器、跨文件搜索、源代码管理、启动和调试和扩展管理。随着后期安装插件的增多，侧边栏可以显示的组件数量也会越来越多，不过你可以通过右击侧边栏选择隐藏那些用不到的组件还可以拖动组件图标进行排序。 侧边栏显示的默认组件中「资源管理器」和「跨文件搜索」就是字面功能，分别用来浏览管理文件和进行内容查找替换，我们会在下篇中配合具体应用场景进行更详细的介绍。源代码管理和调试分别用于 git 一系列操作和 debug，如果你并非程序员，没有这方面的需求也可以选择将其隐藏。 扩展管理及插件 这一部分需要详细介绍「扩展管理」组件和「插件」这个概念。 如文章开头所言，VS Code 中为了保证主进程的稳定所有个性化功能的实现都将通过插件来完成，在下文的应用场景部分我们也会用到大量插件。我们可以把插件理解为 macOS 中的应用，而扩展管理则是 VS Code 的应用商店。 如上图，在组件显示部分可以看到已经安装的插件和推荐插件，所有你想找的东西都可以尝试在搜索框进行搜索。点击感兴趣的插件后会显示插件详情，其中包括详细介绍、作者和更新日志等内容。 需要说明的是，由于 VS Code 的扩展插件数量实在过于庞大，在浏览插件的时候系统已提供了一些过滤操作，点击 ··· 可以选择只查看安装的插件或者流行的插件等等。 更方便的是你还可以直接在插件搜索框中输入 @ 来进行快速过滤。 为了更方便的找到需要的插件，VS Code 支持按照类别进行查找，目前支持的类别如下图所示，包括语言支持、代码片段和主题等。 目前在官方的插件商店中，我们可以看到共有 12 类 20000 余款插件。如果你想开发自己的插件，可以进一步参考官方插件 API 。 命令面板 VS Code 作为一个代码编辑器，它本身有两个比较极客的设计思想。一个是基于文本（命令）的交互界面，另一个是基于文本的系统设置。基于文本的交互界面就是这里提到的命令面板，系统设置将会稍后介绍。 命令面板的存在提供了一种全新的使用逻辑，熟练使用后可以极大提高效率，因此对命令面板有基本了解是上手 VS Code 的关键。其实在上文安装命令行启动以及设置中文支持时我们都用过它，shift+command+p 就是调用命令面板的一种基本方式。 命令面板的高效在于其可以通过输入框中的第一个字符来触发不同功能。 如下图所示，当你按下 shift+command+p 时，命令面板的输入框会自动出现一个 &gt; 它意味着此时命令面板认为你想要搜索相关命令并执行。 当删除 &gt; 后会看到命令面板切换到了「访问最近文件」状态。如果你想在调用命令面板时直接访问最近文件，快捷键是 command+p。 如果此时输入 ? 会触发命令面板的「帮助」功能，我们可以看到支持哪些操作。下图中显示的切换文件、&gt;执行命令、@符号跳转等我们在后续的应用场景中都会提及。其他单词缩写也代表了对应的操作，例如edt接空格可以管理打开的编辑器，term接空格可以打开或管理终端。 修改设置 在下篇介绍中，我们会涉及到更改默认设置的内容，因此有必要了解 VS Code 更改设置的方法。 VS Code 目前已经有了比较完善的图形化设置界面，只需要使用 command+, 就可以调用。 如上图所示，设置面板已经列出了用户常用配置内容，你可以寻找自己想要改变的东西，但是这里更加推荐直接在搜索框里搜索。此外，VS Code 的配置分为用户（User）和工作区（workspaces）两个层级，其中用户配置会对全局生效，工作区配置只会对当前所在的项目（目录）生效且优先级更高。 除了图形化界面以外，VS Code 的所有配置其实都写在 json 格式的一个文本文件中。你可以非常方便的调出该文件进行设置，只需要在命令面板中输入open sett 然后选择 JSON 即可。如果是针对工作区的设置，json 文件将会保存在工作区.vscode目录下。 在 json 文件中，你可以直接编写设置，也可以点击行号前的「笔形」图标查看可以更改的内容。之所以有必要了解如何通过配置文件更改设置是因为部分插件提供的复杂设置只能通过修改 json 文件完成。 工作区 工作区（workspace）是另一个需要了解的核心概念，它对应在 VS Code 中如何进行文件管理。 上文我们提到相比于 IDE 着重于项目管理，代码编辑器更加侧重于文件本身，VS Code 所有操作就是基于当前目录、子目录和其中的文件进行的。在下篇内容中我们会讲到很多操作和插件都会基于所在目录生成相关的配置文件，而这些文件通常都会被保存到所在目录的.vscode文件夹中。.vscode 文件夹中的各种配置决定了不同目录被打开时 VS Code 会启动哪些插件和配置。 随着项目逐渐发展，单一文件夹往往无法满足我们的开发需求，VS Code 通过工作区这个概念解决了同时操作多个文件夹的问题。简而言之，当你使用 VS Code 打开一个文件夹后可以在命令面板中搜索运行 add folder to workspace，然后选择想要打开的其它文件夹，此时就会显示一个尚未保存的工作区。 当所有文件夹添加完成后在命令面板执行 save workspace as 选择我们的工作区名字和要保存的位置，就可以对该工作区进行保存。 这时我们会看到一个名字后缀为code-workspace的文件，其本质依旧是一个 json 格式的配置文件。其中包括了文件夹的相对路径以及针对工作区的其它设置。 此外，记住两个目录切换的快捷键也会大大提高效率，ctrl+r 可以快速查看并切换最近打开的文件夹，ctrl+w 则可以快速在所有打开的 VS Code 窗口中进行切换。 语言支持 作为一个代码编辑器，VS Code 提供了统一的 Language Server Protocol 和 Code Debugging Protocol API，所有语言支持都能够借助这两个 API 在 VS Code 上得到类似 IDE 的开发和调试体验。 程序员可能最关心的内容就是对编程语言的支持，但初学者最不需要担心的其实也是这部分内容。到目前为止常用的主流编程语言在 VS Code 中都得到了很不错的支持，你需要的往往只是安装对应语言插件和进行一点基本配置。这些语言包括基础的 Markdown 和 JSON，以 HTML、CSS 和 JavaScript 为代表的多种前端语言和以 Python、Java、Go、C#、PHP 等为代表的大量后端语言。对于一些在程序员群体中相对使用人数较少的编程语言，例如 R 和 Julia 等也都有插件提供支持。下图为官网展示的几个流行语言插件。 如果想查看自己使用的编程语言是否支持，可以在插件商店中查找。此外，当你用 VS Code 打开一个文件时，系统会根据文件名后缀自动提示你安装与之相关的语言插件，非常方面。 这一部分我们也会在下篇中结合具体的应用场景进行介绍。 常用快捷键 提倡使用使用快捷键，主要目的是提高效率尽量让双手不离开键盘。快捷键的使用开始看似是一件更浪费时间的事情，但是随着肌肉记忆和熟练度增加效率将会大大提高。 如果你是从其它编辑器切换到 VS Code 完全可以移植之前熟悉的快捷键配置，比如 Vim, Atom 或者 sublime。如果是一个新手，下图是我自己日常用到的 VS Code 高频快捷键，供参考。 如果需要查看所有快捷键，可以通过 ctrl+K ctrl+s 进入快捷键设置界面或者直接查看官方文档。 windows 快捷键 macOS 快捷键 以上就是 VS Code 编辑器入门指南的上篇，我们介绍了什么是代码编辑器、为什么选择 VS Code 、从 0 到 1 开始使用 VS Code 以及上手 VS Code 需要了解的核心概念与组件。有了这些知识储备，我们在下篇中将会介绍 5 个 VS Code 实际应用场景，进而更好的了解 VS Code 的特性和一些有些插件。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-04-21-usevscodepart1/"},{"title":"把 Markdown 模板做成 VSCode 插件","content":"希望它能让你写笔记更方便些 关于 VS code 目前是我的主力代码编辑器，在大多数时候也是我的主力文本编辑器。为了在用 VS code 写文献阅读笔记和读书笔记时更加顺手，我根据自己的阅读和记录习惯整理了一些 markdwon 模板，所谓模板其实就是若干适用于 markdown 的 snippets。为了让有需要的朋友也能用上这些 snippets，我把它们打包成了现在的插件，方便安装与使用。 目前这个插件非常简单，只引入了少数 snippet，但后期会一直升级迭代。主要目的是为了熟悉 VS code 插件的开发及发布流程。 使用方法 本插件在 markdown 文本中会自动触发，目前仅有 5 个模板可以使用。 说明：有部分用户反馈在在 Markdown 文档中 snippet 无法触发，原因可能是 Markdown 文本在默认设置中并没有开启editor.quickSuggestions选项，可以尝试在配置文件中写入如下设置： &quot;[markdown]&quot;: { &quot;editor.quickSuggestions&quot;: { &quot;other&quot;: true, &quot;comments&quot;: false, &quot;strings&quot;: true }, }, 文献精读模板 在编辑器内输入 intensive_reading 会自动出现精读模板提示，摁下 Enter 即可插入模板。因为精读笔记通常一次只读一篇，所以在模板中引入了一级标题，标题为文献精读+当前日期，例如文献精读2019-09-09。 随后的内容包括包括文献信息、文献概述、好词好句、文献笔记和相关文献等内容。且光标首先会定位在标题行后面，输入标题之后直接按下 Tab 键会自动定位在 DOI 处，然后依次定位在发表日期、发表杂志和关键词后，方便输入。 文献泛读模板 在编辑器内输入 extensive_reading 会自动出现泛读模板提示，摁下 Enter 即可插入模板。因为泛读笔记通常一次会读两到三篇，所以在模板中并未引入一级标题，而是使用了二级标题。包括文献信息、关键点、参考意义和相关内容。光标首先会定位在标题行位置，输入标题之后直接按下 Tab 键会自动定位在 DOI 和发表日期对应位置。 KPT 每日工作记录模板 在编辑器内输入 kpt_daily 会自动出现 KPT 每日工作记录模板提示，摁下 Enter 即可插入模板。KPT 三个字母分别代表 Keep、Problem 和 Try。具体含义如下： Keep: 当前你正在做的事，不要过于宽泛 Problem：今日所遇到的问题 Try：你准备明天要尝试的解决方案 Debug 过程记录模板 在编辑器内输入 debug_note 会自动出现 Debug 过程记录模板提示，摁下 Enter 即可插入模板。该模板包括：报错信息、猜猜原因、我的常识、参考资料和解决方案五部分。可以比较好的记录整个 Debug 过程。 建议使用方法为首先复制好报错信息，然后再插入模板，此时光标会自动定位在报错信息下的代码框内，直接复制即可保存报错信息。 闪念胶囊写作素材记录模板 在编辑器内输入 idea_pills 会自动出现闪念胶囊写作素材记录模板提示，摁下 Enter 即可插入模板。该模板包括：话题、灵感来源和写作思路三部分。其中灵感来源是那些让你产生表达冲动的内容，可能是看到一篇好的文章或者和朋友的偶然闲聊。 5 分钟日记模板 0.0.5 版本更新 关于 5 分钟日记模板相关介绍可以查看文章21 天日记挑战-5 分钟日记法。 在编辑器内输入 5min 会自动出现闪念胶囊写作素材记录模板提示，摁下 Enter 即可插入模板。该模版包括 5 分钟日记中涉及到的 5 个问题。 下载地址 Markdown Note Snippets 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-04-18-markdownnotesnippet/"},{"title":"简书这些年","content":"我对简书这个平台的感情很复杂。我 2015 年开始把当时自己的考研复习笔记放到网络上，那个时候意外发现了简书，当时的首页还完全是编辑推荐，需要自己给专题投稿然后如果入了编辑的法眼才有可能会被推荐到首页上。 2016 年我写的一篇英语学习方法的文章在那个时候体量的简书小火了一下，有 2 万多阅读。但是这篇文章在几年前已经被他们自我审核给撤掉了，这也是我开始把文章大量发在自己博客的起因。 在后来那个时间段的简书捧红了几个他们平台的 KOL，就不点名了。也不知道那些人现在怎么样了。那之后我还往简书上同步文章是因为他们的在线编辑器当时是少有的使用体验不错，而且整个网站在百度上的搜索权重也不低。 之后简书经历了几次大改版，弱化编辑改为智能推荐、上线各种会员疯狂铺广告，以及莫名其妙的简书币。今天别人告诉我简书崩了，我登录测试，然后看到了不少评论提醒，评论的画风就变成下图了。 然后我又浏览了一下首页，各种暗示的广告和垃圾文章，那广告恨不得跳出屏幕戳你脸上。又看了看简书的官方专题，看到官方介绍还真是唏嘘。 至此，我觉得应该彻底告别这个地方了，然后登陆微博，取消了当年的「简书推荐作者」身份认证。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-04-08-jianshu/"},{"title":"靠谱熊的每周分享 第4期","content":"刊首语 这周的刊首语随便聊聊几个工具。 传闻微信再次收紧第三方接入服务 有传闻，微信即将关闭公众号文章分享到印象笔记的接口。如果过一段时间这个事情成真了，那应该就是所有第三方服务和 app 都要被微信掐死了。 很多国内的效率类笔记类工具一开始主打功能都包括和微信的整合，比如滴答清单比如印象笔记这类。 之前写分享和教程都会特意留意一下能不能和微信联动一下，最早印象笔记可以存微信群聊天记录，滴答清单可以直接发送任务。后来这些一个一个都没了。 不止一次收到类似于「与其用这用那不如好好研究下微信怎么用」的评论，我研究啥啊，研究私域流量，研究局域网么？ 微信是有提醒功能也能聊天消息收藏转笔记，怎么着，这就是未来的 All in One 工具么 🙃。 从移动办公工具看认知偏差 在「财新周刊」最新一期的杂志中，提到了最近几个远程办公工具的一组数据： 今年 1 月初，钉钉的日活用户数已经在 3000 万量级，是企业微信的 5 倍左右，华为和字节跳动则仍在 10 万量级徘徊。据极光大数据，钉钉从 2 月初的数千万日活已上涨超过 2 亿；腾讯会议从 100 多万升至 1000 多万；企业微信也从将近千万升至 1500 万。飞书和 WeLink 则仍在几十万量级。 原来钉钉现在已经到了这样量级，而我日常在用的飞书根本还是排不上号。但是身边接触的人使用飞书的越来越多，以至于我产生了某种程度的认知偏差。 专业文献 projectR: An R/Bioconductor package for transfer learning via PCA, NMF, correlation, and clustering. Dimension reduction techniques are widely used to interpret high-dimensional biological data. Features learned from these methods are used to discover both technical artifacts and novel biological phenomena. Such feature discovery is critically import to large single-cell datasets, where lack of a ground truth limits validation and interpretation. Transfer learning (TL) can be used to relate the features learned from one source dataset to a new target dataset to perform biologically-driven validation by evaluating their use in or association with additional sample annotations in that independent target dataset. RESULTS: We developed an R/Bioconductor package, projectR, to perform TL for analyses of genomics data via TL of clustering, correlation, and factorization methods. We then demonstrate the utility TL for integrated data analysis with an example for spatial single-cell analysis. AVAILABILITY: projectR is available on Bioconductor and at https://github.com/genesofeve/projectR Genome-phenome wide association in maize and Arabidopsis identifies a common molecular and evolutionary signature Zhikai Liang, Yumou Qiu, James C Schnable Molecular Plant 2020 March 11 Linking natural genetic variation to trait variation can help determine the functional roles of different genes play. Often variation of one or several traits are assessed separately. High throughput phenotyping and data mining can capture dozens or hundreds of traits from the same individuals. Here we test the association between markers within a gene and many traits simultaneously. This Genome-Phenome Wide Association Study (GPWAS) is both a multi-marker and multi-trait test. Genes identified using GPWAS with 260 phenotypic traits in maize were enriched for genes independently linked to phenotypic variation. Traits associated with classical mutants were consistent with reported phenotypes for mutant alleles. Genes linked to phenomic variation in maize using GPWAS shared molecular, population genetic, and evolutionary features with classical mutants in maize. Genes linked to phenomic variation in Arabidopsis using GPWAS are significantly enriched in genes with known loss of function phenotypes. GPWAS may be an effective strategy to identify genes where loss of function alleles will produce mutant phenotypes. The shared signatures present in classical mutants and genes identified using GPWAS may be markers for genes with a role in specifying plant phenotypes generally, or pleiotropy specifically. RASflow: an RNA-Seq analysis workflow with Snakemake. Abstract BACKGROUND: With the cost of DNA sequencing decreasing, increasing amounts of RNA-Seq data are being generated giving novel insight into gene expression and regulation. Prior to analysis of gene expression, the RNA-Seq data has to be processed through a number of steps resulting in a quantification of expression of each gene/transcript in each of the analyzed samples. A number of workflows are available to help researchers perform these steps on their own data, or on public data to take advantage of novel software or reference data in data re-analysis. However, many of the existing workflows are limited to specific types of studies. We therefore aimed to develop a maximally general workflow, applicable to a wide range of data and analysis approaches and at the same time support research on both model and non-model organisms. Furthermore, we aimed to make the workflow usable also for users with limited programming skills. RESULTS: Utilizing the workflow management system Snakemake and the package management system Conda, we have developed a modular, flexible and user-friendly RNA-Seq analysis workflow: RNA-Seq Analysis Snakemake Workflow (RASflow). Utilizing Snakemake and Conda alleviates challenges with library dependencies and version conflicts and also supports reproducibility. To be applicable for a wide variety of applications, RASflow supports the mapping of reads to both genomic and transcriptomic assemblies. RASflow has a broad range of potential users: it can be applied by researchers interested in any organism and since it requires no programming skills, it can be used by researchers with different backgrounds. The source code of RASflow is available on GitHub: https://github.com/zhxiaokang/RASflow. CONCLUSIONS: RASflow is a simple and reliable RNA-Seq analysis workflow covering many use cases. KEYWORDS: RNA-Seq; Snakemake; Workflow PMID: 32183729 DOI: 10.1186/s12859-020-3433-x Benchmarking of computational error-correction methods for next-generation sequencing data Abstract BACKGROUND: Recent advancements in next-generation sequencing have rapidly improved our ability to study genomic material at an unprecedented scale. Despite substantial improvements in sequencing technologies, errors present in the data still risk confounding downstream analysis and limiting the applicability of sequencing technologies in clinical tools. Computational error correction promises to eliminate sequencing errors, but the relative accuracy of error correction algorithms remains unknown. RESULTS: In this paper, we evaluate the ability of error correction algorithms to fix errors across different types of datasets that contain various levels of heterogeneity. We highlight the advantages and limitations of computational error correction techniques across different domains of biology, including immunogenomics and virology. To demonstrate the efficacy of our technique, we apply the UMI-based high-fidelity sequencing protocol to eliminate sequencing errors from both simulated data and the raw reads. We then perform a realistic evaluation of error-correction methods. CONCLUSIONS: In terms of accuracy, we find that method performance varies substantially across different types of datasets with no single method performing best on all types of examined data. Finally, we also identify the techniques that offer a good balance between precision and sensitivity. PMID: 32183840 DOI: 10.1186/s13059-020-01988-3 BANDITS: Bayesian differential splicing accounting for sample-to-sample variability and mapping uncertainty. Abstract Alternative splicing is a biological process during gene expression that allows a single gene to code for multiple proteins. However, splicing patterns can be altered in some conditions or diseases. Here, we present BANDITS, a R/Bioconductor package to perform differential splicing, at both gene and transcript level, based on RNA-seq data. BANDITS uses a Bayesian hierarchical structure to explicitly model the variability between samples and treats the transcript allocation of reads as latent variables. We perform an extensive benchmark across both simulated and experimental RNA-seq datasets, where BANDITS has extremely favourable performance with respect to the competitors considered. PMID: 32178699 DOI: 10.1186/s13059-020-01967-8 Transcriptional regulation of genes bearing intronic heterochromatin in the rice genome. Abstract Intronic regions of eukaryotic genomes accumulate many Transposable Elements (TEs). Intronic TEs often trigger the formation of transcriptionally repressive heterochromatin, even within transcription-permissive chromatin environments. Although TE-bearing introns are widely observed in eukaryotic genomes, their epigenetic states, impacts on gene regulation and function, and their contributions to genetic diversity and evolution, remain poorly understood. In this study, we investigated the genome-wide distribution of intronic TEs and their epigenetic states in the Oryza sativa genome, where TEs comprise 35% of the genome. We found that over 10% of rice genes contain intronic heterochromatin, most of which are associated with TEs and repetitive sequences. These heterochromatic introns are longer and highly enriched in promoter-proximal positions. On the other hand, introns also accumulate hypomethylated short TEs. Genes with heterochromatic introns are implicated in various biological functions. Transcription of genes bearing intronic heterochromatin is regulated by an epigenetic mechanism involving the conserved factor OsIBM2, mutation of which results in severe developmental and reproductive defects. Furthermore, we found that heterochromatic introns evolve rapidly compared to non-heterochromatic introns. Our study demonstrates that heterochromatin is a common epigenetic feature associated with actively transcribed genes in the rice genome. PMID: 32187179 DOI: 10.1371/journal.pgen.1008637 数据库 免费可商用插画素材 插画素材风格多样、质量超高，网站上提供了 80 个免费的插画，可以免费用于个人和商业项目中。 https://lab.streamlineicons.com/ 好书好文 2010 编年史：我们所爱的流行文化们 Astrian 写在 2019 年底的 2010 编年史：我们所爱的流行文化们 最近因为巧合又读了一遍，很多地方都说出了我的感受，但是我并没有能力把过去的 10 年做一个个人化的梳理，因此要再次推荐一下。从一篇文章中能读懂一个人，看到一个人的知识储备。 在文章中他写到这样一段话： 人们彼此相连，却又彼此成为一座座孤岛。我们无法摆脱孤独，正如我们无法摆脱与他人产生联系。 现代百大设计最佳产品。 The greatest designs of modern times 早在 1959 年，美国《财富》杂志就启动了旨在发掘现代 100 种设计最佳产品的行动。该榜单由伊利诺伊理工学院设计研究所所长杰伊·多布林(Jay Doblin)编制，基于对那个时代 100 名顶尖设计师、建筑师和设计教师的调查完成。其结果完美地说明了上世纪中期的设计理念，同时也反映了当代的品味，上榜产品包括保时捷的时尚跑车，甚至还有伊姆斯(Eames)、阿尔托(Alalto)和萨里宁(Saarinen)的更时尚的扶手椅等。 2019 年，为了纪念最初榜单发布 60 周年，《财富》杂志与现由丹尼斯·韦尔(Denis Weil)担任院长的 IIT 设计学院合作，重新创建了这项调查。研究人员尽可能地遵循多布林的方法，并进行了明智的现代调整，就他们认为真正伟大的发明对教育家、有影响力的人、自由设计师和公司设计团队进行民意调查。经过一年多的策划、调查和整理，为我们呈现了“现代百大设计最佳”产品。 https://fortune.com/longform/100-best-designs/ What does it take to become a design icon? There‘s more to it than good looks. These 100 products have made our lives simpler, better, and yes, more stylish. 中文报道：http://reader.s-reader.com/article/f5/3892463.html 学习素材 远程学习怎么学 GitHub 和 juypter https://jupyter4edu.github.io/jupyter-edu-book/ http://tljh.jupyter.org/en/latest/ https://github.blog/2020-03-18-set-up-your-digital-classroom-with-github-classroom/ Resources and tips for teaching (with) R remotely Unix, R and python tools for genomics and data science https://github.com/crazyhottommy/getting-started-with-genomics-tools-and-resources Teaching resources http://rafalab.github.io/pages/teaching.html Bioinformatics Workbook https://bioinformaticsworkbook.org/ https://github.com/ISUgenomics/bioinformatics-workbook 影音推荐 熊言熊语 本周的影音类内容推荐一个私货，「熊言熊语」播客的试播正式上线了。 播客 RSS 地址：https://podcast.kaopubear.top/episodes/feed.xml 「熊言熊语」是一档由 思考问题的熊 主持的播客（podcast）栏目，在双周更新的基础上争取单周更新。目前托管在喜马拉雅，思考问题的熊和他的朋友们一起聊学习聊工作聊生活。 形式 单口：由思考问题的熊一人录制，分享想法观点 访谈：主播+嘉宾的形式，就嘉宾擅长的话题进行访谈 对话：主播+客座主播，就大家关心的内容和话题进行讨论 内容 观点知识：对于某些问题的想法看法，针对文章书籍的学习笔记和评论 专业相关：生物信息（数据分析）相关的内容 学习技能：学习心得方法和生产力工具及技能的介绍 工作生活：聊工作和生活碰到的各种问题和应对方法 订阅 「熊言熊语」目前托管在喜马拉雅平台，你可以通过苹果播客（Podcast）、Google Podcast、Spotify 以及其他泛用型播客客户端进行订阅收听，也可以在喜马拉雅、网易云音乐和 Bilibili 等国内平台搜索收听，还可以在该播客首页直接收听节目。 Creating an R data package (cord19) in RStudio https://www.youtube.com/watch?v=F4oUJp76KUY&amp;feature=youtu.be 介绍如何创建一个 R 的数据包。 工具 Mac 端翻译软件 Bob Bob 是一款 Mac 端翻译软件，翻译方式支持划词翻译和截图翻译，翻译引擎支持有道翻译、百度翻译和谷歌翻译。 RStudio 1.3 Preview: The Little Things https://blog.rstudio.com/2020/03/17/rstudio-1-3-the-little-things/ RStudio 发布了新的预览版本，有几个比价不错的更新，其中比较重要的两个如下： 全局替换：Ctrl_Shift_F （MacOS： Cmd_Shift_F）现在支持了全局替换 Shiny 后台运行：现在可以把 Shiny 放在后台运行了 GitHub 移动 App 正式上线 https://www.jiqizhixin.com/articles/2020-03-18-10 据官方介绍，移动 app 有四个主要的特性功能值得关注。有了这些功能，用户可以在手机上浏览代码、管理工作日程和任务、评价其他工作和项目、合并和管理分支等。 优秀的网页 Markdown 写作工具 介绍三个比较不错的在线写作网站以及他们的特点和问题 https://telegra.ph/ 访问和使用 Telegraph 不需要注册账号与下载软件，只需在网页浏览器中访问 http://telegra.ph/ 便可看到简约的界面，填入要发布的内容即可匿名发布。内容发布之后，只要清除浏览器的缓存，便无法再编辑文章。内容发布之后，不能追溯到文章作者和发布者。类似于一个匿名博客，问题是在国内无法正常访问。 https://wtdf.io/ WTDF.io 与 Telegraph 在编辑体验上类似，编辑器本身提供了字号、字体和背景配色，国内环境可以正常访问，支持富文本导出，分享时也能保证风格和排版不会出现太大的差异。wtdf 同时支持 markdown 和富文本，和 typora 类似。 https://hackmd.io/ 一个台湾工程师开发的即时在线协作 markdown 编辑器，在使用上是一个相对传统的 markdown 编辑器，协作的体验非常好。 Coda 一款主打 No Code 的工具 最近三年 Notion 越来越火了，尤其是过去一年在国内获得了不少关注，其实和它使用体验类似甚至某些层面还更优的并不止一款工具，Coda 就是一个。最近有 一篇文章 介绍了 Coda 的发展历史。 Coda 的核心思想是：在线文档像一块画布，在里面可以添加按钮以及各种控件，文档就变得像一个 app。他们 2014 年开始做，闭门造车做了 3 年才上线；在上线前就融资 $6 千万，估值 $4 个亿。 Coda 同 Airtable、Notion 等工具主导思想都是 No-Code，我们曾经习惯的笔记终将想数据库的形式迈进，在 Coda 看来，未来的软件本质就是文档，或者说在文档里完全可以呈现出一个 APP。 关于 No-code，少数派作者整理了一个Notion 网页有不少信息资料可以参考学习。关于 Coda 的介绍也可以参考少数派中的几篇教程。 共享屏幕且露脸 现在大多数录屏直播或者视频都没有分享者的脸，其实这个问题在游戏直播界很早就有推荐的东西了，也有不错的视频会议工具可以使用，比如 zoom 和 loom。 不过这里要推荐的工具是OBS，OBS 是一个全平台且开源的直播和录播工具，非常强大，可以叠加多个画面，捕捉窗口和屏幕都不是问题。 关于 OBS 的使用介绍和教程 https://obsproject.com/wiki/ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-03-22-weeklyshare4/"},{"title":"靠谱熊的每周分享 第3期","content":"刊首语 本周想分享一个「汉隆剃刀」经验法则：能解释为愚蠢的，就不要解释为恶意。 Hanlon's Razor: 'Never attribute to malice that which can be adequately explained by stupidity.' 这句话究竟是谁说的，汉隆究竟是谁，似乎也不太可靠了，想看比较可信度源头可以参见 Wikipedia。 之所以我们感觉这个世界充满了恶意，很大一部分原因是因为我们理解错了这个世界。潜意识里，我们每个人都会以自我为中心思考问题，最常见的一个句式就是「他问什么这么对我」，但现实是每个人都是一个平行的个体。 @Matthew Cook 汉隆剃刀说的「愚蠢」，代表各种无知的、偶然的、非故意的的原因，这些情况发生的可能性远远大于恶意。彼此熟悉的人，突然对你产生恶意的可能性很小，不熟的人也没什么理由对你产生恶意。 这里的愚蠢不仅仅是指「笨」，可能是忘了、错了、误会了、累了或者有事耽误了。并不是这些人恨你，不喜欢你，还是前面说的，这个世界并非以你为中心，很多人也不会专门针对你。 @Matthew Cook 回到开头，评论一个人或者一件事不是坏就是蠢。事后看，往往都不是坏，而仅仅是蠢。 不提别人，可以想一下自己，平时我们有多大的概率会精心设计一件事情，会思考很多其他人之后再做一个决策。通常都是被惯性和情绪驱动，不会想太多。问题在于我们一般意识不到自己的愚蠢，不经意就有了一些让人误解的行为。从另一个角度讲，如果你感觉自己承受了阴谋和恶意，一定要直接交流、小心求证防止误判。 学会和这个世界在某种程度上和解。 专业文献 HisTrader: A Tool to Identify Nucleosome Free Regions from ChIP-Seq of Histone Post-Translational Modifications Yifei Yan, Ansley Gnanapragasam, Swneke Donovan Bailey Motivation: Chromatin immuno-precipitation sequencing (ChIP-Seq) of histone post-translational modifications coupled with de novo motif elucidation and enrichment analyses can identify transcription factors responsible for orchestrating transitions between cell- and disease-states. However, the identified regulatory elements can span several kilobases (kb) in length, which complicates motif-based analyses. Restricting the length of the target DNA sequence(s) can reduce false positives. Therefore, we present HisTrader, a computational tool to identify the regions accessible to transcription factors, nucleosome free regions (NFRs), within histone modification peaks to reduce the DNA sequence length required for motif analyses. Results: HisTrader accurately identifies NFRs from H3K27Ac ChIP-seq profiles of the lung cancer cell line A549, which are validated by the presence of DNaseI hypersensitivity. In addition, HisTrader reveals that multiple NFRs are common within individual regulatory elements; an easily overlooked feature that should be considered to improve sensitivity of motif analyses using histone modification ChIP-seq data. Availability and implementation: The HisTrader script is open-source and available on GitHub (https://github.com/SvenBaileyLab/Histrader) under a GNU general public license (GPLv3). HisTrader is written in PERL and can be run on any platform with PERL installed. DOI: https://doi.org/10.1101/2020.03.12.989228 数据库 REWORK 一个大牛做的效率工具导航，700+ 实用工具，涵盖个人、协作、产品、设计、开发、运营。很有意思。 好书好文 「到处说」是到很多地方去说 上周「人物」的一篇报道被刷屏了，这个事情甚至慢慢的变成了一个有点「泛娱乐」的时间。因为人们一边发平台一边删，逐渐性质就变成了大家抖机灵。我在朋友圈里看到了大量的类似文章，有竖排版的，有变成乐谱的，甚至还有变成 DNA 序列的。 但是不禁一个疑问也随之产生：到处说的地方难道只有微信了么？变出一百个奇奇怪怪的版本都发在微信里，为什么不换个阵地呢？还是我们如今的信息只剩下了微信？ 正如一篇博客提到的 以上可以理解，但下面的不好理解，也容易被忽视：为什么网民的接力「到处说」，仅仅局限在微信中？ 一个公号倒下了，另一个公号站起来，以此类推。但为什么我们的互联网阵地现在只有微信一个了，这是从什么时候开始的？ 现在，微信已经完全等于互联网了吗？差不多是的，就像网民的身份证一样，微信把人们的吃喝玩乐基本上都筐进去了。 人们爱谈微信红利，都希望从中借力，增长自己的产品。而且大势所趋，不是每个人都会自己建网站，也不是每个人都会折腾自己的网络设置来开心上网，也没必要。 如果一个东西没必要，我们确实不应该做。但如果有必要，而且还很重要，我们只是忘了技术实现以及它的名字，那就应该再将它提上日程。 最重要的是，我们要认清，我们不只有一个阵地，也确实需要更多的阵地，集中抱团是最危险的行为，因为这样，对方一个大炮，我们就被轻易消灭了。 snakemake 如何处理大量的文件 流程控制工具 snakemake 如何处理大量的文件，这篇文章提到了一些技巧 如何清理你的 apple 设备，看看官方怎么说 苹果官网更新了设备清理说明，其中提到了是不是可以使用消毒剂。其中说到，其实是可以用酒精来擦屏幕的，比如把酒精喷到无绒布上然后猜猜设备。 关于显示器怎么清理，一般情况下其实就是无绒布+水即可。 首先，断开显示屏与电源、电脑以及所有外部设备的连接。然后使用显示屏随附的布或其他柔软的干布擦拭屏幕上的灰尘。 如果需要另外清洁显示面板或外壳，请使用微湿的无绒软布。避免开口处受潮。不要使用窗户清洁剂、家用清洁剂、喷雾剂、溶剂、氨水、研磨剂或含有过氧化氢的清洁剂来清洁显示屏。 不要使用含有丙酮的清洁剂清洁显示屏的屏幕。请使用屏幕或显示屏专用的清洁剂。切勿将清洁剂直接喷到屏幕上。清洁剂可能会流入显示屏内部，导致损坏。 美股暴跌，什么是「熔断机制」 北京时间 3 月 9 日 21:34 分，标普 500 指数日内跌 7%，触发第一层熔断机制，这是美股史上第二次熔断，交易暂停 15 分钟。此外，巴西基准股指下跌 10％，触发熔断。加拿大股指开跌 7％，为 2008 年以来最大跌幅。欧洲股指同样录得自 2008 年经济危机以来的最大跌幅。 以下内容来自中文维基百科 熔断机制（Circuit breaker / Trading curb）指的是在股票市场的交易时间中，当价格波动的幅度达到某一个限定的目标（熔断点）时，对其暂停交易一段时间的机制。此机制如同保险丝在电流过大时候熔断比较相似，故而得名。熔断机制推出的目的是为了防范系统性风险，给市场更多的冷静时间，避免恐慌情绪蔓延导致市场波动，从而防止大规模股价下跌现象的发生。然而熔断机制也因切断了资金的流通性，同样会造成市场情绪加大，并令市场风险在熔断期结束后继续扩大。 在美国交易时段，熔断机制可以分为三级： 一级市场熔断，市场下跌达到 7%；二级市场熔断，市场下跌达到 13%；三级市场熔断，市场下跌达到 20%。 如果触发一级或者二级市场熔断，且时间是在：美东时间 9：30-15：25(含) 之间，全市场所有股票暂停交易 15 分钟。美东时间 15：25 之后，不暂停交易。另外，如果该交易日为半天交易，则时间分界点为 12：25。全天任意交易时段，如果触发三级市场熔断，全市场停止交易，直至下个交易日开盘。 发布前美股又经历了第二次熔断。 国外新闻媒体应该看些什么 想了解外面的世界就需要看看国外新闻媒体，那么国外媒体应该怎么分类哪些该看哪些不该看呢？这里推荐一篇文章。简单来说就是看下图中绿色框和黄色框里的。 学习素材 Introduction to Data Science 一本介绍数据分析很好的教材，推荐！ Bioinformatics Algorithms An Active Learning Approach Bioinformatics Algorithms 这本书目前已经出到了第三版，其中第二版应该是可以从网络上找到的，第三版目前作者已经在逐步开放，现在前三章都可以阅读。 比较厉害的是这本书配套有一个网站，其中有对应的视频和 FAQ 可以一起学习参考。作者在 coursera 上也有对应的课程。 影音推荐 Super Band 本周的视频分享来自韩国一档综艺节目「super band」超级乐队的一次现场表演，一把六弦贝斯+三把吉他，演奏曲目是 Coldplay 的 Adventure Of A Lifetime。 听了很多遍， 只能说 awesome。 工具 Tools and tricks for a data scientist 生物信息 IP 网红 Ming (Tommy) Tang 最近分享了学习生物信息（数据科学）应该掌握的一些工具和技能。主要涉及到的知识点如下，不知道哪些是你在用的。大部分我也在使用，在此简单罗列和介绍。 Oh-my-zsh!: zsh 配置 Mosh: mobile shell 远程终端后台执行，可以代替 ssh 使用 csvkit：和 csvtk 类似，文本处理工具 body：一个小脚本，处理出 header 以外的所有行 csvtk 爪哥写的命令行工具 GNU parallel：Linux 并行命令 Brename：爪哥写的文件重命名工具 Notion App：笔记类 All-in-on 工具 Hackmd：一个台湾开发者开发的在线协作 markdown 工具，之前我们分享过 Blogdown：使用 Rmarkdown 搭建个人博客 Workflowr：项目结果网页化展示 Docker + rstudio：容器 Snakemake：流程控制工具 crontab：备份命令 讨论 BWA-MEM2 Review: Should You Upgrade? 是否需要升级成 BWAMEM2 呢？前一段时间，序列比对工具 BWA 的升级版本 BWAmem2 更新了一个版本，其中一个内容是完善了的大基因组数据的处理（我之前在分析的时候反馈了一个 issue，这次得到了修正）。不过在主页上还是不建议用于生产环境，目前还处于测试版本。 Readme 中给出了在一些情况下和 BWA-mem 的比较说明。双端无论是使用单线程还是多线程，基本上提速在 1.5-2 倍速。 这里也有一篇测评文章 BWA-MEM2 Review: Should You Upgrade? 大家可以参考。 我使用最新的预编译版本最近进行了一点测试， 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-03-15-weeklyshare3/"},{"title":"非蠢既坏 别这么想","content":"「能解释为愚蠢的，就不要解释为恶意」 现在评论人和事，有一个特别万能的句式：XXX，不是蠢就是坏。 这话是万能且很有力量的，非蠢即坏，用两个字就把所有可能性都包括了。 今天听了一期「精英日课」，里面提到了一个法则：汉隆剃刀。 说到剃刀，大家比较熟悉的应该是「奥卡姆剃刀」，它的意思是「如无必要，勿增实体」，选择最简单的解释来回答问题就好了。 「汉隆剃刀」则是一个经验法则：能解释为愚蠢的，就不要解释为恶意。 Hanlon's Razor: 'Never attribute to malice that which can be adequately explained by stupidity.' 这句话究竟是谁说的，汉隆究竟是谁，似乎也不太可靠了，想看比较可信度源头可以参见 Wikipedia。 之所以我们感觉这个世界充满了恶意，很大一部分原因是因为我们理解错了这个世界。潜意识里，我们每个人都会以自我为中心思考问题，最常见的一个句式就是「他问什么这么对我」，但现实是每个人都是一个平行的个体。 @Matthew Cook 汉隆剃刀说的「愚蠢」，代表各种无知的、偶然的、非故意的的原因，这些情况发生的可能性远远大于恶意。彼此熟悉的人，突然对你产生恶意的可能性很小，不熟的人也没什么理由对你产生恶意。 这里的愚蠢不仅仅是指「笨」，可能是忘了、错了、误会了、累了或者有事耽误了。并不是这些人恨你，不喜欢你，还是前面说的，这个世界并非以你为中心，很多人也不会专门针对你。 @Matthew Cook 回到开头，评论一个人或者一件事不是坏就是蠢。事后看，往往都不是坏，而仅仅是蠢。 不提别人，可以想一下自己，平时我们有多大的概率会精心设计一件事情，会思考很多其他人之后再做一个决策。通常都是被惯性和情绪驱动，不会想太多。问题在于我们一般意识不到自己的愚蠢，不经意就有了一些让人误解的行为。 从另一个角度讲，如果你感觉自己承受了阴谋和恶意，一定要直接交流、小心求证防止误判。 在「精英日课」的文章中提到汉隆剃刀后来又被别人进行了扩展，我也找到了原文： 能解释为愚蠢的，就不要解释为恶意。 能解释为无知的，就不要解释为愚蠢。 能解释为可原谅的错误的，就不要解释为无知。 能用你未知的其他原因解释的，就不要解释为错误。 用一句概括，就是用最大的善意去理解别人。 这个法则可以扩展到日常各种领域，或许也可以包括近期一些我们无法理解的事情。 不方便展开了。 理解践行汉隆剃刀，希望你能减少一些无缘无故的愤怒和压力，改善和别人的关系，和这个世界达成某种程度的和解。 番外：这个「剃刀」在哲学领域非常有意思，各种剃刀理论非常多。 剃刀指的是能指导人们排除（剃掉）一个现象中不太可能的解释或避免不必要行动的一个原则或经验法则 。 与此相对的还有各种反剃刀理论，如果有兴趣，可以再去查查看。 了解更多： https://en.wikipedia.org/wiki/Hanlon%27s_razor https://medium.com/@matthewcook/hanlons-razor-f7fa63e70e9a http://jonathanbecher.com/2017/07/30/you-should-embrace-hanlons-razor/ https://rationalwiki.org/wiki/Hanlon%27s_razor 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-03-07-HanlonRazor/"},{"title":"靠谱熊的每周分享 第2期","content":"刊首语 本周把自己一年多没更新的个人公众号(思考问题的熊)更新了一次，结果很快就有了五十多条留言。 很多人都在反馈自己过去三四年发生和经历的事情，很神奇的感受，看似没有交集但是却也没有断了联系。 不知道你有没有一个自己很久没有留意却突然发现还有人在关注的东西，不妨分享一下。 专业文献 The Bioinformatics Toolbox for circRNA Discovery and Analysis Circular RNAs (circRNAs) are a unique class of RNA molecule identified more than 40 years ago which are produced by a covalent linkage via back-splicing of linear RNA. Recent advances in sequencing technologies and bioinformatics tools have led directly to an ever-expanding field of types and biological functions of circRNAs. In parallel with technological developments, practical applications of circRNAs have arisen including their utilization as biomarkers of human disease. Currently, circRNA-associated bioinformatics tools can support projects including circRNA annotation, circRNA identification and network analysis of competing endogenous RNA (ceRNA). In this review, we collected about 100 circRNA-associated bioinformatics tools and summarized their current attributes and capabilities. We also performed network analysis and text mining on circRNA tool publications in order to reveal trends in their ongoing development.** PMID: 32103237 DOI: 10.1093/bib/bbaa001 circRNA 发展历史 circRNA 分析工具 Quality control and processing of nascent RNA profiling data Experiments that profile nascent RNA are growing in popularity; however, there is no standard analysis pipeline to uniformly process the data and assess quality. Here, we introduce PEPPRO, a comprehensive, scalable workflow for GRO-seq, PRO-seq, and ChRO-seq data. PEPPRO produces uniform processed output files for downstream analysis, including alignment files, signal tracks, and count matrices. Furthermore, PEPPRO simplifies downstream analysis by using a standard project definition format which can be read using metadata APIs in R and Python. For quality control, PEPPRO provides several novel statistics and plots, including assessments of adapter abundance, RNA integrity, library complexity, nascent RNA purity, and run-on efficiency. PEPPRO is restartable and fault-tolerant, records copious logs, and provides a web-based project report for navigating results. It can be run on local hardware or using any cluster resource manager, using either native software or our provided modular Linux container environment. PEPPRO is thus a robust and portable first step for genomic nascent RNA analysis. Publisher URL: http://biorxiv.org/cgi/content/short/2020.02.27.956110v1 DOI: https://doi.org/10.1101/2020.02.27.956110 PAREameters: a tool for computational inference of plant miRNA–mRNA targeting rules using small RNA and degradome sequencing data MicroRNAs (miRNAs) are short, non-coding RNAs that modulate the translation-rate of messenger RNAs (mRNAs) by directing the RNA-induced silencing complex to sequence-specific targets. In plants, this typically results in cleavage and subsequent degradation of the mRNA. Degradome sequencing is a high-throughput technique developed to capture cleaved mRNA fragments and thus can be used to support miRNA target prediction. The current criteria used for miRNA target prediction were inferred on a limited number of experimentally validated A. thaliana interactions and were adapted to fit these specific interactions; thus, these fixed criteria may not be optimal across all datasets (organisms, tissues or treatments). We present a new tool, PAREameters, for inferring targeting criteria from small RNA and degradome sequencing datasets. We evaluate its performance using a more extensive set of experimentally validated interactions in multiple A. thaliana datasets. We also perform comprehensive analyses to highlight and quantify the differences between subsets of miRNA–mRNA interactions in model and non-model organisms. Our results show increased sensitivity in A. thaliana when using the PAREameters inferred criteria and that using data-driven criteria enables the identification of additional interactions that further our understanding of the RNA silencing pathway in both model and non-model organisms. Publisher URL: https://academic.oup.com/nar/article/48/5/2258/5707202 DOI: https://doi.org/10.1093/nar/gkz1234 数据库 R 社区的发展探索 https://benubah.github.io/r-community-explorer/rugs.html 该页面总结了 R 语言近年来社区的发展情况，女性用户的分析以及历届 Google Summer of Code 中 R 相关的项目。 好书好文 R 的 20 年 最近有 一篇文章 从三个纬度介绍了 R 这 20 年的发展。 R 在这些年里发展速度有多快 2000 年以来发布了多少个 R 包 包的下载量如何增长 10 个节省时间的 R 操作技巧 Keith McNulty 总结了可以节省时间的10 个 R 操作技巧 Downloading and reading files straight from source Storing your credentials for regular use RStudio’s shortcut keys Global chunk options in RMarkdown Easy pasting of ggplots with the patchwork package Smoother dependency management using Renv Multitask with RStudio’s Jobs Rename all variables in scope Using . to keep piping Immediately invoked display Mac 触控板 ForceTouch 可以做什么 9to5mac 发布了一篇关于的教程，介绍了Mac 触控板 ForceTouch 可以做什么，包括如何设置 ForceTouch 以及哪些应用可以使用 ForceTouch。 学习素材 lncRNA 定量注意事项 关于如何定量 lncRNA，19 年有一篇发表在 Gigascience 的文章进行了不同方法的测试，整体的结论如下： Pseudoalignment methods and RSEM detect more lncRNAs and correlate highly with simulated ground truth. On the contrary, HTSeq and featureCounts often underestimate lncRNA expression. Antisense lncRNAs are poorly quantified by alignment-based gene quantification methods, which can be improved using stranded protocols and pseudoalignment methods. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6897288/ 伪比对方法和 RSEM 检测到更多的 lncRNAs，反义 lncRNAs 通过基于比对的基因量化方法难以量化。关于这个问题在 GitHub 有一个简单的讨论：https://github.com/alexdobin/STAR/issues/848 Canadian Bioinformatics Workshops https://bioinformaticsdotca.github.io/ Canadian Bioinformatics Workshops 旗下的生物信息教程合集基本上所有内容都可以公开获取 ggplot2 教程合集 Erik Gahner Larsen 整理了目前可以找到的 ggplot2 相关教程合集 awesome-ggplot2 各个角度的教程都有，可以学习。 ggplot2: Elegant Graphics for Data Analysis Hadley Wickham 主编的第三版 ggplot2 教程已经在路上了，服气。 影音推荐 理解 RNAseq 是如何工作的 这个简短的视频说明了 RNAseq 是如何工作的，以及如何研究中使用它。Jose Manuel Garcia Manteiga 解释了如何有效地设计 RNAseq 实验以及可以从这项技术中获得的结果。 十分钟的视频把转录组分析相关内容的方方面面今本都涉及到了，很喜欢这样的讲课方式。如果有机会做一些类似的小视频就好了，不过机会在哪呢 ╮(￣ ▽ ￣)╭ (我从油管做了一个搬运放到了 B 站，嵌入了英文字幕） 工具 Datawrapper https://www.datawrapper.de/ Datawrapper 是一种简单的可视化工具，无需编程基础。大量的媒体和记者都在使用这个工具进行数据的可视化，官方也提供了详细的教程。 如何使用 datawrapper https://academy.datawrapper.de/ AntV 和语雀出自同一家，AntV 是蚂蚁金服全新一代数据可视化解决方案，致力于提供一套简单方便、专业可靠、无限可能的数据可视化最佳实践。近日其 G2 正式发布了 4.0 版本。 https://antv.vision/zh 技巧 微信双开 微信这个让人又恨又不得不用的东西，有时候不仅不得不用，可能一次还得用两个。这里就涉及到了微信双开的问题。在 android 系统上，现在多数国产厂商都适配了微信双开。至于 Windows 和 macOS 其实也都有自己的方法（其实都是命令行启动），供各位参考。 Windows 上的使用方式就是以极快的速度连续点击微信图标有两种思路，我比较喜欢的是在微信安装目录新建一个 bat 文件，里面写两行 start WeChat.ext 。在把这个文件做一个快捷方式到桌面。也可以直接写绝对路径，把文件直接放到桌面。 macOS 本身是利用 nohup 命令让微信进行后台运行，如下所示，原则上，这种方法可以同时开启 N 个微信。 nohup /Applications/WeChat.app/Contents/MacOS/WeChat &gt; /dev/null 2&gt;&amp;1 &amp; 订阅 该周刊每周六发布，暂时作为「素材分享学习小组」内部资料，我们会挑选部分内容进行公开分享。 完成前期测试运行后将择期通过博客和公众号等形式同步更新，届时将发布具体的订阅形式。 交流 如果想要加入「素材分享学习小组」可以参考申请说明，如果想和我们交流，欢迎在评论区留言，我们下周见！ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-03-06-weeklyshare2/"},{"title":"R 的 20 年","content":"最近有一篇文章从三个纬度介绍了 R 这 20 年的发展。 R 在这些年里发展速度有多快 2000 年以来发布了多少个 R 包 包的下载量如何增长 我提取一些结果和大家分享。 测试 R 的运行速度 作者使用了一段测试代码： col_len &lt;- function(n) { len &lt;- 0 while (n &gt; 1) { len &lt;- len + 1 if ((n %% 2) == 0) n &lt;- n / 2 else { n &lt;- (n * 3 + 1) / 2 len &lt;- len + 1 } } len } res &lt;- lapply( 1:10, function(i) { gc() system.time( max(sapply(seq(from = 1, to = 999999), col_len)) ) } ) 运行时间如下图所示 2000 年 2 月: 第一个 R 版本超过 17 分钟，1.0.0 2002 年 1 月: 1.4.1 版本带来了巨大的性能提升约为 4.5 分钟 2004 年 10 月: 在版本 2.0.0 只有 168 秒，不到 3 分钟。 2014 年 4 月 -- 10 年后，3.1 版将时间缩短到大约 145 秒 2017 年 4 月-最后，3.4 版本已经看到了另一个显著的性能提升，从这个版本上执行这个计算所需的时间不到 30 秒。 R 包数量的增长速度 在 2000-2004，新发布的包数量不到 100 个 在 2010 中，CRAN 已经看到了 400 多个 2014 年，超过 1000 个包首次发布 在 2017 中，超过 2000 个新包被添加到 CRAN 在 2018 和 2019 中，总 CRAN 释放量超过 10000 R 包的下载量 上面的数字仅代表了许多 CRAN 镜像中的一个，因此包下载的真实数量要高得多，图表的信息价值主要在增长: 2013 年 1 月有大约 110 万个 2015 年 1 月 770 万 2017 年 1 月 2690 万 2020 年 1 月超过 1.28 亿次下载 原文地址：https://jozef.io/r921-happy-birthday-r/ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-02-29-r20years/"},{"title":"靠谱熊的每周分享 第1期","content":"刊首语 在「素材学习分享小组」进行的第二个年头，为了让它能再向前走一小步，我们决定以电子杂志的形式发布「素材学习分享周刊」。 每期都会有一位小组成员作为轮值编辑为大家奉献一期内容，同时也作为小组成员的阶段性考核。**我们会提前一周提醒轮值编辑，如果断更则基本会取消下一阶段小组成员资格。**每位轮值编辑对自己当期的内容持有版权，可以决定除小组分享外是否公开分享，亦可发布在自己的博客或者公众号等个人平台。 当然，如果不是轮值编辑仍然可以记录自己的分享内容，只需要在题目最后增加你的个人 ID 即可。除了清退机制，我们也在思考如何引入奖励机制或成就值。分享的内容越多，在小组的成就值也就越高。 周刊的分享和发布形式都受到了阮一峰「科技爱好者周刊」的启发，在此表示感谢和敬意。 在以后的每期内容中，轮值编辑都会向大家推荐自己的心头好，其中包括但不限于和专业相关的科研文献、近期读到的书籍文章、值得学习的资料素材、自己喜欢的电影音乐和好用的应用工具等等。 希望这些内容可以记录彼此的成长，留住易逝的时光。 思考问题的熊 2020 年 2 月 28 日 专业文献 Regulation of Rice Tillering by RNA-directed DNA Methylation at Miniature Inverted-repeat Transposable Elements Molecular Plant 2020 February 19 PMID: 32087371 DOI: 10.1016/j.molp.2020.02.009 Tillering is a major determinant of rice plant architecture and grain yield. Here we report that depletion of rice OsNRPD1a and OsNRPD1b, two orthologues of the largest subunit of RNA polymerase IV, leads to a high-tillering phenotype, in addition to dwarfism and smaller panicles. OsNRPD1a and OsNRPD1b are required for the production of **24-nt siRNAs **that direct DNA methylation at transposable elements (TEs) including Miniature Inverted-repeat TEs (MITEs). Interestingly, many genes are regulated either positively or negatively by TE methylation. Among them, OsMIR156d and OsMIR156j, which promote rice tillering, are repressed by CHH methylation at two MITEs in the promoters. By contrast, D14, which suppresses rice tillering, is activated by CHH methylation at a MITE in its downstream. Our findings reveal control of rice tillering by RdDM at MITEs and provide potential targets for agronomic trait enhancement by epigenome editing. 水稻分蘖是水稻结构和产量的主要决定因素。这篇文章揭示了 RNA 介导的 DNA 甲基化（RdDM）在 MITE 这个类型的转座子上可以分别正向和负向调节 D14 和 OsMIR156 家族成员，从而促进水稻分蘖的调节。 Robustness and applicability of transcription factor and pathway analysis tools on single-cell RNA-seq data Genome Biology 2020 February 12, 21 (1): 36 PMID: 32051003 DOI: 10.1186/s13059-020-1949-z BACKGROUND: Many functional analysis tools have been developed to extract functional and mechanistic insight from bulk transcriptome data. With the advent of single-cell RNA sequencing (scRNA-seq), it is in principle possible to do such an analysis for single cells. However, scRNA-seq data has characteristics such as drop-out events and low library sizes. It is thus not clear if functional TF and pathway analysis tools established for bulk sequencing can be applied to scRNA-seq in a meaningful way. RESULTS: To address this question, we perform benchmark studies on simulated and real scRNA-seq data. We include the bulk-RNA tools PROGENy, GO enrichment, and DoRothEA that estimate pathway and transcription factor (TF) activities, respectively, and compare them against the tools SCENIC/AUCell and metaVIPER, designed for scRNA-seq. For the in silico study, we simulate single cells from TF/pathway perturbation bulk RNA-seq experiments. We complement the simulated data with real scRNA-seq data upon CRISPR-mediated knock-out. Our benchmarks on simulated and real data reveal comparable performance to the original bulk data. Additionally, we show that the TF and pathway activities preserve cell type-specific variability by analyzing a mixture sample sequenced with 13 scRNA-seq protocols. We also provide the benchmark data for further use by the community.** 转录因子和通路分析工具对于单细胞数据是不是数据，以及有哪些影响，应该怎么用，这篇文章给出了一些介绍。这篇文章也提到了一些我们这方面可以借鉴的工具。 MUM&amp;Co: Accurate detection of all SV types through whole genome alignment Bioinformatics 2020 February 25 PMID: 32096823 DOI: 10.1093/bioinformatics/btaa115 SUMMARY: MUM&amp;Co is a single bash script to detect Structural Variations (SVs) utilizing Whole Genome Alignment (WGA). Using MUMmer's nucmer alignment, MUM&amp;Co can detect insertions, deletions, tandem duplications, inversions and translocations greater than 50bp. Its versatility depends upon the WGA and therefore benefits from contiguous de-novo assemblies generated by 3rd generation sequencing technologies. Benchmarked against 5 WGA SV-calling tools, MUM&amp;Co outperforms all tools on simulated SVs in yeast, plant and human genomes and performs similarly in two real human datasets. Additionally, MUM&amp;Co is particularly unique in its ability to find inversions in both simulated and real datasets. Lastly, MUM&amp;Co's primary output is an intuitive tabulated file containing a list of SVs with only necessary genomic details. AVAILABILITY: https://github.com/SAMtoBAM/MUMandCo 借助 MUMmer 写的一个一千多行的 shell 脚本，用来分析各种 SV，测试了不同物种的分析效果，发到了 bioinformatics。 Small RNAs in the Transgenerational Inheritance of Epigenetic Information Published:January 14, 2020 DOI:https://doi.org/10.1016/j.tig.2019.12.001 In recent years it has become evident that RNA interference-related mechanisms can mediate the deposition and transgenerational inheritance of specific chromatin modifications in a truly epigenetic fashion. Rapid progress has been made in identifying the RNAi effector proteins and how they work together to confer long-lasting epigenetic responses, and initial studies hint at potential physiological relevance of such regulation. In this review, we highlight mechanistic studies in model organisms that advance our understanding of how small RNAs trigger long-lasting epigenetic changes in gene expression and we discuss observations that lend support for the idea that small RNAs might participate in mechanisms that trigger epigenetic gene expression changes in response to environmental cues and the effects these could have on population adaptation. 这篇综述介绍了 smRNA 和表观的关系，推荐大家了解一下。 数据库 *Genome Research *最近发表了一篇 Resource 文章，FANTOM 利用他们已有的数据对人的 lncRNA 数据进行了一次新的综合定量分析。 长链非编码 RNA (lncRNAs) 已经成为生物和细胞过程的关键调控子，在细胞和组织中表征 lncRNA 的表达是理解它们作用的关键。研究者们推出的 FC-R2 是一个转录组相关的综合表达图谱，包括了超过 109,000 个编码和非编码基因。 该图谱极大地扩展了已有的基因注释。我们通过从已发表的大型研究中复制关键发现，并通过在正常和患病的人类样本中产生新的结果，证明了 FC-R2 图谱的实用性。 该图谱有如下几个特点： 确定不同类型编码和非编码基因的组织特异性转录谱 在 13 种癌症类型中进行差异表达分析, 识别潜在参与肿瘤发病和进展的新的非编码基因 确认癌症中几种增强子 lncRNAs 表达的预后价值 相关资料 FANTOM6 Functional annotation of long non-coding RNAs in the human genome recount A multi-experiment resource of analysis-ready RNA-seq gene and exon count datasets Recounting the FANTOM CAGEAssociated Transcriptome 好书好文 如何学会所有编程语言 应该从哪些方面学习一门编程语言 英文原文：This is How You Can Learn All Programming Languages, Yes - “all” 中文译文：如何学会所有的编程语言？ 一个普通 985 研究生的求职全纪录 我也不是很差劲吧，985 研究生，成绩前 5%，发过论文，拿过国奖，怎么找工作就比不上别人？ https://mp.weixin.qq.com/s/ITOV7cHB-KkEYceWYAw_RA 梁文道、周轶君：为什么“假新闻”总是跑得更快？ 弹指之间就能获得大量讯息的今天，自然也伴随着漫天飞的截图、谣言、推测、和评论。这时，真相真的离我们更近了吗？我们该如何获得真相？新闻、媒体、平台与我们的关系又有了哪些改变？ https://mp.weixin.qq.com/s/h-rkTyJ12Kn4olVYhegUSQ 学习素材 如何使用 R 制作 PPT 前天收到了教育中心负责老师的微信，她说我之前作为助教带的一些学生这两年也陆续在当助教，这一届的助教有人推荐了我当时上第一节课的时候使用的 PPT，问我能不能贡献出来给他们参考一下。这就想起了当时用 R 做 PPT 的经历。这几天又看到了一个不错的介绍 地址 https://arm.rbind.io/slides/xaringan.html 影音推荐 北京时间 2 月 25 日凌晨，科比-布莱恩特追思会“生命的礼赞”在斯台普斯中心举行。科比遗孀瓦妮莎首次公开亮相，发表了感人至深的演讲，纪念科比以及两人的女儿吉安娜。迈克尔-乔丹全程流泪演讲，沙奎尔-奥尼尔等也都演讲致敬、怀念科比。 这次推荐两个视频，一个是乔丹此次的演讲，一个是 Jimmy Kimmel 特别节目追忆科比，科比曾经 15 次录制过这个节目。 乔丹回忆科比 Jimmy Kimmel 特别节目追忆科比 工具 文章配图插画制作 itg digital 关于文章配图，推荐过几个比较不错的插画网站，这次推荐的工具支持对不同的元素进行自定义的组合。可以根据自己的需求更改元素、样式和颜色。jpg 格式内容的下载免费。 地址 https://app.itg.digital/ 给我印象很深的是他的加载动画，是一只小狗向前走，然后越走自己的身体越长，如果你的网速不理想就可以看到一只加长小狗～ 讨论 本周我遇到了两个比较有趣的问题，一并记录下来和大家分享。 富集分析用哪些基因 第一个问题是 转录组分析中，常常把上调表达基因和下调表达基因分别进行 GO 分析和 Pathway 富集分析，为什么不是放在一起进行 GO 和 Pathway 分析呢？上调下调的不同基因可能是同一种功能或者同一个通路的，整体分析不是能更全面的找出真正差异的功能或者通路了吗 我的回答： 这个问题很有意思，首先要不要把差异基因上调和下调分别进行 GO 和 Pathway 分析本身是没有定论的，上调下调不同基因当然可能是同一种功能或者同一个通路的。如果 KEGG 的一个通路里本身有抑制性的基因也有促进性的基因，那么使用所有表达差异基因去分析就是合理的。 但是 2013 年曾经有一篇文章专门研究了这个问题，他们使用了 5 种肿瘤的芯片和转录组数据集进行了分析，研究的结果是具有相关功能的基因在表达水平上往往是正相关的，这也就导致特定通路上某一类基因的比例是失衡的，不恰当的具体例子可以理解为一个通路上 100 个基因，可能有 80 个都是在一种处理中上调表达，而只有 20 个是下调表达的。 Hong G, Zhang W, Li H, Shen X, Guo Z. Separate enrichment analysis of pathways for up- and downregulated genes. J R Soc Interface. 2013;11(92):20130950. Published 2013 Dec 18. doi:10.1098/rsif.2013.0950 这种不平衡导致如果使用全部差异基因进行富集分析的统计学检验时会显著降低统计检验效力，在他们检测的 5 种肿瘤数据中，对上调和下调的基因进行单独分析可以确定与表型差异真正相关的更多通路。 这里就出现了一个富集分析的缺点，所谓上调基因和下调基因是不同处理下的相对表达量而言的，但是仅凭 KEGG 里的「富集」就把上调理解为对通路的激活，把下调理解为对通路的抑制是不合适的。 此外，富集分析通常用的都是 Fisher 精确检验或超几何检验来验证相关基因在背景中的比例是不是足够多，这里怎么定义上下调的倍数本身也存在很多争议，也就是为什么要引入某种程度上更有意义的 GSEA 分析。 当然，之前也有过一些其它的分析思路，但是都是发了文章没有人用。 Warden C D, Kanaya N, Chen S, et al. BD-Func: a streamlined algorithm for predicting activation and inhibition of pathways[J]. PeerJ, 2013, 1: e159. Malathi S.I Dona, Luke A Prendergast, Suresh Mathivanan, Shivakumar Keerthikumar, Agus Salim, Powerful differential expression analysis incorporating network topology for next-generation sequencing data, Bioinformatics, Volume 33, Issue 10, 15 May 2017, Pages 1505–1513, https://doi.org/10.1093/bioinformatics/btw833 RNA 和蛋白质的关系 有没可能 mrna 没有高表达，但是蛋白高表达。即使发生了也没法解释吧？ 我的回答 mRNA 和对应蛋白质的关系比较复杂，比如转录后修饰和 miRNA 起作用等等，这个推荐一篇研究二者关系的文献，16 年发表在 cell 上 Liu Y, Beyer A, Aebersold R. On the Dependency of Cellular Protein Levels on mRNA Abundance. Cell. 2016;165(3):535–550. doi:10.1016/j.cell.2016.03.014 订阅 该周刊每周六发布，暂时作为「素材分享学习小组」内部资料，我们会挑选部分内容进行公开分享。 完成前期测试运行后将择期通过博客和公众号等形式同步更新，届时将发布具体的订阅形式。 交流 如果你想要加入「素材分享学习小组」可以参考申请说明，如果想和我们交流，欢迎在评论区留言，我们下周见！ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-02-28-weeklyshare1/"},{"title":"停课不停学 推荐 7 门有趣实用的线上课程","content":" 本文首发于「少数派」 由于新型冠状病毒感染肺炎疫情的持续，从最新通知来看很多高校返校时间已调整为二月底，不少公司的线下上班时间也推后到 2 月 14 日。无论是微博还是微信朋友圈，不少人都纷纷表示又一次开始「喜欢」上课和工作了。 面对这个超长待机的假期学生党该如何度过，其实教育部已经帮大家 安排 的明明白白。在这份说明中，一个重点信息是 面向全国高校免费开放全部优质在线课程和虚拟仿真实验教学资源。 截至 2020 年 2 月 2 日，一共有 22 个在线课程平台共免费开放了 2.4 万余门在线课程，这一消息一度登上了微博热搜。这篇文章就向你推荐面对社会公众开放的 7 门有趣或实用的国家精品课程。 中国大学 MOOC：国家精品课程平台 中国大学 MOOC是由网易与高教社共同推出的在线教育平台，承接教育部国家精品开放课程任务，向大众提供中国知名高校的 MOOC 课程，可以说是中国在线课程平台的领头羊。自 2014 年正式上线以来，目前平台运行着 8000 余门课程，其中包括国家精品在线开放课程 916 门。除了免费的高校课程，目前也延伸出了付费专栏和针对各种考试的付费培训课程等内容。 中国大学 MOOC 中的高校课程按照期数开课，每门课程可能存在「正在开课」和「即将开课」两种状态，正在进行中的课程可以直接加入，如果想按照课时进度学习也可以选择「报名下一次开课」。通常完成课程要求的作业并通过线上考试即可获得相应等级的结课证书。 对于往期课程，有些老师会选择关闭课程有些则不会，如果你只想学习课程内容完全可以选择查看尚未关闭的往期课程。接下来要推荐的内容全部都可以通过这个平台在线学习。 宇宙简史 宇宙有多大？它从何而来又将归向何处？古老而又神秘的宇宙始终激发了人们无限好奇与想象。而宇宙如此广袤，人类又是如何认识和理解它的？“宇宙简史”课程，希望带给大家一次精神旅行，在这里既有知识和智慧的碰撞，也关照历史和人文的视野，更有全人类千百年来勇于探索、追求真理的精神力量的绽放。——官方课程介绍 「宇宙简史」这门课程的老师是南京大学天文与空间科学学院教授、博士生导师李向东。无论是每节课的片头效果还是授课现场的布置，与其说这是一门大学课程，我感觉它更像是豪华加长版 TED 讲座。 李老师一个人站在空旷的讲台上娓娓道来，和大家讨论我们在哪、星空中有什么秘密、天有多高和黑洞是黑的吗等 8 个融合了科学和哲理的问题，进而反映天文学研究的方法与成果，揭示宇宙之美及其背后的规律。 目前这门课程刚刚开始第五期，点击第四次课程也可以查看全部内容。如果你对天文学或者宇宙感兴趣但还没有什么基础，这门课程应该不会让你失望。 信息素养通识教程 信息素养通识教程是专为你量身定制的慕课，以好学的方法、好记的高招和好用的工具，助你轻松解决在日常的生活、学习和工作中遇到的各种获取信息的难题，快速学会各类信息获取技能，有效提升信息素养。学会检索方法，受益无穷； 提升信息素养，生活、学习、工作不迷茫。——官方课程介绍 如果说现在这个信息爆炸的时代那些素质是日常学习工作中必不可少的，信息素养一定是其中一个。这门国家精品课程的讲师团队来自中山大学，主讲人是中山大学资讯管理学院教授、博士生导师潘燕桃，潘老师也是《信息素养通识教程》这本教材的作者。 这门课程给我最大的感受是场景明确，结构清晰，虽然内容并不深入，但可以帮我们填补不少信息盲区。从休闲到入学，从升学到创业，可能会需要的基本信息获取渠道与技能都在课程和补充材料里有所涉及。 文献管理与信息分析 欢迎参加中科大为科研人员量身打造的免费网络公开课《文献管理与信息分析》，内容包括信息获取、知识管理、文献管理、文献信息分析、思维导图等。现累计学员 20 多万，共有超过 40 所高校认可本课程的学分。2015 年 7 月入选全国工程专业学位首批在线课程，2017 年入选国家精品在线课程。 ——官方课程介绍 在 MOOC 上和「信息素养通识课」对应的还有另一门国家精品课程，来自中国科学技术大学罗昭锋老师的「文献管理与信息分析」。这门课在中国科学技术大学是选课人数最多的研究生公选课，更加关注于学生视角的信息管理和处理能力，目前已经开设 10 年有余。 尽管这门课程里着重提到的为知笔记和 Endnote 都不是我日常使用的工具，但丝毫不影响它对我的帮助和启发。课程本身包含了信息获取、信息管理、文献信息分析和分享协作四大部分内容，着重介绍了 RSS、Endnote 等工具。如果你刚开始研究生的学习，建议你学习这门课程。 心理学与生活 心理学很神秘？你会发现，只要有人的地方，就有心理学！ 心理学很深奥？你会发现，似乎每个人都是大众心理学家，谁都可以说点“心理学”。 我们生活中处处都是心理学！但这门课程却要告诉你，我们常常挂在嘴边的“心理学”绝大部分是错的，剩下的一小部分也是不全面的。——官方课程介绍 南京大学社会学院心理学系副教授陈昌凯老师但「心理学与生活」应该中国大学 MOOC 平台上最火爆的的心理学相关课程，仅仅是第八次开课一期就用接近 28 万人参加学习。 这门课程给我的感受和「宇宙简史」类似，老师讲解清晰且课程制作非常精良，更像是一位 UP 主上传的系列短视频而非一门枯燥但课程。很多概念和内容都配有大量的漫画风格素材和案例，非常有趣。在「星座和血型是否可信」一节，他列举了一个「李雷和韩梅梅」的例子让我印象深刻。 摄影基础 当今图像时代，摄影已成为一门普遍的艺术语言，是凝固瞬间和认识世界的一个重要手段。本课程以实战拍摄为主要方式，结合基础技术知识讲解，与你一起分享摄影的内容及技巧，提升美学素养，引导大家体验美、发现美，表达美，用相机有选择的观察和记录生活。——官方课程介绍 如果说到大学课程，我的第一反应就是巨大的黑板、潦草的板书以及座位上昏昏欲睡的同学，如果让我想象一门大学教授都摄影课程，我能想到的无非是 PPT 赏析摄影作品。但是，电子科技大学这门国家精品课程直接颠覆了我的认知。 整个课程从实战的角度出发，十周的内容基本上每次老师都会去到一个实际拍摄场景，内容包括实景讲解加上技术知识，涵盖了曝光、构图、用光、风景、静物、人像以及手机摄影等诸多方面。 在第一周课程里一开始桌子上的 8 台相机就直接震撼到了我这个摄影门外汉。 讲风景拍摄的时候老师选择直接去雅安境内的牛背山拍云海，虽然我好像也没学会怎么拍，光是看看牛背山上的风景也开心的不得了。 在最后一周讲棚内摄影的时候，老师还请来了一个真人模特。 如果你刚好有入门摄影的计划，这门课推荐给你，等春暖花开了就可以出去拍拍拍。目前第六次课程已经关闭，可以预约新一期课程或者查看第五次课程内容。 好玩的广告学 需要推销商品的你，需要推销自己的你！ 学一点广告，让你的生活也更有创意！ 通俗有趣的方式讲解广告科学理论、专业知识拆解广告精彩案例。贴近现代受众的方式制作课程，微信公众平台延伸课堂，还有好听的广告音乐，还有业界大咖的独家专访。帮助专业学生成为优秀广告人，帮助普通人成为理性消费者。——官方课程介绍 老实说，我第一次点开这个课程完全是因为首页的宣传视频，这哪里是课程宣传视频，分明就是一个好看的 Vlog。如果你对广告不敢兴趣，答应我也一定要把课程首页的宣传视频看完。 「好玩的广告学」主讲老师是宁波大学人文与传媒学院的副教授汤志耘。整个课程首先介绍了广告学和其它学科的关系，接着讲解了 4P 4C 和定位理论这些经典的广告理论，又从广告的主体、客体、媒介和创意等方面做了深入的讲解。比较特别的是，课程录制使用了多机位且在后期剪辑时也加入了不少花字和音效。 如果你对广告相关的内容感兴趣，这是一门好看好听也好学的入门课。我把课程的几个评价截图展示出来，他们也完全代表了我的学习感受。 课程目前第四期已经结束，第一期内容可以直接收听。同时，在 MOOC 上还有一门课程「爱上广告——广告艺术鉴赏」更加着重于具体的广告案例分析也值得推荐。 现场生命急救知识与技能 天灾人祸、急危重病，一旦突如其来发生，你该怎样面对？如果你是受害者，该如何自保与自救？如果你是目击者，怎样施救才是正确？就让我们随南昌大学国家级实验教学示范中心的老师和 3S 救护会的同学们，学习常用“现场生命急救知识与技能”吧！“学习急救、救人自救”，你我都行！——官方课程介绍 作为一个非医学专业的学生，我们可以先扪心自问了解多少急救常识。如果在商场或者地铁站身边突然有人心脏骤停，这时现场有一台 AED，我们能不能用它在救护车没有到的五分钟挽救一个人的生命，或许很多人都没有听说过什么是 AED。 常见的急救知识这些本应该在初高中就被重视的内容，却在我们每个阶段的教育中都极度缺失。 南昌大学的多名教授讲师在 MOOC 上开设了这门「现场生命急救知识与技能」国家精品课程。 课程整体内容围绕我们在日常生活中所能碰到的各类急救事件，用 10 个章节讲解了包括心肺复苏、创伤骨折以及其它常见意外的现场急救知识。这些内容希望我们都不要用到，也希望我们都能够知道。 以上就是为你推荐的 7 门国家精品课程，希望其中有你感兴趣的内容。反脆弱的最好方法就是行动，一起加油。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-01-06-7mooc/"},{"title":"在家复工，学生党如何使用学术资源","content":" 本文首发于「少数派」 「战疫」尚未结束，各大高校和科研院所的开学时间一改再改，目前多数院校的返校时间点是 2 月 17 日，还有一些已经改为了 2 月底。就在 2 月 3 日，教育部给全国大学生写了一封信，信中提到： 做“修行者”，就是宅其身、抱道行。在网络资源平台上自主专业学习和自我提升，做到“停课不停学、学习不延期” 现在不少同学已经开始着手复工，随之而来的问题就是学生党在家应该如何使用学术资源？本文简单整理一些方法供大家参考和讨论。希望在这段时间里大家既要注意个人健康安全，也可以抓住机会充电学习。 合理使用高校订阅资源 作为在读学生，在家使用学术资源最方便的方法就是远程使用所在高校的读书馆订阅资源。每个学校的远程使用方法各不相同，常用方式有如下几种。 基于 VPN 访问校园网络 VPN 访问目前是大多数高校采取的主要内网访问方式，例如 复旦大学 就分别为教师和学生提供了网络代理服务。你不妨去自己学校图书馆网站查看，通常都会有具体的使用方法介绍。 基于 CARSI 进行访问 所谓 CARSI，其全称是中国教育科研计算机网统一认证与资源共享基础设施（CERNET Authentication and Resource Sharing Infrastructure）。 该项目自 2008 年 12 月由北京大学计算中心发起，在校园网统一用户管理和身份认证系统基础上，面向国内高校和科研机构提供跨域身份认证和资源共享服务。目前有 77 所高校已经或即将其成员，你可以通过官网 成员列表清单 查看自己的学校是否列在其中。 CARSI 本身基于 Shibboleth 进行开发，而 Shibboleth 也被 NREN（National Research and Education Network）普遍采用。在 2019 年 CARSI 已经成为 eduGAIN（国际身份联盟组织）正式会员。这就意味着接入了 CARSI 的国内高校学生可以方便的访问那些支持该服务的资源提供商，例如 IEEE、Springer Nature 和 EBSCO 等。 目前已有 44 项资源完成接入，你可以在官网的 资源列表 中查看资源内容和更具体的访问方法。 下面以 Web of Science 为例简要说明，首先进入网站登陆界面，然后选择通过机构登陆，找到「CHINA CERNET Federation」后点击「转到」。 正常情况下会跳转到 CAERSI 高校选择列表，找到你自己所在高校然后点击验证即可。 需要说明的是目前各高校申请开通的资源各不相同，所以即便你的学校在列表中也无法确认能否正常访问也某些资源。另外，不同内容提供商的登陆方式也不尽相同，可以查看各自高校和内容提供商的详细说明。 此外，组织登陆的方法也适用于部分没有参加该计划，但也可以通过 Shibboleth 进行组织验证登陆的单位，只要在组织列表中尝试搜索即可。 基于邮箱登陆专用网站 部分高校和科研院所拥有自己专门的用户认证体系和资源访问方式，通过拥有使用权限的专属邮箱登陆即可使用。 这里以中国科学院为例，中国科学院拥有自己的 中科科技云 认证系统。该系统已经直接接入了大量的文献服务和应用，认证通过后就可以直接使用。 此外，中国科学院文献情报中心还提供了基于移动互联网的中国科学院知识服务平台「中国科讯」，有移动端 APP 可以使用。 所在地区图书馆等相关平台 目前，全国各省市级图书馆都订阅了大量电子资源供读者使用。如果你有所在城市的读者证，不妨尝试登陆图书馆官方网站，说不定就有意外惊喜，这里以上海和深圳举例说明。 上海市图书馆 拥有上海图书馆的读者证的同学可以在家通过「e 卡通」登陆访问上海图书馆资源。 首先进入上海图书馆个人主页 选择「e 卡通」。 初次使用需要安装 VPN 插件，会自动跳转到 easy connect 进行下载，安装成功后重启浏览器再次登陆，正常情况下会显示「登陆成功」，然后点击「打开资源」即可进入资源导航库。 虽然网页整体设计风格蛮有年代感，但是上海图书馆数据库资源还是很多的，在「e 卡通」一列中为蓝色图标的资源均可以直接使用。 通常访问的数据库正确显示「上海图书馆」相关标示就可以放心访问了。 上海研发公共服务平台 除了上海图书馆外，上海研发公共服务平台是另一个查找文献的好去处。和上海图书馆不同，该平台面向社会大众开放注册，无需提前办理其它证件，其文献资源来自万方和知网两大平台。 注册用户登录后，进入 中西文科技文献服务平台 可直接检索下载文献也可以进行全文传递申请。 这些服务并非免费使用，不过当你注册成功后系统分别会赠送 400 元万方余额，600 元知网余额，20 篇文献传递和 30 篇标准文献，不得不说是一个解决燃眉之急的福利。 深圳市图书馆 深圳市图书馆联合当地的多个院校图书馆开发了「深圳文献港」。它全面集成了六家图书馆（深圳大学城图书馆、深圳图书馆 、深圳大学图书馆 、深圳职业技术学院图书馆、南方科技大学图书馆、香港中文大学（深圳）图书馆）庞大丰富的馆藏，官方说明中显示其包括 1186 万册（件）中外文纸本馆藏和 400 多种数据库。 你可以进入 文献港主页 选择适合你的登陆方式进行登陆。 登陆成功后即可进行相关内容的搜索和查看。 资源提供商免费开放 在当前这个特殊时期，不少资源提供商也都向社会免费开放了部分付费资源，其中部分内容和「冠状病毒」相关。 Wiley 冠状病毒相关论文 Wiley 旗下所有冠状病毒相关论文（包括未来可能发表的相关论文）都将可以开放获取，为此他们专门开放了一个文献汇总网页，论文被分为 Novel Coronavirus Outbreak、Understanding Coronavirus、Epidemiology and prevention 和 Drug discovery and therapy 等类别。 Elsevier 新型冠状病毒信息中心 Elsevier 整合旗下医学期刊文献、教科书和临床信息等内容建立了新型冠状病毒信息中心，该网页提供了包括指导、临床解决方案、中文资源、研究和相关内容等几个板块，如果你感兴趣的话可以访问了解。 中国知网 在疫期内（暂定 2 月 1 日 -3 月 3 日），中国知网上线了三项免费服务项目，其中包括高校、职教用户校外漫游服务、中国知网 OKMS 和知网研学。更多信息可以查看官方发布的解释说明。 清华大学出版社 清华大学出版社旗下「文泉学堂」以清华大学出版社近 10 年的正版电子书资源为基础，拥有大量理学、工学、经济学、管理学等学科相关内容。目前（初定 2 月 16 日前）全国各地的用户无需登录和注册就可以阅读学习。 其它 此外，维普网和 国务院发展研究中心信息网 目前针对注册用户也都开放了免费下载等服务。如果你平时还在使用其它机构的服务，可以留心官网或者官方渠道通知。 开放获取期刊 所谓开放获取（Open Access）是指有别于传统订阅出版模式的另一种选择，通俗解释就是出版社向作者收费但是所有读者都可以免费获取相关研究论文。截止目前，开放获取期刊目录网站（Directory of Open Access Journals，DOAJ）已经收录了来自 133 个国家的 14267 种开放获取期刊，其中不乏像 Nature Communications 和 PLOS Biology 这类知名度较高的期刊。 但是开放获取随之而来的一个问题是部分期刊影响力和公信力逐年下降。因为出版社盈利的来源是作者发表文章缴纳的费用，所以一些杂志就会通过大量增加文章发表数量来增加收入，所以大家也要注意甄别。 接下来推荐几个可以查阅开放获取期刊的平台。 DOAJ DOAJ 成立于 2003 年 5 月，由瑞典隆德大学图书馆维护。其收录的内容均为学术研究性开放获取期刊，如果你想查看所有开放获取内容，这应该是最全的平台。 或许你还不知道自己专业领域内有哪些开放获取期刊，DOAJ 已经把所有内容按照专业类别进行了分类，应该会有符合你需要的内容。 PLOS PLOS 是一个由多名诺贝尔奖得主和慈善机构支持的非赢利性学术组织。它创立于 2000 年 10 月并于 2003 年正式成为出版机构，致力于使世界科学和医学文献成为可访问的公共资源。PLOS 出版的开放获取学术期刊主要关注生命医学领域，其中 PLOS BIOLOGY 在专业领域具有较高影响力。 BioMed Central BioMed Central（BMC）属于 Springer Nature 旗下，包括各类开放获取期刊 300 余种，其中 BMC 系列开放获取期刊（期刊名以 BMC 开头）有 70 种，主要关注生物、医药和物理科学与工程领域。比较有影响力的杂志包括 BMC Biology 和 BMC Medicine。 预印本发布平台 arXiv arXiv 是一个收集物理学、数学、计算机科学、生物学与数理经济学的论文预印本的网站，上面集中了大量尚未正式发表的最新的研究结论，目前由康奈尔大学维护。 所谓预印本就是文章在正规期刊发表之前先公开发布供所有人查阅，这样做一是可以尽快让外界（同行）看到自己的工作，另一方面也可以收到一些意见有助于随后在正式期刊发表。如果做一个不太恰当的比喻，类似于一个软件的公测版本。 不过因为文章在发表预印本之前并不会经历同行评审这一关键流程，文章的可信度和重要性都需要读者自行鉴别。 随着预印本越来越流行，也出现了不少和 arXiv 类似的网站，例如由冷泉港实验室维护的针对生命科学的预印本论文发布平台 bioRxiv，由中国科学院文献情报中心维护的面向全国科研人员的 ChinaXiv 等等。 生物类预印本整合平台 Rxivist 随着预印本文章越来越多，如何从大量文章中发现有价值的内容就成了一个问题，为此已经有科研工作者做了一些尝试。 Rxivist 是一个整合了 bioRxiv 预印本文章的二次开发数据库。为了发现更有价值的信息，开发者从文献下载量和社交平台讨论度两个维度对所有发布在 bioRxiv 的预印本文章进行排序。 该平台每天 6 次从 bioRxiv 中提取新的预印本信息并从推特上检索其热度，反映当前人们正在讨论哪些文献；文章下载量则每两周更新一次。此外这些指标都可以按照具体的文章类别进行筛选过滤。 该网站中每个预印本还提供了详细的作者信息列表，方便你链接到作者个人资料页查看该他们发表的其它文章信息。 其它工具和渠道 除了上面提到的几个渠道，很多时候了解一些搜索工具和方法也可以帮助我们找到可以需要的学术资源。 PubMed 和 Europe PMC PubMed 和 Europe PMC 都是大型的学术资源查询网站，前者来自于美国后者来自于欧洲。 通常你只需要按照正常流程搜索即可，然后在网站的过滤栏使用「Full text」过滤即可筛选出能够阅读全文的文献。需要说明的是这些文献并不都是开放获取内容，而是所有通过合法渠道能够获得的文章，因此可以放心使用。 Kopernio Kopernio 是科睿唯安（Web of Science 的拥有机构）为 Chrome 浏览器开发的插件，其目的是为用户在学术网站上提供一键式获取全文的服务。 当然，这个工具的功能是帮助你节省跳转和寻找原文的时间，并非帮助你下载到本身就没有原文的文献。 安装成功后，每次你点开某包含某篇文献的网址它都会通过几个渠道帮助你查找原文，如果找到了就可以直接浏览 PDF 文档。 实验室主页和 ResearchGate 从科研人员角度而言，他们其实都希望自己的工作成果可以被更多人阅读和引用，因此不少人会通过「个人渠道」提供个人文章的完整版本。这里最主要的个人渠道就是实验室主页和 ResearchGate。 实验室主页不必多说，大多数都会提供 publication list，很可能每个文章就已经附上了 PDF 链接。 至于 ResearchGate，可以将其理解为学术圈的低配版 Facebook，根据官方介绍目前已经有超过 15 万来自世界各地的科研人员用它共享，探索和讨论各自的研究。很多实验室和科研工作者通过它分享自己研究成果的同时也会顺便把原文一并上传。如果你发现文章是不可公开访问的状态还可以直接给作者留言，通常他们都会把文章分享给你。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-02-05-searchpaper/"},{"title":"跨平台协作，让飞书实时接收语雀更新提醒","content":" 本文首发于「少数派」 飞书来自字节跳动，语雀这款工具则来自蚂蚁金服，在目前国内应用市场的整体背景下，大厂之间水火不容似乎才符合常理。好在作为优秀的团队协作工具，飞书和语雀都有着不错的开放心态，这也让二者的整合和连接成为了可能。很多时候给用户多一点选择而不是固步自封，或许反而可以吸引和留住更多用户。 什么是 Webhook 所谓 Webhook 也叫做 Web 回调（callback），效果和 API 类似但不需要客户端主动向服务端获取数据，而是主动接收服务端内容。即一端触发事件另一端就可以监听执行，从而提供实时信息。 具体来说，当 A 发生某一事件时，例如文章更新添或加评论，它就会发起一个 HTTP 请求到 B 服务 Webhook 配置的 URL，然后 B 服务对返回的内容（通常是 JSON 或 XML 格式）解析后再进行展示等进一步操作。 使用场景 语雀是孵化自蚂蚁金服的一个「专业云端知识库」，其知识库的形式非常适合做系统的内容整理和分享，关于语雀的介绍可以参考我之前写过的一篇文章，这里不再赘述。 目前我所在的一个团队正在利用语雀搭建若干和专业内容相关的开源知识库，日常大家会在语雀进行文档的编写和协作，同时我们也在用飞书进行日常的沟通。为了让大家能够及时了解到语雀上的文档信息，如果可以把消息实时推送到飞书就再好不过了。 上面的需求，刚好可以通过 Webhook 实现。 配置方法 获取飞书 Webhook URL 在之前一篇 利用飞书电子表格对 Trello 内容汇总 的文章中，已经介绍了飞书精灵。它是飞书团队推出的自动化工具。通过把不同功能串连到一块，形成一个自运行的工作流，让所有外部信息都有机会汇总到飞书里。 飞书精灵的触发器中有一项就是 Webhook，该触发器可以提供一个 URL，首先我们需要获取这个地址稍后填写到语雀的对应设置中。 需要进行三步操作： 创建一个新的飞书精灵，触发器选择 Webhook 选择触发器，只有一个选项 在设置选项中可以看到生成的 URL ，复制稍后备用 获取 URL 配置语雀 Webhook 语雀支持通过配置知识库的 Webhook 让开发者获取指定知识库下所有文档的发布状态，只要该知识库下的文档被发布或更新，就会按需触发该知识库下所配置的 Webhook。 首先在需要设置提醒的知识库设置界面点击「开发者」，然后将飞书 URL 填写到对应位置，再设置一个有区分度的名字，最后「添加」即可。 了解返回内容 语雀使用 HTTP POST 请求 Webhook URL，具体内容是一个 JSON 数据结构，里面包含了大量的键值对信息。我们首先需要对整体返回内容有一个直观认知，在这里可以通过简单的文档发布来学习。 在飞书精灵触发器的设置选项中参数部分是必填项目，它需要填写一到两个具体的返回内容实例，因为此时我们并不知道具体返回内容是什么，因此可以填写一个大括号 {}。你可以把它理解为一个最基础的 JSON 格式。 接下来进行机器人操作部分的设置： 选择「飞书消息」 选择「通过机器人发送消息」 在设置选项中，标题暂时可以随便取名字，在消息内容部分点击「加号」下拉选项中目前只有「完整 JSON」 点击创建即可 完成前期准备工作之后，现在通过语雀新建一个非常简单的文档并发布，这时就会在飞书精灵中接收到一条消息推送。 语雀新建并发布文档 飞书精灵接收完整 JSON 内容 上面这条很长的消息就是语雀返回的全部内容，把它放到代码编辑器中进行格式美化后我们可以看到 data 下为文档的详细信息，例如 body 是正文 Mrakdown 源代码，title 是文章题目，具体内容可以查看官方说明。此外还包括了知识库信息 book 部分以及作者信息 user 部分。 最终配置及实际效果 通过一篇简单文档我们已经获得了语雀返回的 JSON 格式完整数据，现在可以对之前的机器人进行更加精细化的配置。 首先把所有 JSON 内容复制到触发器设置的参数部分。 然后在操作部分部分的设置选项中将旧变量删除，这时再点击「加号」就可以看到飞书精灵根据 JSON 实例内容提取到的所有参数了。 最后一步，我们对消息推送内容进行更加完善易读的设置。 我目前的设置是将标题设置为文档标题，在消息内容中分别展示所属知识库、文档作者、更新时间、文档字数和访问路径这些内容门，如下图所示。这里需要特别注意的是，语雀本身不会提供文档链接，我们可以通过补充主网址加data.path实现。当然你也可以根据实际需要进行更加个性化的设置。 详细设置消息内容 一套组合拳之后打完收工。以后每当对应的知识库有文档更新，就会在飞书中实时接收到如下所示的提醒，非常方便。 实际推送效果 希望这篇文章可以让你对飞书精灵的 Webhook 设置有一个直观了解，并有机会应用于自己正在使用的其它服务，发挥飞书更大的潜能。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-02-01-larkandyuque/"},{"title":"特殊时期假期返程实录","content":" 这些天虽然发生了很多事情，全国不少地方都封城或者各种停运，但我今天还是按照原计划返回了上海，接下来将是按照规定的两周居家自行观察。 从上海回家，再从家里的 N 线小城出发到北京换乘回上海，整个流程稍微记录和大家分享，希望还在家里的读者有个了解。 另外，积极调整自己的心情是最重要的，即便我们听到了太多悲伤的消息，看到了太多操蛋的事情。 特别要强调的是，以下所有内容只是我自己在 1 月 30 日和 31 日两天的所见所闻，所有描述都是主观且片面的。如果你看到的和我看到的不一致，以你看到的为准。 从上海回家 1 月 22 日我们从上海到北京转车再从北京坐高铁回家。作为不在主要疫区的人，当时还没有真切感受到事情的严重。没有提前做太多准备，当天向还在实验室的工作人员借了几个一次性口罩就回家了。 在火车和北京地铁以及车站里大部分都带着口罩。 不过那时上海和北京的火车站都没有检测体温，反倒是家里的高铁站下车之后给每个人量了体温。似乎家里的小城市还要比北京上海更警觉一些。 在家的感受 过年在家的几天，没怎么出门也没有和老友聚会，家里几个超市和菜市场前几天的价格还相对正常，但从 28 号开始菜价就上去了，比如白菜从一块五涨到三块五，超市里人们开始抢购方便面。 小城市的整个公交系统在年后几天变成了仅有部分车且限时段运行，出租车司机都佩戴了口罩。说到口罩和医用酒精，初一初二就全部断货，一直到初六市区里我家附近的三五家药房都是买不到的。 返程回沪 从家里回上海依旧途径北京转车，感受了一下疫情比较严重的当下，不同城市应对疫情的不同氛围。 之前刷微博显示多地都延迟复工了，上海最早是 2 月 3 日，但是北京似乎没有明确通知，所以一开始我比较担心北京今天人会很多。 在到北京的高铁上需要填写旅客信息登记表，里面要填写个人信息和到京以后的地址。 整个车厢基本满员，一个小时车程里车上的工作人员喷了两次 84 消毒液。 到了北京北站，出站时排队量了一次体温，然后要把旅客登记表放到三个并排的小桶里，老实说，就像三个垃圾桶一样，用的是日常的黑色垃圾袋，也不知道这个信息最后会被怎么收集和整理。 整个北京北站基本上就只有那趟车下来的人，可以直接走到北站附近的凯德 MALL。我进去看了一下，进商场也需要量一次体温，虽然商场里没有什么人但是大多数店都开着。不过仅仅从北站无法准确感知客流量，因为真正的大站是北京站和北京南站。 从北京北到北京南原计划打车，不过因为地铁很方便同时目测人不多，还是选择了地铁。地铁进站口工作人员带着类似防毒面具的东西在安检。 北京的地铁 4 号线平时人不少，但我在的那一节车厢大多数时间就是 3~5 个人，没有不戴口罩的，感觉这个密度和打车也差不多。 到北京南站是下午三点多，我从来没有见过有人这么少的时候。地铁出站前那些点有一半关门状态，另外一半开着也没有什么人吃饭。 下图是地铁出站口 候车室里不少店也处于关门状态，进站要量一次体温，几分钟之后去星巴克的店里还要进行二次测量。即便进站和到星巴克可能也就是前后两三分钟的时间。 北京南站候车厅人真的很少。 很多店都关门了。 有了口罩专用投放箱，但是不确认里面是否真的只有口罩。 从高铁到北京北站出站，到坐上地铁，再到北京南站，整个过程中都非常的安静也感觉很空旷，确实没有感受过这种状态的北京。肉眼可见的范围所大家都戴着口罩，不过看到有人戴反了，也有人漏着鼻子。 在等车的过程中听到有一趟到上海的高铁取消了，后来推测或许是退票改签的太多，也就不开了呢。从我所在的车次看，从北京发车的时候大概车厢里的上座率也就是三成，到了济南站后人稍微多了一些。 在会上海的路上倒是没有填写什么信息登记表。9 点半多到上海虹桥之后从出站再到上地铁都没有发现有明显测量体温的操作，是悄无声息地测过了还是没有测并不能判断。整体感觉比北京要淡定一些。 也许是因为 2 号线暂时停运的原因，仅有的 10 号线客流量并不小，虽说官方的返工日期还有几天才到，但是能感受到不少人都是回来开工的。 不过，换乘另一条不经过机场火车站的地铁线之后整个车厢就又空了，看来大家的确也没有到处乱跑。 回到小区已经晚上 10 点多，拉着箱子刚要进去被门卫大叔给拦住了。原来是要进行返沪人员的登记，记录居住地址，从哪里回来以及个人信息等等。 收拾完在微博看到这样一个信息，当然，我没有验证真假，是一个在北京工作的 HR 朋友发的。 今天上午出了一下家门，菜价还算正常，肉没有涨价。 比较悲伤的是买不到口罩，这应该是全国目前普遍存在的问题，不仅仅是上海。 虽然上海这边现在说是有 1000 个药房每天定量投放，但是我家附近的这个需要早晨去排队领号，只有领上号才能购买。店员和我说很多爷爷奶奶每天药房没有上班天还没亮就来排队了。所以，太难了。 以上就是这两天的见闻和经历。从填写旅客信息表到地铁站的安检量体温再到一些具体的社区管理措施，能感受到北京和上海两地管理的思路和策略是不太一样的。 在上海似乎并没有感受到太多「外在」的东西，当然这不是说监管不力，反而是感觉一切还算正常。其实从学校下发的各种文件和官方发布渠道来看，很多工作也在有条不紊的进行。 至于何时去实验室，学校的要求是不在集体宿舍但是回上海的学生需要自我居家观察两周。目前来看唯一的问题就是买不到口罩和医用酒精。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-01-31-returnschool/"},{"title":"需要远程办公，不妨用 Trello 进行组织和协作","content":" 本文首发于「少数派」 根据需求找工具 个人使用 Trello 已经三年有余，在团队协作中重度使用 Trello 开始于 2019 年 1 月 「学习素材共享协作小组」的成立，这个项目目前已经进入了 2.0 版本。 关于小组需要做一点简单介绍，也能说明我们为什么要使用 Trello 这类工具。 学习素材分享小组成立于 2019 年初，这个小组最初的灵感来自于小时候和小伙伴交换游戏卡带的回忆。小时候可能不少人最喜欢的娱乐活动就是和小伙伴用插卡带的学习机一起打游戏。平时各自练习琢磨秘籍，周末一起切磋。听说谁买了新的游戏卡带，就带着自己的珍藏去和他交换。 到了今天，我们有什么可以互相分享交换的东西呢？我想可能是我们每天接触的信息和学习素材。加入这个小组的成员会不定期共享自己发现或者感兴趣的素材，然后在素材中把感兴趣的内容输出相关文章在小组内分享。 想法要落地就需要一个合适的工具。根据素材共享和写作流程的特殊性，这个工具要可以很好地跟踪每个素材和主题的状态进度，同时成员之间要可以相互协作和沟通，为此我们引入了 Trello 。 为什么选择 Trello 看板 (Kanban) 一词起源于日语，看板管理则源自丰田的「及时生产」（JIT，just-in-time）系统，即利用看板在各工序、各车间、各工厂以及与协作厂之间传送作业命令，使各工序都按照看板所传递的信息执行，以此保证在必需时间制造必需数量的必需产品，最终达到及时化生产的目的。 Trello 就是一款以看板为核心的项目管理协作工具。简便灵活的可视化方式帮助用户管理自己的项目并组织各种事务，2019 年 10 月它在全世界已经拥有了 5000 万注册用户。Trello 以外表简约的看板风格著称，虽然功能强大但复杂功能都被收起到恰到好处的位置。同时因为被财大气粗的 Atlassian 收购所以其基础功能全部免费，对于大多数个人或者小团队而言，免费版本已经完全够用了。 Trello 的主要优点如下： 全平台的项目管理和任务管理工具 通过看板进行项目跟踪和管理 上手简单外表简约但功能强大 协作功能完善且管理方便 扁平化透明化参与性强 免费版可以满足常用需求 基于 Trello 这些优点，我们得以尝试建立一个不依赖微信群的「小组」，我们希望这种协作是简洁且透明的，所有信息都能通过一个简单的辐射源影响到所有成员，可以调动大家的积极性和自主性。 在这个外表松散的小组里，看不到斗图刷屏（但是 Trello 本身有很多 emoji 供你表达情绪），看不到家长里短和商业互吹。打开 Trello 看到的只是谁更新了想法和素材，谁对你的想法和素材感兴趣，自己关注的素材有没有被写成文章。 Trello 满足了我们三大主要需求：可协作可跟踪且简单纯粹。 快速上手 如果你有时间，建议拿出半个小时仔细阅读 看板学习指南 ；如果没时间只需要浏览本文亦可快速上手。如果想查看具体的 Trello 看板使用案例，可以参考 Trello 灵感 。 基本概念 Trello 看板有且只有四个关键组件，下面这幅图来自官网，可以很好的进行说明： A **看板：**看板代表一个项目或是一个信息跟踪的平台，可以用来组织任务并与他人进行合作。 B **列表：**列表可用于创建工作流，列表中的卡片可随着工作流从开始到完成在列表之间移动，可在看板中添加的列表的数量没有限制，并可随心所欲进行组织。它可以保持卡片 (C) 在进度的各个阶段有序组织。 C 卡片：看板的基本单位是卡片。一个卡片可以代表一个任务和观点。卡片可以是需要做的事情，如待写的文章，或者需要记住的事情。只需点击任何列表底部的「添加卡片」创建新卡片，然后对其进行命名即可。通过点击卡片可对其进行自定义，以便添加各种实用信息。在列表之间拖放卡片可以展示进度。 D 菜单：在 Trello 看板的右侧是菜单，也就是看板的任务控制中心。该菜单用于管理成员、控制设置、过滤卡片和启用 Power-Ups 支持的第三方功能。还可以在菜单的动态订阅源中查看看板上发生的所有动态。 创建团队看板和卡片 创建团队和看板 使用 Trello 创建团队和看板都可以在页面右上角的新建完成。 选择「新建团队」后可以设置团队信息并邀请成员。Trello 目前的成员邀请方式是通过邮箱邀请，你可以一次性输入多个成员邮箱，并且编辑邀请邮件内容。（最近有新成员反馈似乎 163 邮箱在接收邀请和注册方面有些问题，大家可以留意一下）。 从模板创建看板 除了从新建处创建看板之外，Trello 本身为我们提供了各种行业类型的 模板，可以按照类别查看或者搜索。在模板页面处可以直接使用。 创建卡片 针对「学习素材共享协作小组」，我们会把所有参加的同学添加到一个团队中，只要加入这个团队就可以查看编辑和修改团队内的所有看板内容，同时你也可以选择加入「写作学习资源共享」这个具体的看板。因此，目前暂时不需要自行创建看板和列表，日常使用最多的操作是创建卡片。接下来介绍创建卡片的若干种方法： 在应用内部创建卡片 在列表右上角有三个点，点击后再选择「添加卡」即可添加卡片内容；在列表最下方点击「添加另一张卡片」即可直接添加内容 Chrome 插件 如果想要分享某一个网页内容，可以在 Chrome 插件中进行快速添加，勾选「附件」网页地址会作为附件添加，而网页名则会作为卡片名。 移动端 可以直接在手机客户端中进行添加或者通过系统分享菜单进行添加。 卡片操作详情 Trello 可能在表面上看起来简单，但其具有无穷的内在功能。每一张卡片在点击打开后都会进入「卡片背面」，展示具体内容。 卡片背面 卡片描述：在这里可以添加更多有关卡片、网站链接或分步骤指示方面的具体信息。要给卡片添加详细信息，可单击卡片背面顶部的「编辑」，还可以使用 markdown 语法。 评论和活动：在与团队成员沟通和协作时可为卡片添加评论，如提供反馈信息或更新信息。还可以使用 @ 在评论中提及看板或团队的成员，他们会在 Trello 中收到相应通知。活动则是卡片上所有评论和操作的时间轴。 添加至卡片部分提供了更多附加信息。 添加成员可以向卡片添加成员以分配任务，轻松查看其他人正在做什么、还需要做哪些工作。 添加标签可以给卡片赋予不同的属性，例如用不同的颜色标签表示优先级或者用不同的颜色表示进度。 为需要子任务或具有多个步骤的卡片添加清单以确保不会出现疏漏。也可以从看板上的其他卡片复制清单，以及通过 @ 提及人员的方式将其分配到清单项目。 为具有截止日期的卡片添加到期日**，**卡片成员将在到期前 24 小时收到通知。任务完成后，到期时间可以标记为已完成。 可从计算机及 Dropbox、Google Drive、Box 和 OneDrive 等众多云存储服务中添加附件。 卡片操作提供了卡片的多种处理方式，例如移动复制和分享归档等等。 用 Trello 做什么 跟踪 Trello 最常见的使用方法是在项目或流程中进行任务跟踪。我们的素材分享和写作也是某种形式的任务跟踪。在看板中，卡片代表需要完成的任务或等等待处理的素材，列表代表一系列步骤。列表的结构可以为「收集箱」「进行中」和「已完成」这种简单的三段式，也可以根据流程需要更加详细，卡片在从开始到完成期间则从左向右移动。 协作 协作是 Trello 的主打功能之一，Trello 的列表和卡片设计非常利于引导人们围绕正在进行的工作展开讨论，当看板中增加一个素材之后，大家可以很方便的跟进交流。下面是几个具体的操作方法： 对卡片发表评论或者打上一个标签，让成员知道任务进度。 在评论中 @ 成员，他们就会收到通知，表达你需要谁和你进行进一步协作。 如果看到了感兴趣的素材或者想要参与的任务，也可以直接把自己作为成员加入卡片，表示对相应内容的持续关注。 存储 Trello 本身不具有太强的云盘属性，但也可以进行轻量存储。一些常规文档都可以直接拖入附件。另外，有很多第三方应用如 Google Drive、Dropbox 和 OneDrive 等可以通过 Power-Up 于 Trello 进行关联，方便组织各种文件。 存档 除了常规的跟踪和存储，我使用 Trello 的一个主要目的就是对日常信息和素材进行存档。得益于浏览器插件和移动端系统层级方便的分享功能，我会把各种渠道看到的学习素材和信息保存到 Trello 中，一方面方便进行后续处理另一方面也可以在后期进行查找溯源。 提高使用效率 快捷键 Trello 中几乎所有的操作都可以通过快捷键来完成，单击问号可查看全部快键键设置。 快捷键说明 有几个高频快捷键推荐一定要记住： Q：快速查看所有成员信息中包括你的卡片 /：光标移动到全局搜索框 F：进入看板内卡片搜索框 E：进入快速编辑模式 Shift-Enter：保存卡片同时进入卡片背面编辑详情 空格：把自己添加为卡片成员 M：快速添加其它卡片成员 搜索 当把看板当作素材库或者用作归档使用时，随着卡片越来越多，后期想要找到卡片最快捷的方式是使用系统提供的快速查找功能。Trello 页眉中的搜索框内支持的搜索粒度非常细，在我看来并不逊色于印象笔记。 常规查找只需要输入你想找的关键词，Trello 将显示与查询内容相关的卡片和看板。此外它还支持很多快捷搜索方式，例如使用 @成员 会返回属于某个成员的所有卡片，#标签会返回带有该标签的卡片。当然，多个搜索条件之间可以组合使用完成交集和补集。 邮件提醒和新建 为了不错过 Trello 中的更新或者不接收提醒，可以在个人设置中修改邮件提醒的频率。 其中「定期」是指如果当前的一个小时没有任何和你相关的提醒则不会收到邮件，和你相关的内容会整合为一封邮件中统一显示。 除了利用邮件接收提醒，还可以通过邮件新建卡片和回复。首先在看板设置中选择「更多」，找到「邮件到看板设置」。在这里会显示一个只属于你自己的邮件地址，发送到这个邮箱的邮件自动会转换为看板进行保存。其中，电子邮件的主题将成为卡片标题，电子邮件的正文将成为卡片描述，电子邮件中的附件将会作为附件。 免费团队使用注意事项 从官方建议中学习使用方法 Trello 为不同类型的团队提供了个性化的介绍和建议，如果你想要为自己的团队引入 Trello 不妨先去看看 官方的团队使用建议。 最近一段时间如果大家都是宅在家里或者需要远程办公，其中「在家」和「远程团队」可能正是你需要的。 宅家模板 远程团队模板 免费版本无管理员权限 Trello 目前有两种付费模式：Trello Gold（个人版）和 Business Class（企业版）。其中个人版按年支付每月 3.75 刀，企业版按年支付每人每月 9.99 刀。以「学习素材共享协作小组」为例，我们 55 人的小组如果要使用付费版本的话每年需要 6,359.47 刀，这个价格只能让我说一句打扰了。 企业版的亮点附加功能如下，其中我个人感觉最实用的就是「管理员功能」。 如果你使用的是免费版团队，那么所有成员针对团队看板的操作权限都是相同的。也就是说如果一个新手在没怎么学习的情况下贸然上手，很可能出现把整个看板删除或者所有卡片归档的操作，这将是灾难性的，因此一定要做好使用前的培训！ 在「学习素材共享协作小组」的醒目位置，有如下四个必须遵守的要求。其中最重要的就是不要私自归档甚至删除非自己创建的内容，不要修改非自己创建的卡片描述，仅进行评论。 使用要求 建立卡片书写规范 每个人在新建卡片的时候都有自己的习惯，有人喜欢把标题起的很长，有人喜欢把细节放到评论。在多人使用同一个看板时，如果不建立必要的规范，会让整个看板看起来都混乱不堪。 这里还是以我们的「学习素材共享协作小组」为例，为了规范大家的新建卡片格式，我们建立了一些规则，供大家参考。 卡片填写要求 数据导出 免费版本的看板仅仅支持 json 格式的数据导出，虽然市面上有些第三方的插件但是测试下来效果均不理想。 我之前使用过的方案是下载 json 格式文本，再通过一些转换工具将 json 格式转换为 csv 格式进行后续处理，整体效果也是聊胜于无。 因为最近一段时间开始使用飞书进行协作，终于找到了一个相对理想的方法：利用飞书精灵中的 Trello 机器人结合飞书电子表格完成实时同步。如果你也在使用飞书，不妨尝试一下这种方法。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-01-29-trellowithothers/"},{"title":"学习素材共享小组V2.0（已停止招募）","content":"是的，你可能会好奇什么是学习素材共享小组，以及 1.0 版本去哪里了。 学习素材共享小组是什么 学习素材分享小组成立于 2019 年初，这个小组最初的灵感来自于小时候和小伙伴交换游戏卡带的回忆。小时候可能不少人最喜欢的娱乐活动就是和小伙伴用插卡带的学习机一起打游戏。平时各自练习，琢磨秘籍，周末一起切磋。听说谁买了新的游戏卡带，就带着自己的珍藏去和他交换。 那么到了今天，我们有什么可以互相分享交换的东西呢？我想可能是我们每天接触的信息和学习素材。 以我自己的实际情况举例。每天我都会浏览一些 RSS 订阅的博客，看看最近出来的文献，水水群看看推送。在这个过程中自己会接受大量的信息，另外，每天遇到问题、搜索问题和解决问题的过程也会接触到大量的东西。这其中不乏一些会让我感觉「有点意思」或者「还能这样」的内容，我会把它们记录在自己的收集箱里，作为写作和学习素材进行扩展和学习。 有时候这样的素材一天有一两个，有时候有四五个，但是因为时间和精力问题，最后能真的深入学习并进行输出的少之又少。很可惜，也挺无奈，还能怎么办？就像小时候我们互换游戏卡带一样，为什么不把喜欢分享和学习的小伙伴聚在一起大家来做这个事情呢？ 学习素材共享小组 V1.0 回顾 于是在 2019 年初，我们就尝试小规模的组织了这样一个「学习素材共享小组」，依托于看板工具 Trello 进行学习素材的分享和讨论。最初就是几个线上线下好友参与，后期又逐渐加入了一些大家之间相互认识且信得过的厉害朋友。这些人在世界各地每个人的专业方向也都不太一样（都和生物信息有关系），但是大家的共同点就是愿意分享和喜欢交流。 再过去的一年里，这个小组陆续谨慎的吸收了成员 29 人，累计分享各类学习素材 429 个，其中包括文献、专业知识、软件算法、编程技巧以及学习资源在内的各类素材和资源。下图是一个整体的统计信息。 也可以感受一下实际看板的壮观 同时，我们也有一个微信的小群，时不时可以水一下，当然这个不是重点。蜜汁打码群成员送上。 学习素材共享小组 V2.0 升级 经过一年的时间，为了让这个小组焕发出更大的活力，我们计划通过生信菜鸟团的平台进行一次谨慎的纳新，加入学习素材共享小组，一起分享交流和学习。 在去年的基础上，学习素材共享小组 V2.0 会有一些小小的升级和补强。 我们分享内容的主要依托依旧是看板工具 Trello，素材分享池 2020 已经建立。 为了保证每个人可以有效的参与，我们还在内部发起了「素材学习分享周刊」。由所有素材分享学习小组成员轮流担任编辑，每周更新。既作为分享机制也作为小组审核机制。内容包括但不限于书籍推荐、博客文章推荐、文献推荐、资源工具推荐和音乐电影推荐。 欢迎你的加入 加入我们可能有哪些收获 在这个信息爆炸的时代了解大家关注什么 提供自己感兴趣的素材和同样感兴趣的人进行讨论 看到自己熟悉的素材可以学习和输出与他人分享 学习和使用当前流行的协作工具 Trello 和语雀 成员之间建立深厚的友谊 有哪些加入要求 原则上，「学习素材共享协作小组」不设置加入门槛，如果你愿意分享自己的学习素材也想了解大家的学习素材就可以加入。 虽然加入不受限制，但是维持运行需要一些基本的要求：保持一定频率的素材分享和讨论参与。也就是说，如果抱着「我就看看不进去」的心态，看不了多久就会被送走。 应该如何加入 使用常用邮箱发送申请给协作小组管理员，管理员会将你的个人介绍同步给所有小组成员，通过后，会使用邮箱邀请你加入我们的 Trello 团队，会通过你的微信号邀请你加入微信群。然后你只需要接受我们的邮件和微信邀请，就可以拥有团队所有看板和文档的浏览编辑权限了。 协作小组管理员邮箱：hi@kaopubear.top 邮件主题：协作小组申请+ID 邮件内容： 个人介绍（尽量能简单说明自己有定期分享的能力和精力） 常用邮箱 （用于接收 Trello 团队邀请，必须提供） 常用手机号/微信号（用于接收微信邀请） 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-01-19-refgroup2020/"},{"title":"Trello 看板内容太多，飞书表格帮你自动整理","content":" 本文首发于「少数派」 重度使用 Trello 的小烦恼 在「把飞书融入日常学习流程：一个人的飞书也挺好」这篇文章中，我曾提到 由于我每天会通过各种方式和渠道把素材保存到 Trello 的多个看板中，因此很难对每天产生的素材内容和数量有一个整体直观的感受，有时候某个列表已经很长了却全然不自知而没有处理。现在，飞书的 Trello bot 帮我解决了这个问题。 Trello 在我日常学习工作中有非常重要的作用，各种类型的学习和写作素材我都会通过 Trello 进行归纳和处理。 任务类的卡片可以在不同列表中移动然后进行归档，但是作为素材类的卡片我通常不会用归档的方式处理。这就导致了一个问题：随着素材越来越多，列表越来越长，虽然可以搜索，但整理汇总起来还是不太方便。 因此，我一度采取的解决方案是定期把 Trello 内容整理为表格。但是导出 CSV 表格是 Trello 的付费功能，所以我尝试了各种可能的方案来实现这个需求，比如寻找第三方插件工具或者利用 JSON 文件进行格式转换，然而效果都不理想。 这也成为我苦 Trello 久矣的一个小烦恼，直到用上了「飞书精灵」。 飞书精灵是什么 飞书精灵是飞书推出的一项应用整合服务（目前还在灰度测试阶段）。当我接触到飞书精灵之后，真正体会到了飞书在其官网的一句 slogan：在飞书 享高效。 飞书精灵提供了大量的第三方应用和内部模块，我们可以非常方便的用它把第三方应用和飞书自身的消息文档等功能串联起来，从而实现各种富有创造性的自动化操作。 飞书精灵特点 可以看一下有没有你在用的效率工具。 如果你对 IFTTT 或者 iOS 捷径比较熟悉，上手飞书精灵也会非常轻松。其「Trigger……Action……」的运行模式本质是「if……then……」的操作逻辑，其中 Trigger 表示在满足某个条件的情况下产生触发效果，然后 Action 就会完成提前设置好的动作。 这个过程在第一次正确设置之后就会自动运行，从而将我们从很多重复性的工作中解放出来。 创建自动汇总 Trello 内容的飞书精灵 目前飞书精灵还在测试阶段，如果你的团队需要使用可以由管理员通过客服进行申请，然后管理员在后台添加「飞书精灵」这个应用后即可使用。 接下来，我将通过具体的操作步骤与大家分享如何使用飞书精灵将在线表格和 Trello 素材库结合，进而实现 Trello 素材库内容更新后自动在表格中追加更新。 在云空间新建表格 表格在飞书精灵中属于 Action 部分的内容，一共有两种操作方式：创建表格和新增一行。因为要实现的是在一个表格中追加新增卡片内容的效果，所以需要提前创建一个表格。 在使用「新增一行」的动作时所选表格必须具备表头以便后续进行更加详细的设置。因此，我根据 Trello 卡片内容在表格中创建了题目、标签、描述、成员和链接 5 列，如下图所示。 创建飞书精灵 表格创建完成后就进入设置飞书精灵的过程，可以通过客户端的「工作台」找到「飞书精灵」并进入设置页面在右上角点击「创建」。 这时展示在我们面前的就是如下图所示的「触发器」和「操作」选择框。 触发器设置 首先进行触发器设置，包括选择应用、选择触发器和设置选项三个步骤。 在「选择应用」界面点击「Trello」，在「选择出发器」选择需要的触发动作，根据一个卡片只需要记录一次的实际需求，我选择了「卡片创建」触发。随后在设置选项中绑定账号并选择需要监听的看板和列表。 三步完成触发器 至此，我们就完成了「触发器」部分的配置，接下来进入「操作」部分。 操作设置 操作部分依旧由三步组成，分别是：选择应用、选择操作和设置选项。 第一步首先选择「表格」作为应用，然后在选择操作时选择「新增一行」，最后设置选项里进行更为详细的设置。 操作设置前两步 设置的前三行表示需要对哪个表格的哪个工作表进行何种形式的追加。根据先前新建的表格信息，这里依次选择即可。 完成基本设置后会自动显示对应工作表的表头内容，也就是先前设置的 5 个列名。如下图所示，点击每个「加号」都会弹出可以添加的 Trello 元素，根据表格名字我依次选择了对应的内容。例如在「题目」列添加 Trello 的卡片名称，在「链接」列添加 Trello 卡片链接。 填充内容设置 给飞书精灵命名 完成了触发器和操作设置，最后只需要给新的飞书精灵进行命名和添加描述，方便他人使用。保存后就可以在「我的飞书精灵」看到它。 命名并开启 实际操作及效果 接下来进入实操步骤。 根据使用习惯，我一般会通过 Trello 的浏览器插件保存后续需要进一步处理的文献。这里勾选附件选项后会自动填充标题并把网页链接作为附件保存，也可以同时添加简单的描述信息。 因为我之前已经设置过 Trello 机器人的自动推送，所以飞书聊天界面会收到机器人的推送消息。 无论何时何地，当你想要对 Trello 卡片进行二次整理和汇总时，只需要在飞书云空间中打开对应的表格即可。 刚才我们保存的 Trello 卡片已经按照想要的方式追加成功，美滋滋。 写在最后 以上就是飞书精灵一个简单的应用示例。配置五分钟，开心两小时，高效一整年。 因为飞书精灵深度整合了飞书的消息、文档和表格三大使用场景，这让它和同类型独立工具相比具有了很大优势，尤其是当你和团队刚好也在用飞书进行协作的时候。希望这个例子可以帮你开启飞书精灵的探索之路，找到适合自己的流程和用法，也期待你的分享。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-01-16-trelloandlark/"},{"title":"把飞书融入日常学习流程：一个人的飞书也挺好","content":" 本文首发于「少数派」 作为仍然奋斗在学术一线的学生，在很多同学和朋友眼里我一直是个喜欢折腾各种工具的「少数派」。除了每天必看的科研动态和文献之外，自己喜欢在摸鱼的时候折腾一些感兴趣的工具，用能提高效率的工具让自己拥有更多的摸鱼时间，我感觉这个逻辑没毛病，你觉得呢？ 最早知道飞书是 2019 年初陆续出现的媒体报道，各类报道中我能提取到的信息无非是「布局」和「战略」这类离我遥远的词汇。直到 2019 年下半年飞书陆续开放注册，我才认真关注和尝试使用它。 初识飞书的喜悦与尴尬 可以即时通讯的在线协作文档 关于飞书的多数介绍中，大家都是将飞书类比于其他在国内已经相对常用的企业级协作工具，所以使用前我担心飞书也是一款「面向管理者开发」的软件。之所以说「面向管理者」是因为这类应用在聊天的基础上融合的往往都是传统公司的线下办公场景，比如上班打卡、出差请假、跨部门通知和报销审批等等，这些需求虽不可谓不高频，但通常只是更方便管理者对企业进行管理。 对于那些仅有十几个人甚至几个人的小团队而言，上班打开报销审批反而不是刚需（这些团队通常也不是传统意义的企业），他们需要的是真正好用的协作工具——协作起来高效，沟通起来方便。 在使用了几天之后，好在飞书的实际体验打消了我先前的顾虑。它的各个客户端整体风格让人感觉十分清爽，取消或弱化了很多管理类功能和工具的入口，转而把「云空间」放在了非常高的层级。所谓云空间可以理解为在线文档、在线表格和云盘的综合体，每个功能都做的很扎实，绝不仅仅是一级入口那么简单。 云空间的一级入口 这里以我日常使用频率最高的在线文档为例，列举两个小细节。 用心的跟随式样式编辑栏 飞书的云文档本身支持大部分 Markdown 语法快捷键可以保证高效写作（常规操作无需多言），在进行富文本编辑时，样式编辑栏并非固定在页面最上端而是自动浮于所选内容上方。 这个设计看似不起眼，但实际用下来有两个很大的不同：一方面它可以让鼠标每次都少移动一点，另一方面使用次数多了基本可以记住常用样式的实际鼠标移动距离从而实现类似于「盲点」的效果。 另外，这个样式编辑栏召之即来挥之即去，完全不会影响沉浸式的写作体验。即便和同样采用跟随式编辑栏的 Notion 相比，飞书这个编辑栏的布局和使用逻辑也让我觉得更顺手，比如飞书调取二级菜单使用悬浮操作，鼠标只要悬浮在高亮处就会自动展示其它颜色，而 Notion 则需要再点一下鼠标；飞书的多级标题都是直接展示在样式栏的，Notion 则藏在了二级菜单。 总的来说，在用了一段时间飞书的文档编辑器之后，我作为一个多年的 Mardkown 重度使用者发现一个好用的富文本编辑器原来也可以很香。 两种表格任君选择 飞书的云空间本身可以创建文档和表格，同时在文档中也可以很方便的插入表格。让我意外的是，飞书在插入选项中思路清奇的设置了两种表格：一种是电子表格，一种是富文本表格。前者可以全屏操作且支持各种筛选和计算，后者则可以对每个单元格内的文本进行更多的样式编辑。 从云空间的优秀使用体验来讲，把飞书当作一个「可以即时通讯的在线协作文档」也无妨。 团队工具迁移的艰难与反思 除了好用的「云空间」，飞书内部文档、日程和聊天各种功能之间都做到了深度整合，整个应用的搜索功能也比较完善，于是我就有了把它推荐给身边团队的想法。 搜索过滤器 我在脑海中设想了不少「学术向」的应用场景，比如把实验室的线下文献分享迁移到飞书中进行组织和协调，通过日历安排时间和会议室，大家把推荐的文献上传到云空间，写好文献解读之后还可以通过文档共享。 我也设想在自己组织的几个学习小组内使用飞书进行交流，这样大家平时既可以聊天还能把学习内容通过云空间的形式沉淀，聊天记录也可以批量保存从而更方便后期回溯。 然后现实总和理想有些距离。对于所有相对扁平的团队和组织来讲，全体迁移到一个新工具进行协作通常都有不小的阻力。一方面是新工具的学习成本和迁移成本，大家已经习惯了之前的交流协作方式，即便有些地方不如人意也不愿再花太多时间到新工具上；另一方面，成员的时间精力有限，即便开始愿意尝试，往往到了后期还是把主要的时间精力放在社交成本更低的国民应用上。 此外，针对小社群和组织，例如像实验室这种既不会有营业执照也没有官方认证的团队，飞书目前还没有开放文档公开分享的功能。这也导致我们确实无法进行全量迁移，于是我推而广之的设想只能作罢。 认证必须要有证书 一个人的飞书也挺好 在飞书官网的首页有这样一句话：成就组织和个人，打造高效愉悦的办公平台。 想到自己日常有很多学习和工作任务，也有不少码字需求，虽然现阶段身边团队还暂时没有一起使用飞书，但我一个人也可以是一只队伍啊。为何不试试用它打造一个给自己的高效愉悦办公平台呢？ 有了尝试将飞书融入日常学习流程这个新目标后，我开始思考其中哪些具体场景可以和飞书关联。 梳理自己的日常学习流程 下面的示意图是我目前比较固定的日常学习流程，整体可以分为对素材（信息）的收集、筛选、扩展、深入和完善五个部分。 学习流程 素材收集 我日常接触的学习素材主要有学术期刊文献、博客与深度报道文章、社交平台的大神分享和即时通讯工具的聊天消息。 其中，学术相关内容主要通过两个专门的文献类网站和对应客户端获取，也用 RSS 订阅了几个高频阅读的杂志；专业领域博客则是通过 RSS 在 inoreader 阅读，一些深度的媒体报道会使用锤子阅读这类聚合应用。 针对 Twitter 这样的社交平台，我在手机上安装了两个 App，比较忙的时候会用官方客户端接受算法给我的推荐内容；比较空闲的时候则会打开 Tweetbot 按照时间线浏览推文。 素材筛选 对于收集到的素材，我一般会首先按照信息源来进行分类。 内容质量高且信息密度低的信息源通常是有更新即进行下一步扩展；如果内容质量高但是信息密度也大的信息源会使用关键词进行部分过滤，通过标题和少量正文内容进行判断筛选；如果是无法确认整体质量的信息源基本上采用随缘阅读的方案以及靠好友推荐了。 素材扩展 在扩展过程中，我会把上一步筛选出的素材进行简单描述和评价。 所谓描述就是用自己的语言把接收到的信息进行一次客观复述，而评价则是在快速浏览整体信息内容之后进行一次主观判断，比如这个学习素材对我有什么帮助或者对我现阶段的帮助有多大。 深入学习 对信息进行扩展后，我会把短期内并非刚需或者没有很大帮助的内容存入资料库，后续通过知识星球等形式分享给其它可能需要这些素材的人；那些我认为对自己现阶段有用的素材则会进入深入处理的阶段。 在深入学习过程中我会找相对完整的时间对素材认真阅读学习，并对内容进行更具体的批注和思考。通常这个过程结束之后针对一个素材就会留下一篇半成品的学习笔记。 完善输出 这个环节和上一个环节有时可能是相继进行，也很可能中间会间隔很久。 在完善过程中，我会把学习内容在我实际工作和生活中应用的过程和效果也记录下来，然后将其和已有的其它素材或笔记进行关联，进而形成相对完整的学习内容。其中一些在整理好之后还会通过博客等平台进行分享交流。 所用工具 这样五个步骤之后也就完成了素材（信息）从接收到处理吸收再到内化分享的流程。这个流程中我近两三年一直重度使用的几个工具包括：inoreader、Trello、Pocket、印象笔记和 IFTTT。 其中 inoreader 主要对所有 RSS 源内容进行接收和初步过滤，Trello 负责对所用筛选后素材进行分类和保存，Pocket 则会保存我进入深入阶段的各种内容，多数半成品学习笔记都存在我的印象笔记中。最后 IFTTT 负责这些工具之间的联动，例如 inoreader 星标的内容自动发送到 Pocket。文章重点不再这些工具的使用上，就不过多进行具体介绍了。 这个学习流程虽然经过一两年的打磨整体已经比较顺畅，但有些地方其实还不尽如人意，比如对于不同工具内素材的统一查找。所以能不能利用飞书把整个流程的体验再完善一点呢？ 用分享和群聊打造信息中转站 由于高频独自使用飞书，我发现了它三个比较有趣的设计细节。 分享方式「多此一举」 飞书系统层级的分享功能非常适合做零散信息的汇总。 在调用系统层级的「分享」后，首先出现的是看似多此一举的分享对象选择界面。如果选择「发送给同事和群」接下来才会出现好友选择界面，如果选择「发送给自己」则可以直接完成推送。 分享到飞书 我的选择就是直接发送给自己，这个过程因为用不着每次都看一遍联系人界面而变得非常愉快。不过现在在 iOS 上选择分享给自己好还是会进入到飞书应用内部，如果后续可以调整分享给自己后自动回到原应用就更好了。 分享链接自动解析 发送到飞书对话框的各种链接都会自动进行解析。 如下图所示，无论是来自其他 APP 的分享还是来自浏览器的链接分享亦或者是微信公众号文章的链接，飞书都会「尽力」的帮你进行二次解析供你预览。 链接自动解析 这样一来，有链接有题目有内容，对这些信息进行后续处理时真的是方便很多。 群聊支持单人模式 飞书可以直接一个人完成建群，嗯，可以一个人建很多群。 虽然在正常情况下，如果建很多一人群然后自己和自己聊天有点奇葩。但换个思路，通过不同的群来把信息进行分类就会有不一样的体验。 例如，我的根据自己的素材类型就建了文献阅读、专业素材、效率素材和阅读材料四个群。这些群的更多用法在下文介绍。 我的四个群 用机器人推送和浏览素材 飞书支持很多第三方机器人或利用 webhook 自行开发机器人。其中有两个机器人可以说是集合与呈现信息的神器：RSS bot 和 Trello bot。 第三方机器人 RSS bot 当我打开 RSS bot 的一瞬间有一点恍惚，大家可以自行看一下操作提示里给出的示例信息源。当我尝试点开推特链接时，发现飞书直接把我引到到了 RSShub。恍然大悟，万物皆可 RSS 没错了。 RSS bot 在飞书中有两种呈现方式：独立的 RSS 助手和群内聊天机器人。 我个人更倾向于在群内使用 RSS 聊天机器人，因为我将不同学习素材分为了四类，就把对应的 RSS 源添加到不同的群机器人中从而省去手动分类的问题。 在 inoreader 我目前有 150 多个订阅源，哪些适合放到飞书中也是一个需要考虑的问题，我的筛选标准依旧是高质量和低密度这两个条件。 在文献阅读群的 RSS 中，我添加了四本必读的专业期刊；在效率素材群中添加了少数派首页文章和三个必读博主的博客；在专业素材群内我用 weRSS 添加了 6 个必读专业公众号和 3 个专业相关好友的博客 ；阅读素材群内经过几次删减，我目前只留下了 slashdot 和 solidot。 把这些订阅源连接到飞书之后，我的明显感受是阅读压力变小了很多。一方面因为又借机重新梳理了一遍自己现阶段的订阅内容和优先级；另一方面是因为现在连续几天不打开 inoreader 也少了之前那份焦虑。 至于你可能会关心的 RSS 内容展示效果，说不上好但足够用。标题加上部分预览内容已经足够大致了解主题，点击「查看详情」在移动端或者是电脑端都是自动跳转到浏览器打开。浏览器打开之后，就又回到了常规的网页内容处理流程。 Trello bot 知道 Trello 是很早的事情，重度使用 Trello 则是在加入少数派作者看板之后，那时我才对如何使用看板整理素材有了一个直观的感受。 目前 Trello 已经成为了我个人的素材库，而且我也以 Trello 作为载体组织了一个专业相关的学习素材共享小组。 由于我每天会通过各种方式和渠道把素材保存到 Trello 的多个看板中，因此很难对每天产生的素材内容和数量有一个整体直观的感受，有时候某个列表已经很长了却全然不自知而没有处理。现在，飞书的 Trello bot 帮我解决了这个问题。 在群里开启 Trello bot 后首先需要授权访问自己的 Trello 账户，然后在设置界面选择关联的看板和推送类型。通常只选择针对「创建卡片」和「添加评论」两个选项进行推送。 我分别把文献素材库以及专业素材库关联到了文献阅读群和专业素材群，也把一个学习小组的公用看板进行了关联。这样当我每天翻看群消息时，就会比较清晰的感知新增素材数量和大致内容。 如下图所示，Trello 推送内容包括卡片的题目和链接，如果是评论更新则会显示评论内容。 用引用回复进行素材扩展 在上文提到的素材处理流程中，有一环是对素材进行描述和评价。这个环节在还没有使用飞书时我是在 Trello 评论中完成的，用了飞书之后我更多的开始选择在飞书中对素材进行回复（移动端的 Trello 真心用不太习惯）。 引用消息这种原本在即时通讯群聊中才需要的功能，用在对素材的初步处理中也像是量身定制一样合适。如下图所示，在一个人的群聊中，我可以直接对一条素材进行反复多次引用，扩展的数目会通过「x 条回复」进行展示。 当我想对扩展后的素材进行分享时，可以直接在电脑端单击原消息，所有回复内容就都会同时展示出来，非常清晰。如果想要全部导出，虽然没有直接操作方式，但在电脑端可以直接「暴力」全部复制然后用匹配样式的方式进行粘贴再进行简单编辑。 用 Pin 和收藏对素材分级 飞书在消息的二次处理上提供了几种选择：Pin 类似于群收藏，Pin 过的消息会被所有人看到；收藏内容仅自己可见，有一级入口；而「完成」和「稍后处理」则是对聊天和群的处理方式，飞书没有删除聊天的功能，只有完成和未完成之分。 我通常会将已经完成扩展和深入环节的素材连带内容一起放进收藏，因为这些内容都是我认为很重要的，方便我随时查看。不同类型的素材需要我尽快处理的内容会 pin 在不同的群聊。每当我完成一类内容就会把这个群勾选为「完成」，眼不见心不烦，等到再有了推送它会自己重新展示在收件箱。 用搜索查找素材和想法 把 Trello、RSS 和各种网页链接以及碎片化记录通通放在飞书中，时间久了看似很乱，但得益于飞书的搜索功能反而让我感觉用的越久越容易找到自己想要的东西。 比如当我搜一个关键词时，无论是 Trello 中评论的内容还是 RSS 推送过的内容，亦或者我之前的零碎思考都会统统被找到。多说一句，扔到飞书中的各种链接，在完成预览后其预览内容也可以被检索（如下图所示），又一次暖心了。 利用聊天尝试移动写作 很长一段时间我一直都很抗拒在移动端码字，想找一个好用的移动端写作工具实在太难了。 因为我同时在用 iPhone 和坚果 R1 两部手机，在实验室用 Windows 台式机不在实验室的时候又用 MacBook Pro，所以一直苦苦追寻一个至少支持这四个平台且可以同步还支持 Markdown 的应用。 直到最近听少数派 Power+ Live 中 Fairyex 说，他所有写作都是在手机上完成后，我才发现自己应该换一下思路。于我而言，现阶段在手机上码字既然找不到符合个人要求的工具，干脆就找一个在 iOS 和 Android 可以打开就能说的应用。 写不下去我改成语音转文字总可以吧，然而目前支持语音转文字输入的工具不少，但尝试若干之后我发现它们要么就是能用但价格不菲要么就是基本不能用，感觉 Drafts 语音识别还能接受但是它又只能在苹果的生态中发光发热。 使用飞书以后事情有了转机，我发现它自带的语音转文字竟然有不少亮点： 语音识别准确率高，说出来的话基本不用大修。 语音内容可以即时显示在屏幕上且可在发送前修改。 支持任意时长（足够长）的语音输入。 支持反复按住和松开录音键，而不是只能一直按住说话。 作为即时通讯工具，天然在所有端无缝同步。 为此我建了一个叫做「写起来」的碎片化个人写作群。一方面我会把扩展后需要深入学习的素材消息转发到这个群里方便记录；另一方面如果突然有了关于选题的灵感和思路，就会拿起手边的手机打开语音转文字然后进入 TNT（touch &amp; talk）的按住说话模式。 这篇稿子在成文过程中，第三部分内容就是通过语言转文字的方式在手机上用语音输入完成的。当我说了几大段心满意足之后，坐在电脑前直接把刚才的所有文字一起复制，稍加修改调整即可。如下图所示，当时我在通勤的路上，即便有「飞书支持」识别为「肥瘦知识」（难道是我普通话不标准）的这种表现，但整体的识别率还是满意的。 现阶段，用语音输入方式写作的瓶颈主要在我自己而非工具，比如在说话的时候尽量训练自己的逻辑要足够清晰，努力克服「呃」这类口头禅。也算是我在 2020 年进行刻意练习的一个方向吧。 用飞书精灵实现应用互动 飞书精灵是飞书推出的一项应用整合服务（成文时还在测试阶段），他提供了大量第三方应用和内部模块，我们可以非常方便的用它把第三方应用和飞书自身的消息文档等功能串联起来，从而实现各种富有创造性的自动化操作。 飞书精灵特点 例如，每当我的 Trello 看板创建了新的卡片后，除了接受飞书机器人的消息提醒，我还会把卡片内容自动追加的我的云空间表格，从而实现了 Trello 看板即时汇总。 自动追加 Trello 内容 关于飞书精灵的具体介绍，可以参考我的另外两篇文章。 Trello 看板内容太多，飞书表格帮你自动整理 跨平台协作，让飞书实时接收语雀更新提醒 写在最后 从接触飞书到希望团队使用未果再到转而开始一个人使用，我似乎在使用这个「团队协作工具」的道路上越跑越偏，但也正是这段过程和经历让我对于工具的定义有了一个全新的认识。 因为他人介绍的几个亮点开始接触一个工具没有问题，但真正使用的时候就应该忘记它所有被人为赋予的定义。从功能出发，尤其是从那些打动你的功能出发，将其整合到你的学习工作中用来解决实实在在的痛点，最后赋予这个工具仅仅属于你自己的定义。 于我使用飞书的这个实际例子而言。我尝试将它融入到自己的日常学习流程后，即便是团队协作工具，一个人的飞书也挺好。如果今后在团队中使用飞书进行协作，那只会让我的这些用法发挥更大的价值。 放到几年前，在我还没有自己的工具方法论也没有自己基本成型的学习工作流时，一定不会写出如此「偏门」的使用感受和学习效率提升心得。彼时的自己一直在重复的就是搜集工具、学习教程和模仿大佬，其中包含了大量的试错成本和无用功作为学费。最近一两年，虽然接触的工具类型越来越多，可每个种类里我在用的工具已经越来越少。 也许，这就是成长，或者开始老了。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-01-15-oneselflark/"},{"title":"人究竟怎样才算来过又怎样才算离开","content":"一个人，究竟怎样才算来过，究竟怎样才算离开？ 今天得知一位神交许久的同龄朋友已经永远离开了，恍惚了很久，从来未曾体会过的一种感觉。我很希望这是一个假的消息，是一个乌龙的消息。 我突然在想，一个人，究竟怎样才算来过，究竟怎样才算离开。 在电影「寻梦环游记」里有一个表达：真正的死亡是世界上再没有一个人记得你，死亡不是生命的终点，遗忘才是。 从这个角度讲，我想他不管怎么样也没有离开。我也希望能够尽自己的一点力量，让他存在的久一点。 你留下的文字，影响了很多人，也依旧会陪伴很多人。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-01-11-rememberyouzjl/"},{"title":"使用 VSCode 愉快地进行远程 R 开发","content":"2019 年底（其实也就是半个多月之前）听了 renkun 大神在上海 R 会议的一个分享，分享主题是「Rstudio vs VSCode」，然后他紧接着又写了两篇使用 VSCode 进行 R 开发的博客。仔细了解之后，感觉自己有救了。 之所以这么说，是因为自己一直有个需求得不到很好的满足：在本地方便的开发部署在远程服务器上的 Shiny 应用。 具体一点说，因为我的 Shiny 需要依托一些 Linux 下才能运行的程序，且这些程序对内存有要求，就导致我无法在 Windows 本地使用 WSL 进行测试和开发。而之前使用 VSCode Remote SSH 让本地 VSCode 连接上服务器本身没问题，但是早期 R Console 运行得到的各种结果本身却无法在 VSCode 中方便的查看，总是需要跳出额外的各种窗口。 当然，使用 Rstudio Server 是一个选择，但在实际使用中会有比如单一 session，时常未响应，编辑器各种不顺手等等问题。 随着几位大神的开发加持，现在使用 VSCode 愉快地进行远程 R 语言开发不仅成为了一种可能，而且还非常香，在使用体验上基本不输 Rstudio，而且很多小细节上更加贴心。 为什么要用 VSCode 写 R 大家可能会有一个非常真诚的疑问，Rstudio (server) 它不香吗，写 R 为什么还要用其它编辑器? 下面这张幻灯片来自 renkun 在会议上的分享，基本说明了问题。 就像上图总结的，RStudio 好用，几乎是所有 R 用户的最佳选择。但同时像上文提到的，时不时的无响应带来的各种不稳定，单 session 操作等又让人苦恼。 你可能会有这样的感受，使用 Rstudio 的过程中因为其本身需要一直和服务器保持通信，live R session 和语言服务又无法分离，当 Console 中运行了一个耗时或者耗内存的命令之后，整个 Rstudio 就无法进行任何操作了。 那 VScode 呢？这个编辑器本身的优点不必多说，虽然之前对 R 的支持没那么友好，不过最近几个月在 VSCode 中使用 R 有了重大的体验升级，这主要体现在两个方面。 R Language Server 在后端的加持 vscode-R 插件在前端的重大迭代 R Language Server 首先说 R Language Server，R Language Server 依托于 Language Server Protocol（可以让任何语言在任何编辑器上得到很好的语法支持）。现在的 R Language Server 在 VScode 中已经非常好的支持了多种鼠标悬停内容展示、帮助文档展示、自动补全、文本高亮以及代码格式化等功能。 R Language Server 和 Rstudio 相比差别最大的一点在于前者是真正的静态分析（static analysis），指在不运行程序的条件下，进行程序分析的方法。也就是说所有功能的实现都无需运行代码，对代码进行的分析仅仅依赖代码本身。而且它的语言服务完全脱离于 R session，即便在 R session 非常繁忙的情况下依旧可以提供服务。 接下来仅仅列举几个在 Rstuido 中不是很方便实现或者无法实现的功能。 鼠标悬停即显示函数定义和文档，无论对应的包是否已经加载。（箭头处为鼠标位置，下同） 鼠标悬停在变量上，直接展示变量类型信息 这个就类似于 Rstuido 中 environment 那个小框的功能，但是更方便直观。 自动高亮文档内所有同一变量 选中代码，自动格式化，例如添加空格等。 vscode-R 新增 Session Watcher vscode-R 插件则在最近的更新中新增了一个 Session Watcher 功能，即便还在测试阶段这个功能也足以让人激动。它实现了在 VSCode 中实时展示各种变量的需求，View() 的时候再也不会有各种弹窗了。文字不好描述，直接上图。 查看 data.frame 如下图右，直接查看 data.frame 内容，支持搜索。 展示 ggplot 出图 展示 htmlwidgets 通过 SSH 连接远程服务器 接下来简单介绍如何实现在本地 VScode 中实现远程 R 开发。 首先要实现的自然是远程操作，这里以使用 PC 通过 SSH 连接远程 Linux 服务器为例。 我们默认服务器已经开通了 ssh 服务，然后本地 PC 已经正确安装了 Windows OpenSSH Client。 安装插件 Remote-SSH 然后在命令行面板中找到 Remote-SSH 相关命令，可以直接选择链接服务器，也可以选择打开配置文件。这里我们选择打开配置文件进行简单的配置。 在配置文件中可以输入相应的用户名 IP 地址以及端口等信息。写法如下图所示，写好保存即可。 再选择连接 Host 的命令，就会看到之前我们已经保存好的 Host 选项。 点击对应的 Host，然后输入密码即可。 如果为了方便不想每次都输入密码，可以使用 SSH key 配置服务器和本地的公钥私钥，这里不再展开。 连接成功之后，VSCode 左下角就会显示一个远程连接的标志，同时你还可以直接在 TERMINAL 中打开一个 shell （我用的是 zsh），就像平时使用类似 Xshell 的工具一样直接进行各种操作。 配置 R 语言开发环境 完成了远程连接服务器的工作，接下来是在 Remote 状态下简单进行 R 相关的配置。 首先安装两个必备的插件，R 和 R LSP。然后还需要在服务器的 R 中安装一个 R 包 languageserver。 install.packages(&quot;languageserver&quot;) 随后在设置界面中进行几个关于 R 的设置。 首先是设置 Linux 下的 R 路径，如果使用系统自带的 R 应该是/usr/bin/R ，如果是使用自己目录下，例如使用 conda 安装的 R 则指定对应的 R 路径。这里推荐使用 Radian 替代 R，所以我的 R 路径就指向了使用 conda 安装的 radian。如下图所示。 如果使用 Radian 的话，则需要勾选 Bracketed Paste 选项。 如果希望使用服务器上的一些 R 配置，例如 .Rprofile 和 .Renviron 文件，那么 Rterm Option 处就不要加什么其它参数，如果不希望使用则可以酌情添加--no-init-file 或者 --no-environ 等参数。 安装插件。在 Rstudio 中路径的自动补全功能非常方便，在 VSCode 中则可以通过插件 Path Autocomplete 来实现这个功能。 至此，就完成了在 VSCode 中使用 R 所需要的一些基本配置，可以开工搬砖。 最终使用效果 直接上截图。 左侧为服务器对应的文件目录，可以直接点击查看编辑 中间是 R 脚本，可以开心的写代码 右边是对应的网页工具，直接查看效果 下面是连接到服务器的终端，可以在 zsh、R 以及 python 等终端任意切换。也可以同时打开多个不同的 R 终端进行不同任务，互不干扰。 扩展资料： Writing R in VSCode: A Fresh Start Writing R in VSCode: Interacting with an R session Remote Development using SSH Quick start: SSH key 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-01-08-remotevscoder/"},{"title":"给一年前自己的一封信-2019","content":"思考问题的熊，你好。 见字如面。 当你看到这封信的时候，时间刚刚来到 2019 年，距离你在 2020 年写 2019 年小结还有一年的时间。 在写这封信之前我翻了翻你 2018 年底的总结。看你在那篇文章的最后写到 2019 争取「少扯淡多学习」，好吧，你还是有些天真，未来的一年，一方面你不会少扯淡另一方面也没有多学习。Relax。 关于写字 你在前几天的 2018 年小结中说自己感觉想写的想说的都已经差不多了，但在 2019 年其实你还是写了不少字，在简书上你会更新接近 9 万字，虽然和 2018 年的 17 万字相比少了一半，不过这些文章依旧会让 3 万人次看到并可能帮助到一些人，所以还是坚持下去。 比如你在 2019 年 1 月的时候将会碰到一个PC 上不能使用 IGV 的 bug，这个问题其实就是 AMD 显卡问题导致的，你干脆趁早别用就完事儿。不过这个文章在一年后还会帮助到和你有同样困惑的人，不换也罢。 像你一直认为的那样，写作是一个非常好的输出渠道，不过我想告诉你无法控制输出的什么内容会影响到别人，所以也没必要太在意这个事情。写文章无需太正经，专业性强的内容可以适当释放一些，多写写有的没的也无妨。 你想不到大家其实往往会因为文章里的几个段子记住你，更想不到会有读者直接「全文借鉴」你博客里的「关于」页到他们的博客去。Relax。 关于博客 说到博客，我劝你不要太折腾，如果折腾的话也不要随意的就把文章 URL 地址都换掉 😃 。Hexo 这个框架用起来麻烦点但功能还算全，其实没必要更换框架。哎，算了，因为下半年你还要给自己配置一个 MacBook pro，又有多了一个「全平台使用」的需求，想挡住你折腾也不太可能。不过我建议你最好还是趁早投入到全端苹果的怀抱好些。 你的博客未来的一年访问量中规中矩，保持佛系更新就好。四五十篇文章换来 2 万次的网页访问，会影响到接近 6500 多人，每次会话平均 2 分。这个数据要比你在 2018 年差一些，因为写的东西也少了。 2019 年 2 月 11 号下午会有一个准备考研的同学用手机浏览你的那本考研复习手册 74 分钟，7 月 24 日下午会有一个备考的学生阅读你的考研书 58 分钟，你最好提前有个准备，如果知道他们是谁可以去鼓励一下。这么多年过去了，当年的文集虽然没再给你带来什么价值但是还在发挥余热。 2 月 26 日上午，有一个读者会集中阅读你博客里关于 VScode 的文章 50 分钟；8 月 19 日晚上会有一个读者在你的博客停留 52 分钟，他应该是在学习转录组分析，集中阅读了你博客里所有和转录组相关的内容；8 月 22 日下午还会有一个读者在你的博客停留 63 分钟。 为了他们，你应该提前把这些文章里的错别字修改修改。 可能你未来会产生几次放弃博客的想法，但最好还是留着，给大家多一个念想。 另外，下半年你会关注到一个叫做「语雀」的平台，我想它目前还算符合你的写作及协作需求，不如早点留意一下。 关于读书 我知道你年初给自己列了一个 2019 年阅读和学习清单，清单的内容看起来很美，但是一年后也许只会觉得很凄美。作为过来人，给你一个认真的建议，把你的清单缩减到原始量的三分之一，这样完成起来压力才不算大。如果狠下心缩减到二分之一应该也可以。 除此之外，看书还是应该有一个侧重点，那十几本非专业书可以精简一下，也不至于剩下几本专业相关的书到了年底还没翻开。对了，买回来的书最好不要直接把塑料封皮打开，什么时候真要看了再拆开也不迟，不然送人或者转手卖都不方便，会落灰。 答应我，2020 年先别买书，把拆了封皮但是还没读的先读完，要不然后面搬家实在不方便。 我从你即将要看的书里推荐如下几本，只读读它们就可以了。 刷新：重新发现商业与未来 硅谷钢铁侠：埃隆马斯克的冒险人生 关键提问 事实 掌控谈话 完全写作指南 读懂一本书：樊登读书法 精要主义 请停止无效社交 真相与错觉 关于技能 未来的一年你会接触到一些新的项目，也会有机会学习一些新的技能。比如 BSA，WGBS，HiC，ISO-seq 还有一些奇奇怪怪的可能你之前都没有接触过的技术。在这些内容上，你还有机会接触一些延伸出来的技能，比如 Docker 和流程控制以及网站制作等等，当然也包括很多基础技能的提升。这些技术将服务于很多实际的科学概念和问题。 所以，你需要看的东西很多，要警惕一件事情：很多事情都做了一些，但是都做的不够，不够细致也不够深入。 2019 年你将会有三篇共同一作的文章发表，无论是 5 分还是 13 分，抛开工作量不谈，这些终究都不是你会写到毕业论文里的工作。但也无需妄自菲薄，坦然接受他人的任何评价，然后忘记。 在集中注意力这个能力上，你还比较欠缺，换句话说有时候做事会抓不到重点。因为一些事情的发生，你并没有在最应该投入精力的地方投入足够的精力。这个问题需要特别注意。 其它一些人和事 在这一年，你会进入两个之前没有接触过的圈子，一个是印象笔记的各路资深大使，一个是少数派的各路专业作者；在这一年，你将会从更多方面参与到生信技能树的团队；在这一年你会有机会认识和接触到非常多优秀的人，并且和几个人有深入的相处；在这一年你也将和很多人从更多维度展开协作。 进入新的圈子意味着你过往的一些东西得到了他人的认可，也意味着你要学会接受很多新的规则。当然，你无需为了取悦任何人而做让自己难受的事情，换言之任何事情也不是非你不可。 如果你想要有所精进和突破，就需要抓住一些看起来不那么好的机会，从以往的经验来看好的机会通常都不会降临在你的身上，有些东西错过可能就会变成过错。在能力和产出都不足够优秀之前，你更是无需为了如何融入某一个团队和圈子而苦恼，关心如何提高能力和产出就够你受的。 在这一年，你将会组织几件事情，比如 8 月份的首届生物信息人才发展论坛、bioc workflow 翻译项目、生产力工具学习路线图和生信知识库。我不质疑你做每一件事情起初的想法和动力，从意义上来说这些事情无论哪一件都值得你做下去，只是希望你能够在做决定之前慎重考虑，一旦决定了就要克服各种困难。 当你什么也不做，不过是一直站在坐标轴的零点。如果你做了却没有做好，答应了又没有做到，别人就会把你向负轴移动一点，以后你还需要再多做些什么才能走回去。上面这些事情，有的会在 2019 年开始却没能在 2019 年完成，如果可以的话，尽快把它们做完。 涉及到人与人之间的问题，就会变得稍微复杂起来，无论什么形式的协作和合作都是如此。 我站在一年后的节点上依旧无法给你太好的建议，只能告诉你一点点我此刻的感受。 有两三个交心的朋友很重要，他们是线上还是线下都可以。 对待协作者和合作者的标准和对待朋友的标准不同，某些情况下对待前者的要求甚至更高更苛刻。 对自己要求严格一些，对他人适当宽容一些，极少有人会故意伤害你。 推己及人，自己做起来有难度的事情就不要对他人抱有太大希望。 珍惜和你有过交集的人，但是不要追着别人不放。 任何事情都不要随便答应，答应了就尽力去做。 大多数情况你不是一个人在战斗，但也有不少情况你就是一个人在战斗。 最后 希望 2019 年这一年你即将经历的所有事情能够让你有一点点感悟，专注自己喜欢和需要做好的事情，不要在意太多的纷扰和无法控制的结果。 2018 年过去了，2019 年也会过去。当 2019 年过去的时候，我希望你一点也不要怀念它，你也不要指望 2020 年会对你好一点。 因为，生活即是不停的告别，我们由此得以顿悟和成长。 以及，2019 年和 2020 年你最在意的计时单位应该是学年而不是新年。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2020-01-02-201-summary/"},{"title":"眼见不为实：为什么29不等于29","content":"浮点数计算和比较的坑 29 怎么会不等于 29 今天有一个小伙伴给我发来了一个截图如下。我下意识的说了一句：0.58*50 不等于 29。 感概，有时候，眼见也不一定为实。这就是一个浮点运算导致的「算不准」问题。 在历史上，其实已经有过类似因为浮点运算导致的事故。 1994 年，英特尔的奔腾微处理器芯片的浮点计算单元出现了一个 Bug。在某些情况下，浮点除法并不能返回正确的结果。例如 4195835.0/3145727.0 产生的是 1.33374 而不是 1.33382。虽然这个 Bug 可能对绝大多数人没有影响，但是市面上 500 万左右流通的芯片都存在该缺陷，随着整个事件的发酵，最终这个 Bug 给 intel 造成了 4.75 亿美元的损失。这次事件也被称为「Pentium FDIV bug」而载入了 Bug 史册。 R 语言中的实际示例 我们分别在 R 中计算 0.58*50，0.29*100，然后让他们和 29 互相比一比。 (a=29) (b=0.58*50) (c=0.29*100) a==c a==b b==c 结果如下所示： &gt; (a=29) [1] 29 &gt; (b=0.58*50) [1] 29 &gt; (c=0.29*100) [1] 29 &gt; a==c [1] FALSE &gt; b==c [1] TRUE &gt; a==b [1] FALSE 我们看到屏幕上显示的 a , b 和 c 都是 29，但是如果用==进行一下比较，发现0.58*50和0.29*100竟然都不等于 29。嗯，很迷。 浮点数的精度和计算问题，在任何编程语言里都类似。 浮点数在计算机中不能以任意精读存储，都会有一个准确性的限制，通过有限的连续字符来保存浮点数。 目前常见的浮点格式包括：单精度，双精度和扩展双精度。他们的准确性从前到后依次提高，其中单精度可以用于一般计算，双精度用于科学计算。在 R 中就是采用了双精度来对浮点数进行保存。如下所示： &gt; (d &lt;- 10) [1] 10 &gt; class(d) [1] &quot;numeric&quot; &gt; typeof(d) [1] &quot;double&quot; 我们让 d 等于 10，通过 class 可以看出它是一个数值型变量，如果用 typeof 查看，就会发现他的存储模式(storage mode)是一个双精度浮点型数字。 这里又涉及到了存储模式和类型的问题。在 R 中class返回的是一个对象的高级类，而typeof返回的是对象的内部低级类。如果用calss查看一个数据框，其返回结果就是他的类(calss)为数据框，如果使用typeof查看，返回的结果就是内部类型为列表，如下所示。（嗯，想起了果子老师课上讲的，data.frame 就是一种特殊的 list） &gt; class(iris) [1] &quot;data.frame&quot; &gt; typeof(iris) [1] &quot;list&quot; 继续回来说浮点数的比较。因为精度问题，在 R 语言中使用 == 进行浮点数的比较是非常危险的。 就像文章开头的例子，此时假设你有一个 if 语句，想进行一下结果的判断。如果判断条件是 0.29*100 == 29，就会返回 F。因为 0.29*100 的实际值在计算机中比 29 要小一些。当你使用 as.interger去处理的时候，结果为 28。 &gt; as.integer(0.29*100) [1] 28 这也就是为什么rep(1,29)有 29 个数字，但是rep(1,0.29*100)有 28 个数字。 如何避免浮点数计算的坑 如何解决这个问题呢？在 R 语言中有一个函数叫做 all.equal，虽然名字是 equal，但是他其实是 almost equal。 这让我不禁想到了一款果子和洲更（当然还有我）都在用全面屏 Almost 手机。 all.equal() 的功能是 Test If Two Objects Are (Nearly) Equal。也就是它可以略微忍受两个对象之间有一丢丢差别。如下所示： &gt; (a=29) [1] 29 &gt; (b=0.58*50) [1] 29 &gt; (c=0.29*100) [1] 29 &gt; a==b [1] FALSE &gt; all.equal(a,b) [1] TRUE &gt; a==c [1] FALSE &gt; all.equal(a,c) [1] TRUE 你可能会问，这个一丢丢究竟是多少呢？ 通过帮助文档，我们可以发现这个一丢丢实际是tolerance = sqrt(.Machine$double.eps)。如果实际运行一下会发现.Machine$double.eps 等于 2.220446e-16，那么sqrt(.Machine$double.eps)就是 1.490116e-08。 这里的.Machine是一个存储了 R 正在运行机器的数值特性的变量，其中包括了最小正浮点数（double.eps)。因此，以后想进行类似的比较，记得使用all.equal()。另外，多说一句，在 if 判断中不要直接使用它，而是写成 isTRUE(all.equal(....)) 。 回到最开始的问题，如果确实需要 rep(1,rep(1,0.29*100))返回 29 个数字，就可能需要用到取整。 在 R 中有 3 种常见的取整，分别是： 向下取整：floor() 向上取整：ceiling() 四舍五入：round() 此外还有一种不常用的「向 0 看齐」取整方法trunc()。 他们的差别如下： &gt; ( x1 &lt;- seq(-2, 4, by = .5) ) [1] -2.0 -1.5 -1.0 -0.5 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 &gt; floor(x1) [1] -2 -2 -1 -1 0 0 1 1 2 2 3 3 4 &gt; ceiling(x1) [1] -2 -1 -1 0 0 1 1 2 2 3 3 4 4 &gt; round(x1) [1] -2 -2 -1 0 0 0 1 2 2 2 3 4 4 &gt; trunc(x1) [1] -2 -1 -1 0 0 0 1 1 2 2 3 3 4 因此通过rep(1,round(0.58*50))就可以得到和rep(1,29)一致的结果了。 写到这里并没有结束，因为如果用 python 算一下，就会发现 0.58*100 真的不等于 58。感觉 R 语言的对于浮点运算结果的展示还是有点问题？同时，0.58 和 0.59 还是不一样。 &gt;&gt;&gt; 0.58*100 57.99999999999999 &gt;&gt;&gt; 0.59*100 59.0 &gt;&gt;&gt; 0.57*100 56.99999999999999 &gt;&gt;&gt; 0.56*100 56.00000000000001 看来，要知其所以然，还得再仔细学习一下浮点精度和计算的实质。 参考资料： R FAQ 7.31 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-12-19-rfloat/"},{"title":"如何简快好省的使用图床","content":"首先说明一点，因为本文的读者中可能单独使用 macOS 的为少数，所以下文介绍的所有工具尽量满足双平台通用（Windows 和 macOS）。 它们不一定是在 macOS 的最佳选择，如果你仅使用 macOS，文章中提到的思路和工具仅供参考。如果你同时在使用 PC 和 Mac，那么这是我目前摸索出来的比较满意的双平台通用方案，希望对你有所帮助。 云服务器配置 可以作为图床的云服务器有很多，例如主打免费的 SM.MS 图床（已经推出付费套餐）主做云存储七牛图床和又拍云等等。 如果要说免费（白嫖），目前我比较推荐的图床是 GitHub 图床，原因是 GitHub 的使用对多数有 md 图床需要的人来说应该都不陌生，而且这个网站毕竟还是专业的，跑路可能性极小。 如果要说付费的云存储，我目前使用的是腾讯云 COS, 这个东西在阿里云里叫 OSS，本质上都是一样的。之所以使用腾讯云的对象存储，是因为有一个直接复制图片到微信公众号编辑器的需求，其它家因为防盗链的原因都无法正常复制图片，但是腾讯云在微信公众号编辑器里还是异常流畅的。如果没有这个需求，阿里云和腾讯云并没有什么差别。 接下来以 腾讯云 注册为例，首先注册登陆自然不必多说。然后为了让图床和写作工具可以连接到你的腾讯云，那么就需要创建密钥供这些工具使用。 获得密钥相关内容 在腾讯云的 API 密钥管理 中新建一个密钥，然后如下图所示会得到 APPID、SecretId 和 SecretKey。这三个内容一是要记住，后面要用到；而是要注意安全保密。 创建存储桶 首先在首页的「云产品」下拉菜单中选择「对象存储」。 然后选择「存储桶列表」后创建一个新的存储桶。 在创建选项中根据提示操作即可，设置名称，然后选择服务器地区，需要注意的是因为要用做图床，所以访问权限设置为「公有读私有写」。也就是只有你自己给存入内容，但是访问内容（图片）不受限制。 在上图的配置中，有两项内容叫做「存储桶名称」和「请求域名」，这个在设置好之后点击你的存储桶，然后选择「基础配置」也可以看到，另外你还需要在基本信息中记住「所属地域」的代码。 至此，你就获得了配置图床工具需要的所有内容。 本地图床工具设置 图床工具有很多，好用的也有不少，但是全平台免费开源且好用的选择就不多了。这里推荐的是 PicGo，满足全平台免费开源且支持多种插件。嗯，好用。 三个特点 主窗口支持拖拽、选择图片上传；支持读取剪贴板的第一张图片快捷上传。macOS 支持顶部栏拖拽上传 上传成功后自动复制链接地址到剪贴板，支持 5 种复制粘贴格式，让你的文本编辑极致高效。 支持 JavaScript 开发的插件，给予插件极大自由度，让 PicGo 更加强大，成为你得手的效率工具。 简单配置 安装好之后，在图床设置中选择「腾讯云 COS」，勾选 V5 版本，然后依次填入上一步响应的信息即可。如果默认想使用 腾讯云 那么就「设置为默认图床」。至此，本地图床工具依旧设置好了。下图为 PC 版本截图，Mac 同理，同时也有命令行版本可以使用。 快速使用 PicGo 的使用非常简单，没有任何学习成本。正如开发者介绍的那样，你有多种方式把一张图片发送到图床中。 打开主窗口，把图片直接拖拽到主窗口 打开主窗口，选择图片上传 复制一张图片后，支持读取剪贴板的第一张图片快捷上传（可以自定义快捷键） 如果你使用 macOS，那么图片拖拽到顶部栏直接上传 上传成功后会有消息提示 这个时候剪贴板已经默认保存了这个图片的地址。这个地址的具体的保存格式你可以进行，我自然是设置为 MarkDown 格式。直接在需要的位置粘贴即可。如果你想快速获取曾经上传的图片地址。只需要在相册视图中点击对应图片下的「复制」图标即可。 至此，本地的图床管理工具已经配置完毕并且可以正常使用。 本地写作工具设置 如上文所言，当你配置好本地图床工具之后，在任何 MarkDown 编辑器里（例如 vscode 或者 typora）直接在需要的位置粘贴即可。但是，如果本地的写作工具直接支持上传至图床岂不美哉？ 本地写作管理工具 VNote 本地写作工具中支持一键将本地图片传至图床的在 Mac 上有不少，例如 Typora（仅 Mac 版本）Mweb 等等。但是同时支持 PC 和 Mac 的本地 MarkDown 写作工具，目前我用下来就只有 VNote 体验佳。提到 VNote 这款开源写作工具完全可以单独再开一篇文章好好写写。这里只介绍其最近一个版本更新后加入的图床功能。注意，一定是最新的 2.8 版本才可以噻。 自 2.8 版本开始，VNote 支持了四种图床，值得一提的是贡献者提供了微信公众号图床，这个可能很多人都没有听说过。 VNote 配合腾讯云 VNote 的图床配置也是非常之简单。在「设置」中找到「图床」，然后选择腾讯云。其中 domain name 就是你的请求域名，其余两项就是上文 API 中 SecretId 和 SecretKey。 这里有几点小坑需要注意！ domain name 就是你的存储桶请求域名，但是务必请去掉链接里 https:// 只需要输入域名即可。 因为是本地编辑器，如果想要顺利上传图片和展示就需要在存储桶的设置中进行一点修改。所以建议你新建一个存储桶来使用。配置内容如下图，修内内容为设置跨域访问。 设置内容如下 都配置好之后可以在 VNote 中进行测试。 一键上传本地图片到图床 配置好后，只要在任意文档的编辑模式下，鼠标右键选择「上传图片」然后点击「腾讯云」即可。随后，该文档内的所有本地图片都会自动上传到你的图床，然后图片的地址会自动替换会图床地址。 如何做到简快好还省 至此，通过： 云服务器配置 本地图床工具设置 本地写作工具设置（可选项） 你就可以愉快的利用图床管理图片和写作了，当然上述都是最基本的入门设置，大体上可以达到简快好的使用图床。标题中的「省」是指的费用问题，使用腾讯云的对象存储毕竟是要钱的。 为了不让别人盗用你的图片借用你的图床花你的钱写（抄）他自己的文章，往往我们还需要在存储桶中进行一些防盗链的设置。因为涉及到一些前端和网页访问的知识，这里就不再基础使用篇介绍了。如下图所示，有兴趣的可以自行研究下。 其实也可以不怎么管这里，因为确实很便宜，便宜到我都想把对象存储当做网盘用。而且腾讯云是有对象存储客户端的且不难用（Mac 端）。我目前存储的数量如下： 花费是多少呢？**从 10 月 1 日到今天，一共花了 3 块 4 毛钱。真的很省。**如果你不是流量大户，一年可能也就三四十块。 结语 最后，祝你使用愉快。另外，本文提到的 PicGo 和 VNote 都是开源工具，如果他们对你有所帮助，希望你可以给开发者捐赠，感谢他们的付出以及开源精神。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-12-14-haotouseimagehosting/"},{"title":"这三个网站让我摸鱼都从容了","content":" 如果你问我每天什么时候效率最高，我想可能是摸鱼的时候。高效摸鱼有很多技巧，关键之一就是不能在浑水里摸鱼。一定要去正确的地方，清楚的看到鱼在哪里，一摸一个准。 查 man page 从未如此简单 自从知道了这个网页工具，无论是查还是读 linux man page 都变得异常简单。而且，这个网站还可以直接解析复杂命令行。 man page 是学习 linux 最强大的手册，很多自以为烂熟于心的命令如果有空能读读 man page 一定会有意想不到的收获。但是 linux 的各种 man page 实在是太多了且阅读体验不好。 这个网站叫做 mankier，开发者说做这个网站的目的就是 tries to make reading and man pages as convenient as possible. 网站有如下几个特点： 侧边栏有每个 subsections outline，跳转极方便，甚至可以直接分享某个 section. 每个命令的参数也是一个链接，可以快读定位 页面支持快捷键搜索，且输入 - 可以直接查看参数 主页搜索命令里支持单独的命令搜索，支持 命令+参数 直接搜索 自动解析负责命令行，例如把du -s * | sort -n | tail 输入搜索框，就会告诉你这个命令做了什么。 地址 Man Pages | ManKier 理解统计概念从未如此清晰 我第一次知道 Seeing-Theory 的时候还没有中文版，因为这个项目后期有几个中国学生的加入现在已经有了中文版，而且有了一个很诗意的名字「看见统计 」。把看见和统计结合在一起，嗯，真棒。 这个网站用 D3 可视化了大量统计基础概念，而且每个概念在学习的时候都可以交互操作。 值得一提的是，这个项目诞生之后获得了若干个奖项，可惜的是目前已经不再继续维护更新而是进入了托管状态。 网站地址：看见统计 学习正则表达从未如此从容 前一段看一篇毕业论文，心血来潮顺路去瞅了一眼给出的脚本。 其中，有一句正则写的是 /[chromosome|chr](\\d+)\\s(\\d+)/。 能看出来作者明显是想匹配 chromosome 或者 chr ，但是这么写必须必配不上啊。而且很可能用户的染色体只有数字，或者是 C 大写，还可能有不规则命名的染色体。 推荐一个正则的在线测试网站给大家。RegExr: Learn, Build, &amp; Test RegEx 这个网站可以交互式的解释正则表达式的含义，然后也可以用自己的文件进行匹配测试。 网站地址：regexr 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-12-12-3goodweb/"},{"title":"我目前的云存储方法","content":"云存储选择及我的使用感受 国内大厂 百度云盘：国内使用度最高，适合保存各种盗版资源，不充会员约等于没法用 腾讯微云：不冲会员下载速度略好于百度云，但是可用空间只用 10G 国际大厂 Google Drive：使用体验好易于协作，和国外用户使用方便，国内需要特殊操作 OneDrive：如果在用 office 365 附赠 1T 空间，无需特殊操作即可使用 iCloud：虽然 iCloud 只是苹果自己的云服务，但对于苹果全家桶的用户来说使用体验是最好的 国内小厂 坚果云：主打增量备份，可能是国内目前用来同步个人工作文件最好的选择 奶牛快传：轻便快捷，非常适合用来分享文件，非常类似于国外的 Droplr 国际小厂 Droplr：也是即用即走的云盘，适合用来分享文件，虽然无需特殊操作即可使用，但速度不及奶牛 Dropbox：只做云盘的一家公司，也推出了协作功能，但是正常使用需要特殊操作且价格较高 其它及自建 115 网盘：我一直没用过但是一直听到有人提起的云盘 和彩云：移动最新推出的云盘 NAS：可能是最安全的云盘选择，但是初期成本较高，我个人推荐群晖的两盘位入门款即可。 我的选择标准 选择使用什么网盘我的主要参考因素有 4 个： 安全：如果是自用和私密为主的文件，首要因素一定是安全。当然，一个东西一旦上公有云，从原理上说就没有了绝对的安全。我只能根据以往的使用经历进行排除法，首先我的百度云里曾经出现过不是自己的文件，而且被非主动删除过文件；坚果云网站一直有无法彻底删除文件的 bug，官方反馈说后期会修复。 稳定：需要特殊操作才能使用的网盘注定在当前环境下无法作为主力网盘工具使用，日常重度使用的网盘争取要做到无感同步。 易用：首先是多客户端均可使用，然后使用体验要好。另外，上传分享等各种操作要简单但是有最好不要有什么功能缺失。同时，最好针对图片等特殊类型文件有好的管理方式。对于分享类的网盘来说，易用的标准就是方便对方下载，比如无需注册即可下载，甚至无需注册就可以直接不限速下载。 价格：价格的接受程度一方面是看绝对的数值大小，另一方面是要看对应工具的使用程度。比如坚果云从来没有过实际的打折活动，而且付费买的的空间也少的可怜，但是因为使用重度所以不能犹豫。 我目前的使用组合 我目前在同时使用若干个云盘工具。 按照使用频率排序：坚果云 &gt; OneDrive &gt; 奶牛快传 &gt; Google Drive &gt;&gt; Droplr &gt;&gt; 百度网盘 ≈ 腾讯微云。 按照付费程度划分：坚果云和奶牛快传是专业版年订阅用户，OneDrive 是跟随 office 365 一起订阅，Droplr 是 10% 的价格入手了终身版，百度网盘和腾讯云会在极少数情况下临时订阅一个月。 按照喜爱程度划分：目前使用体验最好的还是 Google Drive，坚果云和奶牛快传也很不错，OneDrive 虽然是微软的产品但是在 iOS 和 Mac 上却意外好用，而且会对照片进行智能分类（非常类似于 Google Photo） 具体的使用方法如下： 我接近 40G 日常文件和工作文件全部是通过坚果云在 PC 和 MacBookPro 上进行同步的。而且因为坚果云支持 WebDav，所以在用 Zotero 的我目前还找不到好用的替代工具。 不过，考虑到坚果云的潜在不安全性（还不能彻底删除文件）以及鸡蛋不要装在一个篮子里的思想，我的所有不同设备（ Android 和 iPhone 以及电脑）的照片和 13G 左右的工作文件全部同步在了 OneDrive。另外，我所有的照片也都在 Google photo 中。这里需要说一下，Google Photo 真的牛逼，如果有条件一定要用。 偶尔会被吐槽的 OneDrive 同步速度虽然赶不上坚果云，但从我一年多的使用体验来看上传下载的速度也完全说的过去，基本没有碰到不能同步的问题。目前 OneDrive 我保存了大致 20G 的文件，因为一直会买 office 365 ，所以我也在尝试更重度的使用 OneDrive，毕竟和坚果云那点可怜的空间比 1T 还是真香.等到毕业或者要彻底不用 PC 的时候，我的所有文件应该都会扔到 OneDrive 上。 奶牛快传是我目前最主要使用的文件分享工具。对于接收文件的用户来说，奶牛快传现阶段做到了无需注册即可不限速下载，这一点是尤其重要的，不过这里的不限速是说开发者不会主动限速，速度已经和你使用的网络有关，我在自己的网络环境下测试，一般上传是 10M 左右，下载是 5M 左右。不过，我也不知道这样的模式会不会多年一直持续下去。另外，高级用户可以自定义二级域名和背景图，设置各种下载规则，还是非常有逼格和好用的。 Google Drive 和 Droplr 使用相对就用比较轻度了，主要是和在国外的一些同学朋友分享文档以及协作使用。这两款工具的协作和使用体验都非常好，有机会推荐大家仔细体会，这里就不再展开。除此之外，大多数国外好用的其它工具都支持和 Google Drive 的联动，使用起来非常方便，比如 Trello 和 Notion 就可以直接插入其中的文件。 至于百度网盘和腾讯微云，我是真心不推荐，尤其是百度网盘，我里面存的应该只剩下各种分享来的「盗版资源」了。但在目前环境下从某种意义上讲，什么好用不重要，重要的是有多少人用。通常，如果有 10 个人给我发过来云盘链接，一般有 9 个是百度云。早前，我会咬牙充上一个月会员，现在有了按时长下载，不过我现在更多的做法是厚着脸皮问对方要账号。你给我分享了一个几十 G 的百度云链接，按道理就应该有百度云会员或者有办法让我顺利下载，你用百度云恶心一下我，我忍了，不过我也得稍微恶心一下你。微笑。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-12-02-mycloud/"},{"title":"Bioconductor 3.10正式发布","content":"10 月 30 日，Bioconductor 3.10 正式发布，该版本的 bioc 共包括了 1822 个软件包，384 个实验数据包，952 个注释包和 27 个工作流程，基于 R 3.6.1。 其中，新的软件包有 93 个，新的数据包 15 个，新的注释包 2 个，大量的旧包都进行了一波更新。 接下来推荐几个值得关注的最新软件包，以及一些经典包的重要更新。 新加入的 bioc 包 在 3.10 版本中新加入的 bioc 包，我个人比较感兴趣的有如下几个。 ALPS ALPS: AnaLysis routines for ePigenomicS data 一个最新的表观数据（ChIP-seq, ATAC-seq 等）可视化工具包，帮助你绘制高质量的发表级数据。下图是一个可以展示的内容概览。 输入数据是一个包含有 bigwig 源文件位置信息的 data table。再结合其它一些相关 R 包的处理结果可以展示各种类型的信息，例如计算基因组的富集区域供后续进行 PCA 和聚类的分析；绘制不同样品之间的富集差异；绘制基因浏览器或者 IGV 类似的 track 等等。同时也可以对基因组区域进行注释和绘制 motif。 作者也强调，这个包中的大多数图都可以利用 ggplot2 的一套系统进行二次定制。 MethCP &amp; Methrix 在分析甲基化数据的时候比较关注的一个信息叫做 differentially methylated region (DMR) 差异甲基化区域，类似于转录组分析中的差异表达基因。 大多数已有的一些工具（其实也没有很多）针对的都是两组数据，而 MethCP 除了支持常规的两组比较外，也可以处理多种条件的同时比较，例如时序数据。 需要说明的是，MethCP 本身使用 bsseq 这个包加载原始数据。 目前甲基化的数据上游分析产生的基本都会是一个超大的 bedgraph 文件，一般性能的电脑基本是处理不了的。Methrix 这个工具包主要的设计目的就是处理这种大型的甲基化 bedgraph 文件。 在读入文件的同时，还可以利用参考基因组填补确实的 CpG 信息，并且创建甲基化矩阵。后续可以在矩阵的基础上进行一系列过滤和提取操作，并进行可视化展示。当然也可以把这个矩阵结果转换为 bsseq 数据包支持的格式，然后再使用 MethCP 这个包进行分析。 Knowseq 一个据介绍是可以直接完成从原始数据下载到完成所有常规分析的工具包。下图是主要分析流程。 在原始数据下载比对这个步骤中，其可以调用预编译好的 Bowtie2, Kallisto 和 salmon 的工具。首先可以利用downloadPublicSeries(c(&quot;GSE74251&quot;)) 下载 GEO 中的数据信息，然后使用read.csv(&quot;ReferenceFiles/GSE74251.csv&quot;) 读取文件中的数据信息，接下来就可以使用 rawAlignment 这个命令来进行序列比对了。 在进行 Biomarkers identification 的步骤时，可以进行质控和去除 batch effect 等操作，差异分析之后可以结合机器学习方法进行分类和基因筛选。 最后针对差异进行可已经常用的各种富集分析，包括 GO pathway 和 相关疾病。 （从个人经验来说，这种大而全的包质量一般不会特别好，但是可能还是会有一些人喜欢。） APAlyzer 在转录翻译的过程中，mRNA 会在尾巴处添加一些 ployA，这个 A 可是有讲究的，长短位置的不同都会都 mRNA 的稳定性带来各种各样的影响，于是有一个研究方向就是 APA (alternative polyadenylation)。 这方面研究相对权威的新泽西州罗格斯癌症研究所 Bin Tian 实验室针对人类中以后的可信 PolyA 位点信息，开发了一个使用转录组数据分析 APA 的工具包 APAlyzer。当前的版本支持检测 UTR 区域和内含子区域的 APA，并利用编码区进行表达分析。 有重要更新的 R 包 大量的已有工具包在 3.10 版本中进行了更新，这里挑选几个大家比较熟悉的进行简要介绍。 ChIPseeker ChIPseeker 是 Y 叔开发的一个对 genomic region 进行各种注释可视化展示的工具包。其中有一个图比较典型，如下所示，就是把 upsetplot 嵌入 vennpie。这个图在实现效果前前后后经历过几次改变，但是在这个包中的实现方法一直没有升级，近期这个图在使用过程中偶尔会出现一些问题，例如只显示饼图不显示 upsetplot 等，然后 Y 叔就把这个实现方法给升级了。 用 Y 叔的原话说就是 于是我就把 ChIPseeker::upsetplo t 重新给实现了，利用了 ggimage + ggplotify，代码长度变成原来的 1/3，而且不会出现上面的这些问题。 library(ChIPseeker) library(TxDb.Hsapiens.UCSC.hg19.knownGene) txdb &lt;- TxDb.Hsapiens.UCSC.hg19.knownGene library(clusterProfiler) files &lt;- getSampleFiles() print(files) peakAnno &lt;- annotatePeak(files[[4]], tssRegion=c(-3000, 3000), TxDb=txdb) upsetplot(peakAnno, vennpie=T) DESeq2 之前写过一篇文章介绍 船新版本 DESeq2 处理大量样本速度显著提升，现在这个版本的 DESeq2 也随着 bioc 的升级而正式升级。 在之前的文章中，已经比较详细的写了为什么在处理大量样本时速度会有急速提升。在升级说明中则写的比较含蓄 speeds up DESeq2 for large sample sizes (n &gt; 100) by at least an order of magnitude. In fact the speed is now linear with number of samples whereas previously DESeq2 would scale quadratically. ensemblVEP 调用 Ensembl Variant Effect Predictor 的 perl API 进行突变注释分析的 R 包 ensemblVEP 现在支持了 Ensembl release 97/98。似乎没啥可说，但是还是挺重要的。因为每一次 Ensembl 的更新，在一些物种上都会有比较大的升级。 IsoformSwitchAnalyzeR IsoformSwitchAnalyzeR 是一个可以鉴定，注释和可视化可变剪切和转录本转换的工具包。在 3.10 中进行了大量的升级，多数函数都有改变。 maftools maftools 是分析和展示 Mutation Annotation Format (MAF) 文件的工具包，在不少文章中都可以这个包绘制的图。在这次更新中，maftools 增加了 survGroup, mafSurvGroup 两个函数，用来预测和生存相关的基因以及基因集。另外，Signature analysis 分析步骤也有很多调整。 其它具体的更新信息，可以参考官方说明。 如何升级 查看当前版本： library(BiocManager) 应该会展示如下信息 Bioconductor version 3.9 (BiocManager 1.30.4), ?BiocManager::install for help 绝大多数情况下升级只需要执行如下命令： BiocManager::install(version = &quot;3.10&quot;) 通过指定版本号之后，所有可以更新的 R 包都会更新到 3.10 版本。如果你安装的 R 包比较多，提示需要更新一两百个 R 包都是很正常的。祝好~ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-10-31-bioconductor310iscoming/"},{"title":"macOS 10.15 安装R包","content":"早先升级 macOS10.15 电脑 SMC 出了一些问题，试了一些方法都没有解决，无奈只能继续升级到 public beta 版本。 2020/6/15 更新 目前 R macOS 官方安装说明已经更新，地址为 https://mac.r-project.org/tools/ 原文 目前的版本信息如下 10.15.1 beta 版本 &lt;key&gt;ProductBuildVersion&lt;/key&gt; &lt;string&gt;19B86a&lt;/string&gt; &lt;key&gt;ProductCopyright&lt;/key&gt; &lt;string&gt;1983-2019 Apple Inc.&lt;/string&gt; &lt;key&gt;ProductName&lt;/key&gt; &lt;string&gt;Mac OS X&lt;/string&gt; &lt;key&gt;ProductUserVisibleVersion&lt;/key&gt; &lt;string&gt;10.15.1&lt;/string&gt; &lt;key&gt;ProductVersion&lt;/key&gt; &lt;string&gt;10.15.1&lt;/string&gt; &lt;key&gt;iOSSupportVersion&lt;/key&gt; &lt;string&gt;13.2&lt;/string&gt; 升级了之后 R 下的很多需要编译的软件都用不了了。 原因之一是系统自带的 clang 不支持 -fopenmp，这个需要在 R 官网下载安装 LLVM 预先编译好的 clang 7 。我也尝试过跳过这个 R 官网提供的 clang7，直接通过安装 LLVM 来安装最新版的 clang7.1，但是在 10.15 的系统里直接通过 brew install llvm 也会有不少问题，于是放弃。 除此之外还需要安装 gfortran , 如果去官方安装最新的版本在编译过程中会报 warning。因为 R 提供的 clang7 用的是 gfortran 6.1。这个还是需要去 R 官网提供的链接进行下载。 首先确认自己装了 Xcode command line tools (XCode CLI) $ xcode-select -p /Library/Developer/CommandLineTools 如果你之前有旧版本的 gfortran 和 clang 最新好先删除一些文件 # Delete the clang6 binary sudo rm -rf /usr/local/clang6 # Delete the prior version of gfortran installed sudo rm -rf /usr/local/gfortran sudo rm -rf /usr/local/bin/gfortran # Remove the gfortran install receipts (run after the above commands) sudo rm -rf /private/var/db/receipts/com.gnu.gfortran.bom sudo rm -rf /private/var/db/receipts/com.gnu.gfortran.plist 然后安装 clang7 和 gfortran6.1。下载地址：https://cran.r-project.org/bin/macosx/tools/ 如果在 10.14 里，这两个装好了后指定 clang7 的路径基本就解决问题。 但是 macOS 10.15 之后 usr 目录下无法新建 include 文件，这就导致 clang 在运行的时候可能使用默认的位置找不到 sdk 目录。 这个坑还需要再进行一些配置。首先要找到实际的 sdk 目录： $ xcrun --show-sdk-path /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk 然后在 R 的~/.R/Makevars配置文件中指定一些 compilation flags，通过 -isysroot 定义 sdk。如果你发现自己没有这个文件，就新建一个即可。 CFLAGS=-isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk CCFLAGS=-isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk CXXFLAGS=-isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk CPPFLAGS=-isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk -I/usr/local/include 最后在 ~/.Renviron 里写好 clang7 的路径。按道理这个路径写在 zshrc 里也是可以的，但这边测试的时候 Rstudio 启动 R 还是识别的系统默认 clang。 PATH=&quot;/usr/local/clang7/bin:${PATH}&quot; 这些配置写好之后，可以在 R 里通过从 source 装两个软件测试一下。 install.packages(c(&quot;Rcpp&quot;, &quot;RcppArmadillo&quot;, &quot;data.table&quot;), type = &quot;source&quot;) 最后的最后，一般情况下或者新手建议不要从 source 去安装软件，就没有任何烦恼了。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-10-29-macos15user/"},{"title":"数据库网站 API 知多少","content":"API API 这个词在大多数人看来可能和 CNS 差不多，前者天天听说就是用不上，后者天天读就是发不了。 不过，通过今天的一个简短介绍，今后 API 这个东西你就用上了，因为在文章最后我将会展示一个最最基础且高频的 API 使用示例。 所谓 API(Application Programming Interface) 就是应用程序接口。这个应用程序可以类比于手机和电脑，这个接口就类似于数据线，如果我们想用数据线把东西在两个设备之前传输，就需要两者可以接受彼此的传输协议。 对一个应用程序来说，如果你想快速的和它交换数据，也需要采用应用程序可以识别的规则。对于一些成熟的应用程序和网站来说，通常都会提供自己的一套 API 供开发者友好的使用，一方面可以大大扩展应用程序的生态环境，另一方面也可以避免暴力的爬虫。 我们通过下图的「印象笔记 API」为例，如果你使用过印象笔记（Evernote）的话，会发现大量第三方应用都可以支持绑定印象笔记账户进行各种创建笔记推送笔记等操作。这里不是印象笔记去适配第三方应用，而是它提供了一个完善的 API，可以供其他开发者来使用。 REST API API 之后还有一个概念是 REST API。 REST(Representational State Transfer) 的中文翻译一般是「表现层状态转化」（这也太抽象了吧），这个架构是 Roy Thomas Fielding 在 2000 年的毕业论文里提到的，他同时还是 HTTP 协议（1.0 版和 1.1 版）的主要设计者、Apache 服务器软件的作者之一、Apache 基金会的第一任主席。 关于究竟什么是「表现层状态转化」这里就跳过了，因为不跳过你也不会看（我也解释不清楚）。只需要了解，符合 REST 设计风格的 Web API 称为 RESTful API，有如下几个要点： 资源地址：URI，比如：http://example.com/resources。 传输的资源：Web 服务接受与返回的互联网媒体类型，比如 JSON，XML，YAML 等。 对资源的操作：Web 服务在该资源上所支持的一系列请求方法，比如：POST，GET，PUT 或 DELETE。 常用数据库 API NCBI NCBI 是啥就不介绍了，如果太多的功能没用过 PubMed 应该怎么也用过。在 NCBI 的开发文档中，有一个部分专门是讲 API 的。 NCBI 提供的 API 如下图所示，如果需要可以去看看。 EMBL-EBI EMBL-EBI 来自于欧洲，里面有很多很多数据库都是我们日常会使用的，只是你可以还不知道它们和 EBI 有关系的，例如存放了大量基因组及相关数据的 Ensembl ，包括大量蛋白序列和功能信息的数据库 UniPort，当然还有还有不逊色与 pubmed 的文献数据库 Europe PMC。 从个人的使用体验来说，一般能用 EBI 的时候我就尽量会绕过 NCBI，因为整个一系列网站用起来都要更舒服些，文档查起来更顺手些，对一些有进阶需求的开发者会更友好些（如果你有二次开发的需求，经过对比不难理解我的感受）。 目前 EBI 比较知名的几个数据库都有很不错的 RESTful API 支持。 其中 Ensembl 支持 21 个 POST 和 98 个 GET 操作，可以在官方说明中查看；Uniport 数据库 和 Europe PMC 也有大量的操作支持。通过这些 API 你就可以接触到数据库中有的所有信息和 33 million 的文献。另外，EBI 还有一个 QuickGO 的网站也支持 RESTful API 。 他们的 API 完善到直接在 NAR 发了一篇文章。 可用的数据库和工具如下 使用 API 这里以 Ensembl 的一个基础 API 为例对使用方法进行简单的演示。如果我们在 Ensembl 的网站上查看一个基因，会是如下页面。在左侧我况圈出来的是和这个基因相关的所有信息，其中 99%的信息都可以通过 API 获取到。 查看单基因信息 这里以最基础的单基因信息查询作为示例。Ensembl 的 RUSTful API 支持使用各种语言实现，既可以在 Unix 操作系统中使用 curl 和 wget 命令，也可以使用 python java perl 和 R 语言来操作。 如果要是用 wget 来查询一个基因的话，查询规则示例是http://rest.ensembl.org/lookup/id/AT4G34410?expand=1'。其实这就是一个简单的我们都能理解的「网址」，其中 id 后面是我们要查询的基因 id，问号后面可以添加任意支持的参数。另外，还需要 header 信息'Content-type:application/json' 来指定获取的资源类型。 运行命令如下： wget -q --header='Content-type:application/json' 'http://rest.ensembl.org/lookup/id/AT4G34410?expand=1' -O - 得到的内容会是一行 json 内容，这个信息大家看到都是崩溃的我就不直接放上来了。我们可以使用一些命令和操作稍微进行美化。 wget -q --header='Content-type:application/json' 'http://rest.ensembl.org/lookup/id/AT4G34410?expand=1' -O - | jq '.' - 通过 jq 这个命令，可以让输出变成标准的 json 格式。输出截图如下： 为了更方面的处理 json 内容和进行后一步的分析，我们可以移步到 R 中，看看如何使用。 要在 R 使用 RUSTful API 并进行后续的 json 文件处理，首先需要加载两个包，httr 用来调取 GET 和 POST 等命令，jsonlite 用来处理 json 格式的文件。 httr 会把 GET 的结果保存为一个 response 类型的对象，其中包括了 url，状态码以及 header 等各种各样的信息，jsonlite 可以帮助我们根据需求提取 json 里的内容并输出为 list 对象。 简单的运行命令如下： # 加载 R 包 library(httr) library(jsonlite) # 指定 server server &lt;- &quot;http://rest.ensembl.org&quot; # 指定查询内容,为了方便展示这里 expand=0 ext &lt;- &quot;/lookup/id/ENSG00000157764?expand=0&quot; # 使用 httr 包的 GET 进行查询 r &lt;- GET(paste(server, ext, sep = &quot;&quot;), content_type(&quot;application/json&quot;)) # 这里的 r 是一个response类型的对象。 # 将http错误转换为R错误方便debug stop_for_status(r) 到这里其实查询的步骤已经文章，对象 r 的结构如下： 接下来就是首先把这个对象中的内容转换为 json 然后在转换为 table 即可，命令非常简单。 list &lt;- fromJSON(toJSON(content(r))) tb &lt;- do.call(rbind,list) 得到的 table 内容如下 如果需要稍微优雅一些，可以改写为一个函数，如果需要一次查找多个基因，可以使用 POST 方法。 你可能会好奇使用 API 的优势在哪里。 如果只是查找一个基因，API 的优势并不明显，如果只是偶尔查找几个基因，API 的优势也不明显。那什么使用就有优势了呢，类比于「印象笔记」以及和它相关的使用了「印象笔记 API」的第三方应用，不知道会不会给你一些启发。话不能说的太透，点到为止，更多的应用场景我们以后有机会再聊。 资料 Ebsembl 的在线 API 课程 Ensembl REST APIs 使用说明 rentrez REST API in R BiomaRt 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-10-26-apibasic/"},{"title":"转录组表达分析知识图谱","content":"文章信息 Van den Berge, Koen, Katharina M. Hembach, Charlotte Soneson, Simone Tiberi, Lieven Clement, Michael I. Love, Rob Patro, and Mark D. Robinson. 2019. “RNA Sequencing Data: Hitchhiker’s Guide to Expression Analysis.” Annual Review of Biomedical Data Science 2 (1): 139–73. https://doi.org/10.1146/annurev-biodatasci-072018-021255. Annual Review 系列杂志的综述应该说是综述界的老大哥。最近在 Annual Review of Biomedical Data Science 发表了「另」一篇 RNA-Seq 相关的重磅综述。之所以说是另一篇，因为同期在 Nature Reviews Genetics 发表过一篇看名字就非常霸气的综述：RNA sequencing: the teenage years 。 关于 RNA Sequencing Data: Hitchhiker's Guide to Expression Analysis 这篇综述，它重点关注在** RNA-seq 数据的表达分析方法**，**因此适合用来做转录组数据分析能力的自我检测和学习路径。**这篇文章从转录组数据的整体介绍开始，从比对定量、差异表达基础、差异分析种类，单细胞转录组和长读数转录组几个层面展开，重点在比对定量、差异表达基础、差异分析种类这三部分。作者根据分析步骤介绍了对应的大量分析工具和其使用的计算模型和优势。本文不会对文章进行翻译，只是重点指出我读后比较关注的一些细节。最后我也会按照综述的主线梳理出主要内容，理出一幅转录组表达分析的知识地图。 整体介绍 下图是一个转录组试验的标准试验流程。 在建库的过程中，常见文库形式包括单端和单端测序，同时还有非链特异性和链特异性测序。在实验设计方面，有两个比较重要的因素：重复数量和测序深度。如下图所示，最近若干年来，大多数转录组测序的数据 reads 数量都是从 10 到 100M 之间，而样本数量基本上就是每个条件三个重复，很多项目的样本数量在 8 个（中位数）左右。 通常认为，增加测序深度可以提高后期分析的表现。不过，其实非常大的一部分 reads 都来自少数一些表达量很高的基因。具体到统计数字上，超过 80%的 reads 都来自 10%表达量最高的基因，如下图所示。因此，增加 reads 其实只是非常有限的增加了低表达基因的覆盖率。在检查差异表达基因的统计效力上并没有非常明显的提升。因此，增加测序深度不如多增加几个重复。有数据表明，如果想要鉴定低 fold change 的基因，最好能够做到 6 个重复。 转录组测序在应用层面可以进行基因注释，这里的注释包括各种各样的转录相关事件，例如 exon skipping, alternative 3' acceptor, 5' donor sites 以及 intron retention 等等。在基因调控方面，转录组数据可以在各种各样的条件下进行各种各样层面的比较，例如基因、转录本和外显子。当然，还有单细胞转录组的一系列应用场景等等。 关于定量和比对 转录组得到的测序数据通常被称为 junction-spanning reads， 目前针对这样的 reads 有两种最主要的比对思路，一种是使用 spliced alignment 的方法比对到参考基因组，另一种是使用 direct alignment 的方法直接比对到转录组上。往参考基因组比对的方法对应的工具有很多，最早从 DNA 比对进化来的工具例如 bowtie 等，后期发展出来的 STAR, HISAT 和 Subread 以及 GMAP。这种类型的比对一个关键点是对于 splice junctions 的识别。比对到转录组，主要挑战是关于 related isoforms 转录本的区分，这个问题可能会导致大量 multimapping 的情况发生。例如一个基因有三个转录本，其中一个外显子序列可能在三个转录本中都出现。同时，比对到参考转录组也不能找到 find novel splicing 和 expression pattern。因此，到底选择哪种比对方式取决于自己的后续分析需求。关于定量，常见的有基于基因的定量和基因转录本的定量。每种定量方式都有基于不同模型的若干种方法，随着分析的逐渐深入，越来越多的分析从基于基因定量转换为基于转录本定量。 差异分析基础 下图是一个常规的差异分析步骤。 各种差异表达 和定量的方式相对应，差异表达的分析角度其实也有很多种。除了常见的差异基因表达之外，还有差异表达的转录本，以及在一个基因内部不同转录本的使用情况，在一些情况下，即便一个基因在两种不同的条件下没有表达上的明显差异，但是可能存在不同转录本的表达变化。下图是一个比较直观的说明。 更多细节可以阅读综述原文，送上根据综述这里的知识图谱 表达分析知识图谱 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-10-11-rnaseqexpressionanalysis/"},{"title":"船新版本 DESeq2 处理大量样本速度显著提升","content":"太长不看版本 DESeq 最新版本（v1.25.9）针对大样本分析的速度和之前相比有了质的飞越，果子老师的 1215 个 TCGA 样本差异分析时间从 1200 分钟缩短到单线程 20 分钟，使用多线程的情况下最快 6 分钟搞定。 前奏 前一段时间洲更用统计学中的非参数检验方法解决了果子老师关于 1200 个 TCGA 样本使用 DESeq2 分析耗时 20 小时的问题，然后在那篇文章的最后果子老师如此总结道： 这样看来，洲更说的是对的。不过，dds 这里还有一个比较好的点就是可以做 logFC 矫正，就像这个帖子里面提到的，有一些 count 比较小，但是变化值很大的基因，会对 GSEA 分析产生影响。 从这段话里可以看出他还是心心念念 DEseq2。念念不忘必有回响，DEseq2 开发者听到了果子老师心里的呐喊，最近一次 GitHub 上 DEseq2 的更新就着手解决了这个问题。这段代码的贡献者称他们解决了 DEseq2 处理大量样本异常耗时问题，时间随样本量的变化趋势目前已经做到了线性关系。 对比图如下： 究竟效果如何，接下来就用果子老师 1215 个样本数据去测试。 台式机多线程测试 第一次测试环境我选择了自己的台式机，16G 内存。不知道是出于对开发者的信任还是对电脑的信任或者是出于对果子老师代码的信任。我选择了直接复制了果子老师的代码开启并行模式进行分析。 在果子老师的当年的描述中，如此说道： 最困难的一步来了。燃烧你的小电脑。这里还使用了并行化处理来解决速度的问题。但是，耗时依然很长，4 个小时以上，有可能是 10 个小时 （后来，据我私下和果子老师交流，他说实际运行时间远远高于 4 小时，为了显示出自己机器性能的优越稍微在写作手法上做了一些加工，人为缩短了这个时间） 这里我并不知道果子老师小电脑的性能如何以及用了几个线程，姑且按照 4 个小时（240 分钟）来计算。首先要从 GitHub 安装最新版本的包，安装好之后查看包的版本是 1.25.9，没有问题。 以下是测试步骤，原始的 Rdata 来自果子老师，用构建好的 dds 直接做DESeq。 devtools::install_github(&quot;mikelove/DESeq2@ae7c6bd&quot;) library(DESeq2) library(BiocParallel) dds &lt;- DESeq(dds,parallel = T) DESeq 虽然只是一个函数其实包含了若干个步骤，其中耗时很严重的是gene-wise dispersion estimates，这里也是多线程开启的地方。R 自动在我的台式机上开启了 6 个线程。起初我非常开心，新版本gene-wise dispersion estimates 这一步很快完成，目测只有不到 5 分钟。看情况不出问题的话，全部分析应该会在 10 分钟左右完成。 然后我就看了眼电脑的任务管理器，如下图所示。 接下来，就出问题了。因为 6 个线程工作再加上电脑只有 16G 内存，fitting model and testing到一半时我的心态伴随着内存一起都崩了。到崩溃为止，一共运行了大约 11 分钟。 &gt; dds &lt;- DESeq(dds,parallel = T) estimating size factors estimating dispersions gene-wise dispersion estimates: 6 workers mean-dispersion relationship final dispersion estimates, fitting model and testing: 6 workers error: arma::memory::acquire(): out of memory Error: BiocParallel errors element index: 4 first error: std::bad_alloc In addition: There were 13 warnings (use warnings() to see them) &gt; proc.time() - t1 user system elapsed 42.21 253.32 702.48 服务器多线程测试 事已至此，勿忘初心，迁移到服务器上去试试。在服务器安装最新版本的 DEseq2 包，继续运行同样内容，并行开启后，这次自动给我分配了 36 个线程，真棒！ 接下来一切正常，运行时间如下所示： &gt; dds &lt;- DESeq(dds,parallel = T) estimating size factors estimating dispersions gene-wise dispersion estimates: 38 workers mean-dispersion relationship final dispersion estimates, fitting model and testing: 38 workers -- replacing outliers and refitting for 9759 genes -- DESeq argument 'minReplicatesForReplace' = 7 -- original counts are preserved in counts(dds) estimating dispersions fitting model and testing &gt; proc.time() - t1 user system elapsed 1720.880 207.212 379.153 全程跑完一共用时 6 分钟多一点，和之前果子老师的多线程 4 个多小时的时间比，速度提升了应该有 40 多倍的样子。这里再次强调一下，据我私下和果子老师交流实际运行时间远远要高于 4 小时哦。如此看来，文章开头的运行时间对比图还比较靠谱，线性时间的复杂度大大缩短了处理大量样本的时间。 单线程测试 随后，测试如果只开启一个线程的情况（现在很少有单线程的机器，但是不少人都不知道 DEseq 可以多线程运行），如果不用最新版的话，据一些学员反映这个时间是在 20 到 30 个小时之内，如果用了最新版呢？单线程整个时间缩短到 22 分钟左右。（从一个侧面来说，这里的多线程加速效果也并不是非常明显。） &gt; dds &lt;- DESeq(dds,parallel = F) estimating size factors estimating dispersions gene-wise dispersion estimates mean-dispersion relationship final dispersion estimates fitting model and testing -- replacing outliers and refitting for 9759 genes -- DESeq argument 'minReplicatesForReplace' = 7 -- original counts are preserved in counts(dds) estimating dispersions fitting model and testing &gt; proc.time() - t1 user system elapsed 1369.724 18.084 1387.730 分析结果完全一致 从下文会提到的开发者更改内容来看，这次更新提速并没有更改涉及到 DEseq2 模型和参数的内容，所以新老版本的分析结果是完全一致的，包括差异基因的个数和 p 值。 contrast &lt;- c(&quot;sample&quot;,&quot;cancer&quot;,&quot;normal&quot;) dd1 &lt;- results(dds, contrast=contrast, alpha = 0.05) library(dplyr) library(tibble) library(tidyr) ### 导出差异分析的结果 res &lt;- dd1 %&gt;% data.frame() %&gt;% rownames_to_column(&quot;gene_id&quot;) &gt; table(res$padj &lt; 0.01) FALSE TRUE 20502 25189 究竟改了什么 回到文章开头，这次的升级当然不是听到果子老师远在他乡用微信公众号发出的呼唤，而是开发者为了让 DEseq2 可以更好的处理单细胞数据而准备的。在传统的差异分析问题上，我们面对的是高深度和少量几个样本，但是在单细胞上，面对的是上千个细胞和相对很浅的测序深度。 代码贡献者在自己的博客中提到，在几年前大家都还在争论转录组测序数据中大量 count 为 0 的数据应该如何处理，但是最近已经有阴性对照的实验数据表明这些 0 并不会有什么问题。另外，已经有文章测试表明，传统差异分析的很多工具在单细胞数据中依旧可以使用，甚至要比一些专门为单细胞开发的工具表现要好。如下图所示： 但是 DESeq2 开发者的实验室发现，DESeq2 和其他一票软件相比，在处理大量细胞时速度上完败，细胞越多败的越彻底。作为差异分析工具的大哥，当然也是要面子的。于是决定找出问题进行优化。 对于代码改动，可以从 GitHub 的 PR 中略知一二。 以下是 R 脚本的一个优化示例： 在core.R中，旧版本的代码如下图所示 新版本中对应的代码如下图所示： 单独看几行代码可能有些难以理解，在这里尽力解释一下。 上面代码提到的 modelMatrix 参数来自于getModelMatrix()这个函数，内容如下： getModelMatrix &lt;- function(object) { if (is(design(object), &quot;matrix&quot;)) { design(object) } else if (is(design(object), &quot;formula&quot;)) { stats::model.matrix.default(design(object), data=as.data.frame(colData(object))) } } 其中的参数object就是我们实际数据中的 dds，这里首先判断 design(object) 的数据类型，以果子老师的数据为例。 &gt; is(design(dds)) [1] &quot;formula&quot; &quot;oldClass&quot; 果子老师的数据中design(object) 是 formula，那么就会运行stats::model.matrix.default(design(object), data=as.data.frame(colData(object)))来得到 ModelMatrix 实际运行getModelMatrix()我们得到的 modelMatrix其实是一个 1215*2 的矩阵。 如下图所示，第二列samplecancer就是分组信息，其中 0 代表正常，1 代表癌。 原始的metadata 中的样本数量如下 &gt; table(metadata$sample) normal cancer 113 1102 ModelMatrix 中第二列的样本情况 &gt; table(modelMatrix[,2]) 0 1 113 1102 而 nOrMoreInCell函数的作用是返回一个每个样本一一对应的逻辑向量，来表明是否需要被筛选掉。这里又需要提到一个参数minReplicatesForReplace。 这个参数，可能大多数人都不会被注意到。他的含义是 the minimum number of replicates required in order to use replaceOutliers on a sample. 那么replaceOutliers()又是做什么的呢？我们说 DEseq 在进行标准化的时候会丢掉一些 gene counts 数非常异常的值，转而使用所有样本中的 trimmed mean 来进行替代。replaceOutliers()就是做这件事的。 书接上文，minReplicatesForReplace 就指定了在对一个样本使用 replaceOutliers 的时候需要最小的重复数是多少。假如这个值是 5，如果你的一个样本只有 3 个重复，那么就不会执行上面的操作。这个参数默认是 7，假设你不想做这一步（例如针对单细胞数据），你就需要把这个参数设置为 Inf。在实际运行中，如何判断哪个样品该进行哪些样品不该进行这些操作呢？就是进行如下一个比较，下文代码的第一行也展示了nOrMoreInCell()的作用。 # if there are sufficient replicates, then pass through to refitting function sufficientReps &lt;- any(nOrMoreInCell(attr(object,&quot;modelMatrix&quot;),minReplicatesForReplace)) if (sufficientReps) { object &lt;- refitWithoutOutliers(object, test=test, betaPrior=betaPrior, full=full, reduced=reduced, quiet=quiet, minReplicatesForReplace=minReplicatesForReplace, modelMatrix=modelMatrix, modelMatrixType=modelMatrixType) } 扯远了，再说回来，nOrMoreInCell() 是如何在新版本中提速的。 nOrMoreInCell_old &lt;- function(modelMatrix, n) { numEqual &lt;- sapply(seq_len(nrow(modelMatrix)), function(i) { modelMatrixDiff &lt;- t(t(modelMatrix) - modelMatrix[i,]) sum(apply(modelMatrixDiff, 1, function(row) all(row == 0))) }) numEqual &gt;= n } 到这里很可能你已经看不下去了，但是其实不难理解。 原始函数使用sapply在每个样品上都要迭代一次，因此如果的设计矩阵很简单就会出现大量的重复工作。对于大量样本这个函数占用 DESeq（）相当一大部分运行时间。对于 1200 个样本的数据来说，这个过程要重复 1200 次才能得到结果。 如果变成新的函数会有什么效果呢？ nOrMoreInCell_new &lt;- function(modelMatrix, n){ numEqual &lt;- rep(NA, nrow(modelMatrix)) for(idx in seq_len(nrow(modelMatrix))){ if(is.na(numEqual[idx])){ modelMatrixDiff &lt;- t(t(modelMatrix) - modelMatrix[idx,]) equal_to_idx &lt;- apply(modelMatrixDiff, 1, function(row) all(row == 0)) numEqual[equal_to_idx] &lt;- sum(equal_to_idx) } } numEqual &gt;= n } 首先给 numEqual 全部复制为NA；当进行第一次循环idx=1时，因为numEqual[idx]是NA，所以一定会执行一次运算。 但是只要进行一次运算，equal_to_idx 就会返回一个新的逻辑值，所有equal_to_idx为真的位置对应的numEqual的位置都会被赋值这个样本重复的数量，也就是sum(equal_to_idx)。然后第二次循环开始，对于和第一次循环同样组的样本来说，只需要进行if(is.na(numEqual[idx])) 的判断，因为必定会返回False 就不需要再进行后续运算了。 以果子老师的数据为例， 他只有两组数据，1215 个样本。只需要进行一次运算，完成相当于原始函数的 1102 次计算（癌有 1102 个），然后循环到下一个是 NA 的样本时（也就是第一个正常样本时），再进行一次运算，就完成了原始函数的 113 次计算。 也就是当面对 2000 个样本的 2 组数据时，原始函数需要运行 2000 次，而新的函数只需要运行 2 次。 在 1215 个样本的 2 组数据中，前者需要 3.17s，而后者只需要 0.03s。 &gt; t1 &lt;- proc.time() &gt; samplesForCooks &lt;- nOrMoreInCell_new(modelMatrix,3) &gt; proc.time() - t1 user system elapsed 0.00 0.02 0.03 &gt; &gt; t1 &lt;- proc.time() &gt; samplesForCooks &lt;- nOrMoreInCell_old(modelMatrix,3) &gt; proc.time() - t1 user system elapsed 3.06 0.08 3.17 当然，直接导致时间复杂度改变的升级是在核心的 C 脚本中，我也只能勉强读懂一些。 在原始的 DESeq2.cpp中有一步需求是提取对角线矩阵。原代码首先构造了一个 n 行 n 列的矩阵，然后再对整个矩阵进行运算，最后再用diagvec()来提取对角线矩阵，这个思路没什么问题，但是随着样本数量的增加，对于矩阵的运行时间是成样本数的平方增加的，遇到大量样本直接歇菜。 但在新的代码中，避免了对于这个矩阵的计算。取代构造矩阵而是首先构造了一个 n 维向量，接下来不需要对全部矩阵进行计算就也可以得到对角线矩阵。这一步上的时间复杂度，就从之前的 O(ncol(Y)^2) 变成了 O(ncol(Y))的线性复杂度。这也是我们看到文章开始运行时间变化的主要原因。 进一步了解 Bias, robustness and scalability in single-cell differential expression analysis Need for Speed — DESeq2 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-09-17-fasterdeseq2/"},{"title":"Zotero入门学习路径","content":"文献管理的需求和工具 学术文献管理其实主要包括了管理和阅读两个需求。 从管理层面而言，我们希望： 文献可以方便地导入到工具中并提取准确丰富的文献信息 在写作时，可以把工具中的文献进行自如的导入 工作和学习中，可以快速在工具中找到自己想要的文献 从阅读层面而言，就是各种高亮和笔记的操作以及管理，当然还有不同平台之间同步的需求。 目前常用的文献管理工具有很多，比较有代表性的有如下几个： Endnote Endnote 是一款非常老牌且知名的文献管理工具，付费价格相对较贵但多数高校和科研机构会统一购买，移动端（iPad）使用体验优秀。 Mendeley Mendeley 于 2013 年以开源软件身份被 Elsevier 高价收购，目前背靠大树。我现在主用 Zotero，辅助 Mendeley。 从个人使用体验来讲， Mendeley 有如下优点： 真全平台：Web, macOS, Linux, Windows, iOS, Android 设备上所有文献随时随地阅读。 真实时全同步：免费 2G 存储空间（Zotero 300M）,约能存储 1000 千篇文献。这个数量对于大多数人足够，因为文献要及时整理删减，把它当成网盘用也不合适。 真智能：浏览器插件自动保存文献，自动监听本地文件夹，电脑客户端本地 PDF 文件拖入后自动检测论文条目，识别率极高。更可以根据已有文献推荐相关其它文献。 团队社交及推荐属性：网站注册后可以关注和被关注（类似于 ResearchGate），按照研究领域推荐好友，创建或加入小组分享文献。 内置 PDF 阅读器：支持复制高亮和批注等，支持针对整篇文献建立笔记。 多种数据导入导出格式：支持批量导入各种数据库文件（比如 Zotero），支持多种引用格式导出，比如 BibTeX。 使用门槛和 EndNote 与 Zotero 相比非常低，几乎没有学习成本。 好看，手机客户端和网页颜值较高。 缺点：内置阅读器不够强大，分辨率也不是很高；不支持类 Zotero 多附件插入和树状目录，和 Zotero 相比笔记功能也比较简陋。 Zotero Zotero 目前是我的主用工具，具体的介绍见下一部分内容。 F1000 workspace F1000 workspace 是 F1000 旗下产品，和其他几个工具不同，可以说 F1000 workspace 是唯一的真 Web 工具。不需要本地客户端，PDF 可以直接上传 PDF 并通过浏览器阅读和标注，只要有一个浏览器就可以使用。 官网有如下一段介绍： F1000Workspace is the latest offering from F1000 and provides a unified workspace for scientists to collect, write &amp; discuss scientific literature. It features a web-based application, a browser extension, powerful word processing plugins and a mobile application. It includes key article recommendations by our faculty of over 8,000 leading experts in biology and medicine and links to our Open Science publishing platform, F1000Research. 其主要特点是结合了 F1000 的推荐功能和社交属性，可以说是一款相对更加有现代感的工具。如果你已经厌倦了传统的文献管理工具，F1000 workspace 绝对是一个不错的新选择。 不过这款工具也是订阅制的，你可以通过 这个网页 输入所在机构邮箱来查看自己的高校或者研究单位是否进行了订阅。如果如下效果，就可以使用它的全部功能且不受任何限制。 这款工具下文不做具体的介绍，建议在 官方网站 中查看使用说明。 代表性工具 Zotero 在官方网站中，有一篇文章专门替用户剖析了 为什么要使用 Zotero。以下是我把其当做自己主力文献管理的几个主要原因： 软件本身完全免费并且开源，不存在盗版问题 注册后本身只包括 300M 空间同步，但支持 WebDAV 同步，例如 Dropbox 和坚果云等 官方的反馈论坛比较活跃，有问题可以快速得到反馈 从网站和期刊文章等提取保存出版物数据检索 拖入 PDF 的出版物数据准确率高 可以和 Word，LibreOffice 集成，方便文献进一步的使用管理 强大的第三方插件系统 每个条目下可以添加任意数量和格式的附件 当然，使用一个工具首先要了解其上限和下限，Zotero 同样有着比较明显的短板： 因为强大所以上手时略显复杂 并不是一个完全基于 Web 的工具 没有内置的 PDF 阅读工具 没有适配于 iOS 和 Android 的官方应用程序 Zotero 的使用和学习路径 最权威和最新的学习资料一定是 官方文档。目前有针对 Zotero 4 旧版本的 中文说明，如果英文吃力也可以参考。接下来我将按照下图的顺序介绍 Zotero 的使用和学习路径。 添加内容到文献库 使用浏览器插件 不同于一些工具，Zotero 的 浏览器插件 称得上可以「保存一切」。当所在的网页呈现出不同的内容时，Zotero 的插件会呈现出不同的图标。例如，如果打开的是 PDF，那么图标就会变成 PDF。 如果一个网页内有多个文献元数据，可以检测到并同时保存多篇文章。即便是一篇博客，也可以直接保存。 下图为直接保存博客网页后的效果，可以看到它也会抓取部分内容作为摘要进行显示。 如果你好奇 Zotero 支持导入的内容包括什么，可以参考下面这个截图。 使用各种标识符在应用内添加 对于添加文献或者书籍，如果我们知道了它对应的 ISBN，DOI 或 PubMed ID，就可以快速将项目通过标识符添加到库中。 单击 Zotero 窗格中间列顶部的「按标识符添加项目」按钮，输入标识符后按 Enter。如果要一次输入多个标识符，在输入第一个标识符后按 Shift + Enter 会进入多行模式，随后输入其余标识符（每行一个），并通过 Enter 换行。输入完成符后，再按 Shift + Enter 即可一次导入所有项目。 本地 PDF 文件和各种附件直接拖入应用 如果你有已经下载好的 PDF 版本文献，只要直接拖入到应用中即可，Zotero 会自动识别 PDF 文档中的元数据。 和大多数文献管理软件相比，Zotero 有一个非常大的优势就是支持将任意格式的附件添加到某个条目中，例如这里的附件可以是 Excel 格式的电子表格，可以是文献中提到的某一个网页地址，也可以是你自己和文献主题相关的电子实验记录，甚至你还可以将文章中提到的相关代码打包为压缩文件后进行添加。 结合 WebDAV 的同步功能，我们还可以将这些相关资料在多个设备间进行同步，这样就极大的方便了我们对文献相关的各种资料进行整理。 从其它工具导入 Zotero 支持从多种工具的数据导入，且支持的导入格式非常丰富。例如 Mendeley 的数据库，Endnote 的 XML 格式，以及常见的 RDF 和 RIS 格式等等。更多格式见下图截图。 通过 feed 进行订阅 如果你是一个喜欢追文献的人，肯定有各种各样自己的方法，例如通过邮件订阅或者 RSS 等，而 Zotero 本身也为我们提供了一种非常方便的方法。 点击 URL 后可以将一些杂志主页提供的 URL 地址直接添加到这里，并且进行更多高级设置，比如更新订阅时间和删除时间等等。 文献和笔记管理 集合与标签 集合可以理解为支持多个层级的文件夹，如下图在一个合集中新建一个子集。 除了按照目录分类以外，可以为每个文献添加若干个标签。这里建议标签的使用维度不和集合重合。例如，我有个一个叫做「lncRNA」的目录集合，就不应该再建立一个「lncRNA」的标签，这时的标签可以考虑应用维度或者重要性维度。如使用 P1、P2 和 P3 标注文献的重要性，使用「中期」「答辩」等标注一个文献的用途。 每个标签可以设置对应颜色，这个色块也会自动显示在每一个条目的开头，方便查看，一目了然。 搜索 在 Zotero 中，快速搜索支持如下图所示的三种粒度。需要说明的是，如果 PDF 文档已经建立过，通过「所有内容」进行搜索时是可以搜索到文档文本的。 除了快速搜索以外，Zotero 中还有一种高级搜索方法。高级搜索提供比快速搜索更多更精细的筛选条件，并允许保存搜索内容方便下次使用。 运行高级搜索需要打开「高级搜索」窗口，单击中心窗格顶部的放大镜图标，然后就会进入高级搜索界面，搜索支持逻辑判断且可搜索的条目也非常之多。 排序和关联 每个集合都支持显示若干需要的内容并且按照某种方式进行排序，且支持二次排序。 另外，不同的文献之间、文献和笔记之间都可以进行关联。我们可以方便地将关联性强的内容结合到一起。 笔记 每一篇文献支持插入多个笔记。笔记支持的格式内容也非常丰富，例如引用和插入链接以及添加不同层级的标题都没有问题，而且笔记还可以和多篇文献进行关联。 默认笔记本事是富文本编辑器，不支持 markdown 语法。但因为 Zotero 的插件和 Firefox 的插件格式相同，我们只需要把 Firefox 的 markdown here 插件稍加修改打包就可以导入 Zotero 中，从而使笔记支持 markdown。我已经将插件打包好，你可以 点击链接下载安装。 生成引文和报告 无论使用 Endnote 还是使用 Mendeley 抑或使用 Zotero，一个非常重要的需求就是在平时写各种论文的过程中插入参考文献。Zotero 可以从哪些方便满足你的需求呢？ 快速复制 如果你只希望在自己的博客或者笔记中插入一些文章而无需遵守严格的引用要求。那么 Zotero 本身提供了非常方便的快速复制方法。 在设置中可以设置复制时需要的引文格式，然后只需要拖拽即可，非常自由。 多篇文献右键多种导出 当你同时选择多篇文献时，也可以通过鼠标右键选择你需要导出的形式。例如 RTF 或者 HTML，当然，你也可以选择直接复制然后一步粘贴到位。 在 Microsoft Word 中使用插件 通常安装软件的时候就会提示自动安装 Word 插件，如果因为各种原因前期没有安装，可以在设置的引用中进行安装，安装后重启 Word 即可。 安装好之后 Word 中就会出现如下 Zotero 插件： Word 中的 Zotero 选项卡包含以下内容： 在正式插入引文之间，需要设置引文的格式和语言，通过管理样式可以轻松找到海量的引文格式。如果需要显示中文，则可以在语言选项中选择中文。 在需要添加引文的位置点击添加选项 在出现的搜索框中可以使用各种方式来快速搜索自己需要插入的文献，例如作者姓名。 如果需要在一个位置内引用多篇文献，可以一次选择自己多篇想添加的内容统一添加。 所有文献都引用好之后，直接点击书目即可插入引文。 生成报告 除了插入参考引文之外，Zotero 还给出了另一种导出参考文献的方式——生成报告。 报告是简单的 HTML 页面，概述了所选项目的项目元数据，注释和附件。可以打印它们，也可以将它们发布到网上并通过电子邮件发送。 创建报告可以右键单击中心窗格中的项目或选项，然后选择「由所选条目生成报告…」，也可以右键单击左列中的集合，然后选择「从集合生成报告」。 第三方工具插件 可以帮助你更好地过滤报告内容，例如对报告进行排序或者增删条目等。 备份和协作 同步 Zotero 本身支持 300M 免费的存储空间。这对很多人都是不够的，如果你不想购买官方的存储空间可以使用 WebDAV 服务。这里就不做展开介绍了，以国内使用比较方便的「坚果云」为例，官方给了一个比较详细的配置方法教程：如何在 Zotero 中设置 webdav 连接到坚果云。 协作 协作功能可能是很多人都忽略掉或者不知道的一个功能。Zotero 提供了相对完善的协作方式，这里做一些介绍。 如果你想和实验室或者几个好用共享协作一个文献库，那么就可以创建一个私有库，需要去官网创建，方式如下。 随后还有一些具体的权限需要设置，例如什么人可以读，什么人可以编辑。 创建好之后，如果你的客户端已经登陆并且完成同步，将会在侧边栏出现一个新的群组。如下图所示。 另外，在网页版的管理界面中可以进行成员邀请和删除。 其它内容 插件推荐 插件系统是 Zotero 作为开源软件的独特优势，你可以通过 官方插件网站 进行查看。我目前在用的几款插件如下图所示，推荐安装使用。 小技巧 当选择了一个项目时，可以通过按住 Option(Ctrl) 键突出显示包含此项目的所有集合，也就是知道这篇文献所在的分组 在集合列表或项目列表中的键盘上按 +（加号）可以展开所有节点，按 -（减号）则可以折叠 要查看所选库或集合中的项目数可以单击然后使用 Command-A(Ctrl-A) 全选，计数将显示在右侧 若使用快速复制功能，在将项目拖放到文本文档时按住 Shift 键能实现插入引文而不是完整引用 可以单击详细信息中的 DOI 和 URL 字段标签直接打开链接 以上就是关于 Zotero 的使用和学习路径，希望对正在寻找学习文献管理工具的你有所帮助。，计数将显示在右侧 若使用快速复制功能，在将项目拖放到文本文档时按住 Shift 键能实现插入引文而不是完整引用 可以单击详细信息中的 DOI 和 URL 字段标签直接打开链接 以上就是关于 Zotero 的使用和学习路径，希望对正在寻找学习文献管理工具的你有所帮助。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-09-11-howtolearnzotero/"},{"title":"VScode入门学习路径","content":"相关内容简述 如果你对代码编辑器完全没有任何概念，那么可以把所谓的代码编辑器理解为一个更加适合写代码的地方。 在 word 里你可以方便的进行文字的编排，在 PowerPoint 中你可以方便的进行幻灯片的制作，而一个好用的代码编辑器则可以帮助你更加高效的编写代码脚本。 提到代码编辑器，可能了解生信技能树或者听过生信技能树课程的小伙伴第一反应都会是 Notepad++，这款代码编辑器最早发布于 2003 年，并且一致更新至今非常经典。因为使用惯性和轻量的特点，这款代码编辑器依旧很受欢迎。 但是在 2019 年的今天，有更多好用的代码编辑器可以向你推荐。目前比较受大家欢迎且用户量较大的代码编辑器主要用三个，分别是 VS code、Atom 和 Sublime text 。 另外，IDE 和 编辑器相比 IDE 更为关注开箱即用的编程体验、对代码往往有很好的智能理解，同时侧重于工程项目，为代码调试、测试、工作流等都有图形化界面的支持，因此相对笨重，Java 程序员常用的 Eclipse 定位就是 IDE；而编辑器则相对更轻量，侧重于文件或者文件夹，语言和工作流的支持更丰富和自由。鉴于我们大部人的日常使用需求，这里的讨论主题围绕编辑器展开而非 IDE VS code 官网地址：https://code.visualstudio.com/ Atom 官网地址：https://atom.io/ Sublime text 官网地址：https://www.sublimetext.com/ Notepad++ 官网地址：https://notepad-plus-plus.org/ 代表性工具介绍 VS code Visual Studio Code（简称 VS Code）是一个由微软开发，同时支持 Windows 、 Linux 和 macOS 等操作系统且开放源代码的代码编辑器，它支持测试，并内置了 Git 版本控制功能，同时也具有开发环境功能，例如代码补全（类似于 IntelliSense）、代码片段和代码重构等，该编辑器支持用户个性化配置，例如改变主题颜色、键盘快捷方式等各种属性和参数，同时还在编辑器中内置了扩展程序管理的功能。(引自维基百科) 选择 VS code 的原因 由微软核心团队开发，完全免费且开源 开发计划过程和反馈渠道透明，更新迭代稳定 跨平台编辑器，Windows macOS 和 Linux 都可以使用 轻量，系统占用资源较少，大文件打开速度快 又丰富的官方和第三方插件库，可扩展性极强 在性能、语言支持、开源社区方面都做得不错，目前很受欢迎 软件官方地址：https://code.visualstudio.com/ 学习路径 VS code 的基本介绍 2011 年底，微软从 IBM 请 《设计模式》的作者同时也是 Eclipse 掌舵人之一的 Erich Gamma 来开发一款优雅的在线开发工具（后来的 Manaco Editor），2015 年他把这款在线工具移植到了桌面平台，也就有了如今 VS Code 。师承 Eclipse 同时又吸取 Eclipse 的教训，他们决定核心只做一个高性能的轻量级编辑器，个性化功能交给插件系统来完成且要把插件系统运行在主进程之外。同时，VS Code 希望让开发者在编辑器里拥有 IDE 类似的开发体验，比如对源代码的智能理解、图形化调试工具和版本管理等等。总之，就是在 IDE 和编辑器中找到一个比较理想的平衡。 在很多人的印象中，微软一直是一个站在开源世界对立面，靠专利官司和垄断挣钱的公司，但其实微软近几年一直是 GitHub 贡献开源代码最活跃的公司，活跃到现在已经把 GitHub 收购了。而在所有微软的开源项目中，star 最高的 repo 就是 VS Code 编辑器。VS Code 以 MIT 协议开源，所有的开发过程和反馈渠道完全在 GitHub 开放，同时 VS Code 提供了统一的 Language Server Protocol 和 Code Debugging Protocol API，所有语言的开发和都能够通过实现两个 API 在 VS Code 上得到类似 IDE 的开发和调试体验。 如果你是一个 R 语言用户，RStudio 一定是首选 IDE，如果你是一个 Python 用户，Pycharm 则是大多数人的编辑器。但如果你平时既要用点 R，也要用点 Python，偶尔感觉这些 IDE 有点臃肿或者不想在两个 IDE 中反复切换，那么 VS Code 是一个不错的选择。 VS Code 有两个不同版本：稳定版（Stable）每月发布更新一次；预览版（Insiders）每个工作日更新一个版本。当然，你也可以同时安装两个版本互不影响。 常用快捷键 无论我们提倡使用 markdown 还是使用快捷键，主要目的都是提高效率，尽量让双手不离开键盘。对于编辑器中快捷键的使用，一开始看似是一件更浪费时间的事情，但是随着肌肉记忆和熟练度增加，效率将会大大提高。本节内容主要涉及 VS Code 的常用快捷键以及如何定制。 如果你是从其他编辑器转到 VS Code，那你完全可以移植你之前熟悉的快捷键配置，比如 Vim, Atom 或者 sublime。如果你其它快捷键也不熟悉不如就专心学会 VS Code 的常用快捷键。 把自己日常经常用到的快捷键整理成了导图。如果能把下面图中的快捷键用熟练，每天省下 20-30% 使用编辑器的时间不是问题。 如果想要查看所有的快捷键，可以通过 ctrl+K ctrl+s 进入快捷键设置界面。 快捷键官方链接 详细设置信息 https://code.visualstudio.com/docs/getstarted/keybindings windows 快捷键 https://code.visualstudio.com/shortcuts/keyboard-shortcuts-windows.pdf macOS 快捷键 https://code.visualstudio.com/shortcuts/keyboard-shortcuts-macos.pdf 编程语言支持 针对 python 等（对于程序猿群体）非常成熟大众的语言，基本没有任何设置的难度，只需要安装一个对应的插件就可以。 这里以如何支持 R 语言举例，进行介绍。基本操作步骤如下： 安装 R，建议使用默认路径即可。例如我实验室的电脑中是 64 位 R 软件的位置如下，这个位置一定要确认好。 C:\\\\Program Files\\\\R\\\\R-3.6.1\\\\bin\\\\x64\\\\R.exe 打开 R，安装一个 R 包，命令如下 install.packages(&quot;languageserver&quot;) 在 VScode 中安装两个和 R 相关的插件 R support for Visual Studio Code 这个插件是 VS Code 中 R 的核心插件，具有语法高亮，基础代码片段和代码执行等功能。例如你可以在编辑器中选择某几行内容，然后使用 ctrl + enter 将代码发送到终端执行。 R LSP Client 有了这个它就可以进行代码补全、查看函数定义以及参数预览等功能。 安装方法是在插件管理界面输入插件名字，然后点击安装。 在配置文件中进行两个对应配置 通过 ctrl+, 进入设置页面，在搜索页面首先搜索 rterm，如果你是 Windows 电脑就在 windows 对应的 Rterm 位置处输入 R 的路径 再在配置页面继续搜索 r.lsp 找到 rlsp path 对应设置处，在这里也输入 R 的安装路径 打开一个包含 R 脚本的文件夹。注意，不是单独打开一个 R 脚本文件 右键点击文件件，选择使用 vscode 打开，如下图 再打开 R 脚本即可，然后 Windows 点到按 ctrl+enter , Mac 按 ⌘+Enter，激活环境，即可安心使用。效果如下图所示 这时把鼠标放在任意一个函数上，就会出现如下类似的效果。 如果输入函数会自动补全 激活 R 环境后，按住 ctrl+enter，就会依次运行光标所在行的代码。 install.packages(&quot;plotly&quot;) data(&quot;EuStockMarkets&quot;) xx &lt;- EuStockMarkets[, 1] tmp &lt;- as.data.frame(EuStockMarkets) tmp2 &lt;- head(tmp) head(tmp2) x.info &lt;- attr(xx, &quot;tsp&quot;) tt &lt;- seq(from = x.info[1], to &lt;- x.info[2], by = 1 / x.info[3]) data.fmt &lt;- list(color = rgb(0.8, 0.8, 0.8, 0.8), width = 4) line.fmt &lt;- list(dash = &quot;solid&quot;, width &lt;- 1.5, color = NULL) ti &lt;- 1:length(xx) m1 &lt;- lm(xx~ti) m2 &lt;- lm(xx~ti + I(ti ^ 2)) m3 &lt;- lm(xx~ti + I(ti ^ 2) + I(ti ^ 3)) require(plotly) p.glob &lt;- plot_ly(x = tt, y = xx, type = &quot;scatter&quot;, mode = &quot;lines&quot;, line = data.fmt, name = &quot;Data&quot;) p.glob &lt;- add_lines(p.glob, x = tt, y = predict(m1), line = line.fmt, name = &quot;Linear&quot;) p.glob &lt;- add_lines(p.glob, x = tt, y = predict(m2), line = line.fmt, name = &quot;Quadratic&quot;) p.glob &lt;- add_lines(p.glob, x = tt, y = predict(m3), line = line.fmt, name = &quot;Cubic&quot;) p.glob &lt;- layout(p.glob, title &lt;- &quot;Global smoothers&quot;) print(p.glob) 第三方插件介绍 biosyntax 更好的展示生物信息相关格式文本 https://marketplace.visualstudio.com/items?itemName=reageyao.biosyntax Bracket Pair Colorizer https://marketplace.visualstudio.com/items?itemName=reageyao.biosyntax 不同的括号显示不同的颜色 Excel Viewer https://marketplace.visualstudio.com/items?itemName=GrapeCity.gc-excelviewer VScode 中直接查看 csv 数据 LaTeX Workshop https://marketplace.visualstudio.com/items?itemName=James-Yu.latex-workshop latex 语法支持（包括 pdf 预览） Markdown All in One https://marketplace.visualstudio.com/items?itemName=yzhang.markdown-all-in-one VScode Markdown 插件，支持各种快捷键快速输入，支持数学公式，自动补全。带来类似于 typora 的使用体验。 Markdown Preview Enhanced https://marketplace.visualstudio.com/items?itemName=shd101wyy.markdown-preview-enhanced 目前最好用的 markdown 预览插件 Pangu-Markdown https://marketplace.visualstudio.com/items?itemName=xlthu.Pangu-Markdown 中文和数字中文和字母之间自动加入空格 Project Manager https://marketplace.visualstudio.com/items?itemName=alefragnani.project-manager 必备的项目管理目录插件 Settings Sync https://marketplace.visualstudio.com/items?itemName=Shan.code-settings-sync 通过 gist 同步你的 vscode 配置 还有其他一些比较大众的，就不多余列出了，只需要随便在搜索引擎里搜索 vscode 插件即可。 常用的几个小配置和技巧 其实能够熟练的记忆并使用十几个常用快捷键，然后可以配置好常用的编程语言支持环境，并且善于发现好用的快捷键，基本就已经可以上手日常使用 VS code 了。对于一个新手来说已经足够了。 这一部分内容介绍几个我日常会用到的小配置和技巧，（这里和后面几天的内容）供大家进阶了解。 编辑器将所有的空格符、制表符等全部渲染 通过设置 editor.renderWhitespace: all 让编辑器将所有的空格符、制表符等全部都渲染出来。这样你就能够一眼看出这个文件中使用的究竟是制表符还是空格符，以及有没有在哪里不小心多打了一个空格等。 文件快速跳转 如果同时打开了十几个文件，如何在不同的文件之间快速跳转呢？ 在 VS Code 中，解决这个问题的第一个方法，就是按下 “Ctrl+Tab”，然后继续按着 “Ctrl”键但是松开 “Tab” 键，这样你就可以打开一个文件列表，这个列表罗列了当前打开的所有文件。接下来，你可以通过按下 “Tab”键在这个列表里跳转，选择你想要打开的文件。最后选到你想打开的文件后，松开 “Ctrl” 键，这个文件就被打开了。 除此之外，VS Code 在命令面板里提供了一种支持搜索的文件跳转方式。当你按下 “Cmd + P” （Windows 上是 Ctrl + P）时，就会跳出一个最近打开文件的列表，同时在列表的顶部还有一个搜索框。 markdown 内符号跳转 符号跳转本身是针对代码文件而言的，可以快速的跳转到一些函数定义和类定义。但是这个功能在 markdown 中也十分好用，可以起到快速定位段落的作用。快捷键是“Cmd + Shift + O” （Windows 上是 Ctrl + Shift + O）你可以通过符号，快速地在不同的章节直接进行跳转。 指定默认新建文件格式 当你按下 Cmd + N （Windows 上是 Ctrl + N）在编辑器里创建一个新文件的时候，这个新的文件会被识别为普通文本文件，你在里面书写内容时并没有合适的语法高亮和自动补全，所以你可能会经常看到有些用户，创建了新的空文件后，然后再去调整文件的语言类型。 但是，如果通过把 “files.defaultLanguage” 设置为你想要的语言，比如说，把它设置成 “Markdown”，那么创建空文件的时候，VS Code 就会把它当作一个 Markdown 文件，然后你在里面能够得到 Markdown 的所有语言支持。 在前后两次光标处跳转 可以使用 “Ctrl + -” （Windows 上是 Alt + Left）跳转回上一次光标所在的位置。而如果你按下 “Ctrl + Shift + -” （Windows 上是 Alt + Right）则可以跳到下一次光标所在的位置。有了这两个快捷键，我们就能够在阅读代码时快速来回跳转。 多光标特性 多光标特性是 vscode 高效使用作重要的功能之一，这里不在展开介绍，建议大家学习官方文档。这里提示两个关于多光标的特殊命令：“Cmd + D”（Windows 上是 Ctrl + D）和 “Option + Shift + i” （Windows 上是 Alt + Shift + i） https://code.visualstudio.com/docs/getstarted/tips-and-tricks#_multi-cursor-selection 利用好 VScode 终端 VS Code 的设计理念之一是如何让 VS Code 和终端能够更紧密联系在一起。例如，我们可以在终端中以命令行的形式打开 VS Code，我们也可以在资源管理器中通过右键直接打开在终端中打开一个目录。甚至 VS code 直接终端做进了 VS Code 的工作台，这样用户就不需要在编辑器和系统终端之间来回切换。 由于把终端做到了工作台当中，所以我们能够更好地把终端的输入输出和我们经常熟悉的快捷键，以及资源管理器、版本管理、代码跳转等各个部件有机地组合到一起。这种效率上的提升是指数级的，因为它给 VS Code 的各个组件都增添了新的玩法。 自定义快捷键（进阶内容） 如果你是一个老实的 R 语言用户，那么一定不会用 = 代替 &lt;-，但是 &lt;- 需要按两下键盘而且这两个键位置还挺远，更难过的是因为你用了语法提示如果你在&lt;- 两端没有加上空格它还会给你出现「大破浪」下划线恶心你。在 RStudio 中你可以使用 alt + - 一气呵成输入这四个符号&lt;-，在 VS Code 中必须也可以。 打开 Keyboard Shortcuts （快捷键是 ctrl+k ctrl+s)，在搜索框中搜索 alt+s，这个时候你会看到这个快捷键已经被绑定了（别慌），点开 json 文件我们去给这个快捷键设置不同情境下新的含义。 点开快捷键配置文件之后不要管左边的内容，直接去右边设置就好，配置方法如图。从此以后在 R 或者 Rmd 文件里 alt+-就变成了和 RStudio 一样的快捷键。 关于 VS code 的快捷键文本编辑器这里做一些补充介绍，如下是常见的一个 json 格式快捷键代码片段 { &quot;key&quot;: &quot;cmd+enter&quot;, &quot;command&quot;: &quot;command&quot;, &quot;when&quot;: &quot;editorTextFocus&quot; } Key 在这个 JSON 对象里第一个键是 key，也就是你将要使用的快捷键。如果你是使用“定义按键绑定”按钮来生成的，那么 VS Code 会根据你的键盘布局来自动生成这个文本。 VS Code 为了适应各种不同的键盘布局，在 key 这个值上还是有很多特殊要求的。 Command ”command” 这个属性的意思是想要为哪个命令指定特殊的快捷键。 When “when” 这个属性的值说的是在什么情况下这个快捷键绑定能够生效。此时 “when” 的值已经有一个占位符 （placeholder）了，叫做“editorTextFocus”，它代表着光标聚焦在代码编辑器的文本上。 如果光标在编辑器的文本上时，那么 “editorTextFocus” 就是 true，那么这个“when”的条件就生效了，这则快捷键绑定就会生效。而假如光标处在集成终端里，此时 “editorTextFocus”就是 false ， “when” 就不生效，同样也就不会绑定这个快捷键了。 在 “when” 条件里，除了 editorTextFocus 外，我们还有非常多的值可以使用，并且加以组合。比如集成终端对应的是 terminalFocus，资源管理器对应的是 filesExplorerFocus 。除此之外，你也可以利用 VS Code 的文档去查询全部可以使用的值。在我们截图的设置中设置了在哪种语言环境下激活快捷键。 而在书写 “when” 条件时，VS Code 还支持几个基础的操作符。这样我们就能够书写相对复杂的条件语句了。 ! 取反。比如我们希望当光标不在编辑器里时，绑定一个快捷键，那么我们可以使用 !editorFocus，使用 ！进行取反。 == 等于。when 条件值除了是 boolean 以外，也可以是字符串。比如 resourceExtname 对应的是打开的文件的后缀名，如果我们想给 js 文件绑定一个快捷键，我们可以用 “resourceExtname == .js”。 &amp;&amp; And 操作符。我们可以将多个条件值组合使用，比如我希望当光标在编辑器里且编辑器里正在编辑的是 js 文件，那么我可以用 “editorFocus &amp;&amp; resourceExtname == .js”。 =~ 正则表达式。还是使用上面的例子，如果我要检测文件后缀是不是 js，我也可以写成 “resourceExtname =~ /js/”，通过正则表达式来进行判断 可以参考官方说明 https://code.visualstudio.com/docs/getstarted/keybindings#_keyboard-rules 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-09-11-howtolearnvscode/"},{"title":"当我谈工具的时候我在谈什么","content":"好工具那么多，你知道如何学吗 比知道一个工具更重要的是想明白如何学习一个工具。**比如为了以 VS code 为例进行说明，我甚至在今天上午直接写了一个 VS code 插件。**是的，写了一个插件，不是用了一个插件。 工具重不重要 但凡说起工具，首先避不开的问题是「工具重不重要」。 有人认为工具不重要，工具知道再多用的再好也是唯工具论。如果本身既没有 Power 也没有 Point，就算把 PowerPoint 做上天也没用。这话当然是有道理的，就像如果你飙的一手好车但不知道往哪开，反而容易出事。不过，不负责任的指责永远是容易的事情。如果这样的观点来自既不 Power 也没 Point 还不会 PowerPoint 的人，呵呵。 与此相对，另外一部分人认为工具非常重要，而且他们特别投入于各种工具的研究和琢磨。折腾工具有时候会给人带来成就感，往往也容易深陷其中无法自拔。不少人对工具有一种执念，总是希望找到最合适的工具后再开始工作。不过，时间久了，这种成就感通常会伴随着一些失落。 如果让我发表一下自己的观点，我认为工具可以说不重要。但是，这句话是对懂工具的人说的，最起码是针对有工具思维的人而言。对这些人来说，重要的不是工具而是如何用好自己熟悉的工具以及面对不同的场景和问题如何快速找到并切换到合适的工具。工具对于懂工具的人来说不重要，就像马云一直认为钱不是问题。如果自己本身不具备工具思维就跟着起哄工具无用，无形中怕是自己就变成了别人的工具。 如何学习一个工具 小时候，老师总会说要把书从薄读到厚再从厚读到薄。这话听起来朴实无华，但确是工具学习时最应该贯彻的方针。 一个工具小白，慢慢知道很多工具，通过学习和试错找到适合自己的几个，然后把适合自己的工具学精学透，逐渐培养自己的工具思维。 明确方向和需求 解决一个问题首先要明确问题是什么，学习一个工具最基本的前提是知道自己要做什么。 在日常生活中，你可能有机会听到看到各种名字的工具，也会看到不同的人对于同一个工具截然不同的评价，这个时候你应该如何判断。 大家谈及一个工具时往往会从自身角度出发。听到 XXX 工具特别好或者不好，要学会首先判断对方的出发点，如果使用场景和角度完全不是你关心的方向，那就没必要受到别人的干扰。 因此，学习一个工具首先要明确自己的方向和需求。很多时候我们需要的不是一个电钻，而只是想要墙上的一个洞。 了解工具上下限 明确需求之后，最先了解的应该是一个工具的上限和下限，也就是工具擅长什么，不能做什么。开始学习之前，一定要把工具的上限和下限搞清楚，不然浪费自己的时间还要抱怨工具和推荐这个工具的人。 以我目前在用的印象笔记举例，其实它本身有着明确的优点和缺点。如果你记录笔记的需求是要一个很好用的编辑器，那印象笔记目前的编辑器中规中矩甚至有点简陋。而我之所以用了它 6 年，是因为它和第三方应用的结合能力，剪藏能力以及极强大的搜索能力。有些缺点和毛病，能忍就忍了。 谨慎改变在用的工具 每个人或多或少的都正在使用一些工具，在这个过程中我们还会陆续看到非常多看起来「碉堡了」的东西。要不要换就是一个必须面对的问题。我的建议是慎之又慎，当我们清楚的明确需求和工具上下限之后再慎重做出选择。 假设你正在使用的 A 工具有 ABC 三个功能日常重度使用，即便你了解到新工具 B 在 C 功能上比 A 强大了几个数量级也要考虑好 AB 功能在 B 工具是不是够用。尽最大的努力学好手头的工具是一个最划算的选择；反之如果这个工具的上限已经阻碍了你，那就没什么值得留恋，果断换。 用它然后改变它 学习一个工具，在我的观念里一直都不仅仅是为了用一用。如果你真的喜欢一个东西就应该尝试着去接近它甚至改变它，当然，这是如何学习一个工具的最高需求了。而且这样的操作不需要多，有那么一两个工具足矣。在这个过程中，如果从一个围观群众走到行进队伍中去，我们对一个工具的认知就会有一个质的飞越。 比如，从印象笔记用户走到全国只有 30 个人的资深印象大使，让我明白了一个产品的设计理念哲学和开发规划，甚至看到了更多它背后存在的问题。这样的经历，让我对一个产品的来龙去脉有了更加深入的理解和体会。 在一开始使用 VS code 的时候，我就被它丰富的插件所吸引，例如直接在编辑器中操作 CSV 文件，在编辑器中快速分享美观的代码截图。本着用它然后改变它的初衷，我把学习目标定在了写一个自己的插件。于是，借着「生产力工具交流群」这个机会，我就顺手写了一个 VS code 插件。 我的 VS code 插件 有人说，写插件，这么高端吗？ 其实这个事一点都不高端，因为 VS code 的插件体系有非常多种类，其中最复杂的是通过编程来提供插件功能，可以选择 TypeScript 或者 JavaScript；还有一类是提供语法高亮以及定义等的语言支持。以上两类相对高端，可能需要你有一些 nodejs 和 js 基础知识，但是同时还有大量的主题插件、代码片段分享插件以及快捷键分享插件。这些插件都非常容易上手，可能只需要两三个小时就可以学会从写插件到生成插件再到发布插件的全过程，这个话题可以后面再细聊。 VS code 目前是我的主力代码编辑器，在大多数时候也是我的常用文本编辑器。为了在用 VS code 写文献阅读笔记和读书笔记时更加顺手，我根据自己的阅读和记录习惯整理了一些 markdwon 模板，所谓模板其实就是若干适用于 markdown 的 snippets。为了让有需要的朋友也能用上这些 snippets，我就把它们打包成了一个插件，方便安装与使用。这个插件就属于一个代码分享类的插件，目前这个插件还处于非常简陋的程度，简陋到只引入了两个 snippets，还没有添加插件的 icon，但后期会一直升级迭代，调用更多的 API 去实现一些丰富的功能。写它的主要目的是就为了熟悉 VS code 插件的开发及发布流程。 这个插件目前已经发布在了官方的插件商店。 如果想要验证这是一个多么简陋的插件，你可以直接在 VS code 编辑器的插件页面内进行搜索。注意，如果直接搜索插件的名字可能不好找，但是搜索开发者feizhao反而一下就出来了。点击安装之后，在 markdown 文本中即可使用。为了展示一下效果，录制了一个几秒钟的动图作为演示。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-09-10-howtolearntools/"},{"title":"如何使用语雀快速发表自己的博客","content":"拥有个人博客的几种途径 在越来越多的人已经没有耐心读完 140 字微博（micro-blog），短视频逐渐占据人们更多注意力的今天，博客（blog）——这一上个时代的产物——似乎正在被我们渐渐遗忘。 可是无论时间怎么变化，文字本身的力量都不会衰退。总有一部分人喜欢用文字记录学习和生活，希望用文字向公众传达思考和想法。而拥有一个自己的博客（写作平台），依旧是承载这些信息的最好选择。 目前，可供选择的写作平台大致有如下几种类型： 强社交和推荐性质的平台，以简书为代表 有一定写作能力要求的平台，以少数派为代表 强依托第三方生态的平台，以微信公众号为代表 有一定技术门槛的平台，以各种自建博客为代表 根据写作目的不同，你可以有侧重的选择不同平台。例如，想要借助微信的流量，那运营公众号就是最佳选择；想拥有高度可定制的个人站点，那使用各类静态博客系统进行自建是必经之路；如果想在更专业的平台上进行分享交流，如少数派 Matrix 就是努力的方向。 但这些平台或多或少都存在抑制我们写作热情的不足。例如，强社交推荐属性的平台总会「硬塞」给你根本不感兴趣的文章（广告）；强依托第三方生态的平台总是要让你不得不适应各种奇奇怪怪的规则；自建站点又需要有些写作之外的动手能力和钻研劲头。 如果你只希望找到一个尽可能简单且适合写作分享的平台，接下来要介绍的工具——语雀或许是不错的选择。 如果你希望找到一个可以定制访问路径、支持 Markdown 且写作体验优秀、自带图床、可以私密或公开分享、自带评论功能、支持批量导入导出同时还免费的写作分享平台，语雀可能是现阶段为数不多的选择。 语雀是什么 关于语雀是什么，首先摘录一点 官方介绍。 「语雀」是一个「专业的云端知识库」，孵化自蚂蚁金服，是体验科技理念下的一款创新产品，已是 10 万阿里员工进行文档编写、知识沉淀的标配。 语雀诞生伊始，只是希望能给工程师提供一个好用的工具用来写技术文档，达成「用 Markdown 写文档」这个小目标。但在产品研发的过程中，我们发现其实身边的每个人、每个团队、每个组织都有很多知识，但一直以来缺少一个好用的工具让这些知识不只是留在每个人的大脑或电脑里，还可以被记录、分享和交流。 类似于腾讯文档，语雀也是背靠巨头，起家于阿里巴巴的蚂蚁金服团队，且已从公司内部面向大众开放。和一些定位于个人笔记以及在线文档的工具不同，语雀的主打定位是「知识库」和「团队」。 注册之后，你会发现「语雀」的个人主页称之为「工作台」，如下图所示，基本上左侧栏就是它支持的全部功能。 语雀的「主页」 这些功能因为使用场景不同可以有各种解读，在这里我仅从个人写作分享平台的角度说一下自己的理解。 写好的文章可以直接以「文档」形式查看，也可以让它隶属于某个「知识库」或某个「团队」，这三者代表了文章的组织方式和层次。 「协作」和「讨论」则可以帮你和其他作者或读者建立一个沟通机制，不妨理解为一篇文章具有的社交属性；而「关注」和「收藏」则可以让你跟进其他优秀的公开「知识库」和「文章」。 何为知识库 所谓知识库，我的使用体验就是可以存放整理各类型文件的集合。在语雀中提供了如下几种类型。 知识库类型 文档 文档是最基本的知识库形式。其本质可理解为具有关联的文章合集。可以分章分节，有完善的目录功能。它可以是产品手册、技术文档，也可以是一本书，比如我把自己几年前部署在 Gitbook 的一本书《靠谱学长说：聊聊考研复习这件事》搬了过来，最大的好处是国内访问速度明显提升。 左为语雀右为 Gitbook 专栏 所谓专栏，就是下文将要介绍的「个人博客」，可以把它理解为没有强关联的文章合集。在最新版的语雀中，因为其它类型知识库形式的扩充，专栏知识库已经和上文提到的文档知识库统一合并为文档知识库。如果想要新建专栏知识库，一方面你可以通过「从模板新建」选择「博客专栏」，另一方面也可以在知识库的高级设置中修改类型。如下图所示： 切换知识库类型 和常见的博客概念不同，「专栏」可以隶属于个人或团队，换言之，如果定位为一个团队专栏，那每篇文章都可以有不同的作者。 如何把语雀变成博客 所谓个人博客，在我理解首先需要同时满足个人、博客和交流三个基本需求： 支持包含个性化名字的固定访问地址（个人属性） 可以写各种类型文章并公开分享（博客属性） 有点赞评论功能可以和读者沟通（交流属性） 如果还有更高阶的需求，或许是： 自带图床及较好的图片管理功能 文档编辑器功能丰富及较好的使用体验 支持多种类型内容展示如视频和数学公式 有详细的官方文档且有持续维护和更新 使用了一段时间后，我发现以上这些需求语雀都可以满足，有些地方还有意想不到的惊喜。 独立且固定的访问地址 语雀允许你对自己的主页和每个知识库设置有辨识度的个性化访问地址，而不是像少数派（忍不住吐槽一下）等多数平台那样给你一串冰冷的随机字符。 在账户管理页面，你可以设置个人路径。 设置个人路径 针对一个知识库，还可以设置独立的下一级地址。 足够好用的编辑器 语雀的文档编辑器是一个现代文本编辑器该有的样子。支持多级标题、字体、表格、列表、上传图片、代码片段等常用功能，支持 Markdown 常用快捷指令。所见即所得，写的顺手。详细的介绍可以自行查看 官方说明，以下只提写几个在实际使用中让我略感惊喜的细节。 文章中可以上传并展示我目前能想到的绝大多数内容。 如下图所示，文本编辑器支持的插入内容分为一般插入和嵌入两类。熟悉 Notion 的朋友应该对嵌入（Embed）这个操作并不陌生。 支持插入多种格式内容 支持的内容主要有数学公式，思维导图，流程图和各种类型本地文件等，还可以直接插入本地视频或者哔哩哔哩与优酷视频。点击工具条左侧的「插入」或者直接在文档段落首行输入 / 都可以调取卡片控件。 下图是在文章中展示思维导图的两种形式，可以直接插入可编辑的思维导图（样式单一），也可以直接嵌入 Xmind 原文件然后进行自动解析。 两种形式展示思维导图 编辑器支持多种图片插入方式且管理方便。 插入图片的方式有如下三种： 系统层级的复制粘贴 桌面拖拽到网页 顶部 toolbar 插入 在图片管理方面，上传后的图片可以任意调节大小，同时支持图片指定跳转链接。读者只需要点一下图片就可以跳转到指定地址。 图片管理 关于在任何一个编辑器中都经久不衰的 Markdown 话题，语雀支持绝大部分 Markdown 快捷输入方式从而让我们可以轻松完成文档的编辑。和众多主流编辑器类似，所见即所得的实现方式。 Markdown 效果 当然，如果和 All in One 的 Notion 相比，在一些细节和特殊内容的插入上可能语雀还略有不足，但针对大部分人会用到的大部分功能而言，它可以称得上是一个足够优秀的文本编辑器。 公开发表与分享 在设置部分，如果把一个「文档」或者一个「专栏」本身设置为互联网可见， 那么其中更新的文章就会自动公开，知道地址即可访问。当然，如果有些文章并不想公开，仍可以对单篇文章设置为仅自己可见。 设置可见范围 另外，你还可以设置知识库里的内容是否可被搜索引擎收录。如果作为博客使用，打开这个选项可以帮助别人更加方便的检索到你的文章。 设置搜索引擎收录 优化阅读体验 针对单篇文章，在发布时可以进行多种设置。如下图所示，除去封面和摘要之外还可以修改访问路径并设置单篇文献权限。 优化阅读体验 协作和评论 语雀区别于多数纯博客或写作平台的一点，就是类似「腾讯文档」和「石墨」的协作属性（这也是语雀的主要定位）。每一篇文章，如果需要你都可以通过添加协作者的方式进行文章协作。因为这一功能不是本文介绍的重点，就不再展开。在实际使用过程中，我的协作体验还是不错的。 在自建博客的日子里，我经常会在各种各样评论插件中闪转腾挪，今天这个停止维护了就得切换下一个，明天这个国内访问速度不理想了又要切换下一个。语雀发布的每一篇文章下读者都可以进行评论，你也可以对具体评论进行回复，而评论和回复的码字体验与编辑文章没什么差别，从这一点看语雀还真是省了不少心。 官方支持与迭代 背靠大厂再加上官方的重视（目前来看），语雀有相对完善的 官方文档。日常碰到各种问题通过留言等形式也会很快得到回复。下面的截图是部分我通过文档评论向官方反馈 Gitbook 导入 bug 的过程。 沟通和反馈 bug 通过下图则可以感受一下开发迭代速度。 更新速度 重度写作者关注的问题 对于重度写作者而言，通常还会更多的关注其它一些细节问题，比如搜索、历史版本，导入导出以及内部跳转等等。针对这些问题，从我的使用体验来看语雀完成的都还不错。以下仅取两例。 如何进行搜索 文章写多了，如何快速找到自己曾经写过的内容就成了一个问题。对于目前还没有文档标签系统的语雀而言，搜索是唯一的方法。 语雀的搜索功能支持多种粒度。当你在任意界面的搜索框输入内容时它会提醒搜索范围。如可以搜索当前知识库，或者搜索当前团队，亦或者只搜索和你相关的内容。 搜索粒度 方便的多格式导入 针对单篇文章，在文档编辑页面可以直接复制 Markdown 格式文本。在阅读页面，右上角「更多」里面还可以找到「查看 Markdown」。 针对多篇文章，不管之前写文章用的是 Word、Markdown、Pages、WPS 还是 Confluence 或者 Gitbook，它们都可以顺利地迁移到语雀文档。其中 Markdown 可以直接支持标准的 Latex 公式。 支持导入的文本格式 开发者和读者视角 针对开发者而言，语雀本身提供了基本够用的 API 借口和 OAuth 应用，目前已经有一些第三方开发者针对语雀开发了本地文档管理工具和接入服务等等。例如少数派读者和作者们都比较熟悉的 Markdown 写作工具 MWeb 就支持直接把本地文章发布到语雀。 如果想要把语雀作为个人博客平台使用，除了从写作者视角来考虑之外，它本身的实际阅读体验也是需要关注的重点。和 Gitbook 这类专业的平台相比，语雀在阅读状态下还无法提供针对字体或者背景的修改，当然和各种静态博客系统相比，它也不支持主题的自由定制。 在桌面端，阅读过程中可以配合一些第三方的浏览器插件使用。在移动端，虽然是来自阿里系的工具，但语雀团队目前提供的解决方案是微信小程序，因此在这个国民应用里分享语雀的文章还算方便。针对长文，在手机上阅读时可以方便的进行章节跳转。 手机端阅读体验 现阶段存在的不足 写到这里，关于如何把语雀打造成一个入门级的个人博客就介绍的差不多了。说完优势和特点还需要再讲讲使用过程中我感觉仍然不顺手或者不满意的地方。 首先，从前文的官方定义来看语雀并非一个专业的博客系统，只是在使用过程中它具有的诸如自定义路径的一些特性，让我感觉语雀具有成为个人博客平台的可能，然后就顺势做了一些摸索和尝试。从优势的层面来讲，无需复杂的设置部署，基本需求和高阶功能丰富，容易上手；换言之，自然也就存在不提供丰富定制化设置这样的问题。因此，它并不适用于非常追求个性化的技术达人，WordPress 和各类自建博客系统依旧是这类人群的优先选择。 其次，如果你不仅仅把语雀当做个人博客，还想把它真正当成「个人知识库」，在使用过程中还需要注意目前存在的其它几个短板。例如： 移动端：目前只有微信小程序且只有部分基础功能 桌面端：目前还没有独立软件只有网页版可以使用，即没有什么「离线使用」的可能 文档管理：对于习惯了 LTF ( list tag filter ) 体系的人来说，目前语雀中的文档还没有标签系统。内容一多，管理起来略显吃力。 会员及价格：虽然在文章开头，我提到了作为个人博客语雀可以免费使用，但这并不意味着可以免费无限制使用。就在近期，语雀推出了会员服务，价格为 99 元 / 年（首年 59 元）。普通用户在知识库数量，上传流量和协作人数等方面均有所限制，不过好在基础功能并没有进行区分。 上述的问题有些已经在官方下一步开发和完善的计划之中，但是没有明确的时间表供我们参考。值得注意的一点是，在最新的会员权益中官方提及到即将推出付费阅读功能——作者可以对原创知识库开启付费阅读全文模式。对比微信公众平台至今尚未推出的付费订阅功能，我们似乎可以感知到一点点语雀后续发展的思路和野心。 附上一张语雀作为个人博客平台使用的体验优劣对比表，希望有助于你进行选择。 优劣对比 如果有写作热情且不想太折腾的你暂时还没找到一个可以作为个人博客的平台，语雀是一个值得尝试的选择。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-09-01-howtouseyuque/"},{"title":"biotools 综合性生物信息工具资源网站","content":"生物信息涉及到的工具方法过于庞杂，很多时候接触到一个新的内容总是不知该去哪里找相关的工具，还有很多时候找到的工具太多又不知道该用哪个。之前写过两篇文章 66 种测序数据分析方法和流程 和 如何快速找到自己需要的 R 包。分别从测序数据类型和 bioconductor 包两个角度介绍如何快速找到自己需要的工具。 今天是这个系列的最后一篇文章，介绍一个综合性生物信息工具资源网站 biotools。以后只要用好这三个工具，就不会害怕生物信息不知道用什么和怎么选工具的问题。 其实说到这类整合网站，很多人都知道 omictools, 不过它很早之前就已更名为 omicX 并转向商用，每天点上六七次网页之后就会提示付费且价格不菲。现在，有一个同样好用还免费的网站来替代它——biotools。 Genome Biology 近日上线的一篇题为 The bio.tools registry of software tools and data resources for the life sciences 的文章，介绍的就是这个网站。 网站特点 biotools 背后团队来源于欧洲的一个政府间组织 the European Infrastructure for Biological Information(ELXIR)， 这个组织主要的工作就是希望能够协调整合以及维护所有组织成员国内的生物信息学数据和各种资源，而这个网站主要是有丹麦提供资金和领导。因为是非盈利组织，所以无需付费使用。 从网站的介绍来看，主要有如下几个主要特点： 所有的数据公开：可以用这写数据集进行符合开源协议的二次开发 所有网站的源代码开源：可以去 GitHub 上提交 issue 并了解最新动态 所有人都可参与：注册后可以按照规定格式自行提交尚未收录的工具 工具唯一标识：所有资源分配有唯一 ID，方便和其他工具整合以及交叉使用 资源描述有严格标准：涉及到的主题操作数据以及格式等描述都有明确的标准 有 Web API：可以使用官方提供的 API 进行各方便的访问和查询 简单使用 biotools 的使用非常简单。网站首页提供了一些比较受欢迎的词条目录，方便直接访问。以 Nucleic acids 为例，目录如下 。包括和「核酸」相关的序列比对、甲基化分析、变异检测以及转录因子结合预测等。 每一个词条都可以点击，点击后就会进入对应的搜索界面。如下图所示。 首先，可以在右上角选择展示方式，个人比较推荐「详细」模式，看到关于搜索结果更详细的描述信息。 在这个搜索页面中可以按照不同标准（默认是评分）进行排序，包括更新日期、添加日期，发表时间和引用次数等。无论是想要用新的还是想用被使用多的，都可以满足。此外，还可以在搜索栏中继续进行二次搜索，支持联想，会自动提示可能想要搜索的词条。 如果你找到感兴趣的工具，点击工具名字即可进入详情页。这里以 BWA 举例，如下所示。 第一部分是工具的属性标签，包括这个工具的开发成熟度，协议、工具类型、开发语言和操作系统等。右边是工具的受欢迎程度，例如引用次数信息。 第二部分是工具相关的分析流程，其中每一步骤显示的都是语义标签，可以点击进行二次搜索。例如 BWA 的输入数据是 fasta 或者 fastq 文件，可以进行索引和比对，输出内容是 sam 文件。如果点击 fastq，就会看到所有输入数据支持 fastq 的工具。 第三部分内容则是工具对应的开发者联系方式，文档地址和工具下载地址；第四部分是工具相关文献的链接和文献引用情况。 工具有了然后呢 如文章开头所说，如果我们能从测序数据类型和 bioconductor 包和综合性工具这三个层面进行查找，总可以找到一些（或许）适合自己的工具，但是找的到可不意味着用的对和用的好。就像听过很多道理，依然过不好这一生，我们听过很多工具，可能依然解决不了手上的问题。而且对于做生物信息的人来说，搜到一大把的工具不见得是好事。 文末，祝你上得了厅堂，下得了厨房，找得了工具，发的了文章。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-08-15-biotools-web/"},{"title":"听说你也有 emojifont 的字体使用困惑","content":"问题复现 Y 叔有一个神包，能够在 ggplot 图层里随心所欲的添加各种 emoji，然而很多人在使用的时候却不能「随心所欲」，经常一行函数输进去一张白板输出来。最近在我的星球里也有人提到这个问题，作为一个无趣的人我虽然之前没有实际使用过这个有趣的包，但是今天要被迫营业了。 在反馈中可以看到 Windows 中的基本错误信息有两类：一是提示 warning，虽然能出图但是图和想象中的样子不一样；二是提示 warning，然后直接输出一个空白图层。其中 warning 的内容是： In grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, : Windows 字体数据库里没有这样的字体系列。 以下是两个错误示例 library(tidyverse) library(emojifont) load.emojifont() ggplot() + geom_emoji(&quot;rose&quot;, color='steelblue') + theme_void() 虽然这个图画出来了，但是这图和正确的图竟然不一样。下图为正确的图。 另一个错误示例是： ggplot() + geom_fontawesome(&quot;fa-github&quot;, color='black') + theme_void() 输出 warning 信息后直接扔出一个白板。 Warning message: In grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, : Windows 字体数据库里没有这样的字体系列 因为输出白板这里就不放截图了。 问题定位 这个问题有两个地方需要注意，一般我们说遇到warning不用管，但是这里不得不管因为图没展示出来；二是没有报error说明本身代码或者调用的函数没有问题，也就是**图没有出来不是画图（代码）的问题而是打印（设备）的锅。**这里的设备是指图形设备，所以不妨换个图形设备打印一下看看效果，比如用最基本的png()进行测试。 png(file = &quot;test_emoji.png&quot;) ggplot() + geom_emoji(&quot;rose&quot;, color='steelblue') + theme_void() dev.off() 需要注意的是使用png()打开一个图形设备后，在运行画图代码时就没有了上文的警告内容。然后看保存的结果也是正常的。当然，如果使用ggsave去保存也没有任何问题。 至此问题就基本定位应该是 RStudio graphics device 和这个包并不兼容。接下来就是查一查有没有好的解决方案。 解决方案 作为一个如此成熟和受欢迎的 R 包，遇到问题以后和我们通常的 debug 思路是不太一样的。 一般情况下我们会在搜索引擎中输入主要的报错信息，然后加上错误工具的名字等进行检索。但是现在不妨直接去对应的 GitHub 查看已有的 issue。当我打开 emojifont 的 issue 列表时，我感觉这个问题已经解决了。 基本上所有关闭的 issue 都集中在字体上，其中涉及到了 Windows 和 macOS，再看看那些没有关闭的问题，基本也都是和字体相关。（相比此时 Y 叔已经心力交瘁） 简单翻了两个问题，就是我们文章开头提到的内容。既然用户已经有了这么多困扰，把写好文档作为 R 包开发准则的 Y 叔想必会在文档里写清楚这个问题。二话不说，立刻打开文档去瞅瞅。打开以后就会发现在目录上清晰的写着一个** limitation**。本能促使我点开它，然后看到了下面这样一段话： 也就是说，因为 emojifont 依赖于 showtext ，而 showtext 本身和 RStudio GD 存在兼容性问题，所以在 Rstudio 中会出现各种问题，这也是为什么直接用png()保存则正常。因此给出的解决建议是即便在使用 Rstudio，也还是用系统本身的 GD 去打印，在 Windows 中就用 windows() 在 Mac 中就用 quartz()，然后万事大吉功成身退。 如下图所示 问题复盘 关于 emojifont 的实现方式，其实在文档中一开始就写了是用 showtext 去 render 字体。它本身只是打印出 emoji 对应的 unicode。因为我是先收到了 bug 才去使用这个包，所以本身就没有按照正常的顺序去学习。 学习使用一个工具时，第一步就应该是先去看官方文档和使用说明。其实 Y 叔这个包的说明文档已经十分精简了，但还是有很多人可能从来没有打开过。另外，在使用成熟的工具遇到问题时，也要学会查看已有的 issue ，你的问题可能早在两三年前就已经被开发者回答和解释过。 One More Thing 问题解决之后还有一个小的发现。 在 Rstudio 上使用 Rmd 写文章，如果常规操作导出 HTML 那 emojifont 还是会出现无法正确打印的问题。解决方案其实就在 showtext 的说明文档中 。需要注意如下两点。 在文档的 header 添加 fig_retina:1 在使用到 emojifont(showtext) 的代码块中，添加fig.showtext = TRUE Rmd 代码如下： 导出 HTML 效果如下： 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-08-13-emojifont-debug/"},{"title":"首届生物信息人才发展论坛背后的故事","content":"第一届生物信息人才发展论坛落幕已经半月有余，算上前前后后的准备周期，在大家眼中一个「小而美」的论坛其实陆陆续续持续了一个多月的时间。 作为组织者和参会者之一，按道理应该有很多话要说才对。但是过去一个多月尤其是论坛期间的高度集中和紧张，导致我突然变得不知道该从何说起。和健明聊起来，他也是同样的感受。尽管如此，因为没有记录就没有发生，所以还是要从组织者和参会者两个不同的角度做一些记录和回顾，聊聊自己的感受和想法。 办生信技能树自己的会议 健明有举办一场会议的念头由来已久，大概要追溯到两年前。早期小范围聊起的时候，我一直都是打击为主顺带安抚。这其中可以给出的理由很多，比如团队影响力问题，嘉宾问题，内部时间如何协调以及很现实的场地和经费问题等等。归根到底，我最担心的问题只有一个，就是团队里大家的凝聚力和执行力问题。 实打实的举办一场活动和平日大家在群里吹吹牛逼划划水不同，需要原本就不多的几个团队成员拿出大量的时间在很多琐碎的事务上，而且这些人目前大多数都是硕士或者博士在读，本身的工作压力都很重。不过，随着健明在珠海的线下团队快速成长，我对办一次生信技能树自己的会议其实也从最初的否定逐渐转变扭扭捏捏的符合进而更多的变为了一种期待。 从今年开始，伴随着健明的「我的生信五周年巡讲」，线下团队已经经历了十几次现场培训的历练。不少曾经早期的实习生和学徒已经成为了线下团队的中坚力量（当然，更多的人可能选择了放弃）甚至是正式员工，这可以说是「人和」；线下团队所在地横琴澳门青年创业谷在场地和会议服务方面也可以给我们提供大量的支持，这可以说是「地利」。生信技能树走到今天，一方面我们已经有了还不错的受众基础，作为一个特别接地气特别有人气的组织可以明显感受到大家的热情；另一方面，目前国内比较知名的几个生物信息会议都是以学术为主，有些非学术性质的会议又太过商业，找来找去似乎没有一个特别针对生信相关学生以及从业人员发展的会议，这可以算是「天时」。 从上述几点来看，举办一次生信技能树自己的会议已经不是一个需要讨论的议题而变成了一件需要执行的事情。 痛并快乐的筹备过程 从决定举办并确定日期算起，留给我们的实际筹备时间也就是 30 天不到。有过参加会议经历的人应该都懂，对于大部分会议来说可能临近 30 天的时候报名都截止了，而我们才从零开始。在这段时间里，所有的工作都需要筹备小组来完成，没有任何专业的会务公司为我们提供帮助。这件事想想还挺有挑战性。 为了避免和同时期其他几个专业会议的「正面冲突」，我们把论坛的主题限定在了「生物信息人才发展」这个角度。一方面，帮助 10 万人入门生物信息是生信技能树的目标之一，但是我们内心深处也不清楚如果真帮 10 万人入门生信，等待大家的将会是什么；另一方面，对于生信技能树的大部分朋友来说，大家普遍关注的也是如何更好的实现自我成长和发展。从这个主题延展开来，我们构思了企业、职业和学术三个专场，希望可以从这三个方向让大家更全面的认识和理解生物信息行业（学科），也听一听诸多大佬和过来人的建议甚至是困惑。 在整个筹备过程中，我们努力调用大学和研究生期间一些残存的活动会议组织记忆以及自身参加各种会议的经历，筹备小组成员也从最初的几个人逐渐扩大到十几人。即便大家都是业余时间交流，但我们还是尽量让工作变得明确可执行。 把有限的人手分为嘉宾联络和线下沟通以及宣传设计等几个小组。说是小组，其实很多也就是一到两个人，比如所有的海报、工作证和会刊等物料设计都是出自徐妍之手；包括场地和茶歇等在内的所有线下安排沟通事宜都由敏敏和小淑两个人完成；慧美、嘉鋆和 Kim 在内的每一个嘉宾联络人都要负责 9-10 个嘉宾从会议筹备直到会议结束所有具体沟通事宜。每个人，都像是一个队伍。 因为人手实在有限，会议期间，国灵一个人完成了所有嘉宾的酒店住宿安排和接待工作；贾方完成了所有参会者的报名和后期沟通工作，4 位浙大的高材生被我们「大材小用」安排到了签到处，完成了所有证件核验、签到以及物料发放工作。除此之外，线下团队的几位讲师和助教在本身有教学任务的情况下，也都在会议期间承担了非常重要的工作。在此不一一列出，但是一并表达大大的感谢！ 会议筹备的问题和收获 论坛结束之后，我们接收到的大多数反馈都是正面的。不过在我看来，这更多的是源于对生信技能树以及健明的喜爱，同时还有对我们这支「游击队」的宽容。 因为人手及其有限且可以投入的精力和时间有限，我们在和外部的沟通上暴露了很多问题，例如和赞助商以及协办方的沟通。除此以外，在会议嘉宾和内容以及节奏的把控上我们也有极大的提升空间，这些都有待于在第二届论坛的时候加以改进。同时在筹备过程中也有一点心得，在此一并整理出来。 提高效率 为了尽可能提高沟通和协作效率又不让事情太复杂，我们没有选择很专业的协作工具。因为所有交流都是基于微信的，所以会议筹备过程中所有文本资料都使用了在线的腾讯文档。其中嘉宾通过问卷形式填写个人和演讲信息方便后期整理统计，筹备小组成员拥有所有文档的查看和编辑权限，避免了在群里重复上传各种版本的文档。 明确分工 大伙合作完成一件事情，最常见的问题是讨论起来热火朝天，落实起来鸦雀无声，用老话来说「三个和尚没水喝」。所以，该头脑风暴的时候就群策群力，该落实工作的时候就明确到人。三十个人做一件事情需要花费的时间不仅做不到三个人的十分之一，反而很可能是三个人的十倍。如果一件事情比较着急，不要在群里发问「谁可以把这件事情做一下」，而是直接问你信任的人能不能把这件事情处理一下。 讲明诉求 涉及到合作，最大的障碍永远在沟通。当我们抱怨对方执行力的时候很可能问题出在自己没有把事情说清楚。传递一项工作的时候，尽量多重复几遍。其中一遍要说清楚自己希望对方做什么，第二遍让对方复述一下他理解的诉求，第三篇要说清楚做这件事的目的，最后要咨询对方是否有更好的想法和见解。通常，对方一开始的理解都和你的想法有不少出入，这样一来就会有「重来一遍」的风险。 做好分内的事 在合作的过程中，首先要完成好自己该做的事情，再去发表自己观点。如果自己的任务是 A，就不要过分关心 B 和 C 的完成进度，难免会给人一种「你行你来」和「你都干点啥」的感觉。 做好挨骂准备 活动的成功之处都是嘉宾和参与者的功劳，活动的失败之处都是组织者的原因。对于组织者来说，最强的存在感就是没有存在感，类似于跑一个程序没有输出任何消息就是最好的消息。 一个准毕业生的困惑 马上就要开始漫漫人生路的第 27 个年头，不知不觉也走到了硕博阶段第五年。一个明显的感受是越来越困惑，没有想清楚自己毕业后要做什么以及能做什么。 由于同时还要承担两天论坛主持人的工作，带着「毕业后要做什么以及能做什么」的困惑，我完整听完了所有嘉宾的分享。接下来就顺着「毕业工作」这条线，整理一下论坛中嘉宾提到的部分关于行业，需求和能力培养相关的内容。 公司层面的架构要求 烈冰生物的创始人宗杰博士提到了烈冰目前的公司主要人员架构： 研发部：平台搭建，需要代码能力极强，掌握多种涉及模式，有分布式和大数据等经验。 生信部：上线新工具进行平台运维，需要对各种工具敏锐，深入理解各种工具流程及相关参数，可以快速学习，需要一定的代码能力。 项目部：基于平台分析项目，无需会写代码，了解各种工具流程，就是各种结果文件，细心耐心善于学习。 技术部：生物学意义挖掘，生物医学知识要求高，有高质量论文更佳，对生物学问题要敏感，有自己的见解。了解各种组学数据库和新的分析方法。 结合海普洛斯基云惠康等公司的招聘要求，多数集中在如下一些内容： 对相关行业要有兴趣和使命感 良好的沟通和合作能力以及学习能力 熟练使用 Linux 系统，熟练使用 /Python/Perl/R 中至少一种编程语言 熟练掌握各种生物信息工具和分析流程，熟悉常用的生物信息学数据库，对生物统计学原理及意义有深刻应用能力 有良好的英文阅读和文档写作能力 有相关应用产品、分析流程开发经验，发表过相关论文者优先 个人层面的能力培养 综合古奥基因的肖世俊博士在生信相关个人能力培养方面给出了如下一些观点和建议： 生物信息学正在逐渐成为一门工具性学科，逐渐成为所有生物学学生必备的知识内容，单纯的数据流程分析工作会逐渐被机器取代。生物信息学的下游发展会分为两个主要的方向：一是分析工具的开发，需要更多的 IT 和算法基础；二是产业应用的开发，需要更多对于行业的理解。 如果把生物信息作为一项职业，其能力可以分为技术和沟通两种维度。其中技术维度包括熟练程度、项目经历和学习能力等，沟通维度包括汇报能力、抗压能力、领导能力和全局观念等。在初期，技术维度更加关键，随着职业的发展沟通维度则越发重要。 GeneDock 云平台研发总监李明则建议大家要学会在工作中知其所以然，善于总结日常遇到的问题和学会有效沟通，同时能系统的学习编程知识和相关业务。以编程知识学习为例，其中包括语法、调试技巧、算法知识和编程原则等内容。 优秀的人有哪些共同点 在论坛现场看到了各种各样的嘉宾，也看到了太多的可能性。其中有一部分是之前就非常熟的「同龄人」，比如果子、洲更和海涛等等。虽然他们每个人的特点不同风格各异，但我还是尝试从他们的身上总结一些共有的优秀特质，找到自己的差距和努力方向。总结来总结去，好像就是如下几点：对新鲜事物的好奇心和热情；持续不断的学习；从实际的工作场景出发不断扩宽自己的知识和认知边界；持续不断的输出。 嗯，大概就是这些。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-08-07-thefirstbiotraineeforum/"},{"title":"上手 MacBook Pro 基础操作和配置","content":"这个月，我成为了一名 Mac 用户。macOS 诞生于 1984 年，经历了 35 年的发展之后，其在全球操作系统市场中的份额已经不到 10%。 macOS 是第一个商用的图形界面操作系统，和 Windows 相比更加注重人际交互的细节感知。例如，在 macOS 中无需关注剩余内存空间，因为系统首先会占满所有内存，然后根据软件使用情况进行自动调整从而保证系统的稳定。 基础操作和设置 不在触控板的触控板设置 触控板是 Mac 优秀使用体验的一个直观表现，各种多指操作非常顺滑。在系统偏好设置中的触控板，可以完成大多数的设置操作。例如使用轻点来实现点按的效果，使用双指从右边缘向左轻扫查看通知。但是还有几项我们常用的操作被藏在了偏好设置的其他地方。 使用鼠标时一个常用的操作就是一次选择多个文件进行移动，而通过触控版完整这项相同的工作则十分费力。在 macOS 中可以通过在辅助功能中开启三指拖移来实现同样的功能。开启该功能后可以方便的进行文字和文件多选以及拖移操作。 在 Windows 中可以通过win+p进行锁屏，讲鼠标移动到桌面右下角可以显示桌面。在 macOS 中类似的功能被称作触发角，在系统偏好设置的调度中心中，点击触发角就可以进行设置。如下图所示，每个角都可以设置常用操作。设置后，只需要轻松滑动一下触控版，就可以实现对应的功能。我目前常用的是锁屏和启动屏保。 预览及预览插件 之前用 Windows 的时候就非常羡慕 Mac 的「一指禅」预览功能，彼时听闻在 macOS 上万物皆可「空格」预览，无论是图片还是 PDF 或者是什么文档。 真正用上 MacBook Pro 之后确实体会到了它的厉害。最新系统的预览可以直接编辑图片和 PDF 文档，其中很多小的功能甚至比专业的编辑器还要方便。以 PDF 距离，曾经困扰很多人的 PDF「签名」问题，可以直接在编辑模式下通过触控版书写或者通过摄像头进行拍照。 另外，局部高亮和放大功能针对很多截图来说都非常实用。 markdown 及脚本预览 在实际体验中，预览功能对一些我们目前常用的文本无法很好的预览。比如 markdown 文本和各种脚本均不支持高亮。好在有很对第三方的预览插件可以解决这一问题。 例如 qlmarkdown 可以提供 markdown 文本的渲染后预览，而 qlcolorcode 则可以很好的实现代码高亮。如下图所示，R 脚本可以正确的识别。 聚焦搜索 macOS 自带的聚焦搜索（spotlight）可以解决日常的绝大部分搜索需求，无论是查找文件查找目录。在全局使用Command-空格键 都可以调出搜索框。 找到需要的内容后，如果想要直接打开可以使用return，如果有多个重名文件可以通过短按command查看文件路径，如果想打开文件所在位置则可以使用 command+return 初次之外，还可以在搜索框中直接进行运算和各种单位的转换。另外如果你想直接通过搜索引擎来搜索自己输入的内容，可以直接按 command+b 。 掌握了上面几种简单的快捷键，搜索效率就会大大提高了。 自带中文输入法 macOS 自带的中文输入法十分简洁克制，经过简单的学习摸索后我感觉完全不需要再下载什么第三方输入法了。其中有几个常用的技巧可以帮助我们快速的打出想要的文字和复杂的符号。 就文字而言，自带输入法支持按照声调来选词。你可以在输入拼音后按 tab 键，依次会出现从第一个汉子第一声到第四声对应的候选词。 另外，输入法支持包括词频部首笔画表情在哪的多种选词模式。以输入「微笑」为例。 首先通过键盘右上角的加号调出选词框，然后再使用 tab键就可以切换选词方式。当你切换到表情方式的时候就可以看到所有和「微笑」相关的表情啦。如下图所示。 还有一个隐藏的技能是如何快速的查找特殊符号以及颜文字。要知道这一点，首先需要学会如何正确的输入省略号。在自带输入法中，正确打出省略号的方式是在中文输入情况下使用 shift+6 ，这时，你除了可以看到省略号之外还会看到符合和颜文字两个选项，可以通过 tab 进行切换同时使用键盘右上角的加号和减号键快速翻页。 快捷键查询 因为用了 Mac 之后就意味着放弃了鼠标（也可能没准哪天又用回去了），所以快捷键的使用就显得尤为重要了。快捷键因为记不住的原因在很多时候并不快捷，好在 macOS 给了一个全局结局方法，可以帮助我们快速找到当前软件相关的操作位置。 在任意软件中使用 shift+command+/ 都可以调出菜单栏中的搜索窗口。这个搜索窗口可以帮助你找到需要的操作，只要这个软件中有相关的操作，就可以用这个快捷键通过搜索快速的调用对应操作。 例如我在 typora 中想要插入一个超链接，但是忘记了快捷键是什么。于是我就首先调出搜索栏，然后输入「链接」，这时可以看到对应的操作有「链接引用」和「超链接」两个操作，然后通过方向键选择想要执行的命令，一方面会自动用蓝色箭头为你标注出其在菜单栏中的实际位置，另一方面只需要按下回车就可以直接执行对应操作。非常人性化。 小结 掌握了上面几个基本操作和设置之后，手里的 MacBook Pro 就感觉更好用了一点。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-07-30-learnusemac1/"},{"title":"我的私人学术报告准备清单","content":"做学生和做研究的一个重要工作是把自己在做的东西告诉别人，通常是通过各种报告完成的，上到各种高大上的会议，下到组里几个人的小组会。我本身没有什么高大上会议的经历，但是几年下来各种各样的小组会也讲了不少。导师和同门都时常会给出一些建议和意见，逐渐就有了一套个人的「学术报告准备清单」。各种报告都会反复对照这份清单来准备。其中关于幻灯片的制作心得之前已经写过一篇文章，算是「技」。这篇文章主要写这份报告准备清单中「术」的部分，希望对你有所帮助。 比解决问题更重要的是讲清问题 在谈到自己的研究内容时很多人会不自觉进入兴奋状态，随之而来的是直接进入工作细节，上来就讲用多么牛的方法解决了多么难的问题而忘了解释清楚手头的问题是什么。如果观众根本不理解你的问题，自然也不会理解这个问题有多难以及解决方案有多巧妙。 如果一个问题听起来很复杂，观众有可能会认为演讲者很聪明，但是潜意识里也会让观众感觉自己很愚蠢。没有人会喜欢这种感觉。所以先彻底讲清楚你的问题然后再给他们讲出方案和结果。 尽一切可能降低认知负荷 所谓「认知负荷」，其理论提出者给出的定义是处理被给信息所需要的心智能量的水平，可以通俗的理解为在学习或任务完成过程中进行信息加工所耗费的认知资源的总量。下面两幅图的对比可以清楚的说明什么是外部高低认知负荷的差别。 为了降低认知负荷，有一些具体的清单内容需要遵守： 一张幻灯片尽量只有一幅图表 一幅图表尽量只表达一个主题 如果一张幻灯片必须放入多个图，根据逻辑顺序依次出现 连续几张幻灯片介绍了一个高级主题，需在几张幻灯片之后进行小结 主标题就是关键信息 听报告的时候，每次看到没有标题的幻灯片我都会产生一丝恐惧，进而认知负荷也会被大幅提升。每张幻灯片都应该尝试只传达一个关键点，不要试图让观众自己去总结，而是要把关键点作为主标题清楚的放在幻灯片上，此时听众就会为他们即将听到的内容做好准备。 如果你发现不能用一个简洁的语句传递要表达的信息，那么就考虑再把这一页内容分解为两张或者更多张幻灯片。避免出现「A 和 B 的关系」之类的主标题，而是要写清楚「A 和 B 在什么情况下呈现出什么关系」，前者约等于没有关键信息。 讲清每一个图表 这似乎不应该是问题，但很多时候又是我们最容易忽略的问题。因为知识的诅咒，我们总认为自己做的图清晰易懂，标题图例明明白白。但问题是你的观众可能因为和你不在同一领域而难以理解图表的意思，或者你的听众因为太熟悉你的领域反而按照自己的想法误解了你想说明的问题。 所谓讲清楚一张图，就是要讲清楚图中的所有元素。如果是自己画的图，那它是怎么做出来的就要怎么讲出来。这其中包括： 这幅图描述了什么 坐标轴和单位是什么 不同的线 / 颜色 / 点代表什么 这幅图能得出什么结论 幻灯片要讲不要读 人在读文字的时候听觉系统也会受到影响，而且观众读幻灯片上文字的速度通常要比讲的更快。因此如果完全读（背）幻灯片上的内容，他们很可能就不会听你说什么了。一般情况下主标题就是你一张幻灯片上唯一的文字内容，或者最多再加上一行文字对图表进行进一步说明。 如果害怕自己现场忘了要讲什么，那就把文稿放到备注里或者打印出逐字稿提前认真背诵。如果现真忘词，那就保持镇定然后喝水，边喝边想。 为报告准备两种结尾 这个需求可能看起来比较奇怪，但是现场总会有意想不到的事情发生，比如你讲的前半部分超时严重或者你前面的嘉宾超时严重。至于练习的方法比较简单，就是当准备好内容之后，删掉一半的幻灯片然后再把它讲下来。这样如果现场出现一些意外，你就知道可以跳过哪些内容还能顺利结尾。 为提问做好准备 大多数报告都有提问环节，这个确实考验一个人的真才实学和功底，但是也并非不可准备。 和你所讲内容无关的内容尽量不要放 不是重点且讲不清楚的内容尽量不要放 针对难点和易问点提前准备几页 PPT 放在致谢后以备不时之需 确保所有讲到的信息点和概念都可以有几句话可以解释和补充 回答提问前先重复一遍问题，保证理解正确且可以组织语言 正式上场前多多练习 了解每张幻灯片需要的时间 不同内容之间的连接是否顺畅 准备的内容是否存在冗余 试讲观众提出了哪些问题 其它非常重要的内容 有时间的话最好准备 4:3 和 16:9 两种比例的幻灯片 不要忘了给自己的幻灯片生成一个 PDF 版本 给幻灯片添加页码，方便观众提问 内容页幻灯片按照 1 分钟 1 张准备为佳 为论文准备的图通常不适合放到幻灯片中，因为字号不够大 管好手里的激光笔，永远不要在屏幕上乱晃，更不要指到观众席去 每个结果和引用内容都应该标明合作者和引用者信息 多多参加优秀的会议 如果有机会一定要争取多参加各种会议。通过听各种各样的报告，你不仅可以学到知识收获感悟，还能学习别人是如何演讲的。更重要的是不要仅局限于自己的一点点领域，要学会扩宽自己的视野，听到不同的声音。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-07-05-mypresentationlist/"},{"title":"csvtk命令行版极简dplyr","content":"写在前面 什么时候写 csvtk 呀，csvtk 也借鉴了些 datamash 的东西。 之前写 datamash 的使用教程，收到了一位读者的私信，内容如上。 话说这位读者不是别人，正是大名鼎鼎 seqkit 和 csvtk 的开发者 shenwei356 (github ID)，江湖人称「爪哥」。我从来没有问过他为什么 ID 有个数字后缀「356」，我私以为是一年 365 天里有 356 天他都在写程序，剩下的几天过年放假。说到爪哥，如果你看到这篇文章之前不知道他我不怪你，但是今天以后希望他可以每天都和你在一起。 爪哥用两个工具就让自己在生物信息领域有了一席之地。其中 seqkit 是用来处理 fasta/q 文本的工具，这篇文章要写的 csvtk 是处理 c/tsv 文本的工具。如果你感觉我的说法夸张了，不妨想想每天接触到的各种文件，无论是 gff 还是 bed 还是 sam 甚至是 vcf，其本质都是 tsv 格式，再加上 seqkit 针对的 fasta 和 fastq。如果你能熟练使用这两个工具，今后的每一天就都会感受到爪哥无微不至的关怀。我经常在敲完一行命令后会在心里大喊一声「爪哥 NB」。 csvtk 特点 熟悉 Linux 的人谈到命令行的文本处理，定会奉上文本处理「三剑客」：awk，sed，grep。csvtk 并不想抢他们的风头，而是可以无痛的整合到各种处理流程中。它凭借自己的特点，让命令行里的文本处理更容易。 csvtk 的特点之一是对 header 的识别和处理，它可以让你省去很多原本在使用 awk 等命令时针对 header 行的代码。既然考虑到了 header，特点之二就是支持通过列名来进行列的选择，这里的选择还包括反选和模糊选择。除此之外，之所以说便于和其他流程的整合，还因为它可以直接处理标准输入和压缩文本，同时这个软件本身不需要编译也没有任何其它依赖，非常容易安装，conda 可以直接搞定。 csvtk 本身支持多线程以及若干子命令，用起来会发现通常其速度和效率比在 python 和 R 中输入很多行代码都要高。如果这些依旧不能打动你，csvtk 还有一个神奇的功能：直接用一行代码在命令行里画图。真 6。 csvtk 介绍 csvtk 有三十多个子命令，基本上可以理解为是命令行版极简 dplyr 加若干 linux 命令的增强整合。子命令按照类别和功能分类，可以分为如下几类，其中结尾带有+的子命令是我常用的和值得尤其关注的。 文本信息类 headers 打印首行（列名） dim 查看文件的行列数 ，和 R 中的 dim 类似 + summary 对所选列进行简单的描述性统计，如果是统计内容是数字，则类似于 R 中的 summary() ，同时支持分组统计。如果统计内容是文本，支持类似于 datamash 的多内容统计。+ 格式转化类 pretty 可以让 csv 变成漂亮的对齐易读表格+ transpose 类似于 R 中的t()对数据进行转置 csv2json 则可以让数据转换为 json 格式 csv2md 则是炫酷的直接变成 markdown 支持的表格+ 集合操作类 这一类命令是操作的重点，有很多子命令，其中部分类似于 unix 中对应的命令但又有所区别。 head 查看文件开始若干行 concat 合并文件，类似于cat但是可以按照列名进行匹配合并 sample 按照比例对文本进行提取 cut 按照列选择，支持列数和列名，支持反选和模糊选择+ uniq 无需排序进行去重+ freq 所选字段评率统计 inter 多个文件取交集 grep 类似于 lunix 的 grep，支持正则和反选等操作+ filter 按照数学表达式筛选，支持多列判断，精简版 filter2 按照数学表达式筛选，约等于 lunix 中的 awk，复杂版+ join 按照字段合并多个文件，类似于 linux 的 join split 按照某列值拆分文件，也就是分组保存为多个文件 collapse 按照所选字段的 key 合并其它字段+ 文本编辑类 如果你熟悉 R 中的 dplyr，这类型的子命令中有不少都会让你感觉熟悉。 add-header 增加列名 del-header 删除列名 rename 对列重命名 rename2 支持正则表达式的列重命名 replace 通过正则表达式替换所选列对应的内容，支持捕获变量，内置特殊替换符号+ mutate 对某一列进行正则表达处理增加新的一列 mutate2 对多列进行 awk 类似的字符和数学表达式处理，增加新列+ gather 类似于 dplyr 中的gather()函数，数据「由宽变长」 sort 支持按照一列或者多列排序，且支持自定义顺序排序 画图 借助 gonum 中的 plot 包，csvtk 还可以直接画一些基本的统计图，这功能其实已经超越 dplyr 向着 ggplot2 挺进了。画图相关命令可以根据文件后缀自动确定输出类型。 plot 支持 boxplot, histogram, line 和 scatter 四种图，图的主要元素都可以设置，支持的输出格式包括 eps/pdf/svg/tiff/jpg/png，对应如下三个命令： csvtk plot hist csvtk plot box csvtk plot line csvtk 示例 因为篇幅的原因，这里仅展示几个使用示例，更多更详细的内容可以直接参考爪哥写的使用文档。另外本文使用的数据也来自官方测试数据。 描述统计量 csvtk 的 summary 命令有两个亮点，第一是支持对文本和数值的多种分组统计；第二个是可以过滤对应字段的非数值内容（比如N/A）。 $ cat digitals2.csv f1,f2,f3,f4,f5 foo,bar,xyz,1,0 foo,bar2,xyz,1.5,-1 foo,bar2,xyz,3,2 foo,bar,xyz,5,3 foo,bar2,xyz,N/A,4 针对上述数据，按照第一列和第二列进行分组，同时计算第四列和第五列的和，排除非数值内容，以易读方式输出结果。命令如下： $ cat digitals2.csv | \\ csvtk summary -i -f f4:sum,f5:sum -g f1,f2 | \\ csvtk pretty f1 f2 f4:sum f5:sum bar xyz 7.00 106.00 bar xyz2 4.00 4.00 foo bar 6.00 3.00 foo bar2 4.50 5.00 一键变漂亮 上面已经用到的pretty命令可以让输出的结果更加易读。 $ cat names.csv id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 1,Robert,Thompson,abc $ cat names.csv |csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc $ cat names.csv |csvtk pretty -r id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc 无需排序快速去重 之前曾经讨论一个大文本去重的问题，从当时的结果来看，对于大文本在 linux 中排序是去重的主要限速步骤。但是在 csvtk 中，可以不通过排序而直接进行去重。针对当时的问题，对于一个 3,741,430 行的文本，先排序再去重需要 30s 左右的时间，而使用 csvtk uniq 仅需要两三秒。 time awk 'OFS=&quot;\\t&quot; { if($1&gt;$2){print $2,$1,$3} else {print} }' howtouniq.txt \\ | csvtk uniq -H -t -f 1,2 &gt; howtouniq.txt.awk-csvtk #real 0m2.674s #user 0m5.660s #sys 0m0.482s 复杂条件筛选数据 csvtk 中的 filter2 支持使用复杂条件筛选数据，类似于 awk。首先支持 + - / * &amp; | ^ ** % 等运算，也支持&gt; &gt;= &lt; &lt;= == != =~ !~，同时还可以使用|| &amp;&amp; 对多个条件进行组合。例如： $ cat names.csv id,first_name,last_name,username 11,&quot;Rob&quot;,&quot;Pike&quot;,rob 2,Ken,Thompson,ken 4,&quot;Robert&quot;,&quot;Griesemer&quot;,&quot;gri&quot; 1,&quot;Robert&quot;,&quot;Thompson&quot;,&quot;abc&quot; NA,&quot;Robert&quot;,&quot;Abel&quot;,&quot;123&quot; $ cat names.csv | csvtk filter2 -f '$id &gt; 3 || $username==&quot;ken&quot;' id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 快速添加新列 使用mutate2可以按照复杂运算快速添加新的内容，支持的操作和filter2一致。 比如拼接字符串： $ cat names.csv \\ | csvtk mutate2 -n full_name -e ' $first_name + &quot; &quot; + $last_name ' \\ | csvtk pretty id first_name last_name username full_name 11 Rob Pike rob Rob Pike 2 Ken Thompson ken Ken Thompson 4 Robert Griesemer gri Robert Griesemer 1 Robert Thompson abc Robert Thompson NA Robert Abel 123 Robert Abel 甚至还可以通过三元运算符进行判断填空： cat digitals.tsv | csvtk mutate2 -t -H -e '$1 &gt; 5 ? &quot;big&quot; : &quot;small&quot; ' 4 5 6 small 1 2 3 small 7 8 0 big 8 1,000 4 big 单行命令快速出图 在测试数据中，有一组数据包含不同组别的序列长度和 GC 含量，可以通过plot hist绘制长度的直方图，通过plot box绘制每组的 GC 含量箱线图。 $ zcat grouped_data.tsv.gz | head -n 5 | csvtk -t pretty Group Length GC Content Group A 97 57.73 Group A 95 49.47 Group A 97 49.48 Group A 100 51.00 csvtk -t plot hist grouped_data.tsv.gz -f 2 --title Histogram -o histogram.png csvtk -t plot box grouped_data.tsv.gz -g &quot;Group&quot; -f &quot;GC Content&quot; --width 3 --title &quot;Box plot&quot; &gt; boxplot.png one more thing 文末还是要说回开发者。爪哥是一个非常勤奋的人，可以看看他的 GitHub，嗯，真绿。csvtk 最近一次 commit 是在 8 天前，seqkit 最近一次 commit 也是在 8 天前。 所以，如果你在使用过程中有什么问题和需求，不妨去给他提几个 issue，没准他一顺手就实现了你的想法。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-06-28-csvtkbasic/"},{"title":"每周文献-190622-ATAC-seq和转录本从头组装新方法","content":"HMMRATAC: a Hidden Markov ModeleR for ATAC-seq DOI(url): https://doi.org/10.1093/nar/gkz533 杂志：Nucleic Acids Research 发表日期：14 June 2019 关键点 本文利用 ATAC-seq 技术原理中的转座酶插入特性，设计了一种专门针对 ATAC-seq 的隐马尔科夫模型，这种半监督机器学习方法可以用来鉴定染色质开放区域。 参考意义 ATAC-seq 作为一种定位染色质开放区域的手段目前应用已经非常广泛了，因为相对易于操作目前也应用到了单细胞领域。但是目前关于 ATAC-seq 的流程绝大多数都是按照 ChIP-seq 流程来处理的，call peak 方法十有八九使用的都是 MACS。 ATAC-seq 利用了 Tn5 转座酶优先插入 nucleosome-free regions（NFR）的特性，但是 Tn5 也有可能插入相邻核小体之间的连接区，此时其 DNA fragement 会更长（超过 150bp）而且和相邻核小体的个数相关。针对双端测序数据，我们可以根据比对后的位置或插入长度来推断它们的片段长度。如果将 nucleosome free 和 mononucleosome 片段长都和频率的关系图展示出来，可以看出两者的分布不同。 目前还没有工具可以同时考虑 ATAC-seq 中的 NFR 和核小体信息。而本文作者开发的分析工具 HMMRATAC 则采用了「分解和整合」的思路，首先把一套数据首先分解为来自于 NFR 和核小体区域的不同覆盖信号层，然后在隐马尔可夫模型中学习开放染色质区域信号层之间的关系，并用于预测开放染色质。下图是一个整体的分析流程。 在文章中作者将这个工具和 MACS2 与 F-seq 进行了比较，HMMRATAC 在大多数测试中表现优于前两者。这个软件本身使用 Java 来实现的，目前作者也提到其处理速度相对较慢，是后续优化的一个重点。 软件地址：https://github.com/LiuLabUB/HMMRATAC 相关内容 顺式调控元件与反式作用因子相互作用组成了真核生物转录调控过程，这一过程与染色质核小体的动态定位相关，调控因子的结合需要裸露的无核小体的 DNA 区域，即开放的染色质位点（open chromatin）。从全基因组水平定位开放染色质位点有助于发掘基因组调控元件，进而研究基因表达调控机制。 目前使用最多的两种方法是 DNase-seq 和 ATAC-seq。 DNaseⅠ 超敏感位点 (DNase I hypersensitive sites, DHs) 测序使用限制性内切酶（DNase I）对样品进行了片段化处理。染色质开放区域的反式作用因子的结合将导致这些区域缺少核小体结构，染色质裸露、结构疏松，易于与 DNaseⅠ 结合并发生剪切 , 从而表现出对 DNaseⅠ 的高度敏感性。包括启动子、增强子、绝缘子和抑制因子等在内的多种基因调控元件均与 DHs 紧密关联。 转座子虽然对于裸露 DNA 表现出随机插入的特性，但对于染色质而言应同样表现出偏好转座的特点，即优先在开放染色质区插入染色质。转座酶可接近性 (assay for transposase accessible chromatin, ATAC) 测序就是利用了这个特性。相比于 DHs 测序，ATAT 测序操作简单快捷，检测灵敏度高，实验重复性好的特点。细胞核起始量 DHs 测序是 ATAC 测序的 3~5 个数量级。 Essential guidelines for computational method benchmarking DOI(url): https://doi.org/10.1186/s13059-019-1738-8 杂志：Genome Biology 发表日期：20 June 2019 关键点 计算方法基准分析的综述指南 参考意义 作为一个生物信息「调包侠」，我们平时在分析数据的时候经常会面临一个问题，这几种计算方法我究竟选哪一个？根据不完全统计，目前用来分析单细胞 RNA-seq 的方法已经有 400 多种了，这里就带来了一个问题，选择不同的方法通常会带来不同甚至是很不同的结果，我们该如何选择。这篇文章作者总结了进行高质量基准分析（computational method benchmarking）的关键指南和建议。下图为指南内容的概括。 这上面十点要注意的指南中，首先是定义分析的目的和范围，比如有一类基准分析是有开发者本身使用的，他们的目的是证明自己方法的优势；也有通过系统比较一系列方法进行中立性评价分析的。中立的基准测试应该尽可能全面，同时测试也应该充分和原开发者沟通以便在最佳性能的前提下进行测试。在任何情况下都应该避免因为特别关注某一种方法带来的偏差。而针对新方法优点的评价应该仔细设计评价的标准，一个常见的问题是使用竞争方法的默认参数，然后不停的调整自己方法的参数。 关于上述 10 个原则对于一个优秀基准的“多么重要”，以及与每个原则相关的关键和潜在问题，作者总结了如下一个表格； Principle How essential Tradeoffs Potential pitfalls 1. Defining the purpose and scope +++ How comprehensive the benchmark should be Scope too broad: too much work given available resourcesScope too narrow: unrepresentative and possibly misleading results 2. Selection of methods +++ Number of methods to include Excluding key methods 3. Selection (or design) of datasets +++ Number and types of datasets to include Subjectivity in the choice of datasets: e.g., selecting datasets that are unrepresentative of real-world applicationsToo few datasets or simulation scenariosOverly simplistic simulations 4. Parameter and software versions ++ Amount of parameter tuning Extensive parameter tuning for some methods while using default parameters for others (e.g., competing methods) 5. Evaluation criteria: key quantitative performance metrics +++ Number and types of performance metrics Subjectivity in the choice of metrics: e.g., selecting metrics that do not translate to real-world performanceMetrics that give over-optimistic estimates of performanceMethods may not be directly comparable according to individual metrics (e.g., if methods are designed for different tasks) 6. Evaluation criteria: secondary measures ++ Number and types of performance metrics Subjectivity of qualitative measures such as user-friendliness, installation procedures, and documentation qualitySubjectivity in relative weighting between multiple metricsMeasures such as runtime and scalability depend on processor speed and memory 7. Interpretation, guidelines, and recommendations ++ Generality versus specificity of recommendations Performance differences between top-ranked methods may be minorDifferent readers may be interested in different aspects of performance 8. Publication and reporting of results + Amount of resources to dedicate to building online resources Online resources may not be accessible (or may no longer run) several years later 9. Enabling future extensions ++ Amount of resources to dedicate to ensuring extensibility Selection of methods or datasets for future extensions may be unrepresentative (e.g., due to requests from method authors) 10. Reproducible research best practices ++ Amount of resources to dedicate to reproducibility Some tools may not be compatible or accessible several years later 相关内容 这篇文章的作者最近才在 NBT 发布一篇单细胞分析方法的「测评」A comparison of single-cell trajectory inference methods。只能说特别优秀。 Moving beyond P values: data analysis with estimation graphics DOI(url): https://doi.org/10.1038/s41592-019-0470-3 杂志：Nature Methods 发表日期：19 June 2019 关键点 除了 P 值还应该做点什么 参考意义 这篇文章介绍了应该如何分析两组数据是否有显著性差异，除了 P 值，我们还应该展示些什么。 如上图所示，用星号标记的条形图仅显示均值和误差，掩盖了具体的观察值，箱形图同样不显示复杂属性（例如，双峰）和单个观察值。另外，条形图和箱形图都是只展示最终的 P 值计算结果但是没有展示 null 分布（H0 时样本的分布）本身。另外，可以使用每个数据具体的点图来展示数据。当然更好的方法就是使用坐着推荐的图 e。也就是采用估算统计的方法对数据进行展示（Estimation statistics），它使用熟悉的统计概念：均值，均值差（两个不同组中的平均值之间的绝对差异）和误差线。侧重于关注实验的效应值 ，而不是由 P 值产生的错误二分法。从图 e 可以看出其首先将所有数据点都以 swarmplot 的形式呈现，并且尽量展示原数据的分布。同时添加一个独立但是和原始坐标轴对应的坐标轴显示均值差和效应值。 相关内容 R 包地址：https://github.com/ACCLAB/dabestr TransLiG: a de novo transcriptome assembler that uses line graph iteration DOI(url): https://doi.org/10.1186/s13059-019-1690-7 杂志：Genome Biology 发表日期：23 April 2019 关键点 比 Trinity 更厉害的转录本组装工具 参考意义 TransLiG 是第一个通过 phasing 和收缩路径将双端测序信息和测序深度信息整合到从头组装的方法。通过评估，TransLiG 比已有的转录本从头组装工具在 accuracy computing resources 都有很大的优势。 使用 6 种比对方法在三种真实数据集中分析灵敏度 sensitivity 使用 6 种比对方法在三种真实数据集中分析精确度 precision 比较 CPU time 比较 RAM 使用情况 作者也分析了 TransLiG 具有优势的几个原因： Firstly, TransLiG constructs more accurate splicing graphs by reconnecting fragmented graphs via iterating different lengths of smaller k-mers. Secondly, TransLiG substantially integrates the sequence depth and paired-end information into the assembling procedure via enforcing each pair-supporting path being included in at least one assembled transcript. Thirdly, TransLiG accurately links the in-coming and out-going edges at each node via iteratively solving a series of quadratic programmings, which are optimizing the utilizations of the paired-end and sequencing depth information. Finally, TransLiG benefits from the iterations of weighted line graphs constructed by repeatedly phasing transcript-segment-representing paths. 相关内容 如果再有转录组拼接的需求，我会用它试一试。文中提到的 bridger 我曾经做过比较详细的测试，这个包目前已经不再维护了，而且安装的时候有一个 bug 需要手动修改源码。SOAPdenovo-trans 我也使用过，确实在速度和内存控制上要比 trinity 好很多，而且结果也没有多差。 https://sourceforge.net/projects/transcriptomeassembly/files/ https://zenodo.org/record/2576226 除了以上内容之外还有一篇 gene set enrichment analysis 分析相关的文章：Towards a gold standard for benchmarking gene set enrichment analysis 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-06-22-weeklypaper/"},{"title":"linux极简统计分析工具datamash教程","content":"引子 之前写 awk 教程的时候，曾经提到过一些对文本中行列进行某些计算统计的需求，例如使用数组分类求和。一些基本需求 awk 都可以实现，但是写起来稍显复杂。在 R 中使用 dplyr 或者基础函数 aggregate() 可以方便的进行分组操作，如果能在 linux 中使用更加简洁的单行命令针对数值和字符进行一些基本运算就省去了在 R 终端操作的时间。这篇文章介绍一个 linux 中能满足这类需求的工具 GNU datamash。 两个使用 awk 的例子如下： cat awk2.txt USSR 8649 275 Asia Canada 3852 25 North_America China 3705 1032 Asia USA 3615 237 North_America Brazil 3286 134 South_America India 1267 746 Asia awk '{ pop[$4] += $3 }END{ for (name in pop) print name,pop[name]}' awk2.txt #North_America 262 #Asia 2053 #South_America 134 例如利用getline通过第一列信息判断，将第一列相同的第二列内容合并。 cat awk3.txt a qw a we a wet b wer b klj b piu c eie c tmp c ike awk 'BEGIN{getline;a=$1;printf (&quot;%s\\t%s&quot;,$1,$2)}{if(a==$1){printf &quot;,&quot;$2}else{printf &quot;\\n%s\\t%s&quot;,$1,$2;a=$1}}END{printf &quot;\\n&quot;}' awk3.txt a qw,we,wet b wer,klj,piu c eie,tmp,ike datamash 是什么 在 gnu 官网 中，用了下面一句话来介绍 datamash。 GNU datamash is a command-line program which performs basic numeric, textual and statistical operations on input textual data files. datamash 作为一个命令行程序可以对文本文件进行数字和文本相关的基本统计操作（虽说基本但是所有的操作都足够常用高频）。 使用前首先进行安装，可以通过sudo apt-get install datamash来进行安装或者通过源码来安装最新版本，这里采用第二种方式。 wget https://ftp.gnu.org/gnu/datamash/datamash-1.4.tar.gz tar -xzf datamash-1.4.tar.gz cd datamash-1.4 ./configure make make check sudo make install 调用格式与参数 datamash 的基本调用格式如下： datamash [option]… op1 column1 [op2 column2 …] 上面的内容转换为描述语言就是：在option的参数下，对column1列进行op1操作，对column2列进行op2操作。如果使用--group 参数，所有的operation都将会分组进行；如果没有使用--group，所有的operation会对所有的值进行。需要说明的是这里的column1 可以是表示第几列的数字，当使用-H或者--header-in时可以是所选字段的名称，可以使用列名，当 operation 要求输入成对数据的时候使用: 连接，比如spearson 5:6。 主要 operation 不同版本支持的参数不同，以下参数适用于 v1.4 版本。在分组统计相关的参数中，p/s 前缀分别代表 population 或者 sample。一般而言，sample 对应的计算等同于 R 中对应函数，例如sstdev 和 sd()是一致的。 Primary operations: primary operations 决定了文件将被如何处理，如果 primary operatino 没有设置，整个文件将会被逐行处理（针对 per-line operation）或者将所有行按照一组进行处理。 groupby：分组等同于 --group或者-g参数。后面指定用于分组的列 crosstab：类似于 excel 中的数据透视表 Pivot Table，可以按照两列来处理矩阵，默认是计算在 a,b 中出现的次数 transpose：交换行列，转置，等价于 R 中的t() reverse：反转字段顺序，交换列 check：验证数据结构，保证每行字段相同 Line-Filtering operations: rmdup：删除有重复键值的行 Per-Line operations: round：四舍五入整数值 floor：不小于输入的最小整数值，向上取 ceil：不大于输入的最大整数值，向下取 trunc：取整数部分 frac：取小数部分 Group-by Numeric operations: sum：求和 min：最小值 max：最大值 absmin：最小绝对值 absmax：最大的绝对值 range：最大值-最小值 Group-by Textual/Numeric operations: count ：分组中元素个数 first：分组中第一个值 last：分组中最后一个值 rand：分组中一个随机值 unique：逗号分割的所有唯一值 collapse：逗号分科的所有值 countunique：唯一值的个数 Group-by Statistical operations: mean：均值 mode：众数 median：中位数 q1：第一四分位数 q3：第三四分位数 iqr：四分位距 perc：百分位值，默认取 95，perc:25 等同于q1 antimode：最少出现的数 pstdev：总体标准差 sstdev：样本标准差 pvar：总体方差 svar ：样本方差 mad：scaled 绝对中位差 madraw：原始绝对中位差 sskew：样本偏度 关于 sskew 值对应区间的说明 pskew：总体偏度 skurt：样本超值峰度 pkurt：总体超值峰度 jarque：Jarque-Beta test for normality P 值 dpo：D'Agostino-Pearson Omnibus test for normality P 值 scov：样本协方差（要求 pair 数据） pcov：总体协方差（要求 pair 数据） spearson：样本 pearson 相关系数（要求 pair 数据） ppearson：总体 pearson 相关系数（要求 pair 数据） 主要参数 -f, --full: 进行计算前打印所有行 -g, --group：按照列分组 --header-in：输入文件第一行为列名，不进行计算 --header-out：输出第一行为列名 -i：对文本操作是忽略大小写 -s：分组前先排序，等同于sort -t：指定输入文件分隔符 --output-delimiter：指定输出文件分隔符 --narm：跳过 NA -R, --round：输出结果保留几位小数 -W, --whitespace: 使用一个或者多个空格或者 tab 作为分隔符 操作示例 使用软件自带的测试数据集 scores_h.txt，有三列，分别是学生姓名科目和成绩。 cat /usr/local/share/datamash/examples/scores_h.txt |head Name Major Score Shawn Arts 65 Marques Arts 58 Fernando Arts 78 Paul Arts 63 Walter Arts 75 Derek Arts 60 Nathaniel Arts 88 Tyreque Arts 74 Trevon Arts 74 文本基本操作 #检查行列完整性 $ cat scores_h.txt |datamash check 84 lines, 3 fields # 交换列顺序 $ cat scores_h.txt |datamash reverse |head -n5 Score Major Name 65 Arts Shawn 58 Arts Marques 78 Arts Fernando 63 Arts Paul # 根据前两列构建透视表，且显示分数 $ cat scores_h.txt |datamash --header-in crosstab 1,2 unique 3 |head # 因为这个文件有 header 所以需要使用 --header-in 参数 Arts Business Engineering Health-Medicine Life-Sciences Social-Sciences Aaron N/A 83 N/A N/A 58 N/A Allen N/A N/A N/A N/A 50 N/A Andre N/A N/A N/A 72 N/A N/A Angel N/A N/A N/A 100 N/A N/A Anthony N/A N/A N/A N/A 32 N/A Antonio N/A N/A 88 N/A N/A N/A Austin N/A N/A N/A N/A 91 N/A Avery N/A N/A 51 N/A N/A N/A Brandon N/A N/A N/A N/A 72 N/A 分组统计操作 统计每门课的选课人数 $ datamash --header-in --sort groupby 2 count 2 &lt; scores_h.txt Arts 19 Business 11 Engineering 13 Health-Medicine 13 Life-Sciences 12 Social-Sciences 15 查看每门课程的最高分和最低分，在这里使用--header-out 输出时会自动添加列名 $ datamash --header-in --header-out --sort groupby 2 min 3 max 3 &lt; scores_h.txt GroupBy(Major) min(Score) max(Score) Arts 46 88 Business 79 94 Engineering 39 99 Health-Medicine 72 100 Life-Sciences 14 91 Social-Sciences 27 90 因为这是有列名的输入文件，使用--header-in参数后可以使用列名来进行计算。统计每门课程的平局分和标准差，在显示的结果中要求只保留两位小数即可。 $ datamash --header-in --header-out --sort -R 2 \\ groupby 2 mean Score pstdev Score &lt; scores_h.txt GroupBy(Major) mean(Score) pstdev(Score) Arts 68.95 10.14 Business 87.36 4.94 Engineering 66.54 19.10 Health-Medicine 90.62 8.86 Life-Sciences 55.33 19.73 Social-Sciences 60.27 16.64 如果想要对文本中的数字进行简化，可以使用如下几个命令： $ (echo num; seq -1.25 0.25 1.25) \\ |datamash --full -H round 1 ceil 1 floor 1 trunc 1 frac 1 num round(num) ceil(num) floor(num) trunc(num) frac(num) -1.25 -1 -1 -2 -1 -0.25 -1.00 -1 -1 -1 -1 0 -0.75 -1 0 -1 0 -0.75 -0.50 -1 0 -1 0 -0.5 -0.25 0 0 -1 0 -0.25 0.00 0 0 0 0 0 0.25 0 1 0 0 0.25 0.50 1 1 0 0 0.5 0.75 1 1 0 0 0.75 1.00 1 1 1 1 0 1.25 1 2 1 1 0.25 在实际的服务器管理中，可能需要统计一些系统用户信息。这些信息存放在/etc/passwd中，:分割。这里使用login shells 进行分组，然后统计用户数。 $ cat /etc/passwd | datamash -t : --output-delimiter $'\\t' --sort groupby 7 count 7 /bin/bash 10 /bin/false 22 /bin/sh 3 /bin/sync 1 /usr/sbin/nologin 17 生信相关文本 基因表达矩阵 假设有一个行为基因列为组织的表达矩阵如下所示 $ cut -f1-5 input.matrix |head geneid Flag Leaf Node Sheath G1011 0 0.11069839039242035 4.578044680376127 2.202828823551847 G1031 0.09338340723174347 0.11069839039242035 0.46883590100237443 0 G5133 0 0 0.05515716482380876 0 G3987 2.5213519952570738 3.09955493098777 583.17670368213 16.598059042576708 G5604 0.09338340723174347 0 2.923329735661864 0.051228577291903415 G5664 0 0.11069839039242035 0.6067288130618963 0 G4107 0 0.11069839039242035 4.21952310902137 0.15368573187571025 G4147 0.09338340723174347 0 0.19305007688333065 0.051228577291903415 G5786 0 0.33209517117726106 5.1296163286142145 0.9221143912542615 我想要计算每个基因在所有组织中的表达情况（均值标准差），可以进行如下操作 $ cat input.matrix |datamash transpose \\ |datamash --header-in --header-out mean 2-10 sstdev 2-10 |datamash transpose mean(G1011) 3.4218560658562 mean(G1031) 0.13477809345566 mean(G5133) 0.026272278033758 mean(G3987) 237.63686611126 mean(G5604) 1.6544141646051 mean(G5664) 0.25398335468086 mean(G4107) 0.92018619120978 mean(G4147) 0.074272982619755 mean(G5786) 1.8763718749021 sstdev(G1011) 3.6565336756012 sstdev(G1031) 0.15591791251859 sstdev(G5133) 0.025561380705389 sstdev(G3987) 276.34845044642 sstdev(G5604) 1.9673226520581 sstdev(G5664) 0.23076182316703 sstdev(G4107) 1.5120321659008 sstdev(G4147) 0.063632028432619 sstdev(G5786) 2.1600115292083 但是上面的格式看起来不是很美观，可以利用 datamash 自身的命令稍加调整 $ cat input.matrix |datamash transpose \\ |datamash --header-in --header-out sstdev 2-10 mean 2-10 \\ |datamash transpose |sed 's/(/\\t/;s/)//' \\ |datamash crosstab 1,2 unique 3 |datamash transpose mean sstdev G1011 3.4218560658562 3.6565336756012 G1031 0.13477809345566 0.15591791251859 G3987 237.63686611126 276.34845044642 G4107 0.92018619120978 1.5120321659008 G4147 0.074272982619755 0.063632028432619 G5133 0.026272278033758 0.025561380705389 G5604 1.6544141646051 1.9673226520581 G5664 0.25398335468086 0.23076182316703 G5786 1.8763718749021 2.1600115292083 GenePred 文件操作 genepred 和 gff3 文件格式信息一致，但是更加便于我们进行操作。genepred 文件有两种格式，其中一种是标准格式，一种是 extended 格式，具体解释如下。 table genePred &quot;A gene prediction.&quot; ( string name; &quot;Name of gene&quot; string chrom; &quot;Chromosome name&quot; char[1] strand; &quot;+ or - for strand&quot; uint txStart; &quot;Transcription start position&quot; uint txEnd; &quot;Transcription end position&quot; uint cdsStart; &quot;Coding region start&quot; uint cdsEnd; &quot;Coding region end&quot; uint exonCount; &quot;Number of exons&quot; uint[exonCount] exonStarts; &quot;Exon start positions&quot; uint[exonCount] exonEnds; &quot;Exon end positions&quot; ) table genePredExt &quot;A gene prediction with some additional info.&quot; ( string name; &quot;Name of gene (usually transcript_id from GTF)&quot; string chrom; &quot;Chromosome name&quot; char[1] strand; &quot;+ or - for strand&quot; uint txStart; &quot;Transcription start position&quot; uint txEnd; &quot;Transcription end position&quot; uint cdsStart; &quot;Coding region start&quot; uint cdsEnd; &quot;Coding region end&quot; uint exonCount; &quot;Number of exons&quot; uint[exonCount] exonStarts; &quot;Exon start positions&quot; uint[exonCount] exonEnds; &quot;Exon end positions&quot; int score; &quot;Score&quot; string name2; &quot;Alternate name (e.g. gene_id from GTF)&quot; string cdsStartStat; &quot;Status of CDS start annotation (none, unknown, incomplete, or complete)&quot; string cdsEndStat; &quot;Status of CDS end annotation (none, unknown, incomplete, or complete)&quot; lstring exonFrames; &quot;Exon frame offsets {0,1,2}&quot; ) 首先检查一下我们的数据情况，可以看出是 extended 格式 $ datamash check &lt; test.genepred 133744 lines, 15 fields 统计每个基因的转录本个数，同时输出这些转录本的 id cat test.genepred|datamash -s -g 12 count 1 collapse 1 看看每个染色体有多少基因 $ cat test.genepred|datamash -s -g 2 countunique 12 |head chr1A_part1 2694 chr1A_part2 1650 chr1B_part1 2428 chr1B_part2 2286 chr1D_part1 3698 chr1D_part2 786 chr2A_part1 2712 chr2A_part2 3085 chr2B_part1 3076 chr2B_part2 3033 如果结合awk还可以进行很多筛选。例如统计每个基因转录本的个数，这些转录本中外显子的最大值最小值，然后挑选出多余 3 个转录本的基因。 $ cat test.genepred|datamash -s -g 12 count 8 min 8 max 8 |awk '$2&gt;2' |head test1A02G001900 10 9 10 test1A02G005600 6 12 13 test1A02G009000 3 11 13 test1A02G012500 4 13 14 test1A02G013800 4 12 13 test1A02G016900 3 8 12 test1A02G030900 3 6 8 test1A02G035500 4 3 5 test1A02G039100 5 5 9 test1A02G047200 3 10 12 除此以外，针对 bed 文件也有非常高频的使用场景这里就不再展示了。 其它 one-liner 说到使用单行命令解决问题，通常都是 perl 的骄傲，当然 awk 也绝对是一把好手。如果特别喜欢用 R，其实命令行里也可以通过Rscript -e来强行单行。以下简单举一些例子进行比较。 awk 和 datamash awk 计算 mean min 和 max 都没有压力，使用 END 可以解决问题。 $ seq 10 | datamash sum 1 55 $ seq 10 | awk '{sum+=$1} END {print sum}' 55 $ seq -5 1 7 | datamash min 1 -5 $ seq -5 1 7 | awk 'NR==1 {min=$1} NR&gt;1 &amp;&amp; $1&lt;min { min=$1 } END {print min}' -5 $ seq 10 | datamash mean 1 5.5 $ seq 10 | awk '{sum+=$1} END {print sum/NR}' 5.5 如果要进行分组操作，awk 就需要数组和 getline 来搞定。有时候需要写很长一行命令，并不是很划算。 首先构造一个两个的矩阵： printf &quot;%s\\t%d\\n&quot; a 1 b 2 a 3 b 4 a 3 a 6 &gt; test.txt awk 根据第一列的 key 进行分组统计个数以及求和，可以看出 awk 需要写的各种括号实在是不少。 # 统计个数 $ cat test.txt |datamash -s -g 1 count 2 a 6 b 4 $ cat test.txt |awk '{a[$1]++} END {for(i in a) { print i, a[i] }}' a 6 b 4 #求和 $ cat test.txt| datamash -s -g 1 sum 2 a 13 b 6 $ cat test.txt |awk '{a[$1]+=$2} END {for(i in a) { print i, a[i] }}' a 13 b 6 R 和 datamash 尽管可能 90% 以上的人说到单行命令都不会想到 R，但 R 确实可以强行单行。不过要单行操作用到的更多是 R 基础函数，很多喜闻乐见的包用起来就不方便了。 当统计基本的描述统计量时，以下为两者的对比，此时感觉 R 的 summary() 更方便。 $ cat test.txt| datamash --header-out min 2 q1 2 median 2 mean 2 q3 2 max 2 min(field-2) q1(field-2) median(field-2) mean(field-2) q3(field-2) max(field-2) 1 2.25 3 3.1666666666667 3.75 6 $ cat test.txt| Rscript -e 'summary(read.table(&quot;stdin&quot;))' V1 V2 a:4 Min. :1.000 b:2 1st Qu.:2.250 Median :3.000 Mean :3.167 3rd Qu.:3.750 Max. :6.000 如果要分组计算，R 可以使用aggregate。 $ cat test.txt|datamash -s --header-out -g 1 min 2 q1 2 median 2 mean 2 q3 2 max 2 GroupBy(field-1) min(field-2) q1(field-2) median(field-2) mean(field-2) q3(field-2) max(field-2) a 1 2.5 3 3.25 3.75 6 b 2 2.5 3 3 3.5 4 $ cat test.txt|Rscript -e 'a=read.table(&quot;stdin&quot;)' -e 'aggregate(a$V2,by=list(a$V1),summary)' Group.1 x.Min. x.1st Qu. x.Median x.Mean x.3rd Qu. x.Max. 1 a 1.00 2.50 3.00 3.25 3.75 6.00 2 b 2.00 2.50 3.00 3.00 3.50 4.00 总之，在 Linux 下有这么好用的一个工具，命令简单且可以轻松通过管道符和 awk 以及 sed 等连用，完成平时分析数据时的很多基本需求。推荐学习和使用。 参考网站： main page datamash manual 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-06-19-datamashmanual/"},{"title":"极速安装软件的升级版 conda","content":" 喜欢科比的球迷应该熟悉这个词，mamba（曼巴）是科比的绰号，同时曼巴也是眼镜蛇的一种，黑曼巴是世界上移动速度最快的蛇。不过这篇文章里的 mamba 和科比没关系和蛇也没啥关系，说的是一个极速版 conda 。 什么是 mamba conda 国内的各种镜像源最近因为授权的原因纷纷不能用了。当大家都在担忧下载问题的时候，意外发现官方源似乎也没那么糟糕。当然，如果你是一个特别在意速度的人，就会像我的朋友那样把所有 conda 包都下载到本地，然后做一个本地镜像自己用。 其实国外的社交平台一直以来也在吐槽 conda 慢，但这个慢不是下载速度，而是指在下载之前解决软件依赖那几步。conda 在安装许多包或者同时安装多个包的时候速度经常会非常慢。曾经看过一个国外老师发的段子：当我在下课 10 分钟前向学生介绍 conda 优势的时候，我做了一个安装包的演示，现在 20 分钟过去了屏幕上依旧显示 solving environment。 什么事情一旦速度上不去，就总有人受不了。于是，mamba 诞生了，在这个工具的主页上写着这么一句话： Mamba is a fast cross platform package manager, based on and compatible with conda. 翻译一下，mamba 是一个快速的跨平台包管理工具，基于 conda 且与 conda 完全兼容。所谓基于 conda 就是 conda 能干啥它就干啥，所谓兼容就是 conda 怎么用它就怎么用，而优点就是贼快。 mamba 使用测试 话不多说，先测试起来。 我在 win10 的 Ubuntu 里装了 mamba 进行测试。安装方法有两种，如果你之前没有用过 conda, 和 conda 一样可以通过主页下载一个 shell 脚本进行安装；如果你本身已经安装了 conda，可以直接用 conda-forge 的 channel 进行安装 conda install mamba -c conda-forge 。我使用的是第二种方式。 为了测试速度，在一个新的环境里「假装」安装 snakemake, 使用time命令检测时间。出现 proceed([y]/n)? 的一瞬间就ctrl+c结束程序查看运行时间。之所以选择安装 snakemake 是因为我曾经在一台服务器上真实发生过十多分钟都没有解决环境依赖的惨案。 首先用 mamba: time mamba install snakemake # 注意，没有迁移难度，conda 怎么用，mamba 就怎么用。 real 0m9.442s user 0m3.906s sys 0m2.219s 再来看看使用 conda: time conda install snakemake real 1m49.750s user 1m19.188s sys 0m2.406s mamba 用时 10s，conda 用时接近 2 分钟。 速度测试之后再看看兼容性，根据日常使用频率，我分别测试了 install, update, remove, create 都可以正常使用，而且也支持从yml文件安装。但是有两个常用命令是不支持的 activate, deactivate，不过提示信息中会告知直接使用 conda 即可 为什么速度变快了 如果你由留意过 conda 安装软件的过程，在开始下载所需要程序之前，会有如下两步： collecting package metadata solving environment 其实 install 的整体步骤如下图所示，先从你的 channel repodata 中找到你想要的 package，然后再看你要的 package 是否有什么 dependencies。 如下图所示，conda 的牛叉之处在于会根据你系统里已有软件的依赖和要装软件的依赖进行比较，从而选择大家都可以兼容的版本。这也是为什么在安装不同的软件时经常会看到各种包升级降级的问题。 假设你的 foo-lib 有很多版本都符合你的 python 版本，首先 conda 会尝试给你装一个最新版的 foo-lib 3.1 ，但是不巧的是，foo-lib 依赖 bar-lib，这个 bar-lib 又有 20 个版本，foo-lib 3.1 依赖的 bar-lib 可以是 17 以上的版本 。然而你已经装过的 blob-lib 包依赖的 bar-lib 版本最高只能到 16 ，这时 conda 就会给你的 foo-lib 降级，去找一个支持 bar-lib 16 的版本，最后决定给你装一个 foo-lib 3.0。 这个过程我们描述起来比较累，同样 conda 处理起来也没有那么轻松，尤其是当系统里有几百个各种各样软件的时候。 mamba 继承了 conda 的几乎所有内容，除了上面提到的依赖解析这部分。开发者把依赖解析器改成了一个叫做libsolv的 C 库，来实现之前 conda 对应的功能。这个库已经在很多个 linux 发行版中为系统的包管理器提供了支持。 说道这里可能你也想去试试了。 mamba 主页：https://quantstack.net/mamba.html mamba github 地址：https://github.com/QuantStack/mamba 最后提醒一下，暂时先不要在任何重要的生产环境中使用 mamba。至于原因，别问，问就是还只是 beta 版。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-06-12-mambabeta/"},{"title":"每周文献-190606-多篇结构变异和转录组分析方法文章","content":"Alignment and mapping methodology influence transcript abundance estimation DOI(url): https://doi.org/10.1101/657874 发表日期：June 03, 2019 关键点 不对比对方法对转录本定量的影响有哪些（读完感觉是给 Salmon 最近一次升级写的软文） 参考意义 使用 RNA-seq 数据进行转录本定量的准确性取决于许多因素，比如比对的方法和所采用的定量模型。虽然有不少文章已经讲过定量模型的重要性，但比较各种比对方法对定量准确度的影响并没有那么受关注。作者在这篇文章中研究了比对方法对定量准确性以及对差异基因表达分析的影响。 即使定量模型本身不变，选择不同的比对方法，或使用不同的参数对定量的影响有时可能很大并影响下游分析。作者也强调当评估过于注重模拟数据时，这些影响可能会被我们忽视，因为在模拟数据中，比对这一步往往比实验获得的样本更简单。文章讨论了用于定量目的的最佳比对方法，同时也引入了一种新的混合比对方法，称为 selective alignment(SA)。 文章中，作者选择了三种比对策略： unspliced alignment of RNA-seq reads directly to the transcriptome spliced alignment of RNA-seq reads to the annotated genome (with subsequent projection to the transcriptome) (unspliced) lightweight mapping (quasi-mapping) of the RNA-seq reads directly to the transcriptome 具体的比对方法： Bowtie2 – Alignment with Bowtie2 to the target transcriptome and allowing alignments with indels, followed by quantification using Salmon in alignment mode. Bowtie2 strict – Alignment with Bowtie2 to the target transcriptome and disallowing alignments with indels (i.e. using the same parameters as those used by RSEM), followed by quantification using Salmon in alignment mode. Bowtie2 RSEM – Alignment with Bowtie2 to the target transcriptome and disallowing alignments with indels, followed by quantification using RSEM. STAR – Alignment with STAR to the target genome (aided with the GTF annotation of the transcriptome) and projected to the transcriptome allowing alignments with indels and soft clipping, followed by quantification using Salmon in alignment mode. STAR strict – Alignment with STAR to the target genome (aided with the GTF annotation of the transcriptome) and projected to the transcriptome and disallowing alignments with indels or soft clipping, followed by quantification using Salmon in alignment mode. STAR RSEM – Alignment with STAR to the target genome (aided with the GTF annotation of the transcriptome) and projected to the transcriptome and disallowing alignments with indels or soft clipping, followed by quantification using RSEM. quasi – Quasi-mapping directly to the target transcriptome, coupled with quantification using Salmon in non-alignment mode. SA– Selective alignment directly to the target transcriptome and a set of decoy sequences, coupled with quantification using Salmon in non-alignment mode. 相关内容 # For indexing, we use the following extra command line arguments, along with the regular indexing and threads parameters: STAR --genomeFastaFiles &lt;fasta file&gt; --sjdbGTFfile &lt;gtf file&gt; --sjdbOverhang 100 Bowtie2 default salmon -k 23 --keepDuplicates kallisto -k 23 # For quantification, we use the following extra command line, \\ # along with regular index and threads, with each tools we compare against: SA --mimicBT2 --useEM quasi --rangeFactorization 4 --discardOrphansQuasi --useEM Bowtie2 --sensitive -k 200 -X 1000 --no-discordant --no-mixed Bowtie2 strict --sensitive --dpad 0 --gbar 99999999 --mp 1,1 \\ --np 1 --score-min L,0,-0.1 --no-mixed --no-discordant -k 200 -I 1 -X 1000 Bowtie2 RSEM --sensitive --dpad 0 --gbar 99999999 --mp 1,1 \\ --np 1 --score-min L,0,-0.1 --no-mixed --no-discordant -k 200 -I 1 -X 1000 STAR --outFilterType BySJout --alignSJoverhangMin 8 --outFilterMultimapNmax 20 \\ --alignSJDBoverhangMin 1 --outFilterMismatchNmax 999 \\ --outFilterMismatchNoverReadLmax 0.04 --alignIntronMin 20 --alignIntronMax 1000000 \\ --alignMatesGapMax 1000000 --readFilesCommand zcat --outSAMtype BAM Unsorted \\ --quantMode TranscriptomeSAM --outSAMattributes NH HI AS NM MD \\ --quantTranscriptomeBan Singleend STAR strict --outFilterType BySJout --alignSJoverhangMin 8 --outFilterMultimapNmax \\ 20 --alignSJDBoverhangMin 1 --outFilterMismatchNmax 999 \\ --outFilterMismatchNoverReadLmax 0.04 --alignIntronMin 20 --alignIntronMax 1000000 \\ --alignMatesGapMax 1000000 --readFilesCommand zcat --outSAMtype BAM Unsorted \\ --quantMode TranscriptomeSAM --outSAMattributes NH HI AS NM MD \\ --quantTranscriptomeBan IndelSoftclipSingleend STAR RSEM --outFilterType BySJout --alignSJoverhangMin 8 --outFilterMultimapNmax \\ 20 --alignSJDBoverhangMin 1 --outFilterMismatchNmax 999 \\ --outFilterMismatchNoverReadLmax 0.04 --alignIntronMin 20 --alignIntronMax 1000000 \\ --alignMatesGapMax 1000000 --readFilesCommand zcat --outSAMtype BAM Unsorted \\ --quantMode TranscriptomeSAM --outSAMattributes NH HI AS NM MD \\ --quantTranscriptomeBan IndelSoftclipSingleend \\ RSEM default kallisto default or --rf-stranded as appropriate 这里所谓的 SA 模式其实就是在 salmon 最近升级中加入的一个参数，具体可以了解 官方说明 A practical guide to methods controlling false discoveries in computational biology DOI(url): https://doi.org/10.1186/s13059-019-1716-1 发表日期：4 June 2019 关键点 在数据分析的过程中如何更好的控制 false discoveries 参考意义 以下是 8 中可用的 FDR-controlling methods ，其中 IHW 和 BL 是考虑了协变量的现代方法。 不同方法的适用性评价，从结果来看更加推荐使用 IHW 和 BL 这两种方法。 相关内容 Independent and informative covariates used in case studies Case study Covariates found to be independent and informative Microbiome Ubiquity: the proportion of samples in which the feature is present. In microbiome data, it is common for many features to go undetected in many samples. Mean nonzero abundance: the average abundance of a feature among those samples in which it was detected. We note that this did not seem as informative as ubiquity in our case studies. GWAS Minor allele frequency: the proportion of the population which exhibits the less common allele (ranges from 0 to 0.5) represents the rarity of a particular variant. Sample size (for meta-analyses): the number of samples for which the particular variant was measured. Gene set analyses Gene set size: the number of genes included in the particular set. Note that this is not independent under the null for over-representation tests, however (see Additional file 1: Supplementary Results). Bulk RNA-seq Mean gene expression: the average expression level (calculated from normalized read counts) for a particular gene. Single-Cell RNA-seq Mean nonzero gene expression: the average expression level (calculated from normalized read counts) for a particular gene, excluding zero counts. Detection rate: the proportion of samples in which the gene is detected. In single-cell RNA-seq it is common for many genes to go undetected in many samples. ChIP-seq Mean read depth: the average coverage (calculated from normalized read counts) for the region Window Size: the length of the region Science-wise false discovery rate and proportion of true null hypotheses estimation Independent Hypothesis Weighting A Simple Deep Learning Approach for Detecting Duplications and Deletions in Next-Generation Sequencing Data DOI(url): https://doi.org/10.1101/657361 发表日期：June 03, 2019 关键点 使用机器学习方法在低丰度数据中鉴定 CNV 参考意义 拷贝数变异 (CNV) 的检测仍然是一个难题，特别是在质量比较查或覆盖率较低的二代测序数据中。这篇文章介绍了一种在二代测序数据中检测 CNV 的方法。在低覆盖读数据中，机器学习在检测 CNV 方面似乎比之前的 gold-standard 更加准确，在高覆盖率数据中两者效果相当。甚至可以在以前使用长读数的数据中鉴定到新的 CNV。 相关内容 更多信息可以查看工具 GitHub 地址，不过如果使用机器学习的方法应该最起码有已知的 CNV 信息才可以，这个东西从哪里来呢。还是使用其他工具据预测？ Comprehensive evaluation of structural variation detection algorithms for whole genome sequencing DOI(url): https://doi.org/10.1186/s13059-019-1720-5 发表日期：3 June 2019 关键点 综合评估全基因组测序的结构变异检测算法 参考意义 结构变异（SV）或拷贝数变异（CNV）极大地影响基因组中编码基因的功能并且和多种疾病有关。尽管许多现有的 SV 检测算法可以使用全基因组测序（WGS）数据检测多种类型的 SV，但是没有一种算法能够以高的 precision 和 recall 鉴定每种类型的 SV。 本文作者使用多个模拟和真实的 WGS 数据集评估了 69 个现有 SV 检测算法的表现。分析结果显示有一组算法根据 SV 的特定类型和大小范围准确鉴别 SV，并可以准确地确定 SV 的断点，大小和基因型。文中列举了针对每类 SV 优秀算法，其中 GRIDSS，Lumpy，SVseq2，SoftSV，Manta 和 Wham 是 deletion 或 duplication 这类 SV 更好的算法。 下图 A 是模拟数据，B 是真是数据，不同颜色代表不同的突变类型，包括插入、重复、到位和易位。检测 SV 的算法被分为以下几类：RP, read pairs; SR, split reads; RD, read depth; AS, assembly; LR, long reads 。以及他们的不同组合方法 RP-SR, RP-RD, RP-AS, RP-SR-AS 和 RP-SR-RD。 针对不同长度不同工具的表现如下： SV 检测算法的运行时间和内存消耗如下图： 相关内容 文章中使用到的软件信息： 所用软件的用法参数：附件下载 Using multiple reference genomes to identify and resolve annotation inconsistencies DOI(url): https://doi.org/10.1101/651984 发表日期：May 30, 2019. 关键点 近似基因组间基因错误注释情况分析 参考意义 大家越来越有钱，各种基因组测序结果越来越多。例如在植物中，往往一个物种就会存在很多个不同品种的基因组序列。虽然这些新基因组每一个都在彼此之间有很多共线性部分，但这些区域内的基因的注释结构却通常存在各种不同。有一种情况是 split-gene 的错误注释，也就是一个基因被错误地注释为两个不同的基因或两个基因被错误地注释为一个基因。这些错误注释可能对功能预测、定量分析以及许多下游分析产生重大影响。 本文作者开发了一种基于两两比较注释的高通量分析方法，可以检测潜在的分裂基因情况并评估不同基因是否应该合并为单个基因。文章使用来自玉米（B73，PH207 和 W22）的三个参考基因组的基因注释证明了方法的实用性。在每个两两比较中发现数百个潜在的分裂基因错误注释情况，对应于 3-5％的注释基因。同时还利用来自 10 种组织的 RNAseq 数据确定生物学上支持哪种状态。 相关内容 Split-gene misannotation pipeline The script that generated the tables, figures, and numbers NGSEP3: accurate variant calling across species and sequencing protocols DOI(url): https://doi.org/10.1093/bioinformatics/btz275 发表日期：25 April 2019 关键点 一个可以检测基因组各种变异的集成分析流程 参考意义 从软件名字可以看出，这个工具目前已经迭代到第三个版本，最早是 2013 年发表在 NAR 。下图为整体的分析流程，其中 STR 代表 short tandem repeats 整个 pipeline 支持的分析如下： Alignment of reads to a reference genome with bowtie2 Alignments sorting by reference coordinates Integrated analysis of multiple samples for efficient discovery and genotyping of SNVs, indels and STRs. This is now the recommended option for GBS, RAD-sequencingExome sequencing, RNA-seq and low coverage WGS data. Complete individual sample analysis for discovery and genotyping of SNVs, indels, STRs, and CNVs from WGS data. Merging of genotype calls from different samples into a single VCF file Functional annotation of genomic variants Filtering of VCF files using quality, coverage, and functional criteria Conversion of VCF files to input formats for several downstream analysis tools such as Mega, Splitstree, Structure, PowerMarker, Flapjack or HapMap Quality and coverage statistics Comparison of genotype calls between VCF files Genome-wide comparison of read depth patterns between two samples Deconvolution for single read experiments Genotype imputation Allele sharing statistics for inbred populations A window-based analysis to discover haplotype introgressions from population VCF files Distribution of k-mer abundances from fastq or fasta files Distribution of relative allele counts from BAM files Calculation of IBS distance matrices from VCF files Construction of neighbor joining dendograms from distance matrices Simulation of single individuals from a reference genome Large scale alignment of two assembled and annotated genomes Construction of a haploid genome for a sequenced individual from homozygous alternative variants Benchmark statistics comparing test and gold standard VCF files Calculation of variant density across the genome 相关内容 软件下载地址 https://sourceforge.net/p/ngsep/wiki/Home/ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-06-06-weeklypaper/"},{"title":"随时随地跟踪最新热点文献","content":" 本文的图表及主要内容均来自 Meta-Research: Tracking the popularity and outcomes of all bioRxiv preprints 和 Rxivist.org: Sorting biology preprints using social media and readership metrics 两篇文献，一篇发表在 elife 一篇发表在 plos biology，如果有兴趣不妨直接阅读原文。 另外，说一句题外话，关于「bioRxiv」如何发音这个事可能每个人都有不一样的读法，在上面的文献中给出了正确的发音方式，「bioRxiv」的发音等同于「Bio Archive」。 一句话读完全文版 只要有网络随时随地用电脑或者手机打开 Rxivist 这个网站就都给你安排明白了。 bioRxiv 发展情况分析 如下图所示，截至 2018 年 11 月底，bioRxiv 上已经发表了 37,648 份预印本。值得一提的是，2018 年前 11 个月（18,825 份）的预印本比前四年的总预算数量还要多。其中，神经科学、生物信息学和进化生物学是排名前三的系列。 如果使用预印下载次数作为读者数量的指标，bioRxiv 在读者中也在迅速的流行起来就。如下图所示，2018 年 10 月的总下载量（1,140,​​296）比 2017 年同期增加了 82％，与 2016 年同期相比则增长了 115％。BioRxiv 预印本文章在 2018 年前 11 个月一共被下载了近 930 万次，仅仅在 2018 年 10 月和 11 月，bioRxiv 的下载量（2,248,652）比网站前两年半还要多。每篇论文的下载量中位数为 279，其中基因组学类别每篇文献的下载中位数最高达到了 496。 除了统计下载数据外，bioRxiv 还会记录预印本在其它期刊中的发表情况。根据 bioRxiv 预印本与其它出版物的关联记录来看，总共发布了 42.0％（15,797 篇）bioRxiv 预印本。按比例统计，进化生物学预印本具有最高的出版率。 总体而言，15,797 篇 bioRxiv 预印本已出现在了 1,531 种不同的期刊中。Scientific Reports 发表最多其次是 eLife 和 PLOS ONE。不过可能还需要考虑到每个期刊上发表的论文总数的不同。例如，Scientific Reports 在 2018 年发布了 398 份 bioRxiv 预印本，仅占其当年发表的 16,899 篇文章的 2.36％。相比之下，eLife 2018 年的 1,172 篇文章中有三分之一以上首次出现在 bioRxiv 上，而 GigaScience 在 2018 年发表的文章中预印本比例最高（49.4％），其次是 Genome Biology（ 39.9％）和 Genome Research （36.7％）。 另外，每篇论文的下载数量与发表期刊影响因子之间存在显着的正相关：一般，影响因子较高的期刊会发布具有更多下载量的预印本。例如，Nature Methods（2017 IF 26.919）发表的 119 份 bioRxiv 预印本下载中位数为 2,266。相比之下，PLOS ONE（2017 IF 2.766）已发表的 719 个预印本下载中位数为 279。 通过检索所有已发表预印本的发表日期可以全面了解预印本首次发表在 bioRxiv 的日期与其他期刊发布日期的间隔。统计显示，其间隔中位数为 166 天（5.5 个月）。75％ 的预印本是在 bioRxiv 发布的 247 天内发表的，90％ 在 346 天内发表。 跟踪最新热点文献 在这些数据的基础上，开发者们又开发了一个 配套的网站 供大家使用，可以根据下载数量和在社交平台的热度随时掌握最新的热门预印本文献。 这个网站每天 6 次从 bioRxiv 中提取新的预印本信息并从推特上检索其热度，反映当前人们正在讨论哪些文献，这意味着在这里你每天总能找到新的内容。在默认索引视图中，当天包含超过 110 条推文的预印本标有「红红火候」的图标，提醒你需要重点关注。因为下载数量是按月统计的，所以这个指标一般是两周更新一次。同时，也可以按照具体的类别来进行筛选过滤。 另外，网站还有其它几个界面用不同的方式对数据进行分析，比如有一个页面列出了 2018 年最受欢迎的预印本论文，而在摘要页面中可以通过可视化的形式看到 bioRxiv 的各种整体指标。如果你点开某一篇具体的文献，还可以看到详细的统计信息，会显示该文献每个月的下载数量。 更贴心的是，每个预印本还提供了详细的作者信息列表，可以连接到每个作者的个人资料页，而且还会通过一些 ID 来合并作者的所有预印本数据。在作者索引页面，你还可以筛选某个类别中哪些作者的文献被下载的次数更多。 顺便多说一句，如果你是一个比较硬核的用户网站还提供了比较详细的 API 供使用，如果你习惯邮件订阅，网站还提供了每周热点邮件推送服务。 Rxivist https://rxivist.org Web 爬虫程序和 API 的源码 https://github.com/blekhmanlab/rxivist Rxivist 网站 https://github.com/blekhmanlab/rxivist_web Meta-Research: Tracking the popularity and outcomes of all bioRxiv preprints Rxivist.org: Sorting biology preprints using social media and readership metrics 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-06-05-usebiorxiv/"},{"title":"大文本另类去重多种解法","content":"今天分析数据的时候刚好碰到一个小问题，因为本身文件较大一开始想不出比较好的解决方法，睡个午觉醒来突然有了灵感，自认为目前解决的还算巧妙。 问题 一个 3 列 3,741,430 行的文本（行数比较多），第一列是字符，第二列是字符，第三列是数值，tab 分割。数据格式如下： A23 B66 1234 C56 D34 2334 B66 A23 1234 D34 C56 2334 E78 F88 1234 这个文本虽然是 3,741,430 行，但是其有效信息只有一半。因为A23 B66 1234 和 B66 A23 1234 只是第二列和第一列互换了下位置。 需求 如何尽可能快的处理这个 3 列 3,741,430 行的文本，当某一行的第一列和另一行的第二列相同同时它的第二列又和那一行的第一列相同时，就只保留这两行中的一行即可（具体留哪行没有要求）。简单说就是如下的 4 行只保留 2 行： A23 B66 1234 C56 D34 2334 B66 A23 1234 # 同第一行 D34 C56 2334 # 同第二行 要修改为 A23 B66 1234 D34 C56 2334 讨论 不知道各位读到文章朋友有什么妙招，可以快准狠的解决这个大文本的另类去重问题。不限制使用语言可以是 shell，可以是 R，python ，也可以是 C 甚至是 PHP，不限制代码行数，可以多 CPU。 如果做不到云测试写代码，可以下载这个好多好多行的文件进行测试，文件有 170MB，云盘下载链接 https://share.weiyun.com/5iFEju3 对了，我目前的运行时间是：real 0m29.131s；user 0m30.316s；sys 0m0.824s 文章发出后收到了不少回复，以下摘录一些不同的解法。 先说下我当时的解决思路，因为我自己用的最熟的是 awk（写代码的弱鸡），所以我当时的想法是如何用 awk 和 uniq 来解决这个问题，既然只有第一列和第二列被互换位置且第三列一样，那我只要把其中一半数据的第一列和第二列给它颠倒过来就可以用 uniq 去重了。 位置颠倒这个事情说起来容易，上篇文章的评论区也有很多小伙伴提到了，但是难点在于怎么只颠倒一半的数据。在 awk 里其实用一下字符串比较比较就可以解决这个问题，因为字符串本身也是可以比较大小的，所以在测试数据中，有一半的数据$1&gt;$2，另一半的数据$2&gt;$1，那么只要我用这个判断条件把一半的数据挑出来就可以进行排序了。因此写出了如下一行命令： awk 'BEGIN{OFS=&quot;\\t&quot;}{if($1&gt;$2){print $2,$1,$3} else {print $0} }' howtouniq.txt \\ |sort -k1,1 -k2,2 |uniq 这行代码在我的机器上跑了接近 30s，在另一个人的机器上跑了 20s，大概就是这么一个水平。这次讨论的高票答案，其实也是用了 awk，但是他的一行代码只有 2s 不到，为什么呢？因为我上面的分析思路还是被 sort 和 uniq 限制住了，忘了自己当初的需求到底是什么。我的需求其实只是筛除我要的那一半数据就好了，既然利用字符串比较就已经可以区分出来，为什么还要在 uniq 一次呢？于是上面的代码就被简化为: 箫山茔 time awk '$1&gt;$2' howtouniq.txt &gt; uniq.txt # real 0m2.259s # user 0m1.968s # sys 0m0.265s 所以，这个讨论就是想说：会写代码很重要，能把自己的想法提炼成最简单的需求也很重要，尤其对于不怎么会写代码的人来说（比如我）。顺便多说一句，上篇文章发布以后意外得到了爪哥的关注（seqkit 作者），他也提供了一种方法，即便被 uniq 禁锢了思路，也可以非常快的解决问题。那就是用他的另一个牛逼工具csvtk进行无需 sort 的去重。在csvtk中有一个命令也叫做 uniq，但是它的特点就在于：unique data without sorting。这也给了我们一个启发，自己不行的时候就要多认真学习大佬的工具。 爪哥 time awk 'OFS=&quot;\\t&quot; { if($1&gt;$2){print $2,$1,$3} else {print} }' howtouniq.txt \\ | csvtk uniq -H -t -f 1,2 &gt; howtouniq.txt.awk-csvtk #real 0m2.674s #user 0m5.660s #sys 0m0.482s 以下是其它一些朋友给出的代码，供大家学习和参考，谢谢参与的每一个人。感恩。 贾石石石 open FH_IN, &quot;$ARGV[0]&quot;; open FH_OUT, &quot;&gt;filtered_$ARGV[0]&quot;; my %saved; while(fh_in){ my @tmp = split/\\t/; if($saved{&quot;$tmp[1]_$tmp[0]&quot;} == 1){ next; }else{ print FH_OUT $_; $saved{&quot;$tmp[0]_$tmp[1]&quot;} = 1; } } #时间统计如下： #real 0m8.136s #user 0m7.880s #sys 0m0.258s 黯蓝 #!/usr/bin/perl -w use strict; open my $fh, &quot;howtouniq.txt&quot; or die; my %repeat; while ($fh){ chomp; my @array = split &quot;\\t&quot;, $_; next if ($repeat{$array[0].$array[1]} || $repeat{$array[1].$array[0]}); $repeat{$array[0].$array[1]} = 1; print &quot;$_\\n&quot;; } close $fh; 李志锦 library(data.table) DT &lt;- fread('howtouniq.txt') n&lt;- nrow(DT) DT[,identifier := 1:n] DT1 = melt(DT, id.vars = c(&quot;identifier&quot;,'V3'), measure.vars = c(&quot;V1&quot;, &quot;V2&quot;), variable.name = 'columns') DT2 &lt;- DT1[order(identifier,value)] DT2[,columns := rep(c(&quot;newV1&quot;,&quot;newV2&quot;),n)] DT3=dcast(DT2, identifier+V3 ~ columns) DT4=DT3[,.(newV1,newV2,V3)] fwrite(DT4,&quot;uniqued.txt&quot;,sep = &quot;\\t&quot;) DT &lt;- fread('howtouniq.txt',stringsAsFactors = T) DT1&lt;- DT[,.(V2,V1,V3)] colnames(DT1) &lt;- colnames(DT) DT2&lt;- rbind(DT,DT1) DT3 - as.integer(DT2[,V2]) ] fwrite(DT3,&quot;uniqued3.txt&quot;,sep = &quot;\\t&quot;) 欧哎的人 import time time1=time.time() fl=open('howtouniq.txt') fo=open('uniq.txt','w') dict={} for line in fl: seq=line.split('\\t') key1=seq[0]+'\\t'+seq[1] key2=seq[1]+'\\t'+seq[0] value=seq[2] try: dict[key1] except: try: dict[key2] except: dict[key1]=value for key,value in dict.items(): fo.write(key+'\\t'+value) fl.close() fo.close() time2=time.time() print('time:'+str(time2-time1)) # time:6.823026418685913 kim for each in open(“./howtouniq.txt”,”r”).readlines(): if each.split(“\\t”)[0]&gt;each.split(“\\t”)[1]:print(each.strip()) FaDIng #include stdio.h #include string.h int main () { FILE *fp = NULL; fp = fopen(&quot;howtouniq.txt&quot;, &quot;r&quot;); char token1[32]; char token2[32]; char token3[32]; while(!feof(fp)) { fscanf(fp, &quot;%s&quot;, token1); fscanf(fp, &quot;%s&quot;, token2); fscanf(fp, &quot;%s&quot;, token3); if(strcmp(token1, token2) &gt; 0) { printf(&quot;%s\\t%s\\t%s\\n&quot;, token1, token2, token3); } } fclose(fp); return(0); } // 0.80s user 0.23s system 99% cpu 1.038 total 华中医想吃涮羊肉 自己写的： import time start = time.perf_counter() d = dict() with open(file) as f: for line in f: a, b, c = line.strip().split(&quot;\\t&quot;) if a &gt; b: a, b = b, a if str(a+&quot;\\t&quot;+b) in d.keys(): continue else: d[str(a+&quot;\\t&quot;+b)] = c f2 = open(file2, &quot;w&quot;) for key, value in d.items(): f2.write(str(key)+&quot;\\t&quot;+str(value)) end = time.perf_counter() print(&quot;Running time:%s seconds&quot;%(end-start)) # 运行时间：8.962766784 seconds 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-06-03-uniq-big-file/"},{"title":"如何快速找到自己需要的 R 包","content":"Bioconductor 的存在让只用 R 语言完成 (90% 的） 生物信息分析成为了一种可能，也在很大程度上推动了 R 在生物信息领域的应用和发展。目前 Bioconductor 配合 R 3.6 使用升级到了 3.9 版本。一共有 R 包 1741 个。学习生物信息和 R 语言，它是非常好的资源。 平常偶尔会有人问到我这样的问题：我目前正在做某某分析，你知道有什么 R 包可以用么？如果是不熟的人而且他做的分析我也不熟悉，一般我的回答直接就是不知道；如果是好朋友那我就得顺手帮他快速的找到想要的 Bioconductor R 包。看完今天的文章，这个操作对你来说以后也没有什么难度。 几步操作，快准狠，找到自己要想的 Bioconductor 工具。 入门玩家 在 Bing，Google 等搜索引擎搜索 Bioconductor + 关键词。如果稍微进阶一步，你可能会配合上一些简单的搜索语法，比如指定在它的官方网站搜索，甚至指定搜索一些文件类型。这不是本文的重点，暂时就不展开了。 普通玩家 如果你已经使用过一些 Bioconductor 包，那么肯定或多或少浏览过某一个具体 R 包的主页。你会发现在官网的上方有一个搜索框，只要在里面搜索自己能想到的关键词就会在整个网站内进行检索。不过由于索引内容的问题，你搜出来的链接一是不一定可以打的开，二是打开了不一定有你关心的东西。 这时候，你需要了解 Bioconductor 内一个特有的「分类器」biocViews 。 biocViews 对所有的 R 包按照四个维度进行了分类： Software (1741) AnnotationData (948) ExperimentData (371) Workflow (27) 其中每一个大类下面都有第二级或者第三极分类，如下为部分截图。每一个 R 包会根据自己的功能被打上若干个标签。 在这个页面，你就可以放心的根据自己需求的关键词进行检索了，因为是开发者给 R 包定义标签，所以找起来非常准确。而且这个页面的搜索框会根据你输入的内容进行自动提示，帮你找到自己关心的关键词。在搜索结果页，你可以看到最基本的 R 包信息。 进阶玩家 如果不甘心止步于普通玩家，现在有了一个进阶的机会。终于有一个 Bioconductor 的 R 包对 Bioconductor 自己动手了。 接下来要介绍的这个 Bioconductor R 包叫做 BiocPkgTools。简单的说，它其实是对所有的 Bioconductor R 进行了一次文本挖掘和整理。通过几个函数可以让我们快速的获得所有包的 metadata, 被下载情况和依赖关系等等，而所有的数据都会通过 tidy data 的形式呈现方便我们进一步操作。你可以通过 [主页](https://bioconductor.org/packages/BiocPkgTools](https://bioconductor.org/packages/BiocPkgTools) 进行深入了解，这里只介绍几个和文章相关的功能。 更易用的搜索 作者提取了所有的 biocViews 标签，制作了一个可以交互的可视化气泡图。 # if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) # install.packages(&quot;BiocManager&quot;) # BiocManager::install(&quot;BiocPkgTools&quot;) library(BiocPkgTools) biocExplore() 如下图所示，首先在 filter 中进行筛选，然后就会出现带有相关标签的 R 包，颜色的大小表示了下载的相对次数或者说受欢迎程度。 点击自己感兴趣的一个包，就可以看到更加具体的介绍。包括描述，最近下载次数和主页地址等信息。 元数据探索 每一个 R 包都会有一个描述文件，其中记录了关于这个包最基本的信息，如下图所示。 因为这个文本是有固定字段可寻的，所以作者把所有的描述文件按照其内容进行整合后做成了一个 data.frame。 bpi &lt;- biocPkgList() colnames(bpi) &gt; colnames(bpi) [1] &quot;Package&quot; &quot;Version&quot; [3] &quot;Depends&quot; &quot;Suggests&quot; [5] &quot;License&quot; &quot;MD5sum&quot; [7] &quot;NeedsCompilation&quot; &quot;Title&quot; [9] &quot;Description&quot; &quot;biocViews&quot; [11] &quot;Author&quot; &quot;Maintainer&quot; [13] &quot;git_url&quot; &quot;git_branch&quot; [15] &quot;git_last_commit&quot; &quot;git_last_commit_date&quot; [17] &quot;Date/Publication&quot; &quot;source.ver&quot; [19] &quot;win.binary.ver&quot; &quot;mac.binary.el-capitan.ver&quot; [21] &quot;vignettes&quot; &quot;vignetteTitles&quot; [23] &quot;hasREADME&quot; &quot;hasNEWS&quot; [25] &quot;hasINSTALL&quot; &quot;hasLICENSE&quot; [27] &quot;Rfiles&quot; &quot;Enhances&quot; [29] &quot;dependsOnMe&quot; &quot;Imports&quot; [31] &quot;importsMe&quot; &quot;suggestsMe&quot; [33] &quot;LinkingTo&quot; &quot;Archs&quot; [35] &quot;VignetteBuilder&quot; &quot;URL&quot; [37] &quot;SystemRequirements&quot; &quot;BugReports&quot; [39] &quot;Video&quot; &quot;linksToMe&quot; [41] &quot;OS_type&quot; &quot;License_restricts_use&quot; [43] &quot;PackageStatus&quot; &quot;License_is_FOSS&quot; [45] &quot;organism&quot; 一旦变成了 data.frame 就可以进行各种操作了，比如看看那些包用到了 DESeq2。 library(dplyr) bpi %&gt;% filter(Package==&quot;DESeq2&quot;) %&gt;% pull(dependsOnMe) %&gt;% unlist() # [1] &quot;DChIPRep&quot; &quot;DEXSeq&quot; &quot;FourCSeq&quot; &quot;rgsepd&quot; &quot;TCC&quot; &quot;XBSeq&quot; 查看一下感兴趣的包对应 URL 地址 bpi %&gt;% filter(Package==&quot;DESeq2&quot;) %&gt;% pull(URL) %&gt;% unlist() #[1] &quot;https://github.com/mikelove/DESeq2&quot; One more thing 如果想要的包不在 Bioconductor 而是 CRAN 中甚至是在 GitHub 上，又该怎么办呢？有一个 网站 自称可以「搜索 R 的一切」，推荐给你。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名 - 非商业性使用 - 禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-05-24-searchbiocinr/"},{"title":"给你的高效搜索小技巧","content":" 本文提到的内容多余绝大多数人来说是没有必要的，因为你可以能一天也不会有几次搜索，但是对于一个如我这般常年「面向搜索编程」的人来说。一天搜索 30 次，每次节约 10 秒，就是 5 分钟，一年就是 30 个小时。 高级搜索 以 Google 搜索语法为例 普通搜索：rna-seq analysis 精确搜索：&quot;rna-seq analysis&quot; 排除搜索： &quot;rna-seq analysis&quot; -youtube 指定文件类型：&quot;rna-seq analysis&quot; -youtube filetype:pdf 指定网站搜索：&quot;rna-seq analysis&quot; site:www.biostars.org 就不百度 bing 国际版（推荐） 国内版 www.bing.com Bird so 为程序员群体开发的搜索引擎 相关网站权重高但自身域名不稳定 http://126kr.com/ http://caup.cn/ 只能百度 又不是不能用 善用高级搜索 多用英文搜索 快速搜索 以 Chrome 浏览器为例 设置 -&gt; 管理搜索引擎 -&gt; 添加搜索引擎 搜索引擎 -&gt; 关键字 （快捷键） -&gt; 查询网址 (%s 替换搜索词） 了解搜索格式 搜狗微信 http://weixin.sogou.com/weixin?type=2&amp;query=%s type=1 搜索公众号 type=2 搜索文章 bing 英文 https://www.bing.com/search?q=%s&amp;ensearch=1 ensearch=1 开启英文搜索 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名 - 非商业性使用 - 禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-05-19-searchtips4you/"},{"title":"小议 linux 并行方法","content":"─=≡Σ(((つ •̀ω•́) つ 车速飚起来，坐稳扶好 前几天朋友圈各种神仙「打架」秀了一波在 R 里分组统计的骚操作，思路总结起来大致是：split-apply-combine。果子还给我直接来了一次需求提速，几个月前需要十几分钟完成的操作如今只要十几秒就拿下了，特别生猛。 在 linux 环境下，不少软件和命令其实也都面临着如何提速的问题。我现在还记得大概一年前 jimmy 问过一个问题：要从一个很大的文本中提取出一批想要的行，如果用 grep -f hewantfile.txt rawdata.txt 来 grep 的话实在是太慢了。当然，这个需要用 R 或者 Python 来做的话，极短时间就可以完成。但如果一定要用 grep 来实现，一种可行的加速方法就是把可拆的元素最大程度拆分，极端的说，就是把 1 个 1 万行的文本拆成 1 万次分析，只运行 1 次。 当然，这些操作都是在你自己一台机器上利用自身多 CPU 特性完成的，如果你能同时操控 1 万台（即使性能很 low 的）机器，那就可以通过 remote 的方式来批量运行，这时「split-apply-combine」的分组思想就近似变成了「MapReduce」的并行思想，而在 linux 也有不少方法可以实现类似这样的效果。 本文所提到的在 linux 中并行主要针对两种需求：一种是只能单线程工作的命令比如 grep 和 sed 以及 bzip2 这类；另一种是一些虽然支持多线程但是并不能充分利用分配线程数的软件，比如 trimmomatic 在实际使用的时候给它 5 个或者 10 个甚至 20 个线程，但每次用到的就是两三个。 并行的使用场景也有两种：多文件和大文件。通常又可以把大文件的场景转换为多文件的场景去解决。 首先介绍下文会用到的测试文件： 37923 行的测试文件 file.txt（其实是 gff 格式） 5000 行的待查找文件 need.id （其实是转录本 id） 为了模拟多文件处理场景，我们把 file.txt 分割成 100 个小文件，每个文件都是以 split_file 开头。 split -n l/100 file.txt -d -a 3 split_file # -n l/100 这个参数的写法略讲究，目的是为了防止 split 把某一行给拆开在两个文件。 最耗时做法：大文件直接 grep 的常规操作，在我当时的测试环境下需要 5 分多钟才能完成。 time grep -w -f need.id file.txt &gt; filter.out real 5m15.913s user 5m15.772s sys 0m0.140s shell 脚本 多文件处理 说到 linux 批量运行命令，可能最简单的就是在命令结尾使用 &amp; 从而让命令在后台执行紧接着再运行下一条命令。比如： for i in `ls split_file*` do grep -w -f need.id $i &gt; ${i}.out &amp; done 这种命令处理方法要比直接对 100 个文件因此操作的总时长节省很多。但是也有一个问题，循环一旦结束 grep 的进程仍在后台执行，如果想让所有命令都结束之后这个脚本在结束，可以上一点技巧。 for i in `ls split_file*` do grep -w -f need.id $i &gt; ${i}.out &amp; pid+=(&quot;$!&quot;) done wait ${pid[@]} 在这里，使用 $! 来获得进程的 PID，$! 保存着最近一个后台进程的 PID，然后放入数组，用 wait 命令等待这些进程结束。但是这种方法一旦面临文件远远超过自己的线程数时容易失控，造成服务器卡顿甚至卡死。比较理想的改进是能够识别这个循环执行次数，当达到某个数量时就停止添加新任务等待前述命令结束。 如下所示，一旦循环执行次数超过了 19，就让循环等一等。 t=0 for i in `ls split_file*` do echo $i grep -w -f need.id $i &gt; ${i}.out &amp; sleep 1s t=$(($t+1)) if [[ $t -gt 19 ]] then echo $t wait a moment wait t=0 fi done 大文件处理 大文件处理的思路其实和多文件很类似，只是需要我们提前把多文件拆分为大文件，例如我们把一个大文件利用 split 拆分为 100 个小文件，每次利用 20 个 cpu 同时运行，最后再把结果进行合并。这样会比直接操作一个大文件节省非常多的时间。 t=0 for i in `ls split_file*` do echo $i grep -w -f need.id $i &gt; ${i}.out &amp; t=$(($t+1)) if [[ $t -gt 19 ]] then echo $t wait t=0 fi done wait cat split_file*out &gt; final.all.out &amp;&amp; rm -f split_file*out # 脚本运行时间 #real 0m29.666s #user 7m41.872s #sys 0m3.312s PPSS 当然，上面的脚本是我们的入门操作，如果仔细推敲存在不少问题而且不够灵活，例如不能时时刻刻充分利用好设定的最大线程数（上述为 20）。很早之前就有人写过一个更加复杂的 shell 脚本 PPSS 来实现并行操作，这个脚本一共有 3000 多行，具体用法可以查看其 GitHub 的说明。 以下是一个明令行的帮助说明： ppss |P|P|S|S| Distributed Parallel Processing Shell Script 2.60 usage: ./ppss [ -d &lt;sourcedir&gt; | -f &lt;sourcefile&gt; ] [ -c '&lt;command&gt;&quot;$ITEM&quot;' ] [ -C &lt;configfile&gt; ] [ -j ] [ -l &lt;logfile&gt; ] [ -p &lt;# jobs&gt; ] [ -D &lt;delay&gt; ] [ -h ] [ --help ] [ -r ] Examples: ./ppss -d /dir/with/some/files -c 'gzip' ./ppss -d /dir/with/some/files -c 'cp&quot;$ITEM&quot;/tmp' -p 2 ./ppss -f &lt;file&gt; -c 'wget -q -P /destination/directory&quot;$ITEM&quot;' -p 10 除了利用 bash 脚本，已经有大量写好的工具来完成这个需求，在这篇文章里简要介绍几个用的相对多的工具。 parallel GNU parallel 这个命令在一部分服务器中可能没有被预装，通过 官网 进行下载安装。它应该是目前使用量最广的 linux 端并行工具，后续大多数工具都是在其思路上利用不同的语言进行开发，并且都是以它作为标准进行比较。 GNU parallel 的主要目的就是用来代替 xargs (xargs -P 可以实现并行处理) 和 for 循环这些操作，所以大多数用 for 来写的循环都可以使用 GNU parallel 来进行改写提速（解决多文件问题），同时它也可以把输入的大文件进行 block 切分再并行的进行处理（解决大文件问题）。 parallel 可以支持各种格式的输入，比如 stdin、单一文件、多个文件，命令行等等。可以输出 stdout，整合结果或者未整合结果。 多文件处理 # 多文件压缩 ls split_file* |parallel gzip # 多文件解压缩 ls split_file* |parallel gunzip 再比如一次创建 20 个目录 seq 20 | parallel mkdir temp_{} 大文件处理 time cat file.txt |parallel --pipe grep -w -f need.id &gt; temp.txt real 2m0.893s user 5m31.536s sys 0m0.344s 时间从原始的 5 分多降低到 2 分钟，如果感觉上面的数据处理还不够快那么不要用默认参数可以有另一种写法，20s 搞定。 time parallel --pipepart -a file.txt --block -10 grep -w -f need.id &gt; temp2.txt real 0m21.260s user 9m32.360s sys 0m12.236s xjobs xjobs 也是一个平时会偶尔使用的命令，它可以直接执行命令行中的命令，也可以执行一个包含多个命令行的文件。然后自己根据分配的线程数进行分配，每一个命令结束就会启动新的命令，保证 CPU 的利用效率。 多文件处理 # 多文件压缩 ls split_file* |xjobs -j 20 gzip # -j 指定处理线程数 # 多文件解压缩 ls split_file* |xjobs -j 20 gunzip 大文件处理 xjobs 如果需要进行大文件处理，需要首先对文件自行拆分，这里直接使用 split 好的文件。 time ls split_file0* |xjobs -j20 -v0 grep -w -f need.id |grep -v bin &gt; temp4.txt real 0m20.344s user 6m5.264s sys 0m2.748s # xjobs 直接使用 sdtout 的时候有一个问题就是会写出执行的命令，需要在输出的结果中把命令行除去。 rush rush 是 seqkit 开发者（江湖人称爪哥）的作品。因为爪哥本身做生物信息，在介绍这个工具时他还提到了在生物信息中的应用示例。而这个工具也体现出了爪哥一贯的风格，说明文档的用法示例清晰移动，给出各了种参数对应 GNU parallel 的功能，安排的明明白白。 多文件处理 多文件处理最基础的版本和其它工具类似，不过其借鉴了 awk 的赋值方法，可以利用 -v 给变量进行赋值。另外，如果命令被中断还可以通过 -c 继续进行。 ls split_file* |rush -j 20 'gunzip' -c 大文件处理 rush 不支持直接传 stdin。你对一个文件 grep 操作，没法通过 rush 来并行。如果文件多的话，可以 ls *.txt | rush 'cat {} | grep' 这样多文件并行。 --- 爪哥本爪 我的理解：如果需要进行大文件的处理，可以自行对文件进行拆分，和 xjobs 类似，问题就再一次转换为多文件处理。 time ls split_file0* |rush -j 20 'cat {} |grep -w -f need.id || true' &gt; temp5.txt # 在 rush 中，直接使用 grep 会有问题，需要按照 grep foo bar || true 这样的格式来使用 real 0m18.891s user 5m48.664s sys 0m2.684s 生物信息应用 因为爪哥特意给了一个 bwa 比对的例子，在这里直接引用一下，供参考。 A bioinformatics example: mapping with bwa, and processing result with samtools: $ tree raw.cluster.clean.mapping raw.cluster.clean.mapping ├── M1 │ ├── M1_1.fq.gz -&gt; ../../raw.cluster.clean/M1/M1_1.fq.gz │ ├── M1_2.fq.gz -&gt; ../../raw.cluster.clean/M1/M1_2.fq.gz ... $ ref=ref/xxx.fa $ threads=25 $ ls -d raw.cluster.clean.mapping/* \\ | rush -v ref=$ref -v j=$threads \\ 'bwa mem -t {j} -M -a {ref} {}/{%}_1.fq.gz {}/{%}_2.fq.gz &gt; {}/{%}.sam; \\ samtools view -bS {}/{%}.sam &gt; {}/{%}.bam; \\ samtools sort -T {}/{%}.tmp -@ {j} {}/{%}.bam -o {}/{%}.sorted.bam; \\ samtools index {}/{%}.sorted.bam; \\ samtools flagstat {}/{%}.sorted.bam &gt; {}/{%}.sorted.bam.flagstat; \\ /bin/rm {}/{%}.bam {}/{%}.sam;' \\ -j 2 --verbose -c -C mapping.rush Since {}/{%} appears many times, we can use preset variable (macro) to simplify it: $ ls -d raw.cluster.clean.mapping/* \\ | rush -v ref=$ref -v j=$threads -v p='{}/{%}' \\ 'bwa mem -t {j} -M -a {ref} {p}_1.fq.gz {p}_2.fq.gz &gt; {p}.sam; \\ samtools view -bS {p}.sam &gt; {p}.bam; \\ samtools sort -T {p}.tmp -@ {j} {p}.bam -o {p}.sorted.bam; \\ samtools index {p}.sorted.bam; \\ samtools flagstat {p}.sorted.bam &gt; {p}.sorted.bam.flagstat; \\ /bin/rm {p}.bam {p}.sam;' \\ -j 2 --verbose -c -C mapping.rush 其它 在 GNU parallel 的主页有一个详细的其它并行工具和 GNU parallel 的 比较说明，如果闲来没事可以仔细研究，如果想进一步学习，可以参考 GNU parallel 的 详细官方说明。 如果要推荐一种方法，十几万行的数据挑出几万行的内容，在 R 里 merge 一下或者 left_join 一下，基本没有感觉。 one more thing 以为文章到这里就结束了么，其实还没有…… 如果你也感觉 grep 单线程处理这样大规模的数据集太慢了，那可能是还不太会用 grep。比如同样的需求，多加一个参数就可以让其无感完成，比上述所有方法都快出几个数量级。 time grep -F -w -f need.id file.txt &gt; filter2.out real 0m0.026s user 0m0.016s sys 0m0.008s 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名 - 非商业性使用 - 禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-05-17-linuxparallelbasic/"},{"title":"解决 Stringtie 基因重复定量的意外收获","content":" Bioinformatics was like a box of chocolates. You never konw what you're gonna get ——阿飞正传 铺垫 由于自己之前一直不喜欢用 cufflinks，所以后面的 stringtie 也是能不用就不用，偶尔用下也都是浅尝辄止。因为 stringtie 可以直接拿到基因的 TPM 值，比 RSEM 需要单独构建一次索引的操作省力些，所以最近自己注释了些基因就用它对十几个样本跑了一波基因定量的常规操作。心想做个表达矩阵进行下游分析，结果偶买噶，每个定量结果的行数（基因数）竟然都不一样。同一个注释文件定量出了不同的结果，检查一下原始基因数，发现有的定量结果行数要比实际基因数多 7 个，有的要多 5 个，还不尽相同。 尝试 遇事不怕事，先看看多出来了什么基因，我发现有八九个基因竟然会重复出现在定量结果中。回到注释文件里看这些基因为什么作妖，随便看了 3 个发现一个规律。这些基因对应的转录本 ID 并不是连续的（因为上游分析时我过滤掉了一些不符合自己要求的转录本），如下截图所示，gff 删掉了 2 和 3，结果在定量时出现了两个相同的 ID 。 如此这般，难道是 stringtie 不能识别不连续 ID 转录本的基因？暗自感觉这个 bug 无语的同时动手把那几个命名有 gap 的转录本 ID 重命名为连续，又测试了一次还是重复出现了这个问题。看来并不是 ID 不连续造成的，肯定还有一些背后的原因。 再一次仔细观察这些不连续的转录本信息，CS.104750 在最后的表达定量中出现了两次，且一个基因给出的位置坐标是在转录本 1 和 4 上（18509027-18513961），另一个基因位置是在 4-8 上（18574381-18579343）。如果是通过 ID 来拆分转录本应该是转录本 1 独立为一个基因，其它转录本独立为一个基因。这里似乎是按照位置进行了区分，因为转录本 1、4 和另外 5-8 之间没有位置上的重叠，所有被分为了两个基因。在检查其它几个重复出现的基因，都符合我这个猜想。 好了，现在另一个问题是，如果是没有重叠区域的转录本会被按照独立的基因单独统计，那为什么不同的样本重复的基因数量并不一样呢？到底 stringtie 是怎么一个定量逻辑，到这里靠猜就解决不了问题了，只能去找原始文献和源代码。 惊喜 历史的经验告诉我自己不太可能是第一个遇到这问题的人，于是问了一些朋友但也是答非所问。不如干脆去 GitHub 提个 issue，习惯性在提之前尝试搜了一下 stringtie gene abundance duplicate 。用这几个关键词，Google 第二个结果 就是一个和我完全一样的困惑（似乎也只有这一个内容和我的困惑相关），而且也是在 GitHub 上提出的问题。 我点进去发现内容还挺长，开发者和提问人有好几个回合的问答。读完不禁长处一口气，这个 issue 不光解答了我的困惑，还提供了一个如何提问的绝佳范本。非常值得我们去学习和反思。 以下是主要内容的摘录和简要评论： I am currently running stringtie on Arabidopsis rna-seq data sets and I am encountering duplication events that vary from sample to sample. The command I am running is: stringtie -v -p 1 -e -o test.gtf -G TAIR10_Araport11.gtf -A test.ga -l test OutputFromHisat-Samtools_sort-Samtoools_Index.bam I am using the arabidopsis gtf downloaded from TAIR, and the reads I am running are downloaded from NCBI. My workflow is trimmomatic, hisat2, samtools_sort, samtools_index, stringtie. I am running stringtie v1.3.4d. My workflow was run on a llinux slurm cluster, and I have also verified the same results on my local machine (Ubuntu 18.04). I typically have 1 or 2 genes per run that have duplication events. A colleague running the same workflow on bovine data is having the same issue. 提问人在问题的描述中首先给出了自己处理的数据是什么物种，然后附上了自己处理的完整命令，另外也说了自己的参考基因组下载自哪里。同时写明了自己的分析流程和 stringtie 对应的软件版本。作者也强调自己在服务器集群和本地都是一个结果，以及自己的朋友也重复了这个问题——总有一两个基因在定量的时候会被重复呈现。 在开发者的第一次回复中提到了是不是注释文件做过某些处理，本身存在重复的 gene id，另外希望能提供一点有问题的 bam 文件，另外作者还非常贴心的提供了如何提取一些 bam 结果的方法。这里就不引用原始内容了。以下是提问者的第二次回复。 Sorry, the name of the gtf was confusing, it makes more sense in the context of our workflow. Yes, the gtf was produced from the file on the TAIR page named Araport11_GFF3_genes_transposons.201606.gff.gz using the command from Cufflinks gffread -E Araport11_GFF3_genes_transposons.201606.gff -T -o- &gt; TAIR10_Araport11.gtf I cannot attach my file due to size constraints, but by downloading the above file and using that command you should be able to get the same reference file to work with. The file that results from the above command does not appear to have duplicates. In the output files from stringtie on my arabidopsis data, each file seems to have a random duplication of 1 of three genes. Those genes are: ATCG09900 AT1G79790 AT1G58520 Here is a subset of my list of my output files (whole list is very long), and below each file name is what gene is duplicated (bash uniq command). The name of the file indicates the srx ID from NCBI. Each of these samples had multiple runs associated with it (sra). Before running through the pipeline these “sra” were combined into one large fastq file corresponding to their respective “srx”. You will notice that each file had different combinations of genes that were duplicated, but that they were always 1 of the 3 genes listed above. SRX2248274/SRX2248274_vs_TAIR10_Araport11.ga SRX2248275/SRX2248275_vs_TAIR10_Araport11.ga AT1G58520 SRX2248276/SRX2248276_vs_TAIR10_Araport11.ga AT1G58520 SRX2248277/SRX2248277_vs_TAIR10_Araport11.ga AT1G58520 SRX2248278/SRX2248278_vs_TAIR10_Araport11.ga AT1G58520 SRX2248279/SRX2248279_vs_TAIR10_Araport11.ga AT1G58520 ATCG09900 SRX2248280/SRX2248280_vs_TAIR10_Araport11.ga AT1G58520 SRX2248281/SRX2248281_vs_TAIR10_Araport11.ga AT1G58520 SRX2248282/SRX2248282_vs_TAIR10_Araport11.ga AT1G58520 SRX2248283/SRX2248283_vs_TAIR10_Araport11.ga AT1G58520 ATCG09900 SRX2248284/SRX2248284_vs_TAIR10_Araport11.ga AT1G58520 ATCG09900 SRX2248285/SRX2248285_vs_TAIR10_Araport11.ga AT1G58520 SRX2248286/SRX2248286_vs_TAIR10_Araport11.ga AT1G58520 SRX2248287/SRX2248287_vs_TAIR10_Araport11.ga AT1G58520 As I was thinking about it, I got paranoid that this combining of sra’s into srx may have caused the issue, so I redid it with a sample without combining (used sample SRR4426362). I got the same results. The attached files are a subset of the resulting *.bam that will cause a duplication event when used with this command and the above mentioned reference file: stringtie -v -p 1 -e -o test1.gtf -G TAIR10_Araport11.gtf -A test1.ga -l catz bundle.bam I used this command to see the duplicated gene in the gene abundance file: awk '{print $1}' test1.ga|sort |uniq -d # AT1G58520 I have also included the output gene abundance file from this subset bam. I went through all of this again to verify that the results are still happening. Our workflow is using the latest editions of all of the other software as well. I had to rename the attached files with a &quot;.txt&quot; extension to be able to upload them to git hub, so I hope that the bam still work when you get it. 这一段回答内容比较长，提问者首先解释了自己对 gtf 文件进行了哪些操作以及具体的命令是什么，同时他又描述了一些自己的做过的尝试，并且排除了自己认为可能的出现问题的原因，最后还上传了开发者想要的测试文件。以下是开发者的第二次回复，已经涉及到了关于这个问题的一些具体解释。 Ah, I thought you somehow suggested that transcripts were duplicated (the fix mentioned in the release notes for v1.3.1 was about that), but now I see that your problem is that genes are duplicated in the &quot;gene abundance&quot; output file. That's actually not quite true; each line in that output file is rather about estimating abundance for&quot;gene&quot;regions (loci), formed by overlapping transcripts, and in some cases such gene regions are not uniquely identified by their ID/name, the coordinates (genomic location) of each such&quot;gene region&quot; (locus) sometimes make a very important distinction. Look at the transcripts for that gene (AT1G58520) in the annotation file: there are 7 transcripts there, but one of them (AT1G58520.3) is actually not overlapping any of the others, so StringTie treats it as a separate locus (&quot;gene&quot;), and thus it creates a separate entry in the gene abundance file for that particular locus (AT1G58520|Chr1(+)21729913-21731344) which is different from the other, &quot;main&quot; locus which has all the other overlapping transcripts: AT1G58520|Chr1(+)21732566-21738808 StringTie cannot &quot;trust&quot; the reference annotation, as sometimes the gene ID can be just a duplicated string providing no true locus identity.. So you can think of it as StringTie splitting that &quot;gene&quot; into two non-overlapping gene regions and assessing the expression for each gene region independently. Again, the identity of a &quot;gene&quot; (actually &quot;locus&quot;) in that file is given by gene ID and the genomic location of the underlying cluster of transcripts which define that locus. As you can see, that single transcript gene region (locus Chr1(+):21729913-21731344) has zero coverage so I don't know if that gene region is even real (or perhaps just an annotation artifact). If you really do not care about these situations (where gene definitions are not quite consistent with the transcripts so StringTie separates them like this), you could just add up the coverage values for all these lines with the same gene ID in the gene abundance file and call that the &quot;total&quot; abundance of that &quot;gene&quot; -- but this could be really misleading if the gene ID is not uniquely identifying a locus, i.e. if it's duplicated in other places on the genome (perhaps even on another chromosome). 这一段的作者的回答信息量比较大，和我之前写到的实际类似，stringtie 本身给你的所谓基因定量结果，看的并不是基因（名），而是基因的位置，如果你的两坨转录本没有交集，就会被自动划分为两个位置进行定量。作者特别用拟南芥的注释文件来举了个例子，并且说道我的软件可不会真的相信注释文，因为有的时候基因注释文件中的 id 会出现重复的情况，所以你可以理解为 stringtie 把一些转录本没有重叠的基因分成了两个部分来独立定量。我们在意的是 locus。最后作者也给了一个建议，如果你不在乎，可以把这些基因手动的合并一下，但是如果一个基因竟然出现在基因组的两个位置，这么做似乎也没什么意义。 然后，提问者并没有就此停下，他又提到了一个新的疑问，也就是我在上文有提到的，不同的样本重复情况不尽相同。这又是什么原因。 Ok, that makes a lot of sense, I like that stringtie identifies genes this way so that it does not combine only on a gene ID. What I am seeing though is that stringtie will &quot;duplicate&quot; some genes in only some of the output files. It would make sense if it did it all the time, but I only see it happening in some of them. I guess what I am concerned about is that stringtie is Identifying different amounts of genes each time. So far for arabidopsis I have seen it identify either 37363 or 37364 genes. From your last response, it seems that it should be identifying scenarios like the AT1G58520 and the AT1G58520.3 every single time it is run, not just occasionally. I was looking back at my data, and it appears that yes, this is true for AT1G58520, but it is not for ATCG09900. At the bottom of this response I have a grep of my gene abundance files for gene ATCG09900, and it appears that in some samples stringtie identifies 2 copies, but sometimes only 1. I looked at the reference.gtf, and it looks like it should have 2 copies every time like AT1G58520 because even though it has the same gene ID, it has different genomic location. Your response above makes a lot of sense to me, stringtie should require both gene ID and genomic location to avoid bad reference.gtf files. My problem now is that I don't understand why in the case of ATCG09900 it is not being consistent across samples? I would think that the part of stringtie that identifies the gene from the reference.gtf would be independent of the sample. Here is the reference.gtf for gene ATCG09900, I would expect that stringtie would always identify it as 2 genes from your last response: ChrC Araport11 exon 7967 7996 241.00 - . transcript_id &quot;ATCG09900.1&quot;; gene_id &quot;ATCG09900&quot;; gene_name &quot;ATCG09900&quot;; ChrC Araport11 exon 8176 8207 241.00 - . transcript_id &quot;ATCG09900.2&quot;; gene_id &quot;ATCG09900&quot;; gene_name &quot;ATCG09900&quot;; Here is a section of a grep of my output gene abundance files that shows that ATCG09900 is sometimes represented by 2 copies, and sometimes only 1. It seems that its representation as 2 copies is independent of if it is actually expressed or not. SRX2248582/SRX2248582_vs_TAIR10_Araport11.ga ATCG09900 ATCG09900 ChrC - 7967 7996 0.000000 0.000000 0.000000 ATCG09900 ATCG09900 ChrC - 8176 8207 0.0 0.0 0.0 SRX2248583/SRX2248583_vs_TAIR10_Araport11.ga ATCG09900 ATCG09900 ChrC - 7967 8207 0.0 0.0 0.0 SRX2248584/SRX2248584_vs_TAIR10_Araport11.ga ATCG09900 ATCG09900 ChrC - 7967 7996 1.533333 0.790024 1.578678 ATCG09900 ATCG09900 ChrC - 8176 8207 0.0 0.0 0.0 SRX2248585/SRX2248585_vs_TAIR10_Araport11.ga ATCG09900 ATCG09900 ChrC - 7967 8207 0.0 0.0 0.0 SRX2267752/SRX2267752_vs_TAIR10_Araport11.ga ATCG09900 ATCG09900 ChrC - 7967 8207 0.0 0.0 0.0 SRX2267753/SRX2267753_vs_TAIR10_Araport11.ga ATCG09900 ATCG09900 ChrC - 7967 8207 0.0 0.0 0.0 SRX2267754/SRX2267754_vs_TAIR10_Araport11.ga ATCG09900 ATCG09900 ChrC - 7967 8207 0.0 0.0 0.0 SRX2267755/SRX2267755_vs_TAIR10_Araport11.ga ATCG09900 ATCG09900 ChrC - 7967 7996 0.333333 0.276271 0.562470 ATCG09900 ATCG09900 ChrC - 8176 8207 0.875000 0.725212 1.476486 SRX2267756/SRX2267756_vs_TAIR10_Araport11.ga ATCG09900 ATCG09900 ChrC - 7967 7996 0.333333 0.177870 0.363462 ATCG09900 ATCG09900 ChrC - 8176 8207 0.281250 0.150078 0.306671 SRX2267757/SRX2267757_vs_TAIR10_Araport11.ga ATCG09900 ATCG09900 ChrC - 7967 8207 0.0 0.0 0.0 SRX2267758/SRX2267758_vs_TAIR10_Araport11.ga ATCG09900 ATCG09900 ChrC - 7967 8207 0.0 0.0 0.0 这里提问者再一次详细的贴出了自己的实际分析结果，也非常清楚的说明白了自己困惑。于是，开发者又进行了进一步的回答。 Good question -- apologies for leaving out an important piece of information in my previous explanation: the fact that overlaps with read alignments from the BAM file are also taken into account when determining a &quot;gene region&quot; (locus), so they can act as a &quot;glue&quot;, or &quot;bridge&quot; which could put together &quot;gene regions&quot; otherwise separated when looking only at overlaps between reference transcripts. So it is likely that in some samples the two gene regions of ATCG09900 get &quot;bridged&quot; by read alignments overlapping both those regions.. Thus only one gene region is reported for such samples. It is all related to the concept of &quot;bundle&quot; as used by StringTie. Read alignments and reference transcripts are binned together in a &quot;bundle&quot; defined as a transitive closure of the exon overlap relationship between these objects (read alignments or reference transcripts (guides)). StringTie analyses a &quot;bundle&quot; and unless &quot;weak spots&quot; are found (spurious alignments) to break the bundle into multiple regions, the &quot;bundle&quot; will end up as a &quot;gene region&quot; (locus) reported in the output. This &quot;clustering by overlap&quot; approach can also have the downside of merging multiple otherwise clearly distinct gene regions together (i.e. with different reference gene IDs), when alignment artifacts and/or transcriptional noise artificially &quot;bridge&quot; over intergenic regions, in some rare cases (especially when the actual genes are very close to each other). 开发者先感谢对方提出了这样一个好问题，他解释道自己有一个重要的统计细节没有讲，就是当决定基因范围时，stringtie 还会考虑实际的数据比对情况，reads 可以作为胶水将两个分离的基因区域连接起来，如果有这样的情况，这个基因也不会被分开。当然，最后作者也说了这样处理数据的一些缺陷。 这次，提问者的困惑被解决了，他对自己的问题进行了一个自我总结作为最后的回复，也作为对开发者回答的响应。内容如下： Ahh, very good. So the samples where there is only 1 gene region means that there was either a bridge between the two transcripts, or there was no spurious alignment to break apart the bundle (in my case, this often meant no alignment). With that info, I think I am able to answer my last question on my own. Above, some of the samples has genes that had fpkm of 0, but they still split, while others had fpkm of 0 and did not split. For example: SRX2248582/SRX2248582_vs_TAIR10_Araport11.ga ATCG09900 ATCG09900 ChrC - 7967 7996 0.000000 0.000000 0.000000 ATCG09900 ATCG09900 ChrC - 8176 8207 0.0 0.0 0.0 SRX2248583/SRX2248583_vs_TAIR10_Araport11.ga ATCG09900 ATCG09900 ChrC - 7967 8207 0.0 0.0 0.0 It would appear that SRX2248582 and SRX2248583 should both fail to break the bundle since no alignment has happened in either that would cause the bundle to break. This is the case in SRX2248583 but not in SRX2248582. I went and looked at the sam file for these, and found that SRX2248582 had a read in that region, while SRX2248583 did not (I also checked the region 100 before, but none overlapped with the region so for brevity I will omit them): $ grep ChrC *.sam| awk -F &quot;\\t&quot; '{ if(($4 &gt;= 7967 &amp;&amp; $4 &lt;= 8207)) { print } }' SRR4426896.15866700 16 ChrC 8000 60 9M1I90M * 0 0 ATATATATATTTTTTTTTCATTTTCTATATTTTTTTCTATATTTTATTATATTATTATATATATATATATTCTTTTTGATTATTTGATTATATAAATATA CEEDEEEDDDDDDFFFDDDHHGGHHJJJJIGIJIIJIJJJJJIJIHIIGIGGIGJJJJIJJJJJJJJJJJJJJJJJJJJJJJIJJJJHHHHHFFFFFCCC AS:i:-8 ZS:i:-10 XN:i:0 XM:i:0 XO:i:1 XG:i:1 NM:i:1 MD:Z:99 YT:Z:UU NH:i:1 $ cd ../SRX2248583 $ grep ChrC *.sam| awk -F &quot;\\t&quot; '{ if(($4 &gt;= 7967 &amp;&amp; $4 &lt;= 8207)) { print } }' I suppose that this spurious alignment caused the split, but was not counted towards the fpkm for some other reason. Thank you for all of your help and quick response times, I appreciate it a lot. 在最后的总结中，作者又提到了一个观察到的现象：一个基因在不同的样本中定量的结果都为 0 ，但是有一些样本中这个基因被拆分为二，另外一些样本则没有。他认为这可能就是开发者提到的是否存在一些 reads 比对的问题，于是他又检查了不同样本中这个基因所在位置区间的比对情况，果然和开发者提到的内容相符。 反思 写到这里，忍不住在 GitHub 上评论了一下，虽然 issue 已经关闭了。 这次 debug 我最先猜测到的还是问题的表象，然后通过一些后续的分析找到了可能的问题。在看到上面这个完整的 issue 后，我深切地感受到了什么是一个优秀的提问，他可以指引被提问对象说出关键的信息，并且循序渐进的做出需要的补充内容。如果没有提问者详细的描述和认真的思考，可能这个问题不知道还要经历多少个来回才能被讨论清楚。 经历了这么一番波折，我对这个工具的喜欢竟然增加了一点，接下来就是再仔细看看文章和代码。也许，这就是为什么人总是会对伤害过自己的人和事念念不完。Bioinformatics was like a box of chocolates. You never konw what you're gonna get ——阿飞正传 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名 - 非商业性使用 - 禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-05-07-stringtiegenetpm/"},{"title":"「关键提问」读书笔记","content":"基本信息 原作名：Wait, What?: And Life's Other Essential Questions 作者：詹姆斯 ·E. 瑞安 (James E. Ryan) 页数：177 整理：思考问题的熊 劳动节这几天抽空读完了一本书，这里做简要整理和记录。「关键提问」的作者是哈佛大学教育研究生院的第十一任院长詹姆斯 ·E. 瑞安，他本人是一个非常优秀的法学家和教育家，全书框架来自其 2016 年在哈佛大学发表的毕业演讲，点击前面的链接可以看到 5 分钟的精华版。 一本能用 5 分钟演讲视频看完的书属于不少人眼里所谓的「只看目录」系列，但是我在阅读过程中字里行间还是能和作者有所共鸣并进行自我反思，这就够了。全书共 6 章，其中前 5 章是 5 个关键问题，结语部分作者回忆了如何从一位离世好友身上看到这 5 个关键问题的呈现。 这里的关键提问不涉及具体专业知识，但却是绝大多数有效交流不可或缺的。它们可以从不同的层面通过提问帮助你和他人建立良好关系，引导他人的同时也更好的认识自己。 太长不看版 “Wait, what?” is at the root of all understanding. “I wonder . . . ?” is at the heart of all curiosity. “Couldn’t we at least . . . ?” is the beginning of all progress. “How can I help?” is at the base of a3ll good relationships. And “What truly matters?” helps get you to the heart of life. 「等等，你说什么？」是一切理解的源泉。 「不知道为什么……？」是一切好奇心的根源。 「我们能不能至少……」是一切进步的起始。 「我能帮什么忙？」是所有美满关系的根基。 「真正重要的是什么？」能帮助你触及生活的核心。 理解问题 「等等，你说什么」这句话在我自己的语言体系里一般就是两个字：啊（二声）啥？当然「啥」可能也是不少人的口头禅，在这里建议大家以后当你想说「啥」的时候就用「等等，你说什么」来进行代替。 根据语气的不同，这句话可以延伸出非常多的用法和含义。直截了当的说，可能只是要求他人重复之前的话或是对于对方的某个观点或建议让人感到出乎意料；用拉长的语气说「等一下」简短但语气很强的「你说什么」，适合表达发自内心的怀疑，类似于礼貌地问 “这种话你也能说出来？”；先简短「等一下」再接一句拉长的「你说什么」，可以在你被某人要求做某事时使用，有效地传达对于所提要求背后动机的怀疑和反对。 从我个人的实际经验来看，还有一个类似的建议：在和他人沟通尤其是合作者交流的时候，要在适当的时候学会重复对方的需求。 保持好奇 提问「不知道为什么」会让你对这个世界保持好奇心，提问「不知道能不能」能够让你保持与这个世界的联系。我参与的每一次冒险以及尝试过的每一件新事物，几乎都是由「不知道我能不能这样做」这个问题开始的。 总的来说，「不知道为什么」这个问题之所以不可或缺，就在于它直指好奇心的根本，提问能让人对周围世界以及自己在世界上的定位保持好奇心。「不知道能不能」这个问题之所以不可或缺，是这个问题能让你保持与世界的紧密联系，并能让你开始思考该如何对你所处的「一亩三分地」做出改善。 其实很多时候我们在完成一件工作或者一个任务之后，都可以用「不知道为什么」和「不知道能不能」来和自己进行沟通。例如，不知道为什么我的脚本运行起来非常慢，不知道能不能把速度提升一些。 后退是为了前进 当我们和别人进行某种意义上的「谈判」时，很容易陷入僵局，你想要的对方不愿意满足，对方反对的你不愿意做出让步；当我们和同伴在商量某项计划时，很可能因为细节太多找不到前进的头绪。面对这两种情况，提问「我们能不能至少……」是一种破解僵局的好方法。 暂停后退并寻求在一些领域里达成共识的作用，然后再着手进行一些尝试。 学会正确帮忙 用「我能帮什么忙」这个问题来开头，你就是在抱着谦虚的心态寻求指点。这个问题不仅向对方表达了尊重，也很可能让你的协助更有的放矢。 我们提供帮助的方式与提供帮助本身同等重要，用「我能帮什么忙」这句话开场主要为了向对方放低自己的心态，把对话建立在更加平等的基础上。有时候对方的困惑还没讲完我们的一长串问题和解决方案已经甩出去了。另外很多人向我们寻求帮助可能就是需要一个宣泄的渠道，通过这样的提问我们也是给对方一个人继续陈述的机会。问「我能帮什么忙」可能已经帮了大忙。 学会做出取舍 「真正重要的是什么」这个问题不仅会帮助你深入问题或难题的根源，也能帮助你抵达生活的核心。关于工作、家庭、友情，以及该如何行善，这些主题中的重点需要你自己做出判断。 「真正重要的是什么」在和别人的交谈中可以随时调整谈话的重点和方向，帮助团队在追求重大目标的过程中撇开细枝末节。在和自己交流的过程中，这个问题能够帮助你区分真正重要的问题和微不足道的问题，学会拒绝。我们应该尽可能地提高工作效率，以便能完成工作之外具有同样重要意义的事情，比如与家人和朋友共度时光，或是追求其他的兴趣和爱好。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名 - 非商业性使用 - 禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-05-03-keyquestion/"},{"title":"每周文献-190419-植物单细胞BAM重比对以及假基因研究","content":"A Single-Cell RNA Sequencing Profiles the Developmental Landscape of Arabidopsis Root DOI(url): https://doi.org/10.1016/j.molp.2019.04.004 发表日期：April 17, 2019 关键点 国内首篇植物相关单细胞文章，两个一作还都很熟。 参考意义 植物单细胞的阶段要开启了，今天提到的这篇文章是国内首篇，也是世界范围内的第四篇植物单细胞文章。除此之外，还有几篇已经在 bioRxiv 上上线了，不过还没有正式发表。这些文章都不约而同选择了植物中研究最广的模式之物拟南芥，而且全部研究的是根尖。后面在发展就要看看其它组织和物种的情况了。 如果一个东西在植物里已经出现要快速增长的趋势，那么它在人和动物里应该也就已经相对比较成熟了。此时，即便暂时还用不到，但是相关的技术和方法就需要留意和学习起来。 在这篇文章中，作者在单细胞水平揭示了拟南芥根尖细胞的异质性重构了根尖分生组织细胞的发育轨迹。按照文章的说法，成功拿到了 7695 个根单细胞转录组数据。聚类后根细胞被划分为 24 个细胞类群，细胞类群注释分析鉴定了一些潜在的新细胞类型，并找到了一批细胞类型标记基因。 用 t-SNE 和 UMAP 重构了根发育的基本轨迹，实现了根分生组织细胞分裂和分化在单细胞水平上的准确投影。进一步利用伪时间（pseudo-time）分析，捕获了根尖分生组织细胞的分化轨迹和过渡态细胞，解析了根分生组织细胞如何通过协调细胞分裂和分化进程逐步形成根尖不同细胞类型的分子机理。此外，通过分析细胞类群对离子吸收和激素响应情况，揭示了不同根细胞类群的响应热图。该研究加深了我们对拟南芥根细胞组成和发育轨迹的认识，将根发育生物学从原先的组织器官水平提升到了单细胞水平。 (上面这一段话主要来自官方报道，具体的细节需要仔细读完文章在分享) 相关内容 目前已经正式发表的其它三篇植物单细胞文章，看下来会发现分析思路和 figure 都异曲同工。 Single-Cell RNA Sequencing Resolves Molecular Relationships Among Individual Plant Cells Spatiotemporal Developmental Trajectories in the Arabidopsis Root Revealed Using High-Throughput Single-Cell RNA Sequencing Open Access Dynamics of gene expression in single root cells of A. thaliana Benchmarking of alignment-free sequence comparison methods DOI(url): https://doi.org/10.1101/611137 发表日期：April 16, 2019. 关键点 有哪些 alignment-free (AF) 相关的工具，以及如何评价。 参考意义 AF 类的工具，在转录组分析层面使用最多的是定量分析。例如 salmon 和 kallisto，主要原理就是基于对 kmer 的各种操作。其实除了转录组的快速定量 这篇文章比较详细的介绍了目前主要 AF 相关工具的原理和工具。同时，作者使用了 24 个相关软件的 74 种方法，测试了五种应用场景，分别是： protein sequence classification gene tree inference regulatory element detection genome-based phylogenetic inference reconstruction of species trees under horizontal gene transfer and recombination events 作者还提供了一个在线工具，用来展示这些结果。 相关内容 kWIP Skmer Kevlar Bazam: a rapid method for read extraction and realignment of high-throughput sequencing data DOI(url): https://doi.org/10.1186/s13059-019-1688-1 发表日期：18 April 2019 关键点 bam 文件似乎可以方便的回滚了 参考意义 随着参考基因组的更新和比对方法的更新，很多之前的 bam 文件似乎就变得过时了。除了找出原始的 fastq 文件再重新来过一次，现在有了另一个选择。 bazam 首先可以从 bam 或者 cram 文件直接找到 pair reads 在比对回其它参考基因组而不需要中间步骤； 也可以按需要提取过滤后的 reads，例如与特定基因位置有 overlap 的 reads。结果可以直接传到下游工具，或以 fastq 格式存储以供进一步处理。另外还从 read 这个 input 层面提供了多线程比对的思路。加快了比对速度。 整体而言，和目前已有的一些可以转换 bam 文件的工具相比，其在内存和存储占用，已经方便程度上都有优势。 目前我的问题是很多时候会对原始 bam 文件进行一波过滤，这个时候已经丢掉了很多 fastq 的 reads。 相关内容 其它几个已有工具的比较 Tool Storage used Memory Effective Cores Time Sort-Extract-Realign 282 GB 20 GB 16 13 h, 15 min Picard SamToFastq 148 GB 78 GB 16 16 h, 14 min Biobambam bamtofastq 149 GB 30 GB 16 15 h 30 min Bazam (no sharding) 68 GB 28 GB 16 14 h, 55 min Bazam 10-way sharding 102 GB 20 GB 160 1 h, 11 min bazam Evolutionary Origins of Pseudogenes and Their Association with Regulatory Sequences in Plants DOI(url): https://doi.org/10.1105/tpc.18.00601 发表日期：March 2019 关键点 在我看来，假基因和 lncRNA 这类非编码 RNA 其实大多数是定义方式不同，重合度不低。 参考意义 假基因（Ψs）一般是和功能基因的序列相近的非功能性基因，通过复制或逆转录方式形成，通常会含有各种突变导致基因功能的丧失。在这篇文章中，作者检查了七种被子植物（拟南芥，短柄草，大豆，苜蓿，水稻，杨树和高粱）假基因的起源，进化和表达模式及其与非编码序列的关系。作者鉴定了大约 250,000 个假基因，发现非常大比例的非转座因子调控非编码 RNA（microRNA 和 lncRNA）起源于假基因近端上游区域的转录。 还发现与随机基因间区相比转录因子结合位点优先发生在假基因近端上游区域，这表明假基因可能通过提供用作启动子和增强子的转录因子结合位点来调节基因组进化。 假基因定义流程： 假基因鉴定情况 相关内容 主要鉴定步骤 (1) identify intergenic regions (masked genic and transposon regions) with sequence similarity to known proteins using exonerate; (2) quality control, identity ≥ 20%, match length ≥ 30 amino acids, match length ≥ 5% of the query sequence, and only the best match is retained; exonerate --model protein2genome --showquerygff no --showtargetgff yes --maxintron 5000 --showvulgar yes --ryo \\&quot;%ti\\\\t%qi\\\\t%tS\\\\t%qS\\\\t%tl\\\\t%ql\\\\t%tab\\\\t%tae\\\\t%tal\\\\t%qab\\\\t%qae\\\\t%qal\\\\t%pi\\\\n\\&quot;. (3) link homologous segments into contigs (set I Ψs); (4) realign using tfasty to identify features that disrupt contiguous protein sequences tfasty34, with parameters -A -m 3 q (5) distinguish WGD-derived Ψs and set II Ψs. MCScanX -k 50 -g -1 -s 5 -m 25 以及 PlantPseudo 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名 - 非商业性使用 - 禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-04-19-weeklypaper/"},{"title":"数据分析需要更好的问题","content":"设计思维和更好的问题 这篇文章的主要内容来自 Roger Peng 最近的一篇博客 Tukey, Design Thinking, and Better Questions。读了之后有些启发便做简单记录。 John Tukey 是美国的数据学，快速傅里叶变换发明人。它在 1962 年发表过一篇题为 “The Future of Data Analysis” 的论文，其中有一句非常著名的话。 Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise. Tukey 将数据分析的前三个阶段定义为如下三步： 识别一个问题 Recognition of problem 使用一个方法 One technique used 使用大量其他方式 Competing techniques used 不要针对一个问题用一个方法一直做下去，可能你提出的问题就是错的，也可能你认为的某个最佳方法并不是对你的实际问题而言并不是真的最佳。因此，数据分析的开始阶段应该提出更多的问题，尽量找到更好的问题。 Roger Peng 把他自己的想法绘制成了一张图：证据强度和问题质量。 图中红色位置是我们的终极目标，即用最强有力的证据说明一个非常高质量的问题，而我们很多做数据分析的人都认为自己的工作是从右下角开始的，因此我们仅仅需要找出一个最佳方法就可以了。但是实际情况是我们通常从左下角开始自己的项目，我们的问题非常模糊而且定义不清，用什么方法也没有头绪。而接下来的工作就是一个数据分析工作者应该做的。 一方面努力提高问题的质量与清晰度，在这个过程中专业和背景知识这些脱离于数据本身的内容尤其重要，同时尝试若干种方法，有些可能不错有些可能也很糟糕。在这个过程中，我们不断的总结数据可以告诉我们些什么，但是更重要的是我们会逐渐清晰自己可以问出哪些更好的问题，通过数据了解自己。 最坏的情况下我们会从一组数据中找到一个别人已经弄明白的结论，亦可能从看他别人从另一组数据中到了完全相反的结论。所以想从一组数据中找到「答案」往往会让你失望。 It is important to understand what you CAN DO before you learn to measure how WELL you seem to have DONE it 一个好的分析技术或者方法能做的是给你提供更多的数据，而好的探索性分析则会给你带来更多或者更好的问题——更精确更专注更尖锐。只有当你的问题越尖锐越切中要害时它才能提供更大的区别信息的潜力。从一个模糊的问题得到的最好答案也只是一个模糊的答案。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名 - 非商业性使用 - 禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-04-18-weneedgoodquestion/"},{"title":"每周文献-190411-lncRNA功能exRNA分析以及DNA甲基化","content":"Antisense lncRNA Transcription Mediates DNA Demethylation to Drive Stochastic Protocadherin α Promoter Choice DOI(url): https://doi.org/10.1016/j.cell.2019.03.008 发表日期：4 April 2019 关键点 反义 lncRNA 转录可以影响 DNA 甲基化，进而改变染色体结构促进增强子与启动子结合，调控基因表达。 参考意义 Pcdhα 基因有 13 个可以随机启动的可变外显子，每个启动子都可以由自身的启动子驱动，还有 3 个 c 型外显子以及稳定表达的编码 pcdh 结构域的外显子，同时，还有一个 enhancer 调控。 研究者发现，反义 lncRNA 的转录，会造成该位点 DNA 去甲基化的发生，从而使远端增强子靠近该外显子的启动子，促进它的表达。如图 2 所示，Pcdhα 基因座位均带有抑制表达的 DNA 甲基化修饰，而当反义 lncRNA 表达时，该外显子附近的 DNA 被 DNA 去甲基化酶 TET3 识别，去除了甲基化修饰，cohesin 蛋白重塑了染色体的结构，HS5-1 增强子与该基因座位的启动子结合，启动相应 Pcdhα 变体的表达。 相关内容 关于反义 lncRNA 影响正义链基因表达的作用机制，主要有 3 类 反义 lncRNA 的转录过程，抑制正义链基因的转录，该机制认为反义链转录事件本身，而不是反义 lncRNA，调控了基因的表达。 反义 lncRNA 结合 DNA 或组蛋白修饰酶，调控所在基因座位的表观遗传学，从而影响正义链基因的表达。 反义 lncRNA 与正义链 mRNA 通过碱基互补配对结合，影响 mRNA 的可变剪接等。 CTCF: CTCF is an enhancer-blocking protein that inhibits the access of Igf2 to the enhancer elements located downstream from the H19 transcription start site. Cohesin Cohesin is a multiprotein complex that holds sister chromatids together from S phase until the start of mitosis, helping to ensure genomic integrity (Haarhuis, Elbatsh, &amp; Rowland, 2014). 另一篇植物中相关 lncRNA 鉴定方法 First, only transcripts with TAIR10 annotation [Cufflinks class codes ‘u’ (intergenic transcripts),’x’ (Exonic overlap with reference on the opposite strand),’i’ (transcripts entirely within intron) were retained. Second, transcripts of short length (length &lt;150 nt) or low abundance (FPKMmax &lt; 1, FPKMmax stands for the maximum expression level of a lncRNA from all samples) were removed. Third, transcripts with protein-coding potential were removed. Protein-coding potential was determined by using two programs: (1) transcripts were subjected to a BlastX search against all plant protein sequences in the Swiss-Prot database70 with a cutoff e-value &lt; 10-4 and the transcripts with strong hits (alignment length ≥40 aa, percent identity ≥35% and coverage of the alignment region in either query or subject sequence ≥35%) to known proteins were considered to have protein-coding potential; For antisense transcripts, open reading frames were checked. (2) the CPC (Coding Potential Calculator) score71, a value to assess protein-coding potential of a transcript based on six biologically meaningful sequence features, was calculated for each transcript. When the CPC score is positive, we considered the transcript to have protein-coding potential. Transcripts that passed the three filtering steps were annotated as lncRNAs. Global identification of Arabidopsis lncRNAs reveals the regulation of MAF4 by a natural antisense RNA exceRpt: A Comprehensive Analytic Platform for Extracellular RNA Profiling DOI(url): https://doi.org/10.1016/j.cels.2019.03.004 发表日期：April 4, 2019 关键点 一套分析 exRNA 的完整方案 参考意义 exRNA 就是细胞外 RNA，也就是在细胞内转录但是在细胞外发挥功能？最近 cell 有一个专刊介绍了很多 exRNA 的文章，我扫了一眼，感觉主要内容是小 RNA 居多。所以这个分类和 lncRNA 类似，一个从长度一个从位置来进行区分。既然是这样，exRNA 的处理方法应该就和小 RNA 以及一般的 RNAseq 分析类似。看看这个流程里面有哪些不一样的地方。这里提供的分析方法从内容来看主要针对小 RNA，但是官方说也可以很方便的移植到其它 RNA，在 GitHub 的代码里也有针对 longRNA 的脚本。主要流程如下图，质控后会同时比对到多个数据库，具体内容可以参考 GitHub。 相关内容 exceRpt 什么是 exRNA exRNA: Extracellular RNA (also known as exRNA or exosomal RNA) describes RNA species present outside of the cells from which they were transcribed. In Homo sapiens, exRNAs have been discovered in bodily fluids such as venous blood, saliva, breast milk, urine, semen, menstrual blood, and vaginal fluid. Although their biological function is not fully understood, exRNAs have been proposed to play a role in a variety of biological processes including syntrophy, intercellular communication, and cell regulation. exRNA 的种类 Extracellular RNA should not be viewed as a category describing a set of RNAs with a specific biological function or belonging to a particular RNA family. Similar to the term &quot;non-coding RNA&quot;, &quot;extracellular RNA&quot; defines a group of several types of RNAs whose functions are diverse, yet they share a common attribute which, in the case of exRNAs, is existence in an extracellular environment. The following types of RNA have been found outside the cell: Messenger RNA (mRNA) Transfer RNA (tRNA) MicroRNA (miRNA) Small interfering RNA (siRNA) Long non-coding RNA (lncRNA) 研究 exRNA 的关键似乎应该是如何分离得到确实是细胞外的 RNA。 比如 Small RNA Sequencing across Diverse Biofluids Identifies Optimal Methods for exRNA Isolation. Cell. 2019 Apr 4;177(2):446-462.e16. doi: 10.1016/j.cell.2019.03.024. 这篇文章就比较了集中 exRNA Isolation Methods，通过对 5 种生物液体中 10 种 exRNA 分离方法的系统比较，发现所得到的小 RNA-seq 图谱的复杂性和重现性存在显著差异。每种方法对不同的 exRNA 载体亚类的相对效率是通过估计细胞外囊泡 (EV)-、核糖核蛋白(RNP)- 和高密度脂蛋白(HDL) 特异性 miRNA 在每个图谱中的比例来确定的。开发了一种基于 web 的交互式应用(miRDaR)，帮助研究人员为他们的研究选择最佳的 exRNA 分离方法。 另外，还有一篇文章：exRNA Atlas Analysis Reveals Distinct Extracellular RNACargo Types and Their Carriers Present across Human Biofluids. Cell. 2019 Apr 4;177(2):463-477.e15. doi: 10.1016/j.cell.2019.02.018. exRNA Atlas resource 包含来自 19 项研究的 5309 个 exRNA-seq 和 exRNAqPCR 概要文件，以及一套分析和可视化工具。通过分析，该研究得到了一个包含六种 exRNA 类型 (CT1、CT2、CT3A、CT3B、CT3C、CT4) 的模型，每种 exRNA 类型都可以在多种生物体液 (血清、血浆、脑脊液、唾液、尿液) 中检测到。 A statistical normalization method and differential expression analysis for RNA-seq data between different species DOI(url): https://doi.org/10.1186/s12859-019-2745-1 发表日期：29 March 2019 关键点 不同物种之间 RNA-seq 怎么分析确实是一个问题，那么 ChIP-seq 呢？ 参考意义 propose a scale based normalization (SCBN) method by taking into account the available knowledge of conserved orthologous genes and by using the hypothesis testing framework. Considering the different gene lengths and unmapped genes between different species, we formulate the problem from the perspective of hypothesis testing and search for the optimal scaling factor that minimizes the deviation between the empirical and nominal type I errors. 用小鼠来研究人的疾病非常常见，在一些文章中也有人会用同源基因进行比较。对于不同物种的数据来说，除了基因数量基因长度的不同，也有测序深度的问题。让两个物种之间的数据可比，数据的标准化方法非常重要。在之前的一些研究中，有人使用 RPKM 值来进行比较找到一千个保守基因，然后评估每个基因在不同物种中的中位数水平，然后通过让中位值保持一致来得到一个校正因子（median method）。这篇文章作者利用直系同源基因通过对已有方法的改进来进行不同物种之间数据的矫正。 相关内容 SCBN ChIP-seq 类的数据有哪些方法呢？ 雅卡尔指数（英语：Jaccard index），又称为并交比（Intersection over Union）、雅卡尔相似系数（Jaccard similarity coefficient），是用于比较样本集的相似性与多样性的统计量。雅卡尔系数能够量度有限样本集合的相似度，其定义为两个集合交集大小与并集大小之间的比例。在 bedtools 中有这个工具可以 对 jaccard 进行计算。 还有 余弦相似度 cosine similarity score ，比如这篇文章 A Cosine Similarity-Based Method to Infer Variability of Chromatin Accessibility at the Single-Cell Level 另外，dpca 可以用于分析转录因子结合位点处和启动子的不同染色质模式，以及等位基因特异性蛋白 - DNA 之间的相互作用。 DNA methylation analysis in plants: review of computational tools and future perspectives DOI(url): https://doi.org/10.1093/bib/bbz039 发表日期：09 April 2019 关键点 难得的植物 DNA 甲基化分析综述文章 参考意义 在这篇综述中，作者概述了分析 DNA 甲基化数据（特别是亚硫酸氢盐测序数据）最常用的生物信息学工具，也分析了这些工具的性能并且比较了计算拟南芥以及小麦甲基数据的计算时间和一致性。同时举例说明了作物中 DNA 甲基化数据分析的应用。但从软件上看，BSMap 用是最短，尤其是当线程数上去之后，但是内存则是 Bismark 最省。 关于内存的使用情况，不要被下图迷惑。小麦那里只是展示了处理 1 条染色体的需要的内存用量。要知道，小麦可是有 21 条染色体，16G 的基因组。 相关内容 另外一篇文章，Strategies for analyzing bisulfite sequencing data 。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名 - 非商业性使用 - 禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-04-11-weeklypaper/"},{"title":"关于 Shiny 调试你应该知道的","content":" Finding your bug is a process of confirming the many things that you believe are true — until you find one which is not true. —Norm Matloff 第一次接触网页开发是两三年前的事，那时我曾经问过计划带我入门前端的前辈：入门前端的标准是什么。他当时用一种极平和的语气和我说：学会 dubug。几年后的今天我即便也写过一点网页工具，但还是依然没能入门。反思一下：一是 JavaScript 学的不好，二就是不敢说自己有多少 debug 的能力。 遂放弃。 最近因为需要又要涉及一点网页工具开发，同时因为需求整体和 R 交互比较多于是决定用 R 的 Shiny 来搞一搞。 写了一个多星期我感觉 Shiny 确实解决了不熟悉前后端交互的人写网页的大多数问题，但如何 debug 的门槛还是摆在那里。比如前几天一个高手和我吐槽写 Shiny 时不知道改了什么突然不能正确运行了，更糟心的是还没有任何报错信息。当然，后来经过讨论发现其实并非没有报错信息，只是那时他没有找到而已。 这篇文章就结合最近学习的一点资料，大致聊聊在 Shiny 中 debug 的一些方法。 Shiny debug 主要有三个步骤，分别是调试 (Debugging)，追踪(Tracing) 和错误处理(Error handling)。 -Debugging: 所谓的调试就是猜，然后在你认为可能有错误的地方设置一个断点，再执行接下来每个语句的时候就都可以检查程序当时所在的状态。 -Tracing：可以在运行程序的时候收集程序运行产生的信息而无需暂停程序，在诊断系统性问题时因为我们无法频繁的中断使用这一方式就比较合适。 -Error handling: 在客户端和服务器端找到错误的来源并确定原因。 Debugging 调试 breakpoints 断点 说到「断点」，我不由的想对 bug 说一句： 静静地陪你走了好远好远，连眼睛红了都没有发现。 如果你知道哪一行的代码有错（这话本身就像 bug）或者猜测很可能是哪里不对，就可以直接在所在行设置一个断点。Rstudio 只需在行号左边点一下鼠标就会出现红点提示标记成功。开始运行 Shiny 程序后会在断点处停止执行，然后就可以开始逐步执 ​​ 行进行代码调试了。 如上图所示，我们在 40 和 41 行设置了两个断点，现在点击 Run App，代码运行会在 40 行处停下，绿色的箭头指向 41 行，并且在 console 中会有 browse 输出，如下图所示 这个时候我们可以方便的查看环境中已有的变量，例如这里已经运行完毕的 x 变量。如果想继续运行，可以点击 console 里 continue，程序又会向下运行。 现在环境中存在 x 和 bin 两个变量，同时在 console 的 browse[2]&gt; 处你可以进行正常的 R 操作，例如查看变量内容或者做个加法运算，甚至你可以修改当前存在环境中的变量（当然不推荐这么操作）。 说到缺点，目前 breakpoints 只可以在 Rstudio IDE 中使用，而且只能用于 ShinyServer 函数中；另外如果代码很长显然不停的断点也很烦，同时它只能显示发生了什么但是无法告诉你为什么有些事情没有发生。 小结如下： browser() 命令 其实从上面 console 的截图也可以看到，断点就是执行了一次类 browser() 操作。但和断点不同的是，browser() 本身可以被写到任何地方。写法如下图所示： 甚至你还可以把 browser() 写进判断语句中，只在某些特定的情况下执行。例如下图所示，在 input 中的 bins 小于 40 时候程序会正常的执行，当大于 40 时才会自动停下，然后你就可以在调试器中查看具体的变量等信息。 小结如下 Tracing 追踪 在许多情况下通过暂停执行来找问题比较困难，相反需要我们在程序运行时观察系统。对于 Shiny 的程序尤其如此，因为他不像 R 脚本那样线性运行。 Showcase Mode Shiny 在启动时，runAPP() 有一个选项默认是读取配置文件中的设置，它就是 display.mode。如果我们设置为 display.mode=&quot;showcase&quot;，在 Showcase 模式下，代码将与应用程序一起显示，并且程序的 server 端代码在执行时会出现黄色的闪烁进行提醒。这一功能对于可视化哪些部分代码正在执行非常有用。 如果想要默认开启这一功能，可以在该 Shiny 目录下创建一个 DESCRIPTION 文件并写入如下内容： DisplayMode: Showcase Type: Shiny 小结如下 Reactive Log 在 Shiny 中经常会用到响应对象，当开启 Reactive Log 之后，程序运行时除了可以告诉你正在执行哪些响应之外，日志还可以帮助你可视化展示响应对象之间的依赖关系。在开启一个新的 R session 时首先配置 options(Shiny.reactlog=TRUE)，然后在 Shiny app 中通过 Ctrl + F3 就可以启动可视化的 Reactive Log 文件，也可以在运行 Shiny 后使用 showReactLog 查看。详细信息可以在 官方文档 了解。 打印 tracing 在各种编程语言中，一个万变不离其宗的调试技巧就是不停的输出。在 PHP 里面是不停的 echo，在 R 里可以不停的 cat。使用 cat 可以帮助你在不终止程序的情况下查看变量值。在 Shiny 中，最好的方式是打印标准错误(stderr())。 # generate bins based on input$bins from ui.R x &lt;- faithful[, 2] bins &lt;- seq(min(x), max(x), length.out = input$bins + 1) cat(file=stderr(), &quot;drawing histogram with&quot;, input$bins, &quot;bins&quot;, &quot;\\n&quot;) 进行上述修改后，运行 Shiny 每次调整 input 都会在 console 中打印输出。如下图所示 小结如下 Shiny Server 进行 tracing 如果你的程序运行在 server 端而非本地，每次 Shiny 程序运行都会生成 log 文件，默认的路径是 /var/log/Shiny-server/*.log，而这一位置是可以在配置文件中通过 log_dir 进行修改的。如果程序运行没有出现问题，每次 Shiny 运行结束后文件会自动删除，如果报错了则会一直存在于 log 目录等你去宠幸。log 文件的命名格式为 &lt;application directory name&gt;-YYYMMDD-HHmmss-&lt;port number or socket ID&gt;.log 。 客户端和服务器端 Tracing 一个 Shiny 程序包括 client (浏览器) 和 server (R 进程) 两部分。这两者通过 websocket连接，websocket 接收来自客户端的状态，例如输入控件新的赋值，同时发布来自服务器端的状态更改，例如新的输出。在一些比较复杂的情况下，你可以通过打开 trace 来跟踪 JSON 格式的 websocket 内容。 如上图所示，在输出内容中，SEND 表示从浏览器发送到 R session 的数据；RECV 表示从 R session 发送到浏览器的数据。 这一部分目前还没有实际用到，理解到位了可以再写一些。 Errors 错误 跑程序最怕看到的就是报错，但是真要有问题了最希望看到的就是明确的报错。 R 报错 在 Shiny 中大多数报错信息都是由 R 引起的，在 0.13.0 之后的 Shiny 版本中已经有了比较直观的报错形式，会直接给出哪里的程序出现了错误。这里首先人为引入一个报错，当 input 大于 40 的时候停止程序并且抛出 too many bins 的报错信息。 运行程序后调整输入如果错误，可以观察 console 的输出内容： 首先直接观察颜色不同的部分，直接告诉我们 app.R 的 43 行代码出现了问题。在报错部分，每一行内容前都有一个数字，例如 1，82，165 和 167，其表示的是在调用栈 (call stack) 中的索引，可以看到这个例子中有接近 170 个调用栈。 JavaScript errors 目前 Shiny 有很多第三方 JavaScript 组件，有时如果使用上面几种方式都没有定位到错误相关问题或者没有看到报错信息，很可能是 JavaScript 中发生错误导致程序出现了 bug。毕竟 Shiny 是个网页应用，各种和用户的交互少不了 JavaScript 的使用。 要进行 JavaScript 的调试在 Rstudio 就不灵了。如果你是通过 Rstudio 打开了一个单独 Shiny 页面，可以通过右键单击 Shiny 页面，选择 Inspect element 进入 JavaScript console；如果你的 Shiny 页面是open in browser，也就是在浏览器中打开的，可以直接通过 F12 进入开发者模式打开 JavaScript console 。 在 Shiny 中 UI 的每个部分都会有一个 id 参数，这个 id 对应的参数在浏览器中解析之后就是对应着 HTML 标签中的 id。在 HTML 中，这个 id 是必须唯一（区别于 name）。因此，在 Shiny 的 ui 中每一个 id 参数也必须唯一。解析效果如下图所示： 如果你不小心在 UI 中写入了两个一样的 id，在上图中就有两个标签的 id 都是 a，程序运行后在 Rstudio 并不会抛出什么错误，但是在 Shiny 页面端的各种操作就进行不了。如果不在开发者模式下进行调试只能通过各种方法在 Rstudio 进行测试，但是如果打开 JavaScript 的 console，就会看到其实已经给出了明确的报错信息。 当然，Chrome 开发者工具的用法是在太多，这也是我在文章开头提到的自己入门不了前端的原因之一。如果在你的 Shiny 中用到了大量 JavaScript 相关内容，或者需要定制很多 CSS 相关的内容，可以学习一下官方的开发者工具文档。 至此，也就简单的写完了 R Shiny debug 的三个主要步骤，其中提到的每一个用法在实际使用中都需要进一步深入学习。当然，每一个方法用到的频率也各有不同，可以根据个人的实际情况进行后续的练习。 One more thing：shinyjs 写到这里本来文章就可以结束了，但是似乎总有哪里不对。 为什么在 Rstudio 的 console 里就不能查看 JavaScript 的 log 信息。要知道 Rstudio GUI 本身使用的就是 QT 框架，其中的很多部分都可以理解为一个网页。从维基百科或者它自己的说明中都可以看出这一点。 不信的话你也可以在 Rstuido 的每个 pane 里右击然后选择 Inspect element 看看会出现什么，比如在 Console 中右击 你会看到下面图所示的内容 既然如此，没有理由不去解决这个不方便的问题。其实在 R 中有一个专门为 Shiny 提高 JavaScript 使用体验开发的 R 包，叫做 shinyjs。这个包的存在让 Shiny 使用 JavaScript 变得强大和高效了很多。其中针对调试有两个专门的函数。 showLog Print any JavaScript console.log() messages in the R console, to make it easier and quicker to debug apps without having to open the JavaScript console. 这个函数类似于 JavaScript 中的 console.log()，它可以把 JavaScript console 的信息显示在 R console 中而不需要再打开专门的 JavaScript console。 logjs Print a message to the JavaScript console (mainly used for debugging purposes). 这个函数则可以把信息输出到 JavaScript console 中方便进行调试。 例如下面一段代码： library(ShinyJavaScript) if (interactive()) { library(Shiny) ShinyApp( ui = fluidPage( useShinyJavaScript(), # Set up ShinyJavaScript actionButton(&quot;btn&quot;, &quot;Click me&quot;) ), server = function(input, output) { observeEvent(input$btn, { # Change the following line for more examples logJavaScript(R.Version()) }) } ) } 运行后通过点击 button ，就可以把 R.Vsrsion() 的信息输出到 JavaScript console 中，如下图所示： 嗯，先写到这里吧。 我的学习材料 Chrome 开发者工具 Debugging Shiny applications Debugging with RStudio shinyjs 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名 - 非商业性使用 - 禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-04-06-debug-shiny-basic/"},{"title":"用漫威数据学习 ggplot2 facet","content":" 本文主要内容翻译整理自：Easy multi-panel plots in R using facet_wrap() and facet_grid() from ggplot2，部分代码有修改。 ggplot2 一个非常强大的功能就是进行 multi-panel plots 的呈现，也就是我们常说的分面（facet）。通过使用 facet_wrap() 或者 facet_grid() 这样的函数我们就可以很方面的将单一的一个图变为多个相关的图。本文将通过一个具体的数据示例帮助你理解 ggplot2 分面的不同方法以及参数。 数据准备集 为了纪念 Captain Marvel 和即将到来的 Avengers: Endgame ，我们将使用来自 Kaggle 的 漫威角色数据集 我们将主要用到其中的 3 个变量信息： YEAR: 角色第一次出现的年份 SEX: 角色的性别 ALIGN：角色的人设，包括好坏和中立 在进行分析之前，首先对数据进行几步清洗，比如去除上述三个变量存在缺失值的数据，对变量进行更简单的重命名，同时因为涉及到的角色太多我们只选择那些出现次数大于 100 次的角色。 library(ggplot2) library(dplyr) marvel &lt;- readr::read_csv(&quot;marvel-wikia-data.csv&quot;) marvel &lt;- filter(marvel, SEX != &quot;&quot;, ALIGN !=&quot;&quot;, Year != &quot;&quot;) %&gt;% filter(!is.na(APPEARANCES), APPEARANCES&gt;100) %&gt;% mutate(SEX = stringr::str_replace(SEX, &quot;Characters&quot;, &quot;&quot;)) %&gt;% arrange(desc(APPEARANCES)) %&gt;% rename(gender = SEX) %&gt;% rename_all(tolower) 按照年份统计角色出现次数 在整篇文章中，我们将生成按年份分组的演员数来作为整个分析过程的开始，在某些情况下还会生成其他一些分组变量。对于这个初始图我们仅是按年进行简单的计算。 marvel_count &lt;- count(marvel, year) glimpse(marvel_count) # glimpse 可以展示数据的观测和变量数量以及每一列的名字和尽可能多的列信息，和 structure 类似。 ## Observations: 57 ## Variables: 2 ## $ year &lt;dbl&gt; 1939, 1940, 1941, 1943, 1944, 1947, 1948, 1949, 1950, 195... ## $ n &lt;int&gt; 3, 5, 4, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 7, 20, 36, 34, 21,... 首先画一个由线点构成的单一图形。 ggplot(data = marvel_count, aes(year, n)) + geom_line(color = &quot;steelblue&quot;,size = 1) + geom_point(color=&quot;steelblue&quot;) + theme_classic() + labs(title = &quot;New Marvel characters by year&quot;, subtitle = &quot;(limited to characters with more than 100 appearances)&quot;, y = &quot;Count of new characters&quot;, x = &quot;&quot;) 使用 facet_wrap() 按照角色人设分面 首先按照 year 和 alignment 来统计数目 marvel_count &lt;- count(marvel, year, align) glimpse(marvel_count) ## Observations: 114 ## Variables: 3 ## $ year &lt;dbl&gt; 1939, 1939, 1940, 1940, 1941, 1941, 1943, 1944, 1947, 19... ## $ align &lt;chr&gt; &quot;Good Characters&quot;, &quot;Neutral Characters&quot;, &quot;Bad Characters... ## $ n &lt;int&gt; 2, 1, 1, 4, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 6, 4,... 只需要在上面绘图命令的结尾加上 + facet_wrap(~ align) 就可以绘制按照 alignment 分面的 multi-panel plot ggplot(data = marvel_count, aes(year, n)) + geom_line(color = &quot;steelblue&quot;,size = 1) + geom_point(color=&quot;steelblue&quot;) + theme_classic() + labs(title = &quot;New Marvel characters by year&quot;, subtitle = &quot;(limited to characters with more than 100 appearances)&quot;, y = &quot;Count of new characters&quot;, x = &quot;&quot;) + facet_wrap(~ align) 这张图拥有了更大的信息量，比如我们可以发现在 1963 和 1964 年出现了大量的坏蛋，随后则逐渐减少；而好人在后面还是一直在稳定的加入。在未特殊指定的情况下，这里 facet_wrap 选择了一行展示三个图。 如果对 facet_wrap() 使用两个变量，其实只需要简单的使用 + 来进行链接。但是通常情况下，为了更好的调整布局，建议使用 facet_grid()。 marvel_count &lt;- count(marvel, year, align, gender) ggplot(data = marvel_count, aes(year, n)) + geom_line(color = &quot;steelblue&quot;,size = 1) + geom_point(color=&quot;steelblue&quot;) + theme_classic() + labs(title = &quot;New Marvel characters by year&quot;, subtitle = &quot;(limited to characters with more than 100 appearances)&quot;, y = &quot;Count of new characters&quot;, x = &quot;&quot;) + facet_wrap(~ align + gender) 按照 facet_grid() 指定行列进行绘图 facet_grid(row_variable ~ column_variable) 可以通过指定行和列来进行绘图，例如使用 align 作为行变量，gender 作为列变量 ggplot(data = marvel_count, aes(year, n)) + geom_line(color = &quot;steelblue&quot;,size = 1) + geom_point(color=&quot;steelblue&quot;) + theme_classic() + labs(title = &quot;New Marvel characters by year&quot;, subtitle = &quot;(limited to characters with more than 100 appearances)&quot;, y = &quot;Count of new characters&quot;, x = &quot;&quot;) + facet_grid(align ~ gender) 如果想要排除行或者列变量可以通过 . 来进行代替。如下所示： ggplot(data = marvel_count, aes(year, n)) + geom_line(color = &quot;steelblue&quot;,size = 1) + geom_point(color=&quot;steelblue&quot;) + theme_classic() + labs(title = &quot;New Marvel characters by year&quot;, subtitle = &quot;(limited to characters with more than 100 appearances)&quot;, y = &quot;Count of new characters&quot;, x = &quot;&quot;) + facet_grid(. ~ gender) ggplot(data = marvel_count, aes(year, n)) + geom_line(color = &quot;steelblue&quot;,size = 1) + geom_point(color=&quot;steelblue&quot;) + theme_classic() + labs(title = &quot;New Marvel characters by year&quot;, subtitle = &quot;(limited to characters with more than 100 appearances)&quot;, y = &quot;Count of new characters&quot;, x = &quot;&quot;) + facet_grid(align ~ .) 颜色有时效果更好 在时间序列数据中，使用两条不同颜色的线有时比分面效率要更高。 # Limit to male and female and change levels for drawing order marvel_count &lt;- filter(marvel_count, gender%in%c(&quot;Female&quot;, &quot;Male&quot;)) %&gt;% mutate(gender = factor(gender, levels = c(&quot;Male&quot;, &quot;Female&quot;))) ggplot(data = marvel_count, aes(year, n, color = gender)) + geom_line(size = 1) + geom_point() + theme_classic() + labs(title = &quot;New Marvel characters by gender&quot;, subtitle = &quot;(limited to characters with more than 100 appearances)&quot;, y = &quot;Count of new characters&quot;, x = &quot;&quot;) 颜色和分面混用也不失为一个高效的选择。 ggplot(data = marvel_count, aes(year, n, color = gender)) + geom_line(size = 1) + geom_point() + theme_classic() + labs(title = &quot;New Marvel characters by alignment &amp; gender&quot;, subtitle = &quot;(limited to characters with more than 100 appearances)&quot;, y = &quot;Count of new characters&quot;, x = &quot;&quot;)+ facet_grid(. ~ align) 几个常用参数 在 faceting 函数中，有一些参数是通用的，只是在使用略有差别。 nrow 或者 ncol 只对 facet_wrap() 有效 控制图形布局 ggplot(data = marvel_count, aes(year, n)) + geom_line(color = &quot;steelblue&quot;,size = 1) + geom_point(color = &quot;steelblue&quot;) + theme_classic() + facet_wrap(~ gender + align, nrow = 2) + labs(title = &quot;New Marvel characters by gender &amp; alignment&quot;, subtitle = &quot;(using nrow=2)&quot;, y = &quot;Count of new characters&quot;, x = &quot;&quot;) ggplot(data = marvel_count, aes(year, n)) + geom_line(color = &quot;steelblue&quot;, size = 1) + geom_point(color =&quot;steelblue&quot;) + theme_classic() + facet_wrap(~ gender + align, ncol = 6) + labs(title = &quot;New Marvel Characters by gender &amp; alignment&quot;, subtitle = &quot;(using ncol=6)&quot;, y = &quot;Count of new characters&quot;, x = &quot;&quot;) + theme( axis.text.x = element_text(angle=50, hjust=1) ) margins 只对 facet_grid 有效 增加额外的一个分面进行汇总 marvel_count &lt;- mutate(marvel_count, align = stringr::str_replace(align, &quot;Characters&quot;, &quot;&quot;)) ggplot(data = marvel_count, aes(year, n)) + geom_line(color = &quot;steelblue&quot;, size = 1) + geom_point(color = &quot;steelblue&quot;) + theme_classic() + labs(title = &quot;New Marvel characters by alignment &amp; gender&quot;, subtitle = &quot;(margins= TRUE)&quot;, y = &quot;Count of new characters&quot;, x = &quot;&quot;) + facet_grid(align ~ gender, margins=TRUE) 自由定义不一致的 Y 轴 可以使用 scales = &quot;free&quot; 或者 scales = &quot;free_x&quot; 或者 &quot;free_y&quot; 进行设置。但是一定要注意这样的图可能会使读者造成误解。 ggplot(marvel_count, aes(year, n)) + geom_line(color = &quot;steelblue&quot;, size = 1) + facet_wrap(~gender, scales = &quot;free_y&quot;)+ theme_classic() + labs(title = 'with&quot;free&quot;y axes' , y = &quot;Count of new Marvel characters&quot;) space 仅 facet_grid() 有效 控制每个 panel 的高和宽 默认所有的 panels 有一样的 size 可以设置 &quot;free&quot;, &quot;free_y&quot; &quot;free_x&quot; 三个参数 需要和 scales = &quot;free&quot; 一起连用 ggplot(data = marvel_count, aes(year, n)) + geom_line(color = &quot;steelblue&quot;, size = 1) + geom_point(color = &quot;steelblue&quot;) + theme_classic() + labs(title = &quot;New Marvel characters by alignment &amp; gender&quot;, subtitle = '(space =&quot;free&quot;)', y = &quot;Count of new characters&quot;, x = &quot;&quot;) + facet_grid(align ~ gender, space=&quot;free&quot;, scales=&quot;free&quot;) strip.position 仅 facet_wrap() 可用 控制 facet subset labels 有四个选项 &quot;top&quot; (default), &quot;bottom&quot;, &quot;left&quot; 和 &quot;right&quot; ggplot(marvel_count, aes(year, n)) + geom_line(color = &quot;steelblue&quot;, size = 1) + theme_classic() + facet_wrap(~gender, strip.position = &quot;right&quot;) + labs(title = 'strip.postition =&quot;right&quot;', y = &quot;Count of new Marvel characters&quot;) switch 进对 facet_grid() 有效 默认是右上角 x 会让 label 在底部，y 右改为左，both 则改为左下 ggplot(marvel_count, aes(year, n)) + geom_line(color = &quot;Steelblue&quot;, size = 1) + theme_classic() + facet_grid(~gender, switch = &quot;x&quot; ) + labs(title = 'switch =&quot;x&quot;', y = &quot;Count of new Marvel characters&quot;) 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名 - 非商业性使用 - 禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-04-04-facet-ggplot2/"},{"title":"每周文献-190330-DTU分析及转录组denovo拼接解析等","content":"文献题目 Relative Abundance of Transcripts (RATs): Identifying differential isoform abundance from RNA-seq DOI(url): https://doi.org/10.12688/f1000research.17916.1 发表日期：24 Feb 2019 关键点 差异表达中比较少见的一种方式 参考意义 在 F1000Research 发表的这篇文章介绍了一个利用 alignment-free RNA-seq quantifications 结果进行差异分析的工具，主要是用来对转录本进行差异定量分析。在日常的分析中我们进行差异分析最常见的是对差异基因进行定量分析，这里没有考虑到每个基因内部转录本的情况。 在这篇文章中提到了一个三种差异分析的方法，分别是： differential gene expression (DGE) differential transcript expression (DTE) differential transcript usage (DTU) 根据需求的不同，这三种方法会分析出非常不同的结果。在 DTU 中，即便是两个表达总量没有差异的基因其也可能发生 isoform switching，及 dominant isoform 的改变。而文章中作者发表的 R 包即可进行 DTU 的分析，其输入数据可以是 Kallisto 或者 Salmon 的定量结果。 R 包地址：https://github.com/bartongroup/Rats 相关内容 考察一个基因内不同转录本在不同情况下的表达丰度，这个需求在我的实际分析中还没有用到。不过把转录本定量的结果转为基因定量的结果，使用 R 包 tximport。 文献题目 Error, noise and bias in de novo transcriptome assemblies DOI(url): https://doi.org/10.1101/585745 发表日期：March 22, 2019 关键点 详细讨论转录组 de novo 拼接的那点事。 参考意义 这篇发表在 biorxiv 的文章，从多个方面阐述了转录本拼接本身存在的问题。这其中包括作者评估的几个算法都没有拼出数百个真是表达的基因，一大部分拼接处的 contigs 完全由内含子和 UTR 组成；对转录本有效长度的不准确给定量带来了很大的偏差等等。最后建议现在测序价格便宜了，能拼基因组就拼基因组吧。（这道理难道我不懂么，我只是没钱）。 这篇文章更值得参考的是他做的分析和采用的方法，50 页的文本非常详细的记录了具体的分析过程以及参数。也提醒了我们在做类似的分析是有哪些角度可以思考。 主要分析流程 Short read processing：trimgalore De novo transcriptome assembly TRINITY SHANNON BINPACKER BUSCO Assembly and read functional composition Coverage of reference transcripts and genes RSEM TRANSDECODER Expression estimation Analysis of missing genes PANTHER Evaluating assembly redundancy SNP-based analysis of assembly composition 相关内容 敢把流程写的及其详细的文章自然就敢把代码全部 show 给你，GitHub 地址 TranscriptomeAssemblyEvaluation 。 文献题目 Predicting the effects of SNPs on transcription factor binding affinity DOI(url): https://doi.org/10.1101/581306 发表日期：March 18, 2019 关键点 非编码区 SNP 可以研究的方向之一，对转录因子结合能力的影响。 参考意义 GWAS 显示 88％的疾病相关 SNP 位于非编码区。然而，非编码 SNP 仍未得到充分研究，这其中一部分原因是它们难以确定实验验证的优先级。这篇文章作者提出一种确定非编码区 SNP 重要性的评判标准以及方法。通过观察全基因组功能性转录因子结合位点内 SNP 的 ChIP-seq 信号强度差异来估计转录因子结合亲和力 的变化。 目前用来分析转录因子结合位点的 martix 叫做 position weight matrix (PWM)，而文章中则提出了 SNP effect matrices (SEM)。 SNP Effect Matrix pipeline 使用数据 ChIP-seq data： provides a transcription factor's endogenous binding in the genome DNase I hypersensitive sites sequencing (DNaseseq) data: represents regions of open chromatin where transcription factors are known to function position weight matrices (PWMs): denote previous knowledge of the binding pattern of transcription factors 流程 相关内容 GitHub https://github.com/Boyle-Lab/SEM_CPP 文献题目 LNISKS: Reference-free mutation identification for large and complex crop genomes DOI(url): https://doi.org/10.1101/580829 发表日期：March 19, 2019 关键点 针对 Bulk segregant analysis (BSA) 设计的无参考基因组 call snp 流程 参考意义 对于植物（作物）来说，通常手里拿到的材料并不是真正的测序品种。比如水稻就包括籼稻和粳稻，而且很可能手里的粳稻也不是真正的粳稻。面对这种情况，其实不少用到和参考基因组比对的工作都或多或少的存在一些问题，因为那个基因组在很多位置其实你都无法「参考」，而其中影响最大的一类工作就是 call snp 相关的工作。当你的材料和参考基因组差别比较大的时候就会存在很多黑箱。如果能够不依赖基因组信息而直接 call snp 一定程度上就可以规避这类问题。但是准确度如何需要进一步考证。 相关内容 相关的几篇文章： Mutation identification by direct comparison of whole-genome sequencing data from mutant and wild-type individuals using k-mers Rapid cloning of genes in hexaploid wheat using cultivar-specific long-range chromosome assembly Resistance gene cloning from a wild crop relative by sequence capture and association genetics 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名 - 非商业性使用 - 禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-03-30-weeklypaper/"},{"title":"每周文献-190322-DNA甲基化分析工具及silencers鉴定","content":"文献题目：RnBeads 2.0: comprehensive analysis of DNA methylation data **DOI(url)😗*https://doi.org/10.1186/s13059-019-1664-9 **发表日期：**14 March 2019 关键点 DNA 甲基化全功能分析 R 包 RnBeads 2.0 更新。 参考意义 DNA 甲基化是一种被广泛研究的表观遗传标记，其在发育和疾病中具有重要作用。最近甲基化分析工具 RnBeads 在 bioconductor 上更新了其 2.0 版本。它可以分析目前诸多种类的甲基化数据，并且可以完成目前甲基化分析相关所有主流内容。 本次升级主要是在输入数据、分析方法、交互界面以及计算效率上进行了提升。软件官方地址为 https://rnbeads.org/index.html 可以进行进一步了解。 在文章中给出了三个应用示例。分别是使用 Infinium 450k 芯片分析大量的血液样本 DNA 甲基化数据；利用 WGBS 数据在全基因组范围内分析造血细胞的 DNA 甲基化情况；利用 RRBS 数据分析在肿瘤中对 DNA 甲基化异质性进行定量分析。我没有测试是不是文章中所有的图都是 R 包直接出图，如果是的话感觉整体分析起来还是比较方便。 相关内容 目前常见的 DN 甲基化测序手段 Whole-genome bisulfite sequencing (WGBS) genome-wide coverage single-basepair resolution poor sensitivity for detecting small differences Reduced representation bisulfite sequencing (RRBS) cost-effective studying DNA methylation heterogeneity the microarray-based Infinium DNA methylation assays MethylationEPIC BeadChip (EPIC) HumanMethylation450 BeadChip (450k) 文献题目：Compressed Filesystem for Managing Large Genome Collections **DOI(url)😗*https://doi.org/10.1093/bioinformatics/btz192 **发表日期：**18 March 2019 关键点 如何管理众多的基因组文件 参考意义 基因组数据的增长速度在一定程度上超过了我们的存储容量，另外还有传输，处理和分析的问题。每隔几天就会看到又有新的基因组被发布，这其中不乏类似于小麦这种的超大基因组。可能你服务器上有大大小小的很多基因组，如何把他们进行合理的压缩和管理就成了一个问题。该工具基于物种间的相似性对基因组数据进行压缩，感觉自己后面可能会用的到，先放在这里有需要的时候方便再查看。 相关内容 说到基因组管理工具，还有一个 genomepy 是用来从三大数据库进行下载的。 文献题目：Identification of human silencers by correlating cross-tissue epigenetic profiles and gene expression. **DOI(url)😗*https://doi.org/10.1101/gr.247007.118 **发表日期：**18 Mar 2019 关键点 鉴定 enhancers 的多但是鉴定 silencers 的少 参考意义 作者利用具有组织特异性的 H3K27me3-DNase I 超敏感位点（DHS）peaks 与 25 种不同细胞系中邻近基因的表达负相关，同时利用 Hi-C loops 或者 eQTL 进行进一步的鉴定。另外，这些位置也富集了 CTCF, MECOM, SMAD4 和 SNAI3 等 transcriptional repressors。除此之外，作者发现 snp 在预测 silencers 时和疾病表型显著相关。 相关内容 表观修饰作用 The methylation of H3K9, H3K27, or H4K20 is commonly associated with transcriptional down-regulation (Mozzetta et al.2015). In particular, H3K9me3 features heterochromatin formation of chromosomal regions with tandem repeat structures (Kim and Kim 2012). H3K27me3, which is catalyzed and maintained by Polycomb repressive complexes (PRCs), directly inhibits gene transcription by impeding or poising the occupancy of RNA polymerase II (van Kruijsbergen et al. 2015). Transcriptional dynamics during development and disease initiation have been attributed to H3K27me3 (Simon and Kingston 2009; Sexton et al.2012; Jiang et al. 2013; Pinello et al. 2014; Laprell et al. 2017). Notwithstanding the fact that H3K27me3 is well-known as modification of silencers, the regulatory contribution of H3K27me3 has been asserted to be context-dependent (Young et al. 2011; Lv et al.2016). H3K27me3 and H3K4me1, simultaneously recruited by Polycomb repressive complex 2 (PRC2), collaborate to precisely fine-tune the expression of targeting genes in pluripotent cells(Mikkelsen et al. 2007; Schwartz and Pirrotta 2008). 相关文献 Epigenetic memory at embryonic enhancers identified in DNA methylation maps from adult mouse tissues Genome-wide analysis of histone marks identifying an epigenetic signature of promoters and enhancers underlying cardiac hypertrophy 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名 - 非商业性使用 - 禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-03-22-weeklypaper/"},{"title":"学习新工具的思路","content":"有两件事情，第一是前几天看到一个朋友分享了自己 学习生物信息工具的经验，借着这个机会刚好反思了一下自己过去几年是如何做的；第二是最近有人问了我一个问题：“使用 tophat 比对完的转录组数据 bam 文件想用 RNA-SeQC 来质控，但是这个软件好像没人维护了”（竟然还在用 tophat）。那这次就聊聊如何学习一个新的工具。 学会提炼需求 学习新工具有两种途径，一种是按需搜索一种是被动获取。被动获取还好，就是一般最新的杂志发表了什么平台推荐了什么就看什么。如果是按需搜索需要首先明白自己的需求是什么。 举一个最简单的例子，如果你使用一个转录组拼接工具提示内存不够了不能正确运行。这个时候你的需求是什么，很自然会想到去找一款需要消耗内存更少的软件。然后找了另外两个软件，一测试一个效果非常不好另一个压根自己不会安装。卒。 但如果换个角度分析一下自己的需求，你要做的可能是想办法去除 input 文件中那些只带了冗余信息的 reads，进而减小拼接工具所需要的内存。 做一件事情，总有前因后果。遇到问题除了盯住眼前的一点点内容，还要尽可能往前看一看向后想一想。 搜索工具 搜索引擎 明确了自己的需求，接下来就需要去找想要的工具。首先是搜索引擎，通常我们建议在力所能及的情况下，先 Google 再国际版 bing 在 bing 在百度。当然，你可能还听说过一些程序员自己开发的小众搜索引擎，其实本质就是人为提高了一些网站的搜索权重。国内目前有一个叫做 http://caup.cn/ 的工具类似于 duckduckgo，不过它的地址偶尔会变，属于打一枪换一个地方。 说到搜索引擎，我曾经写过几篇相关的搜索技巧，比如在 Google 中指定搜索哪一个网站或者哪几个网站，指定搜索什么样类型的内容。你要是有心也可以去网上自己找找类似的内容学习。 moicX moicX 之前叫做 omictools，最近改版之后增加了很多非常强大的功能同时伴随而来的是持续的邀请你付费。omicX 的口号是释放大数据的潜能（Unleashing the value of big biodata）。按照官网的说法他们现在已经索引了 30k+的 protocol，50k+的 datasets 以及 40k+的 software tools。很多时候在这里就可以找到你需要的工具了。 文献积累 自己搜出来的工具，很多时候都感觉用着没底。还有一种比较简单的方法就是去自己的文献库中搜索，你看过哪些文献可能记不住具体的细节，但是总应该知道他做了什么，如果人家做过的事情也可能涉及到你目前的需求，去翻翻人家的文章，没准就有意外收获。而且人家用那个工具已经发了文章，你总不会自己担太大的风险。 学习工具 通过一番搜索，你或许找到了两三个感觉自己可以用的工具，接下来的问题就是怎么学习和使用的问题了。学习一个工具大致有如下几个主要的思路。 快速查看 input 和 output 可能一个软件的 manual 有好几十页上百页，有十几个命令上百个参数，但是这些都不应该是你最开始先关注的问题，你要做的是先快速的找到它的输入文件和输出文件。一看他的输入文件是不是你手里现在有的数据类型内容，或者是不是可以比较方便的转换；二看他的输出文件会不会有你想要的那个结果或者可以很方便的进行二次处理得到你要的结果。如果这两者有一样不满足，首先把它放在一边，即便这个软件引用再多写的再好，可能并不适合此刻的你。 查看原始文献 如果，发现了这个软件的输入输出内容都比较符合你的需求，接下来要做的最好是浏览一下它原始文献的关键信息点。这一步不是必需步骤，但是强烈建议不要舍去。泛读工具的原始论文可以让你简单了解其开发背景和实用的方法，而且通常会包含和过往工具的一些比较，以及自己的优势特长。如果你发现自己很在意文章中所提到的优势你就可以留下来进行后续步骤，如果人家的注意事项里强调的问题恰好是你目前的状况，可能这个工具就又要舍弃了。 看谁引用了它 看完原始论文，接下来的一步依旧不是安装使用而是建议再看看有哪些后续的文章引用了它以及这些文章的水平。这样做，一方面是看看它的受认可程度，另一方面是要学习别人怎么用它。在 pubmed 或者 google 学术中，你可以轻易的看到有哪些文章引用这篇文章，挑几篇出来索引一下，看看别人是在什么前提和需求下使用了这个工具，以及别人在用这个工具的时候进行了哪些设置。 在这一步还可能会有意外惊喜，比如你发现一片更新的文献引用了它，而这篇文献恰好也是一个类似功能的工具，但是表现更加优秀。 使用工具 注意，至此你都还没有仔细看过这个工具的 manual 或者详细的帮助文档，不要担心因为很可能你根本就装不上这个工具，更别提用了。但是你可能会问为什么一开始就不先装这个软件呢？那是因为一旦装不上你就很可能失去了了解和学习这个工具的唯一机会，也很可能就错过了通过它了解到其它相关内容的机会。总之，多看点文献总是好的。 安装 安装这一步没法展开说，但是按照现在的风气如果我说「300 字学会软件安装」恐怕是要犯错误。推荐你去看技能树开发的生物信息软件安装入门课程，只需要在腾讯课堂的搜索界面输入生信软件，然后按照人气排序，排在第一位已经卖出去** 900 多份**的那个就是了。 只提醒一句，如果一个软件需要的依赖环境太多，需要的各种配套内容很旧。那通常是你没有找到和它同类更好更方便的工具。比如 OrthoFinder 之于 Orthomcl。 跑测试文件 软件装好了也想好了要跑那些命令。先别急着直接上，把 input 文件随机提取出 1/10 或者 1/50 去进行一下测试，确认一下是不是能跑通也能给出你想要的结果。因为现实和想象总是存在着一定差距，很可能 1/10 的数据已经内存不够了。 即便跑通了也不要着急，这个时候可以相对仔细的学习一下官方帮助文档或者看一些七七八八的教程。试着修改几个你感兴趣的参数，看看会不会得到更理想的或者很奇怪的结果。如果有，你就要再去想想自己应该用调整哪些参数来处理自己的实际数据。 实际运行 实际运行需要注意的就是留意一下软件的 log 文件和报错信息。如果一旦出了问题，自然又回到了搜索一步，再一次强调掌握一些常规的搜索技巧十分重要。 如果顺利拿到了结果，恭喜你完成了初级阶段，很可能得到的结果和你自己的预期相差甚远。这个时候，就又要回到文章的开头，想一想问题出在了哪里又该何去何从。 发现了么，当一个合格的「调包侠」似乎也没那么容易。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-03-14-learnanewtool/"},{"title":"Coder：进击的服务器 Web 版 VSCode","content":"自从用上 VS Code 之后，断断续续写过几篇文章。比如： VS Code 使用初体验 VS Code 常用快捷键 VS Code 思维导图学习笔记 VS Code 系列 1：提升 R 和 Python 使用体验 在这个过程中，各种牛 X 的插件让我感觉 VS Code 就要统治世界了。比如 PDF 阅读器插件，Excel 查看插件，有了这些东西在一个工作目录下基本不用开其它的软件，直接在 VS Code 中全部搞定。除了这些还有不少「不正经」插件，比如提醒 番剧更新的插件，播放音乐的插件 还有 看电子书的插件。真是神奇：) 同时我也写过怎么让 本地 PC 和服务器可以更顺畅链接 的问题，在这个文章里没有提到 VS Code，但是用它提供的 terminal 可以替代 Xshell。 最近发现了一个开源软件真的是让本地 PC 和服务器可以更顺畅链接而且非常之简单，可以说从某个层面基本解决了数据分析环境的问题。无论你使用 PC 还是用 mac，无论用笔记本还是平板，只要有网能打开浏览器的设备都可以愉快地在服务器上写代码做分析。之所以能愉快地写就是因为它的使用体验和 VS Code 完全相同。 Coder 简介 这个叫做 Coder 的软件，官网简介如下： Coder is an open source remote development environment serving Visual Studio Code. Accelerate your workflow and surpass the capabilities of your local development machine. 简单说 Coder 之于 VS Code 就相当于 Rstudio server 之于 Rstudio。 初步试用之后这样的类比并不夸张，Coder 确实是像素级把 VS Code 移植到了 Web 端，包括但不限于所有的界面设置、使用体验以及绝大多数的插件，再加上 VS Code 本身就很好用的 Terminal。基本上就做到了随时写随时在服务器测试运行。如果不用了就把网页一关，脚本直接存在服务器，程序在服务器上还可以继续跑着。 在写简单使用方法之前，先上一张实际截图自行感受。如果不是我故意把浏览器截下来，不知道你能不能看出来这其实是一个网页。 使用 真的不难，所以不废话。 官网下载 GitHub 提供了两种不同的安装方式，docker 和二进制编译文件。我这里使用的是编译文件，不需要安装直接解压即用。在 下载页面 选择你需要的版本，wget 到服务器正常解压缩，会看到一个code-server的可执行文件。 小坑和启动 因为我的 openssl 是用 conda 装的，不知道为什么在启动调用 openssl 的时候默认路径下没有openssl.cnf文件。解决方式也很简单，locate 一下这个文件的实际位置，然后链接过去就解决问题。 # 报错信息 #% openssl req -new -sha256 -subj /CN=localhost -key #/tmp/dd56f7a6a17f8221d17ee68f3a0080128caa2868 #Can't open /home/user/miniconda3/ssl/openssl.cnf for reading, No such file or directory #139916132833024:error:02001002:system library:fopen:No such file or #directory:crypto/bio/bss_file.c:72:fopen('/home/user/miniconda3/ssl/openssl.cnf','r') # 软连接到相关位置 cd /home/user/miniconda3/ssl/ ln -s /home/user/miniconda3/pkgs/openssl-1.1.1a-h7b6447c_0/ssl/openssl.cnf openssl.cnf 主要参数 使用 help 查看一下主要参数。 USAGE $ code-server [WORKDIR] ARGUMENTS WORKDIR [default: (directory to binary)] Specify working dir OPTIONS -d, --data-dir=data-dir -h, --host=host [default: 0.0.0.0] -o, --open Open in browser on startup -p, --port=port [default: 8443] Port to bind on -v, --version show CLI version --allow-http --cert=cert --cert-key=cert-key --help show CLI help --no-auth --password=password 这里最主要的三个参数是-d 工作目录， -h IP 地址和-p 端口。另外，--cert和--cert-key 是安全设置，可以查看文档具体说明。不想要生成的随机密码可以指定--password参数。 有一点需要注意的是 coder 默认的端口是 8443，可能需要提前在防火墙中打开端口然后进行监听，或者指定一个可用的端口号进行登录。如果想要一直运行放在后台即可，同时搭配 四步实现内网穿透 就可在任何地方通过任何设备的一个浏览器来操作内网服务器了。 祝使用愉快。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-03-10-webvscode/"},{"title":"用 bedtools 和 bedops 对 bed 文件进行各种运算","content":"bedtools 的傲人光环 如果让你说出日常在进行生物数据分析时，做的最多的事情是什么，我想不管你是什么方向，「不停地转换格式」应该能排进日常前三。如果再问用的最多的工具是什么，想必一定也是和「不停地转换格式」相关的工具。 在这些工具里有几个叫 XXtools 的非常出名，其中 samtools 和 bcftools 我们这次暂且不提，它们都是出自大神 LiHeng 之手。另一个能脱口而出的恐怕就是 bedtools 了，这个工具最初发表在 Bioinformatics 的文章，谷歌学术显示自 2010 年以来已经有了 6600 多次引用。当年这篇文章的第一作者 Quinlan ，如今已经是 UNIVERSITY OF UTAH 很厉害的 PI，它的课题组先后开发了一些列优秀的生物信息工具。当然，他们的故事今天也暂且不提（那位朋友问了，你今天到底要说啥，且看下文）。 6600 多次引用（其实现在很多文章用了它已经不引用了）让 bedtools 在 bed 相关格式文本处理领域一家独大。我经常半开玩笑地说 50% 高通量数据后期分析概括一下都是各种位置之间的纠缠，因为但凡分析有参考基因组的数据就会把所有信息都铆定到参考基因组这个坐标系中（如果没有基因组那就拼一个），这也是为什么 bedtools 从一推出就如此受欢迎。在生物信息这个领域，一个软件是不是会被大量使用，最重要的是它是否真的有用然后再加上一点点出现的时机和运气。 bedops 略被忽视的优秀工具 除了 bedtools，其实还有一个处理 bed 系列文件很强大的工具没有引起太多人的注意，这个软件叫做** bedops**。比 bedtools 晚出生两年，同样发表在 Bioinformatics，至今它的文章只有 273 次引用。当然这里的「只有」是和 bedtools 进行对比而言，不要误会。 bedops 突出的特点是多快好省。它的运算速度要比 bedtools 快不少（后来 bedtools 升级速度有所改善）同时针对大文件很省内存，而且支持各种 pipe 的结合连用。具体可以了解 官方文档，其中作者专门做了一个「你问什么应该使用 bedops」的解释。链接如下： https://bedops.readthedocs.io/en/latest/content/overview.html#why-you-should-use-bedops 这篇文章不会对 bedops 的功能逐一介绍，但是从今天开始你的心里要记住一件事：bedtools 中 95% 的功能在 bedops 中都有对应的方法（有些实现的更好），而且 bedops 还有一些其他特有且好用的命令。另外 bedops 有一个的隐形有点也需要记住，如果有一天你在使用 bedtools 处理某些大基因组数据，因为超过软件本身的各种限制而报错无法使用时，用 bedops 吧，它不存在这类问题。 总之，从今以后，你的心里不该只有 bedtools。 试举一例供你参考 考虑到文章篇幅，接下来只为大家介绍一种日常分析比较常见的需求供参考：对两组 bed 相关文件进行统计计算。 具体分析场景： 已有两组感兴趣的位置文件，至于这些位置是从哪来的都无所谓，可能是某组基因所代表的坐标，可能是某些分析找出的结合位点，还可能是一些 snp 或者 indel 的变异信息。有了这两组位置信息，如果只是想知道一些交并补集的逻辑运算在 bedtool 中常用的 intersect, closest, merge 等等就可以完成。但是，如果想根据一组位置，对另一组位置对应的某些数据进行相对复杂些的统计计算要如何操作呢？ 比如想知道在 1024 个上调基因位置区间（一组位置）内每个基因里有多少个某某转录因子的 peak，每个区间这些 peak 的最大值是多少，亦或者这些 peak 峰度均值和变异系数（另一组位置对应的某些数据）是什么。 使用 bedtools groupby 在 bedtools 中有一个对应的命令叫做 groupby, 官网文档对这个命令的基本解释如下： Given a file or stream that is sorted by the appropriate “grouping columns” (-g), groupby will compute summary statistics on another column (-c) in the file or stream. This will work with output from all BEDTools as well as any other tab-delimited file or stream. groupby 主要参数为 -g、-c 和 -o。其中，-g 指定根据那些信息进行 group，默认是根据 bed 文件的 1-3 列； -c 指定针对哪一列数据以 group 为单位进行各种运算； -o 则指定进行何种运算。 目前，groupby 可以进行的运算内容如下： sum - numeric only count - numeric or text count_distinct - numeric or text min - numeric only max - numeric only mean - numeric only median - numeric only mode - numeric or text antimode - numeric or text stdev - numeric only sstdev - numeric only collapse (i.e., print a comma separated list) - numeric or text distinct (i.e., print a comma separated list) - numeric or text concat (i.e., print a comma separated list) - numeric or text freqasc - print a comma separated list of values observed and the number of times they were observed. Reported in ascending order of frequency* freqdesc - print a comma separated list of values observed and the number of times they were observed. Reported in descending order of frequency* first - numeric or text last - numeric or text 具体的使用示例去参考官方文档吧，只提一句，一般 groupby 和 intersect 连用较常见。 使用 bedops bedmap 针对上文提到的需求，在 bedops 中有一个对应的核心工具叫做bedmap，它可以根据你的基因组输入文件提供各种各样的统计操作。 bedmap 的输入文件为两个 bed 文件，其中一个用来分 group 的叫做 ref-bed，这个文件可以是最简单的三列格式，用来提供位置信息；另一个需要进行后续计算的 bed 文件叫做 map-bed ，它根据实际计算需求要提供 4 列或者 5 列的 bed 文件，其中 1-3 列为位置信息，第 4 列为 id，第 5 列为要计算统计的 value。 一个典型的 map bed 文件格式如下： chr21 33031165 33031185 map-1 1.000000 chr21 33031185 33031205 map-2 3.000000 chr21 33031205 33031225 map-3 3.000000 chr21 33031225 33031245 map-4 3.000000 chr21 33031245 33031265 map-5 3.000000 chr21 33031265 33031285 map-6 5.000000 chr21 33031285 33031305 map-7 7.000000 bedmap 参数整体可以分为三大类，如下所示： USAGE: bedmap [process-flags] [overlap-option] &lt;operation(s)...&gt; &lt;ref-file&gt; [map-file] 第一类是处理参数，例如指定处理速度（是否开启快速处理）和数据格式等；第二类是 overlap 参数，即满足怎样的条件才进行计算，例如指定位置间 overlap 的碱基数或者比例等，这一部分就比 bedtools 灵活很多；第三类参数则为运算参数，其中一个子类是分值类计算，例如最大值，均值，中位数和变异系数等等，另一个子类是非分值类参数，例如包含个数等。需要提醒，如果进行分值类运算 map bed 需要 5 列，如果是非分值类运算 map bed 文件根据要计算的内容不同还略有差别。更多的使用方法和技巧有机会就再写写，如果你感兴趣还是去学习官方文档。 写在最后 就个人使用体验来说，我目前已经把绝大部分 bed 文件相关处理工作从 bedtools 转移到了 bedops，现在也把这个工具推荐给你。 当然，除了上面两个工具，在 Python 和 R 中也有人进行了相应的移植工作以满足不同的使用环境和需求，在文章的最后列出来供你参考。 Python：pybedtools; bedtools-python R: bedr 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-03-03-bedopsandbedtools/"},{"title":"RNAseq 必读综述和在线教程","content":"最近读到一篇 博文，介绍了学习 RNAseq 数据分析非常推荐的两篇综述和七个在线教程并发表了相关评论。本文将进行简要整理并对相关评论内容进行大致翻译，供国内读者参考。 两篇综述 J. Costa-Silva et al. 这篇文献 基于实际 qRT-PCR 测量得到的结果对各种统计分析技术进行了详细的比较。他们得出的主要结论是 NOIseq，limma + voom 和 DESeq2 是精度，准确度和灵敏度三者平衡最好的几组软件。本文的图 1 展示了 RNAseq 数据分析不同阶段中使用的各种工具的精彩总结。 Ana Conseca et al. 2016 年的这篇文献应该叫做 RNA-seq 分析方法中的沃尔玛. 它方方面面都有涉及到不少东西因此也被很多文章引用。 在线教程 接下来将会提到七个详细的在线教程。你可以下载他们的数据然后尝试使用 R 重现分析步骤。唯一的缺点是这些教程主要介绍了六七年前发布的成熟方法。如果你正在找过去两三年内发布的那些方法（例如 Kallisto，Salmon）就需要查阅它们的用户手册了。 Annick Moisan, Ignacio Gonzales, Nathalie Villa-Vialaneix 这个教程 在统计方面非常强，你可以下载他们编写的很好的 pdf 版本 教程。 Friederike Dündar, Luce Skrabanek, Paul Zumbo 这个教程 是生物信息教程中为数不多带有详细实验步骤的。 Thomas Girke, Rakesh Kaundal (UC Riverside) 来自加州大学河滨分校的 Thomas Girke 的教程 非常优秀， 这里 还有一个他旧版教程的 PPT。 另外，来自同一个学校的 Rakesh Kaundal 也有一个 详细的教程。 Mike Love Mike Love 是 DESeq2 的主要作者，他在 bioconductor 上有一个 很棒的教程. 同时别忘了看 DEseq2 的 vignette. Stanford Bios221 这个小组发表了和各种 Bioconductor 主题相关的 一系列详细教程 其中就包括是用 edgeR 来分析 RNAseq。 University of Cambridge 这个教程 是一个而来自剑桥大学的优秀在线教程。 List of All Analysis Steps including Biological Analysis Weijun Luo 是 GAGE 和 pathview 这两个工具的作者，他发表过一个关于 RNAseq 分析流程的 简要总结。 上述所有提到的 PDF 相关文档已经下载打包，下载地址：链接：https://share.weiyun.com/5rvQy3e 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-02-23-rnaseqreviewandcourse/"},{"title":"linux 去除文本中的空行","content":" sed grep tr awk 测试文件如下： $ cat tmp.txt a b c d e sed $ sed '/^$/d' tmp.txt grep $ grep . tmp.txt or $ grep -Ev &quot;^$&quot; tmp.txt or $ grep -v -e '^$' tmp.txt awk $ awk NF tmp.txt or $ awk '!/^$/' tmp.txt or $ awk '/./' tmp.txt tr $ cat tmp.txt | tr -s '\\n' 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-02-11-linux-remove-blank/"},{"title":"给你的印象笔记模板使用心得","content":"说明：本文首发于少数派。可在 少数派官网 阅读完整版本。 目录 为什么要使用模板 好用的官方模板 我的私人模板 模板相关使用技巧 为什么要使用模板 一个优秀的程序员会把「DRY」作为自身的行为准则，即 Don't repeat yourself。同样，一个高效的记录者也不应把同样的内容反复重复记录，而是需要学会借助模板的力量。 提到模板不知道你会想到什么，我最先想到的是小时候使用的「田字格」练习本。这个模板简单到只有一横一竖再加一个方格，但是对于初学写字的人来说却非常重要，它让我们知道汉字的结构和书写规范，让我们明白每个字的不同部位都有各自的位置不可以随意摆放。 同样，在记录的过程中学会合理使用模板也非常重要。一方面，对于新手来说使用笔记模板在规范记录习惯的同时还可以培养良好的思考方式；另一方面，对于高端玩家来说使用个人深度定制的笔记模板则可以大幅提高工作学习效率。 印象笔记（除特殊说明本文提到的印象笔记泛指国际版 Evernote 和国内版印象笔记）作为一款优秀的笔记应用，近日也在客户端中深度整合了模板功能（目前 Evernote 官方客户端已经支持在笔记中快速插入模板，印象笔记客户端模板功能已经开始内测）。下文我将结合自己的使用经历向你推荐几个印象笔记或者 Evernote 官方提供的优秀模板，并介绍一些关于模板的使用心得。（文本提到的所有模板已打包导出，可在文末点击下载后直接导入印象笔记客户端使用） 好用的官方模板 日历日程模板 通用指数：⭐⭐⭐⭐⭐ 实用指数：⭐⭐⭐ 日历日程类的模板可以细分为月历周历和日程。跨度时间由长到段，记录的内容也可以越来越详细。 月历和周历近几年可以是说各厂家最火的周边之一，不少人的办公桌上都会有一本精致的周历，我也不例外。我曾经入手过果壳的「物种日历」和丁香医生的「健康日历」，从实际使用情况来看它们的记录提醒功能越来越弱，更多的变成了某种个性或者知识的展示。 因为印象笔记自身较弱的提醒功能，月历和周历模板也不太适合用来作为行程提醒。在月历中，可以记录一些重要的时间节点或者有纪念意义的事情，方便定期进行回顾或者留念。在周历中，可以把它作为周计划表（在内测版印象笔记中还提供了精确到小时的更加复杂的周计划表），每周初列出几项接下来的主要工作，方便周末进行复盘和写周报。在日程中，你可以为每天设置几个量化的指标，对自己的生活进行打分。 项目执行模板 通用指数：⭐⭐⭐ 实用指数：⭐⭐⭐⭐ 年底了，写年终总结的时候总是需要把一年来大大小小经手的项目做一次梳理。如果平时能为每个项目建立一个完善的项目管理笔记，做起梳理来自然游刃有余。 我目前还是一名在读博士僧，一年时间算下来大大小小的各种项目也有七八个，其中有主导也有合作，有些合作断断续续分为几个阶段跨度接近一年。如果你也有类似的情况，印象笔记推出的「项目执行模板」就非常适合你对每一个项目进行跟踪管理。该模板包括了项目概述、头脑风暴、时间表、阶段笔记和任务跟踪器等诸多部分。以下为部分截图： 学习笔记模板 通用指数：⭐⭐⭐⭐ 实用指数：⭐⭐⭐⭐ 无论你现在的身份是不是学生，写学习笔记都是日常经常会遇到的事情。这里的「学习」既可以是坐在教室里的大学课程，也可以是通过网络进行的各种公开课或者慕课，甚至还可以是某本书的阅读学习笔记。 提到笔记，目前最为大家熟知的应该是「康奈尔笔记法」。康奈尔笔记法本质就是一个三栏的笔记架构，首先笔记页面进行上下比例为接近 4:1 的划分，再将上半部分进行左右比例为 1:2 的划分。右上方最大的一栏（笔记栏）记录学习时具体的内容，左上方一栏（整理栏）记录学习后整理的重点，后期进行复习整理时可以在下方一栏（摘要栏）对笔记内容进一步归纳总结。 针对这种思路，印象笔记官方也提供了一个简洁的学习笔记模板，除了主要的三栏内容之外还加入了课程信息。 会议记录模板 通用指数：⭐⭐⭐ 实用指数：⭐⭐⭐⭐ 想要高效的主持和参加会议，一个好用的会议议程模板和会议记录模板必不可少。 如果你是会议负责人，为了保证会议的高效和精简应该在会议前制定好详细的议程安排并所有参会人分享，协助大家做好会议准备。这种情形可以使用「会议议程模板」。 如果你是一次会议的参与者，可以使用「会议记录模板」，记录下会议期间分配的任务、形成的决策和最终的要点总结，方面后期执行和进一步跟进。 日常记录模板 通用指数：⭐⭐⭐⭐⭐ 实用指数：⭐⭐⭐⭐ 日常记录类模板适用于那些我们会日常记录并且需要定期整理的信息，例如以月或周为单位的个人财务记录、个人健康和运动管理等等。 目前市面有很多优秀的专业记账软件可以帮助我们详细记录各类信息。如果你在个人财务管理方面有强需求，可以每周把这些专业软件中汇总的信息记录到印象笔记中；如果没有强需求，也可以直接使用印象笔记提供的财务管理模板进行大致记录。 如果你有健身的习惯或非常关注个人的身体状况，可以使用官方提供的健身模板。 计划清单模板 通用指数：⭐⭐⭐⭐ 实用指数：⭐⭐⭐⭐⭐ 除了学习和工作，使用印象笔记也可以进行生活相关的计划和清单管理，这里以旅行为例。如果你是一个热爱旅行的人，可以利用印象笔记提供的旅行规划模板来安排自己的每次出行。 在 Evernote 官网和印象笔记内测版中分别提供了精简和详细两个版本。 精简版旅行规划： 详细版旅行规划： 我的私人模板 印象笔记官方提供的模板虽然丰富，但落实到每个人的实际情况自然少不了做一些修改和调整。根据自己日常工作和生活中的一些高频操作，我也逐渐形成了一些私人模板。 debug 记录模板 因为工作中有一部分是编程相关的内容，经常会碰到各种各样的 bug。一开始自己并没有详细记录的习惯，出现问题就去网站和论坛搜一搜，搜到相关的内容解决之后就算 debug 成功。但随后遇到类似的问题往往还是不能独立解决，又要重复一遍之前的各种搜索和尝试。后来我就摸索出了一个「debug 模板」，遇到一个 bug 就把详细信息和解决过程记录下来。 每周写作模板 在我看来，写作是一项非常高效的社交方式，无需各种应酬交际，只需要通过文字就可以结交很多志同道合的朋友，同时还可以通过输出来内化自己学习的内容。从大学开始我就坚持定期写些东西，后来为了量化自己的写作内容就整理了「每周写作模板」。 读书笔记模板 「读书笔记模板」类似于上文提到的日常记录类模板，只不过被我修改后用来记录每本书的阅读进度。 这里需要说明的是每个章节的详细阅读笔记并不会写在这个表格中，而是利用笔记内跳转功能，将具体的笔记链接复制到对应的位置。这样一本书读完之后，这个表格既可以作为阅读进度记录，也可以作为整本书的读书笔记目录。后期回顾和再整理的时候异常方便。 模板相关使用技巧 看到这里，很可能你已经有了整理一下个人模板的想法。在文章最后一部分，我结合自己的印象笔记使用经验向你推荐几个和模板相关的使用技巧与注意事项，希望有所帮助。 如何使用模板 目前 Evernote 桌面客户端和移动端已经可以在新建笔记时选择直接插入官方推荐模板或者自定义模板（在 Evernote 中插入自定义模板为高级用户功能），而印象笔记桌面客户端也已经开始了这项功能的内测，相信很快就会在正式版的升级中和我们见面。 除此之外你也可以将模板单独保存为一条笔记，之后如果要使用该模板只需对模板笔记右击选择「复制笔记」后即可在新笔记中进行编辑。 熟练表格操作 如果留心观察上面提到的各种模板，不难发现其本质都是对印象笔记表格功能的操作。在建立 a*b 常规表格的基础上，还可以通过「下拉菜单」完成诸如修改背景颜色、调整表格宽度以及合并单元格等一系列操作。 此外还有一个关于表格的注意事项需要强调。桌面客户端到移动客户端的转换中表格的适配并不是十分完美，多列表格可能会出现宽度被严重压缩的问题。官方提供的很多复杂模板在桌面端使用没有问题，但是如果有很强的移动端编辑需求建议慎重选择。从以往的经验来看，自己建立的移动端使用模板最好不要超过两列。 灵活运用模板 凡事都讲究一个度的把握，模板的使用虽然可以帮助我们建立良好的记录习惯和思考方式，但过度依赖模板也会限制思路。应该学会充分利用印象笔记的应用内笔记跳转功能，既可以将不同模板通过合适的方式进行关联，也可以把日常并不十分规范的笔记链接嵌入到规范的模板笔记中相互补充。 最后，你可以到 Evernote 或者 印象笔记 官网查看更多模板，也可以 直接下载 上文提到的所有模板后导入印象笔记客户端进行使用。 注：题图来自 Evernote 官网 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-01-28-evernote-templates/"},{"title":"服务器和 Windows 本地电脑无缝衔接","content":" 服务器和 Windows 本地电脑经常需要反复上传下载文件，对于初级用户来说通常会建议其下载类似于 winscp 之类的软件。但是这类高频操作有没有无需借助其它软件更方便的方法呢？ 本教程使用前提： Windows 系统为 win10 且已经可以正常使用 Ubuntu 子系统 安装有 Xshell 这类可以用来链接服务器的工具 最好安装有 vs code 本地编辑器 所有测试是在内网之间进行且本地电脑为网线连接有固定 IP 地址 开启 win10 Ubuntu 子系统的 SSH 服务 进入 win10 Ubuntu 子系统安装 openssh 服务（如果已经安装可以直接跳过），并修改相关配置 sudo apt-get install openssh-server sudo vi /etc/ssh/sshd_config # 默认端口是 22，也可以修改为其它自己喜欢的和 Windows 不冲突的端口。 # 如果只希望监听固定的 IP 也可以进行相关的设置。 # What ports, IPs and protocols we listen for Port 22 # Use these options to restrict which interfaces/protocols sshd will bind to #ListenAddress :: #ListenAddress 0.0.0.0 # 其它设置基本不用修改，也可以根据自己的需要定制 确定本机的 IP 地址 bash 中可以使用 /sbin/ifconfig 进行查看，int 后面跟的就是 IP 地址，当然，也可以通过网络设置，查看 ipv4 的属性即可。 启动 SSH 生成 SSH key 并启动 SSH sudo dpkg-reconfigure openssh-server sudo service ssh start # 会出现如下提示 #* Starting OpenBSD Secure Shell server sshd # 如果不确定服务是否开启，可以使用 service ssh status 查看状态 开机本机防火墙 接下来需要开启本地的防火墙才可以开启访问， 在安全中心中选择防火墙和网络保护，然后选择高级设置。 在高级设置中选择新建入站规则 然后依次选择端口，TCP 再填入设置的端口，然后一路操作最后命名保存即可。 实际效果 Xshell 连接本地电脑 有些人找不到 Windows 本地好用的命令行工具，有些人推荐使用 git，我更推荐在 vs code 中调用本地 bash，现在开通 ssh 后就可以在 xshell 这类软件中通过ssh登陆了。 通过 scp 直接传文件 如果需要临时把一些服务器上的文件传到本地电脑，就不再需要打开 winscp 这类软件了。直接使用 scp 命令就可以轻松传到电脑上，非常开心。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-01-19-sshserver2pc/"},{"title":"IGV 哐当就不能用了，我的 debug 思路","content":" 不知道是哪一次更新，不知道是因为更新了什么，PC 上的 IGV 突然就不能用了。不能用了，怎么办。文章记录了我的 debug 过程以及一点思考。 最近一个多月有一件事情一直萦绕在心头，今天算是初步解决了，记录一下。 IGV 这个工具因为是 Java 写的，又因为 Java 全平台适配，一般不太容易出现 bug。在 Windows 上常见的问题一般就是由于 Java 32 位和 64 位造成的。在 64 位的电脑上安装了 32 位的 Java（通常默认就是 32 位），如果给 IGV 分配的内存超过了 2G，就会报内存错误。最直接的方法就是把 Java 升级到 64 位就可以了。 然而，我不知道是哪一次更新，不知道是因为更新了什么，自己 PC 上的 IGV 突然就不能用了。如果是因为 Java 可用内存的原因，用官方提供的 IGV.bat 通过 cmd 启动 IGV 是根本无法打开，但是我的 bug 表现是 IGV 可以正常启动但启动后只要进行任意一次点击就会闪退。 最初我的初步猜测是不是因为某一个内容的更新，导致了 Java，Windows 和 IGV 三者不兼容。于是我首先分别更新了最新版的 IGV 和最新版的 Java，然后还升级过一次电脑系统，不过问题都没有得到解决。 当时如果时间有限，debug 的最直接方式就是绕开 bug。 替代方案 必须要用的软件突然不能用了又着急用，应该怎么办。立刻买个 Mac 应该就可以避免 Windows 上的问题了，但是对于我目前的状态来说并不现实。所以只能立刻寻找替代方案，因为 Java 本身是全平台，我在服务器上安装了 IGV linux 版本，然后通过 Xming 在本地电脑上调用 Linux 开启的 IGV 图形操作界面。 这个方法给我解决了燃眉之急，不过从服务器通过 xming 在本地进行点选操作，很多操作会用明显的卡顿和延迟而且分辨率实在是低。虽然解决了马上就要用的问题，但并不是一个持久的方法。这个过程大概维持了一个月，直到最近今天又需要重度使用 IGV，硬着头皮也要把问题解决一下。 dubug 过程 我的相关 IGV 报错信息 # # A fatal error has been detected by the Java Runtime Environment: # # EXCEPTION_ACCESS_VIOLATION (0xc0000005) at pc=0x00007ffe51899e54, pid=8364, tid=0x0000000000004590 # # JRE version: Java(TM) SE Runtime Environment (8.0_191-b12) (build 1.8.0_191-b12) # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.191-b12 mixed mode windows-amd64 compressed oops) # Problematic frame: # C [atig6pxx.dll+0x9e54] # # Failed to write core dump. Minidumps are not enabled by default on client versions of Windows # # If you would like to submit a bug report, please visit: # http://bugreport.Java.com/bugreport/crash.jsp # The crash happened outside the Java Virtual Machine in native code. # See problematic frame for where to report the bug. # 详细阅读报错信息 因为我本身不懂 Java，只能根据报错信息提取自己认为关键的内容进行检索。 从以往的经验来看，首先要重点关注是哪里失败或者不能启动。在 log 文件的 header 部分恰好出现了一句话「Failed to write core dump. Minidumps are not enabled by default on client versions of Windows」，我认为这个信息应该非常关键，看样子很可能是因为 Windows 不可以写入 core dump 导致的，应该首先开启 core dump 试试。 在 SO 上查到了 core dump 的开启方式，对于 Java 8 使用 -XX:+CreateMinidumpOnCrash 即可。修改 IGV.bat 文件再命令行里添加该参数后重新运行，问题依旧存在，但是这次除了会生成 log 文件以外，还会生成一个大小有几 G 的 core dump 文件。看来这个问题并不是我 IGV 闪退的原因。 在检索的过程中，有中文帖记录了出现这样的问题是因为「JRE 的 version 和 JDK 不一样。所以，重新下载一个版本对应的 JDK 或者 JRE 就可以解决了」。虽然我其实 分不清 jre 和 jdk 有什么区别，而且也确定自己是不是同时装了这两个东西，但是抱着试试又不会挂的心态，我还是再一次卸载了电脑里的 Java。 这次因为担心是之前 Java 升级有问题，我还专门下载了 官方的 Java 卸载工具，想把自己电脑里所有和 Java 相关的东西都卸载个干干净净，重新来过。 按照 IGV 网站上给的 Java 8 下载链接，我又一次重新安装了 Java，运行之后竟然没有出现闪退的情况，因为根本就打不开了。其实这就是因为 IGV 网站上的 Java 下载链接引导我下载了 32 位的 Java 版本，但是 IGV.bat 中使用的内存配置是 4G，超过了限额。我又不得不再一次卸载 32 位重新安装了 64 位 Java，闪退问题依旧存在。 不过，至此我确认了自己的电脑不存在所谓的「JRE 和 JDK 版本不一致的问题」，信息如下： # JRE version: Java(TM) SE Runtime Environment (8.0_191-b12) (build 1.8.0_191-b12) # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.191-b12 mixed mode windows-amd64 compressed oops) 控制变量 Debug 一个非常重要的经验和做实验一样是需要 控制变量。如果有条件，不妨找一台能够正确运行某个程序的机器，看看它和自己报错的机器有什么差别。 为此，我分别测试了实验室不同的几台可以正确运行 IGV 的 PC，发现有人用的 IGV 版本较低，有人用的 Java 版本较低，但是大家都可以正常使用，于是我又分别测试了几个低版本的 Java 或者 IGV，然并卵。 考虑个人的笔记本系统和软件版本与我的工作 PC 高度一致，我又用最新版的 IGV 和 Java 8 在笔记本上进行了测试，神奇的是在笔记本可以正常运行。 至此，我基本懵逼。 因为 Windows 系统和 IGV 版本以及 Java 版本完全一致的情况下，我的笔记本可以正常运行 IGV，但是 PC 却不可以。这里面一定有某些不可告人的力量在操控。 理解报错 log 信息 通过上面几步折腾，问题的关键应该不在于解决 「Failed to write core dump」而是再向前回溯，这个时候就要理解 Java 生成的 log 文件究竟传达了哪些信息。 通常只有一个严重的错误引起 Java 进程非正常退出，出现了 Crash，才会产生一个文件名为 err+pid number 的日志文件。 EXCEPTION_ACCESS_VIOLATION (0xc0000005)，检索后发现很多 Java 的报错都会出现这一句话，他意味着 Java 应用 Crash 时正在运行 JVM 自己的代码，而不是外部的 Java 代码或其他类库。在这个位置还可能出现SIGSEGV(0xb)或者EXCEPTION_STACK_OVERFLOW这样的内容。 再往下看另一个重要信息点是 Problematic frame: # C [atig6pxx.dll+0x9e54] 这里的信息是显示 Crash 时 JVM 正在从哪个库文件执行代码。我遇到问题是 C，还可能是 V 和 J 等等。他们的意思 FrameType Description： C: Native C frame j: Interpreted Java frame V: VMframe v: VMgenerated stub frame J: Other frame types, including compiled Java frames 接下来我就阅读了一下 Java 的 debug 指南，里面的分析思路都是要看 C 后面提示了什么信息，然后给了一些 debug 的建议： The first step to solving a crash in a native library is to investigate the source of the native library where the crash occurred. If the native library is provided by your application, then investigate the source code of your native library. A significant number of issues with JNI code can be identified by running the application with the -Xcheck:jni option added to the command line. See The -Xcheck:jni Option. If the native library has been provided by another vendor and is used by your application, then file a bug report against this third-party application and provide the fatal error log information. If the native library where the crash occurred is part of the Java Runtime Environment (JRE) (for example awt.dll, net.dll, and so forth), then it is possible that you have encountered a library or API bug. If so, gather as much data as possible and submit a bug or report, indicating the library name. You can find JRE libraries in the jre/lib or jre/bin directories of the JRE distribution. See Submit a Bug Report. 仔细阅读之后发现基本等于白读，但是现在从报错信息中我已经完全明确了问题指向 atig6pxx.dll。 指果所因 既然定位到了 atig6pxx.dll ，就要查查它是个什么，搜索atig6pxx.dll windows 10。在前面几条结果中，我看到了这样几个信息 AMD Graphics Driver not working/incompatible with Win 10 Technical Preview OpenGl for crimson drivers 如此看来，这个 atig6pxx.dll 和 AMD 的显卡驱动有关，而我的两个显示器之一显卡确实是 AMD 的，从查询结果来看，AMD 显卡驱动的这个 atig6pxx.dll 和某些 win10 版本确实存在问题（有可能我用的就是有问题的版本？）。 接下来再试试 atig6pxx.dll Java的搜索结果，真的还搜到了相关的一个帖子，官方给的回复如下，就是要详细确定显卡和升级啊各种信息，看来这个问题确实是 Java 和 PC 的显卡驱动有 bug。同时又联想到我的控制变量实验，笔记本是** NVIDIA **显卡而不是 AMD，进一步让我相信问题可能真的出自 AMD 显卡上。 Crash is reported with JDK 8u161 in Windows 10. From the stack trace it appears to be a driver issue. Writing back to the submitter seeking additional details to System configuration including video card make? Version of installed video drivers? What is the outcome of updating drivers? Outcome with JDK 10 available at: http://www.oracle.com/technetwork/Java/Javase/downloads/index.html Exact steps to reproduce this issue in house? 解决问题 基本决定了 bug 的原因，接下来就要考虑如何解决问题。 首先我需要知道 Java 和显卡驱动怎么能联系到一起，于是检索一下Java graphics看看，找到了 官网的一些说明。 这里主要涉及 Java 2D 这么一个东西，在搜索的过程中又找到了 Java 2D 的 options。在检索的过程中，还从 SO 看到了 这样一个帖子，其中一个建议 也是对显卡进行一系列操作，其中提到了一个参数-Dsun.Java2d.d3d=false。 这个参数似乎有一点点眼熟，看到这里就要回过头重新看看 IGV.bat 文件了。 官方提供的 IGV.bat 实际命令如下 ::Get the current batch file's short path for %%x in (%0) do set BatchPath=%%~dpsx for %%x in (%BatchPath%) do set BatchPath=%%~dpsx Java -Xmx4g -Dproduction=true -DJava.net.preferIPv4Stack=true -Dsun.Java2d.noddraw=true -jar %BatchPath%\\lib\\IGV.jar %* 仔细看了一眼，官方这条命令实际调用的程序就来自 lib 目录的 IGV.jar，只不过添加了几个平时并不常见的参数，其中-Dsun.Java2d.noddraw=true和之前 SO 中建议添加的参数非常类似，而这个参数又是一个和显示性能相关的参数。隐约感觉问题就出在这里。 继续贯彻控制变量的思想，首先不加任何参数在 lib 目录下双击直接运行 IGV.jar，这次竟然没有闪退。回到 bat 依次修改上面三个参数进行测试，直到我把-Dsun.Java2d.noddraw=true 改为 false 后，闪退 bug 终于消失了。 至此问题得以解决。 复盘及与反思 综上，通过学习 log 文件，查找关键内容，控制变量测试，一步一步把 Java 的运行错误和显卡联系起来。可是谁能想到这错误竟然是和显卡相关呢？ 通过进一步的检索，了解下 Dsun.Java2d.noddraw 这个参数的作用 The following list describes some useful properties on Windows platforms. The DirectDraw/GDI pipeline is the default pipeline for Windows. Change this default as follows: -Dsun.Java2d.noddraw=true Disable the use of DirectDraw pipeline. GDI will be used instead. -Dsun.Java2d.noddraw=false Enable the use of DirectDraw pipeline. -Dsun.Java2d.d3d=false Disable the use of Direct3D pipeline. 更进一步的说明如下： The default pipeline on the Windows platform is a mixture of the DirectDraw pipeline and the GDI pipeline, where some operations are performed with the DirectDraw pipeline and others with the GDI pipeline. DirectDraw and GDI APIs are used for rendering to accelerated offscreen and onscreen surfaces. Disable DirectDraw pipeline: When DirectDraw is disabled, all operations are performed with GDI. Provide the following flag to disable the use of DirectDraw: -Dsun.Java2d.noddraw=true. In this case all offscreen images will be created in the Java heap, and rendered to with the default software pipeline. All onscreen rendering, as well as copies of offscreen images to the screen will be performed using GDI. Enable DirectDraw pipeline: In case the pipeline was disabled by default for some reason, it can be enabled by providing the -Dsun.Java2d.noddraw=false flag to the VM. However, typically there was a reason why it was disabled in the first place, so it is better not to force it. 也就是说，因为 AMD 显卡驱动中atig6pxx.dll的问题，我目前的电脑并不能只使用 GDI 来进行渲染，而是必须要开启 DirectDraw。至于更深次的原因没有深究的必要。 回顾整个 debug 的过程，虽然我一直在尝试使用控制变量的思路，但是具体的执行顺序不对。使用别人的电脑来控制变量，不相关的因素实在是太多，所以各种软件版本的不一致只是不一样的表象，并没有指明到是真正的显卡差别。而使用自己的笔记本和台式机做比较，其实已经排除了软件版本的关系。 最后才进行的控制变量测试其实才是变量最可控的最应该首先进行的，也就是在同一个电脑上对同样的软件进行不同的操作。其中一个操作是官方并不推荐的直接运行 lib 中的 IGV 程序，另一个操作是运行官方推荐的添加了三个参数的 IGV.bat 。如果把这一个测试提到第一步来做，就会节省大量的测试时间。 最后，对于 debug 的一些建议如下所示： 仔细阅读报错信息确定关键词 成熟的工具一定有着非常详细的报错信息，而我们要做的就是从详细的报错信息中提炼关键词进行检索 按照从小到大的顺序尽量找到一个可以正确运行的方式 想要找到问题所在很关键的一点是谁或者哪里成功了。这一步对之后的 debug 过程十分重要。 所谓从小到大的意思是正确运行和错误运行之间的差异越小越好。最好在自己的一台电脑上完成，只是改变软件的运行方式或者参数；如果不行就找配置尽量类似的电脑或服务器进行软件及版本的比较，越相似越好，以此类推。如果我首先能想到抛弃官方的建议打开方式，直接运行 jar 程序，直接就可以锁定参数问题。 控制变量是进行测试应该遵循的首要思路 通过检索，我们可以找到大量的相关信息，可能会存在各种五花八门的解决方法。如何判断哪些值得尝试哪些不值得尝试非常重要。对于本文的 bug，即便检索到了很多关于软件版本的问题，只要我在版本相同的另一台电脑运行成功了，那么所有和 Java 版本，Windows 版本以及 IGV 版本相关的内容都可以忽略，就可以省去很多卸载安装这样的无用功。 同时根据检索信息在结合控制变量的思想就更加容易锁定问题，进而找到解决方式。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-01-15-igvdebug/"},{"title":"研究生培养阅读习惯的十条法则","content":" 最近在 PLoS Comput Biol 上发表了一篇文章，作者对于研究生应该如何培养良好的阅读习惯给出了 10 条建议。简单整理供自己和大家参考。 法则 1：养成每天阅读的习惯 可以利用通勤时间，或者用白天几个零碎的时间。要相对仔细的阅读一篇论文而不是非常粗略的或者紧张的浏览一下。 法则 2：仔细阅读建立对主题的全面理解 你的将来一定会比现在更忙，所以没什么捷径，仔细阅读文章将为你提供有关你学科中的概念，方法，结果，潜在意义和含义等内容。一旦你具备了关于某个主题的良好背景知识，就可以开始更有选择性地阅读那些填补了特定空白或满足自己好奇心的论文部分。但是良好的背景知识需要很长时间才能建立起来，在你的职业生涯早期做好功课以便以后可以节省时间。 法则 3：不要忽视学科经典 一定要阅读经典论文，你可能正在科学的最前沿工作，但你的专业肯定有很长的历史。需要识别和阅读所在学科的基础论文，这里会涉及到概念，方法或观点。如果这让你不得不回到两个世纪以前也无所谓。只有通过阅读经典才能深入了解自己的研究课题，这不仅会阻止你重新造轮子还会使你能够为重大发现提供强大的背景。 法则 4：如果您必须熟悉新主题，可以按时间顺序阅读 在职业生涯早期，或者进入一个新领域要收集大量参考资料了解这个领域的时候，要考虑按时间顺序去阅读它们。如果所有参考文献都是最近的，那么这可以让你了解这些交流是如何发展的以及谁在回答谁的问题。如果时间跨度较长，你也会惊讶地发现概念，方法或解释可能随时间在变化。按时间顺序阅读将使你能够发现术语在使用或含义的变化，从而有利于增加你对主题的背景知识的了解。 法则 5：阅读其它领域的内容来避免变得狭隘 在其他学科的工作中很很多有趣的想法、概念和方法在等着你。密切关注其他领域的进步，在精读和泛读之间找到平衡。方法是确定一些关注范围更广泛的期刊并定期浏览其内容（参见法则 6）。也可以使用社交网络加入一些期刊俱乐部或关注特定领域之外的知名科学家。 法则 6：创建相关期刊列表 找出哪些期刊发布你研究相关的信息并订阅新内容的在线提醒。如果发现自己过滤到的期刊少于 20 种，可能就是缺少相关来源，这里也应该包括仅偶尔发布相关信息的期刊。不要忘记那些发表新分析，实验或统计方法的期刊，因为它们并不总是与发表基础研究的期刊重叠。准备在科学生涯中随时重新评估您的期刊清单 法则 7：并非所有有趣的东西都会出现在文章中，去看书 书籍提炼了知识或提出了开创性的想法，去阅读经典和近期的书籍。发现经典书籍相对容易，但是找到新的相关书籍并不像寻找新文章那样简单。Google 学术搜索和大多数重要社论都会为可自定义的新书提供提醒或邮件列表。另一种方法是找到包含新书部分内容的期刊，例如* Quarterly Review of Biology*。最后还可以咨询所在机构的图书馆了解新书的推广方式。 法则 8：使用文献管理工具来跟踪您的文献 首先，每天投入一些时间来更新最近的阅读材料。其次，永远不要在里面存储你没有读过的论文。未读文件最好存放在“待阅读”文件夹中，可以根据主题或紧急程度进行细分。第三，请记住，在文献管理工具中存储文献会强制你识别有意义的关键词。因此，不要仅仅导入已经包含在文献中的关键词，还要创建自己的个性化关键词列表，这将有助于建立你对该学科的背景知识。 法则 9：定期回顾记住所阅读的内容 你读的越多忘记的越多，记住自己所阅读内容的一种有效的方法是打开一个（或几个）主题的「review」供你自己使用。你可以使用文献管理工具做到这一点（法则 8）。不过，我建议使用电子表格或文本文档来存储主要文献中的基本信息或主要信息。 法则 10：建立自己的图书馆使自己独立并激励他人 你可以尽快开始自己的论文和书籍收藏，不要完全依赖自己机构的图书馆。考虑订阅一些特别有趣的期刊或成为发布相关期刊信息的社团成员。由于资金限制或在不同机构之间的轮转，在职业生涯早期建立自己的图书馆可能是一个挑战。然而，应用这个法则也不应等到你获得永久职位，并且数字图书馆始终是一个选项。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-01-10-reading10rules/"},{"title":"关于文档，还没人告诉你的那点事","content":" 学习一个新的工具或者软件，首选方法是阅读开发者写的软件文档，因为 TA 最清楚怎么回事；其次是阅读最新的英文相关使用讨论或者介绍，因为中文的很多资料往往滞后；再次才是阅读中文相关介绍，而且一定要谨慎参考认真判断。评判一个工具好坏的标准之一也是其文档是否写的足够「好」。 因此无论是开发者还是用户，文档都至关重要。那到底好的文档需要包含哪些内容或者应该如何写出一个尽量好的文档呢？最近看到一篇英文博客：What nobody tells you about documentation ，以下为尽量保留作者原意的不完全翻译版本供你参考。 写在前面 无论你如何认真地写软件文档，它可能都对你的软件起不到什么帮助，除非你掌握了正确的文档写作方法。为了写好软件文档你需要了解一个秘密：「文档」不是特指某一个内容，而是有四个。 它们是：教程 (tutorials)，操作指南 (how-to guides)，说明 (explanation ) 和技术参考 (technical reference)。它们代表了四种不同的目的或功能并且需要用四种不同的方法来写，了解这一点将有助于极大改进大多数软件的文档。 一个软件有多好并不重要，因为如果文档不够好，很多人就不想使用它。 即使由于某种原因（没有第二选择）别人不得不用，如果没有规范良好的文档，使用者也不会高效地或者按照开发者想要的方式来使用。虽然几乎每个人都明白这一点，每个人也都知道他们需要一个好的文档并且试图创建一个好的文档，但是大多数人还是失败了。这并不是因为他们不够努力而是因为没有找到正确的方法。 接下来我将解释如何使你的文档变得更好，不是更加努力而是通过正确的方式。所谓正确的方法其实就是更简单的方法：更容易编写，更容易维护。 The right way is the easier way - easier to write, and easier to maintain. 有一些非常简单的原则可以指导我们进行文档编辑，但似乎又像是一个秘密很少被人们提起和总结。如果你能够将这些原则付诸实践，它就可以使你的文档变的更好，进而使你的项目、产品或团队更成功。 原则 好的文档需要包含并围绕其四个不同的功能进行构建：教程 (tutorials)，操作指南 (how-to guides)，说明 (explanation ) 和技术参考 (technical reference)。每一部分都有自身独特的写作模式，使用软件的人在不同的时间不同的情况下会需要这四种不同的文档 。因此，需要围绕它们明确地来构建文档并且必须保持独立和彼此不同。 教程 学习为导向 (learning-oriented) 可以让新手轻松入门 可以理解为是一节课 如果要打个比方，就像教小朋友怎么做饭 操作指南 目标为导向 (goal-oriented) 展示如何解决特定问题 是一系列步骤 打个比方就是烹饪书中的一个食谱 说明 理解为导向 (understanding-oriented) 用来进行解释 提供各种相关的背景 打个比方就像是一篇关于烹饪历史的文章 参考 信息为导向 (information-oriented) 描述一个工具的系统方法 一定是准确而且完整的 类比的话，可以参考百科全书中的文章 以上这种分类可以使开发者和用户明白哪些信息在哪里。它告诉开发者如何写，写什么以及在哪里写，使他们免于浪费大量时间来尝试将想要传达的信息改为其他乱七八糟的形式，因为这四种文档，每一种只有一个任务。 如果这些文档没有明确地展现出自身用处和界限，想要维护一个良好的文档就是非常困难的。每种类型的文档要求都与其他三者不同。你一旦理解了这些结构它就能成为一种非常有用的工具，一方面你可以用它分析自己现有的文档，另一方面可以了解需要采取哪些措施进行改进。 教程 教程是让用户通过一系列步骤来完成某个项目的课程。它是你的软件所必须具备的，用来向初学者展示他们可以用它实现某些目的。教程完全以学习为导向，进一步讲，他们的目标是学习如何使用而不是了解你的项目。 此时你是一个老师并对学生将要做的操作负责。在你的指导下学生将执行一系列操作以达到目的。什么时候结束和进行哪些操作都取决于你，但决定一个初学者应该做什么非常困难，一方面这些操作和最终的结束点必须有意义，同时对于一个真初学者而言又要可以实现。 现在想想教孩子做饭的例子。你教孩子做了哪道菜其实并不重要，重要的是让孩子觉得做饭这件事很有乐趣并且有信心，同时还希望自己可以再来一次。通过孩子所做的事情，他将学习烹饪的一些重要事项并且将了解在厨房里使用餐具来处理食物是一种什么感觉。 使用软件（做饭）是一个「手艺」问题。它的确是知识，但它是一种实践得来的知识。当我们学习一项新的手艺或技能时，我们总是从实践开始。记住，完成教程后学习者应该就能够理解软件本身和其余的那些文档。老实说，大多数软件项目的教程都非常糟糕或者根本不存在教程。教程可以让一个学习者变成你的用户，错误或缺少教程将阻止你的软件获取新用户。不过好的教程很难写，它需要对初学者有用有意义易于参照且够强大。 如何写出好教程 允许用户通过实际操作进行学习 小时候我们都是通过实践和尝试来学习东西，比如说话或走路。在你的软件教程中学习者需要有事可做，而且他们所做的事情需要涵盖这个工具大量的操作，从最简单的操作开始再到更复杂的。 让用户走出第一步 不管初学者的第一步是复制粘贴，还是不像一个有经验的用户那样操作，或者甚至不是一个“正确的”使用方式，这些都是可以接受的。初学者的教程与最佳实践手册不同，教程的目的是让学习者开始他们的旅程而不是让他们到达目的地。 确保教程可以运行 作为老师你的一个重要工作是激发初学者的信心，有很多途径可以促成这一点，比如友好的语气和富有逻辑性的内容与资料等等。但最重要的是你要求初学者做的事必须确实可以做到。学习者需要看到你要求他们采取的操作会产生你答应他们会有的效果。如果学习者的操作产生报错或有了一个意外的结果那教程就等于失败了， 即使这不是你的锅。 当你的学生和你在一起时你可以现场解决问题；如果他们自己阅读文档你就不到这一点了。所以必须提前防止这种情况发生，emm，这说起来容易做起来难。 确保用户可以立刻得到结果 **初学者所做的一切都应该是容易理解的。**如果他在看到结果之前必须做很多步难以理解的操作那就很糟糕了。每一个操作的效果都应立即展示出来，并且明确它与操作之间的联系。教程的每个部分或整个教程的结论必须是有意义的。 确保你的教程可重复 教程必须能可靠地重复，这其实不容易实现，因为人们使用不同的操作系统，经验水平也不一样。更不要说他们使用的软件或资源很可能在一段时间内会发生变化，比如版本。因此教程需要定期和详细的测试，以确保它们一直有效。 关注具体步骤而非抽象概念 教程需要具体，围绕特定的操作和结果展开。引入抽象的概念通常诱惑巨大，但是所有的学习都是从特定和具体到一般和抽象。 提供最低限度的必要说明 不要解释学习者完成教程不需要知道的任何内容。扩展讨论很重要但它不是教程的作用，在教程中这反而是一个会让学习者分散注意力的绊脚石。只要有最低限度的解释就可以了，你可以链接到文档中其他地方的说明。 只关注用户需要采取的步骤 教程只需要专注于学习者手头的任务。也许你的命令有许多其他选项，或者可能有不同的方法来访问某个 API。但是现在你的学习者不需要了解那些就能取得进步。 操作指南 操作指南使读者了解解决实际问题所需的步骤。它们是食谱，实现特定的目标。例如如何创建 Web 表单，如何绘制三维数据集，如何启用 LDAP 身份验证。 操作指南完全以目标为导向。想想一个食谱就可以，它解决了一个具体问题，我们可以假设用户已经拥有一些基本知识，他仅仅想知道如何实现某些目标。操作指南与教程完全不同，操作指南是对初学者甚至无法提出的那些问题进行的回答。 在操作指南中我们可以假设用户已经知道如何执行基本操作并使用基本的工具。让我们开心的是，不少软件文档中的操作指南往往做得都还不错。 如何写出好的操作指南 提供一系列步骤 操作指南必须包含需要按顺序执行的步骤列表（就像教程一样）。你不必从头开始而是应该找到一个合理的起点。操作指南应该可靠，但不需要具有教程那样万无一失的可重复性。 关注结果 操作指南必须注重实现目标，其它的都会让用户分析，与教程一样，详细的说明在这里也不合适。 解决问题 操作指南必须解决特定的问题，也就是「我如何。..」。这是操作指南与教程不同的地方：当涉及到操作指南时，可以假定读者知道他们应该实现什么但不知道如何实现， 而在教程中你有责任决定学习者需要了解的内容。 不要解释概念 操作指南不应该进行解释，这里不是讨论的地方，它们只会妨碍用户操作。如果解释很重要请链接到该有的地方。 允许一些灵活性 操作指南应该允许用稍微不同的方式来做同样的事情。它需要足够的灵活性，用户可以看到如何应用于与你描述示例略有不同的场景，或者了解如何使其适应与你假设略有不同的系统或配置。 该结束就结束 实际的可操作性比完整更有价值。教程需要完整但是操作指南不需要。它们可以在合适的地方开始和结束，也不需要提及所有和主题相关的内容。臃肿的操作指南无法帮助用户快速获得解决方案。 认真命名标题 操作方法文档的标题应该告诉用户确切的内容并且指明是一个操作指南。比如「如何创建基于类的视图」就是一个好的标题，但是直接叫「基于类的视图」就不好了。 参考 参考是工具的技术描述和如何进行操作。 参考只有一个任务就是描述。它们是由代码决定的，因为描述的是：关键类，函数，API 等等，应该列出函数，字段，属性和方法等内容并列出如何使用它们。 参考以信息为导向。技术参考可以包含示例来说明用法但它不应该尝试解释基本概念或者如何实现通用的功能。参考资料也应该是切中要害的。用烹饪类比，它可能是一篇关于某种食材的文章，描述了它的来源、化学成分和如何烹饪等等。 请注意，描述确实包括了如何使用工具的基本描述，比如如何实例化特定类或调用某个方法，或者在将某些东西传递给函数时必须采取的预防措施。然而这仅仅是其作为技术参考功能的一部分而且和操作指南也完全不同。 对于一些开发人员，参考指南是他们可以想到的唯一文档形式。他们已经了解了自己的软件并且知道如何使用它，所以他们想象其他人可能需要的就仅仅是它的技术信息。参考往往很多软件也写得很好，现在它甚至可以在某种程度上自动生成。 如何编写好的参考文档 在代码周围构建文档 为参考文档提供与代码库相同的结构，以便用户可以同时浏览代码和文档。这也将有助于维护人员查看缺少参考文档或需要更新的位置。 始终如一 在参考指南中，结构，格式必须一致，与百科全书或字典一致。 只进行描述 技术参考的唯一任务是尽可能清楚和完整地描述。其他任何事情（解释，讨论，指导，推测，意见）不仅会分散注意力，而且会使其更难以使用和维护。避免使用参考来指导如何实现某种功能，并且不要对概念或讨论进行解释。如果需要，可以酌情链接到操作指南说明和入门教程中。 准确 这些描述必须准确并保持最新状态。工具与描述之间的任何差异都将不可避免地导致用户误入歧途。 说明 说明用来解释、讨论和阐明特定的一个主题，它们拓宽了文档对某一主题的覆盖范围。说明是以理解为导向的。解释同样可以描述为讨论。它可以让你从更广泛的视角，从更高层次甚至从不同角度阐明它。可以想象一个讨论文档是在闲暇时阅读的，而不是在浏览代码时阅读。 通常这部分文档很少被明确的创建，解释的片段会分散在其他部分中。其实说明和讨论不像看起来那么容易创建 ，它的主题不是由你想要实现的特定任务定义的（操作指南），也不是你希望用户学习的（教程），当然也不是具体的函数定义的（参考材料）。 如何写出好的说明 提供上下文 说明通常需要指明背景和上下文，有时候说明还可以解释「为什么是这样」，可能是设计决策，历史原因或者技术限制。 讨论替代方案和意见 说明也可以提供一些替代方案或同一问题的多种不同方法，甚至可以考虑并权衡相反的意见。 勿提供技术参考或指导 说明应该做的事情就是文档其他部分没有的东西。告知用户如何做某事并不是说明的任务它也不应该提供技术描述，文档的这些功能在其他部分中已经完成了。 关于文档结构 为什么分界不明显？ 上文讨论的文档结构很清楚并且很有效，但通常分界没有那么明显，这是因为文档四象限中每个象限与相邻的都会有一些重叠特征。 教程和操作指南是相似的，因为它们都关注描述实际步骤；操作指南与技术参考的交集在于它们是在实际工作和编码时所需要的；参考指南和说明相似是因为它们关注理论知识；最后教程与说明的共同点是它们在我们进行学习时最有用。如下表所示： 学习时最有用 工作时最有用 实际步骤 教程 操作指南 理论知识 说明 参考 鉴于这些重叠，不同类型的文档变得混淆并相互混合也就不足为奇了。虽然很难找到完全使用这四种结构的示例，但是大量的文档都在努力以不同的方式来完成这四个类别的任务。有些项目就完全采用了这种结构，包括 Django（虽然 在早期版本中没有明确说明）和 django CMS。这两个项目中都证明了这种结构的价值。 为什么要如此分析 本文的文档结构分析基于我多年编写和维护文档的经验并花了很多时间考虑如何改进它。它还基于各种学科的合理整合，例如，教程概念具有教学基础；而且它假定存在一个老师和一个学习者，并把使用软件作为一种「手艺」来看待。 使你的文档更有用 文档维护人员必须解决的最大问题是没有清楚了解他们应该做什么，以至于他们改了又改但发现还是很难令人满意。本文讨论的文档结构通过明确的分工来解决这些问题，基于此制作的文档也更易于编写和维护，同时也更易于使用。 应该写什么，怎么写，以及把它放在哪里都变得更加清晰。 总的来说，针对四象限中的每一个文档进行明确的编写有助于软件吸引和留住更多用户同时用户可以更高效地使用，这是软件开发者最想要的东西之一。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2019-01-02-howtowritedocumentation/"},{"title":"2018，思考问题的熊","content":" 2018 说走就走，还是得记录一下。 码字 我的博客 以下数据来自于 Google Analytics，我对比了几个统计渠道的数据，虽然有些渠道的统计量更高，但是看着都没有 Google Analytics 的合理和靠谱。 写博客一年多的时间，共有 9,113 个独立 IP 访问过网站，共进行了 15,000 次会话（用户在网站保持活动状态的时间段，如果用户在离开网站后 30 分钟内返回则之后活动仍将被计为初次会话的一部分）, 平局会话时长 2 分 57 秒，累计时长 750 小时。也就是说有接近一万人在我的博客共计度过了 31 天时间，是不是可以理解为我这一年其实有 13 个月？ 如果要评选出最忠实的读者和最投入的读者，其中有 5 个人有效会话数超过了 100 次，最忠实读者有效会话数竟然达到了** 382 次，说实话我写文章的时候会登陆一下博客也做不到如此 频率，共有 22 人次会话超过了 1 小时，其中一位以 2 小时 28 分**的阅读时间拔得头筹，很想知道 TA 那一天经历了什么。 在所有用户中，约有 25%拥有个人的兴趣标签，具体信息如下： 从时间段上来统计，上午 9 点-11 点，下午的 2 点-4 点用户量较多。 从地区的会话数来看，非大陆地区贡献了约有 25%的此时。 我的简书 简书这个平台的统计数据来自官网和更更写的 简书数据爬虫脚本，在此首先笔芯感谢。简书上的内容其实和博客 90%重合的，在此只是简单统计下 2018 年的一些情况。截止目前我在简书上共有 1,812 个粉丝，170 篇公开文章，写下来 363,168 字，获得了 4,458 次喜欢和共计 109,737 次阅读。 其中 2018 年简书平台读者阅读量最高的 10 篇文章 2018 年简书平台最受读者喜爱的十篇文章 看到这里不禁概括一下，文章要想阅读量和喜欢数目高就要考虑大多数人的需求和接受程度。比如我在简书至今最后的两篇文章都是和英语学习相关的，其中 如何用英语打开一扇门 ——我的非功利英语学习法 单篇 20k+ 阅读，1.4k+ 的喜欢，非功利性英语学习工具推荐（iOS 版本） 单篇 14k+ 阅读，900+ 的喜欢。 这里需要多补充一句，简书的几次改版已经基本把阅读和推荐机制改的不像样子了，而且现在平台确实充斥了很多没法看的东西，之所以还坚持放在简书上唯有两个原因：不错的 markdown 编辑器使用体验；国内相对较好的 SEO 优化。 比较有意思的是我的写作时间，大量都是在周日一天完成的，嗯，这算是充分利用休息时间吧 少数派 今年很幸运成为了 少数派 的作者，更幸运的是一共写了两篇文章都被官方推荐到了首页，累计收获了 71,248 次阅读和 467 个赞。其中 印象笔记入门进阶与避坑指南 竟然有 **50k+**人次阅读是我没有想到的。 感谢印象笔记感谢少数派，让我再次看到了题材和平台对于写作者的重要性，当然，希望这篇文章对正在用和想用一个优秀笔记工具的读者能有一些帮助。 小节 2018 年一年公开了大约 20 万字，粗略估计阅读量有十多万，当然我最看重的是博客的会话数。2018 年几个主要的收获和完成的 flag 都是通过写作帮我完成的，这也无形中有一次印证了我的一个看法：写作是一件非常高级简单的社交活动。 经历 2018 年有些比较特别的体验和经历值得记录一下： 作为印象笔记官方的印象大使参加了印象笔记 6 周年的活动并且认识了一些牛人，他们的经历和经验让我感受到了自我管理的重要性 和几个朋友一起做了一些有趣的事情，和专业有一丢丢相关又其实真没什么关系，从这些牛人的身上我收获了很多很多很多，无论是业务上还是生活上 第一次接触了少数派这样专业的编辑团队，和他们的协作让我意识到了高效协作的价值和重要性。 当然，还有一些经历感悟不方便拿出来讲也很难落实在纸面上，放在心里默默记着就好。 遗憾和 2019 这个遗憾说来很简单，就是 2018 年定下的最主要目标没完成，这怎么办呢？当然是搬到 2019 年（尴尬。gif）。 2019 年，从码字的角度说，受众广的文章应该会越写越少。但我会争取让一部分人参与到一个略带专业性质的写作协作项目中来，希望能顺利开展。 2019 年，对于我应该是一个更加在意学习和积累的一年，也是非常非常关键的一年。 最近这两三年感觉把该说的话和该写的字都说的写的差不多了，因此少扯淡多学习是六字方针。另外 3 个关键的 flag 已经立下了，2019 年底回过头再看看，争取不把它们带进 2020 年。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-12-29-my2018/"},{"title":"每周文献-181223-单细胞单分子表观","content":"单细胞及单分子在表观的应用 文献题目：Single-cell and single-molecule epigenomics to uncover genome regulation at unprecedented resolution DOI(url): https://doi.org/10.1038/s41588-018-0290-x 发表日期： 2018 Dec 17 关键点 这篇综述介绍了单细胞和单分子表观基因组学正在以前所未有的分辨率揭示基因组调控的各种机制。作者重点介绍了变革技术中的一部分，并讨论了它们如何被用于识别新的基因调控模式 这些技术如下表所示 参考意义 作者将这些分析与单细胞转录组学的最新进展进行了对比，论证了表观基因组学技术在理解细胞多样性和发现基因调控机制中的重要作用。 相关内容 另外这边文章的「Box」作者还首先阐述了进行表观研究需要测定的一些信息。如果你对表观遗传完全没有概念推荐了解。 TF binding to regulatory elements. Chemical modification to genomic DNA. Post-translational modifications of histones. Chromatin accessibility. 3-D genome organization 一种组装大片段重复区域的方法 文献题目：Long-read sequence and assembly of segmental duplications DOI(url): https://doi.org/10.1038/s41592-018-0236-3 发表日期： 2019 Jan;16 关键点 作者开发了一种基于长序列 reads 的多倍体 Pasing 计算方法，用来解决基因组组装中大片段重复的折叠区域问题。 方法流程图： 该方法利用旁系同源序列突变（PSV）和相关性聚类来精确组装先前在 long-read 人类基因组组装中塌陷的的 SD 的不同旁系同源大片段重复序列。 首先利用全基因组重测序数据根据深度的差异定义大片段的重复区域，其中大于 9kb 且覆盖度高于 3 个 sd 加上均值并且不全部是由 common repeat 组成的区域被认定为 SD ；接下来定义每个基因组塌陷区域的旁系同源序列突变 paralogous sequence variants (PSVs) 并对 PSV 进行聚类。随后根据 PSV 利用 WhatsHap 将 reads 进行分组然后分别对不同组的 reads 进行组装。 参考意义 在基因组异染色质和基因富集区域存在很多大片段重复 segmental duplications (SDs)，长度大于 100kb 并且存在于多个位置。即便是基于 FALCON 的单分子实时（SMRT）测序的基因组组装在很多结果中也有一半类似的区域没有解决。 当前 ONT (https://nanoporetech.com/) 和 PacBio (https://www.pacb.com/) 的主要问题是测序的错误率会达到 10%-15%，主要针对 WGSA 的长序列组装方法是基于 reads 的矫正和矫正后的重叠来得到更长的 contig。但是这些高错误率对于区分旁系同源和等位基因序列特别成问题，因为很多序列重复序列高度相似（&gt; 95％）并且差异部分在测序的误差范围内。这篇发表在 nature methods 文章提供了一个不错的思路。 相关内容 工具地址：Segmental Duplication Assembler (SDA; https://github.com/mvollger/SDA) RSEM 转录本定量的提速升级版 文献题目：A revisit of RSEM generative model and its EM algorithm for quantifying transcript abundances. DOI(url): https://doi.org/10.1101/503672 发表日期： December 21, 2018 （预印本） 关键点 本文作者团队修改了 RSEM 的 EM 算法，而且将计算时间减少了大约 100 倍，而且准确性还略有提高。 以下是一些比对测试信息 参考意义 RSEM 定量相对其他软件是比较准确的但是速度比较感人，近几年 Salmon, Kallisto 这类软件因为采用了 pseudoalignment 极大的提高了运算速度也取得了很大的成功。但是，这类软件不能提供一些具体的比对信息，导致很多需要这些比对信息的软件无法进行。 现在，有团队出来管管这事儿了，不过实际的使用感受和测试还没有进行。另外，他们作为一个商业团队还有一个开源的 RNA-seq 分析，具体信息可以参考相关内容里的链接。 相关内容 hear https://github.com/bioturing/hera hear-EM https://github.com/bioturing/hera/tree/master/hera-EM 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-12-23-weeklypaper/"},{"title":"生物信息发文章哪家强","content":" 如果想在生物信息学专业杂志上发一篇不用做任何具体生物信息分析的文章，应该怎么做？最近发表在 Bioinformatics 的一篇文章或许可以给你一点思路。 随着生物信息的发展，生物信息学相关的文章近 10 年呈现大量增加的趋势。世间万物皆可比较，你有没有想过，生物信息发文章哪家强。（山东技校找蓝翔？） 一句话介绍 BIOLITMAP ：一个基于地理位置，允许按照年份、杂志和主题轻松筛选查看生物信息学文章发表情况的网站。 略加介绍英文版 Motivation: The fast growth of bioinformatics adds a significant difficulty to assess the contribution, geographical and thematic distribution of the research publications. Results: To help researchers, grant agencies and general public to assess the progress in bioinformatics, we have developed BIOLITMAP, a web-based geolocation system that allows an easy and sensible exploration of the publications by institution, year and topic. Availability: BIOLITMAP is available at http://socialanalytics.bsc.es/biolitmap and the sources have been deposited at https://github.com/inab/BIOLITMAP 详细介绍举例版 最近，来自西班牙的研究团队在 Bioinformatics 发表了一篇文章向大家介绍了一个网站，这个网站统计了 2005 年-2017 年发表在 Bioinformatics OUP, BMC Bioinformatics, BMC Genomics, PLoS Computational Biology, 和 Nucleic Acids Research 这五篇杂志的一共 46,552 篇文章。从选择的杂志来看，确实都是偏生物信息的杂志，很多综合类杂志或者生物类杂志涉及到大量生物信息分析的文章都没有考虑。 在此基础上网站开发者把这些文章按照发表机构所在的地理位置，发表年份和杂志以及主题进行了详细的分类，包括 DNA, Functional genomics, Mapping, Molecular genetics, Pharmacogenomics, Phylogeny, Proteomics, RNA, Sequence analysis, Structure analysis, Tools, Transcriptomics 和 Molecular interactions, Pathways and Networks 这 13 个类别。 基于地理位置 首先来看看这个地球文章发表的整体情况，嗯，和经济发展应该比较正相关，主要还是集中在北美和欧洲。 当然，还是忍不住点开我们国家看看几个「大红点」都是那里，把地图局部放大。不出意外，北上广红了，但是哈尔滨也红了，武汉也红了。不知道你能不能猜出这两个地方是因为什么而红，在这里简单剧透一下，如果再放大一点哈尔滨有两个红点，其中一个是哈工大，另一个则是哈尔滨医科大学（国内很早开设生物信息学本科专业的学校）；武汉只有一个红点，你觉得应该是武汉大学还是华中科技大学，嗯，是华中农业大学（其实武大和华中科技是两个黄色点）。 目光再聚焦到魔都和帝都看一看。在魔都有四个机构上榜，三个知名高校复旦交大同济再加上中科院上海生科院，而在四个地方中，上海生科院是发表文章最多的。在帝都则有 7 个地方被标注为红色，中科院（所有中科院系统的文章都会算在这里一份）和清华北大自然不必说，但是其它几个你不一定能猜的出来，它们是：中国农业科学院、中国医学科学院、中国农业大学和北京基因组研究所。而在台湾省，也有 6 个机构是红色，仅次于帝都。 查看具体信息 让我们把目光移回到哈尔滨医科大学，点击红点就可以查看具体的文章发表信息。 柱状图不同的颜色代表不同的杂志，其中蓝色代表的杂志是 NAR ，推测其它医学类相关的机构应该也是类似情况。针对人类和医学大量的数据，做数据库和数据整合或许是个不错的选择。 设置筛选条件 如果感兴趣，还可以在网页右上方选定具体的筛选条件进行过滤，例如年份或者主题。你可以选定 NAR 推测一下哪些地方可能更加偏爱发表数据库相关的工具或者文章，或者选定 Tools 看哪里发表的工具更多。 查看具体文章 每一个位置查看详细信息时都可以进一步查看具体文章链接，可以按照年份或者杂志排序。如果觉得没什么文章可看，这里应该会有不少供你选择，当然，还可以打印出来慢慢品味。 最后，作者把所有数据都放到了 GitHub 上，你也可以进一步自行探索。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-12-19-biolitmap/"},{"title":"每周文献-181216-lncRNA差异分析流程测评","content":"文献信息 **标题：**Differential gene expression analysis tools exhibit substandard performance for long non-coding RNA-sequencing data DOI(url): https://doi.org/10.1186/s13059-018-1466-5 **发表日期：**24 July 2018 关键词： lncRNA, Differential gene expression, RNA-seq, differential expression 文献概述 这篇文章详细的分析了不同标准化和差异分析方法在 lncRNA 分析中的差别。一共使用了 25 个分析流程，主要关注点是 lncRNA 和一些低表达 mRNA。使用 15 种指标来评估差异基因的分析方法和标准化方法，一共使用了 6 中不同 RNA-seq 数据集，同时还提供了一个 shiny 网页可视化工具用来展示这些分析结果。按道理类似类型的文章应该达不到这个水平的杂志，lncRNA 分析方法的测评能够发到 Genome Biology 上也是牛，想必定有过人之处。 简单说最后的结论是使用 limma 和 SAMSeq 分析 lncRNA 或者表达量很低的 mRNA 效果要稍微好些，值得注意的是，为了获得至少 50％ 的 sensitivity，在实际环境（如临床癌症研究）中研究表达水平时需要超过 80 个样本（what ?）。测试使用的大约一半的方法显示出过多的假阳性，非常不可靠。 笔记 lncRNA 研究的主要问题就是表达量太低，在一些软件中往往是要求去除掉表达量很低的基因，这个时候就非常尴尬。 作者为此挑选了一些引用率较高的软件，这些软件的共同点是都有 R 包可以使用，而且都是用原始的 read counts 作为输出。在数据方面，作者使用了不同规模的 6 个数据，基本上可以概括进行差异分析的不同情况。用作者的话说：据我们所知，我们的研究是迄今为止所进行的最大的实例 评估，包括所使用的真实数据集的数量，评估的指标数量以及 DE 流程数量。 差异分析工具 使用的差异分析工具如下： Tool (package version) Pipelines Citationsa edgeR (3.14.0) (1) Exact test based on NB distribution, (2) GLM with NB family, (3) QL, (4–7) robust GLM with four different prior DF 5406 DESeq (1.24.0) (1) Default, exact test based on NB distribution 4655 DESeq2(1.12.4) Fits GLM with NB family. (1) Default, (2) independent filtering disabled (setting1), (3) independent filtering disabled and outlier-detection off (setting2) 1364 limma (3.25.21) Fits linear models on log-transformed counts. (1) Voom, (2) voom (robust), (3) trended, (4) trended (robust), (5) voom+QW, (6) limmaVST, (7) limmaQN 1828 NOISeq (2.12.1) (1) Default, data-adaptive and non-parametric method 524 baySeq (2.6.0) (1) Default, Bayesian methods with empirical prior distributions 315 SAMSeq (samr, 2.0) (1) Default, non-parametric method based on Wilcoxon rank sum statistic 140 PoissonSeq (1.1.2) (1) Default, uses poisson log-linear model 92 QuasiSeq (1.0.8) Fits GLM with NB family. (1) QL, (2) QLShrink, (3) QLSPline 57 分析过程 first we evaluated various normalization procedures second we compared the level of agreement among DE pipelines using various publicly available RNA-seq datasets; third we explored the ability of the DE pipelines to recover known evidence of differential expression; fourth we used simulation procedures to evaluate and compare the performance of the tools under a variety of gene expression experiment scenarios, such as variability, sample size, and fraction of DE genes. 标准化方法比较 结论是除了 quantile normalization (QN)，其它几种标准化的方法都差不多。 另外，终于在文献里看到了 upsetR 画出来的图。 一致性分析 主要检查指标： number of genes identified as significantly differentially expressed (SDE); similarity in terms of the set of SDE genes; the degree of agreement on gene ranking; similarity of fold-change estimates; handling of genes with special characteristics (lncRNAs, genes with low counts, genes with outliers) computation time 这里的分析结果是使用聚类方法展示的，如果看懂了就很能说明问题。 下图中的 abcd 分别代表： a fraction of significantly differentially expressed (SDE) genes detected at 5% FDR, b overlap among pipelines in detecting SDE genes at 5% FDR, c gene ranking agreement, and d similarity of log fold-change (LFC) estimates) DESeq, baySeq, limmaQN,和 NOISeq 聚在一起，总之就是比较差。 QuasiSeq (both settings), edgeR robust (with both tested prior degrees of freedom), limmaVoom+QW, PoissonSeq 和 SAMSeq 相对而言就都比价不错。 文章后面有介绍了一些其它数据的比价结果就不一一详细罗列，最后的建议是：**limma (with variance stabilizing transformation; voom with or without quality weighting; trend) and SAMSeq control the actual FDR reasonably well, while not sacrificing sensitivity。**另外，就是如果做 lncRNA，多送一些样本吧。 文章上传了分析代码，所有几个主要附件都是网页格式，展示所有评测结果还做了个网站。 最后一点让我好奇的是，文章从投稿到接受一共花了 8 个月的时间，这期间都发生了什么，review 又给了哪些意见，什么数据是在 review 下补的 … 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-12-16-weeklypaper/"},{"title":"任务协作管理工具 Trello 使用简介","content":"为什么使用 Trello 在和一些小伙伴聊天的过程中，发现大家都有一个类似的困惑。每天听到看到不少好东西都会产生「深究一下」的欲望，但是这些想法和素材要么被忘记了要么就因为时间精力没空继续展开学习。 于是就萌生了建立一个「写作素材共享协作小组」的想法，加入这个小组的成员每周共享自己发现或者感兴趣的素材，然后在所有素材中每周至少输出一篇相关的文章在小组内分享。类似于你买香蕉我买苹果，大家聚在一起分着吃。关于这个协作小组，目前正处于试运行阶段，在 12 月月底我们会正式面向大家开放，并在 2019 年 1 月开始正式运行起来。 想法要落地就需要一个方便的工具。根据写作流程的特殊性，这个工具要可以很好地跟踪每个素材和主题的状态进度，同时成员之间要可以相互协作和沟通，为此我们引入了 Trello 。 Trello 是一款著名的全平台项目管理、任务管理、多人协作工具。Trello 是一种简便、免费、灵活的可视化方式，可以管理你的项目并组织各种事务， 已经得到了世界各地数百万人的信任。它以外表简约的看板风格著称，功能强大，几乎无所不包，但复杂的功能都被很好的收起到恰当的地方，又很好的突出了重点。同时，因为被财大气粗的Atlassian 收购了，所以主要的基础功能全部免费。 看板 (Kanban) 一词起源于日语，看板管理则源自丰田的“及时生产”（JIT，just-in-time）系统，即利用看板在各工序、各车间、各工厂以及与协作厂之间传送作业命令，使各工序都按照看板所传递的信息执行，以此保证在必需时间制造必需数量的必需产品，最终达到及时化生产的目的。我们希望即将到来的协作是简洁且透明的，所有信息都能通过一个醒目简单的辐射源影响到所有成员，可以调动大家的积极性和主动性。 简单来说，Trello 目前可以满足我们两大主要需求：可协作可跟踪，简单易用。 如何快速上手 Trello 如果你有时间，建议仔细阅读一下 看板学习指南 ，大概需要时间 30 分钟；如果没时间只需要浏览本文即可。另外，如果你想查看具体的 Trello 看板使用案例，可以参考 Trello 灵感 。 基本概念 Trello 看板有且只有四个关键组件，如下图所示： A 看板 - 看板代表一个项目或是一个信息跟踪的平台，可以用来组织任务并与他人进行合作。 B 列表 - 列表可用于创建工作流，列表中的卡片可随着工作流从开始到完成在列表之间移动，可在看板中添加的列表的数量没有限制，并可随心所欲进行组织。它可以保持卡片 (C) 在进度的各个阶段有序组织。 C 卡片 - 看板的基本单位是卡片。一个卡片可以代表一个任务和观点。卡片可以是需要做的事情，如待写的文章，或者需要记住的事情。只需点击任何列表底部的“添加卡片”创建新卡片，然后对其进行命名即可。通过点击卡片可对其进行自定义，以便容纳各种实用信息。在列表之间拖放卡片可以显示进度。 菜单 - 在 Trello 看板的右侧是菜单，也就是看板的任务控制中心。该菜单用于管理成员、控制设置、过滤卡片和启用 Power-Ups 支持的第三方功能。还可以在菜单的动态订阅源中查看看板上发生的所有动态。 不妨用一些时间查阅菜单提供的所有功能。 创建看板列表和卡片 针对即将成立的「写作资源共享协作小组」，我们会把所有参加的朋友添加到同一个团队中，只要加入这个团队就可以查看编辑和修改团队内的所有看板内容，同时你也可以选择加入「写作学习资源共享」这个具体的看板。因此，目前暂时不需要自行创建看板和列表（当然，创建的方法也非常简单），日常使用做多的就是创建卡片。 单击第一个列表中的“添加卡片”可以需要完成的每个任务添加卡片。保持卡片标题简洁明了有助于成员更轻松的浏览 在卡片内部可以添加很多信息，从而让每个人清楚了解需要完成哪些工作，例如： 到期时间 描述 清单 附件 评论 卡片操作详情 Trello 可能在表面上看起来简单，但其具有无穷的内在功能。每一张卡片在点击打开后都会进入「卡片背面」，展示具体的内容信息。 卡片描述 在这里你可以添加更多有关卡片、网站链接或分步骤指示方面的具体信息。要给卡片添加详细信息，可单击卡片背面顶部的“编辑”(Edit the description)。甚至还可以通过Markdown设置你的文字格式。 评论与动态 — 在与团队成员沟通和协作时可为卡片添加评论，如提供反馈信息或更新信息。你还可以使用 @ 在评论中提及看板或团队的成员，他们会在 Trello 中收到相应通知。活动则是卡片上所有评论和操作的时间轴。 添加部分为卡片背面提供了更多工具。 添加成员可以向卡片添加成员以分配任务，轻松查看其他人正在做什么、还需要做哪些工作。 为需要子任务或具有多个步骤的卡片添加清单，以确保不会出现疏漏。你甚至可以从看板上的其他卡片复制清单，以及通过 @ 提及人员的方式将其分配到清单项目。 为具有截止日期的卡片添加到期时间，卡片成员将在到期前 24 小时收到通知。任务完成后，到期时间可以标记为已完成。 可从计算机及 Dropbox、Google Drive、Box 和 OneDrive 等众多云存储服务中添加附件。（但是因为目前的网络问题，就暂时不介绍和使用了） 使用 Trellos 做些什么 跟踪 最常见的 Trello 使用方式是在项目或流程中跟踪任务。项目一般都有起止日期，如规划一项活动或构建一项新功能，而流程一般具有持续性，如日程业务运营或管理编辑日历。我们的写作进度流程也是一种任务跟踪。在这些看板上，卡片代表需要完成的任务，列表通常代表一系列步骤。列表的结构可以非常简单，例如“收集箱”、“进行中”和“已完成”，也可以根据流程需要非常详细，卡片在从开始到完成期间从左向右移动。 实用功能： 拖放 - 在各个列表之间拖放卡片以显示进度，在一个列表中上下移动卡片以进行优先级排序。 到期时间 - 向卡片添加到期时间，以便随时掌握期限，并且在完成时标记到期时间为已完成。 添加成员 - 通过向卡片添加成员来分配任务，从而让每个人轻松查看其他人正在做什么。 清单 - 将任务分解到其关键组件中，确保不会出现任何遗漏。 存储 Trellos 本身不具有很强的云盘属性，但是也可以进行轻量存储。 实用功能 附件 - 从你的计算机或常见的云服务（如 Google Drive、Dropbox 和 OneDrive）通过 Power-Ups 附加文件，以便组织文档、文件和资产。 Markdown - 通过 Markdown 格式工具创建更明晰、更有序的卡片说明。你可通过 Markdown 为你的文本添加标题、大纲式列表、斜体、黑体、链接等等。 标签 - 使用标签标记卡片，然后使用过滤功能快速显示具有相关标记的所有卡片。如果不希望标签在普通卡片正面出现但仍然希望可以进行过滤，可使用灰色标签。 搜索 - 使用 Trello 强大的搜索功能找出要搜寻的任何卡片。随心所欲创建卡片，数量不受限制，Trello 始终能够便捷地找出你的卡片。 协作 Trello 的标志功能之一是与他人协调合作非常容易。可以在一处位置查看所需的一切内容并访问所有的信息。 协作往往能引导人们围绕正在完成的工作展开精彩的讨论，催生建设性的反馈，以及对一项圆满完成的工作任务给予（理所应当的）祝贺。以下是一些如何让对话进行下去的快速提示： 对卡片发表评论，为你的团队提供状态更新。这样他们就能知道哪些工作正在进行中，此后就不必再打扰你。 在评论中 @ 提及他们可向他们发送通知，引导他们直接进入手头的任务。这是一种很棒的请求输入、共享信息或将任务传递给工作流中的下一责任人的方法。 分别使用 @card 和 @board 提及卡片或整个看板上的所有人。小心使用你新发现的 @提及权力哦！ 感觉...情绪翻涌？在表情符号比言词更能表达情感的时候，不妨单击评论框底部的 😄，发出你的“声音”来。 几个使用 Tips 快捷键 Trello 提供大量省时省力的键盘快捷键，在 Trello 中，单击键盘上的问号键可查看全部快键键，或检查看这个便捷列表。 其中一些最受欢迎的： 想要快速查看你在看板上的所有卡片？请使用快捷键 Q。 将鼠标悬停在卡片上并按空格键即可将自己添加到卡片中。使用 M 键将其他人添加到卡片中，这样所有任务都不会属于你。 从不错过重要日期，使用 D 键添加到期时间。 使用 Shift-Enter 将卡片保存起来，然后进入卡片背面。这简直就是买一送一的特别优惠。 使用 L 键打开标签菜单，然后使用 F 键过滤这些标签以显示对你最重要的内容。 搜索 需要快速查找时，可在左上角的搜索栏中输入，Trello 将显示与你的查询相关的卡片和看板。而且支持很多快捷搜索方式，例如，使用 @me会返回你的所有卡片，due:week 会返回未来七天内到期的所有卡片，label:red 则会返回应用了红色标签的所有卡片，以及更多更多功能。 多个运算符可以串联使用，如 @me due:overdue -list:done 可以显示你的所有过期且并未处于名为“Done（完成）”的列表中的卡片。关于只一点可以查看“终极提示和技巧”Trello 看板。 快速添加成员至某卡片 通过将其头像从菜单的“成员”区域拖拽至 Trello 卡片添加成员至卡片，这样所有人在打开看板时就知道可以做些什么。 也可以在某一个具体的卡片中添加成员，如下图所示 邮件订阅提醒 可以在个人的设置页面设置以什么频率接受提醒，也可以通过邮件进行回复。通过邮件回复时收件人是你在 Trello 中的私有邮箱。 删除卡片 如果误建了一个卡片，你发现自己可能找不到删除选项，这个时候你要把这个任务首先进行归档才能删除。 移动端和插件 Trello 有移动端 APP 可以下载，使用体验还是不错的。如果你不想经常打开 Trello 的网页添加任务，不妨试一试官方的Chrome 插件 。添加卡片和打开都要方便不少。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-12-14-usetrello/"},{"title":"R 语言可视化之原理概述篇","content":"整体介绍 一张统计图形就是从数据到几何对象 (geometric object, 缩写为 geom, 包括点、线、条形等）的图形属性 (aesthetic attributes, 缩写为 aes, 包括颜色、形状、大小等）的一个映射。此外，图形中还可能包含数据的统计变换 (statistical transformation, 缩写为 stats), 最后绘制在某个特定的坐标系 (coordinate system, 缩写为 coord) 中，而分面 (facet, 指将绘图窗口划分为若干个子窗口）则可以用来生成数据中不同子集的图形。 要素 数据 (data) 映射 (mapping): 建立数据与图形元素的关系 几何对象 (geom)：对数据的渲染和展示 统计变换 (stats) 标度 (scale) 坐标系 (coord) 分面 (facet) 主题 (theme) 两两之间通过+以图层（layer）形式叠加。 ggplot2 is a powerful and a flexible R package, implemented by Hadley Wickham, for producing elegant graphics. The concept behind ggplot2 divides plot into three different fundamental parts: Plot = data + Aesthetics + Geometry. The principal components of every plot can be defined as follow: data is a data frame （数据分组时必须根据行，而不能根据列） Aesthetics is used to indicate x and y variables. It can also be used to control the color, the size or the shape of points, the height of bars, etc….. （映射过程，数据关联到图形，分组） Geometry defines the type of graphics (histogram, box plot, line plot, density plot, dot plot, ….) There are two major functions in ggplot2 package: qplot() and ggplot() functions. qplot() stands for quick plot, which can be used to produce easily simple plots. ggplot() function is more flexible and robust than qplot for building a plot piece by piece. 映射 颜色类：color（颜色或边框）、fill（填充）和 alpha（透明度） 形状类：linetype（线型）、size（点大小或线宽度）和 shape（形状） 位置类：x, y, xmin, xmax, ymin, ymax, xend, yend 特殊类：group 和 order；字符串映射 通常基础布局可以写在 ggplot 中，特有的映射信息写在特有的图层中，非动态值要写在映射的外部。如下则是一种通用的作图格式。 ggplot(data = &lt;DATA&gt;, mapping = aes(&lt;MAPPINGS&gt;)) + &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;)) 分组 几何对象如果对应的多个观测值的统计结果（群组几何对象），通常需要进行分组，group =会默认将绘图中使用的离散性变量为数据进行分组。 有时候我们需要绘制基因的表达谱然后还需要加一条拟合单个基因表达值的线出来。这个时候其实就是在两个图层使用两个不同的分组策略。 p&lt;-ggplot(data = dexp, aes(x = Sample, y = Expression)) p + geom_line(aes(group = Gene, color = Gene)) + geom_smooth(aes(group = 1)) 分面 很多图都是将不同的 group 画在不同的小图中，这种操作模式就叫做分面。主要涉及到如下两个函数。 facet_wrap 和 facet_grid 首先是 facet_wrap（只能针对一个变量进行分面） facet_wrap(facets, nrow = NULL, ncol = NULL, scales = &quot;fixed&quot;, shrink = TRUE, labeller = &quot;label_value&quot;, as.table = TRUE, switch = NULL, drop = TRUE, dir = &quot;h&quot;, strip.position = &quot;top&quot;) 重要参数： facets: 分面参数如 ~Group，表示用 Group 变量进行数据分面 nrow: 绘制图形的行数 ncol: 绘制图形的列数，一般 nrow/ncol 只设定一个 scales： fixed，小图均使用统一坐标 free，每个小图按照各自数据范围自由调整坐标 free_x，自由调整 x 轴刻度范围 free_y，为自由调整 y 轴刻度范围 facet_grid（可以针对两个变量进行非面） facet_grid(facets, margins = FALSE, scales = &quot;fixed&quot;, space = &quot;fixed&quot;, shrink = TRUE, labeller = &quot;label_value&quot;, as.table = TRUE, switch = NULL, drop = TRUE) 与 facet_wrap 不同的参数： facets: 应用两个标准分面，如 Gene ~ Group, 基因分行，group 分列 margins: Ture，包含所有数据的组 space: 每张小图的坐标宽度，值同 scales ##分面 p&lt;-ggplot(data = dexp, aes(x = Sample, y = Expression)) p + geom_point() + facet_wrap(~Gene, scales = &quot;free_x&quot;, nrow = 5) dexp_small&lt;-filter(dexp, Gene %in% paste(&quot;G&quot;, 1:9, sep = &quot;&quot;)) ps&lt;-ggplot(data = dexp_small, aes(x = Sample, y = Expression)) ps + geom_point(aes(color = Length)) + facet_grid(Gene ~ Group, scales = &quot;free&quot;, margins = T, space = &quot;free&quot;) 统计变换 统计变化其实在每一个集合对象中都是存在的，只是有些默认到我们通常并不会察觉。每种几何对象都对应一种统计变换，每种统计变换都默认对应一种集合对象，比如直方图是 bin，散点图是 identity。 ggplot 中和统计变换相关的函数 我们常用的画图方式先确定展示方式再进行统计变换，其实也可以先进行统计变换，再确定展示方式。 #geom_histogram( # stat = &quot;bin&quot;, #数据的统计方式：按窗口统计 # binwidth = NULL, #窗口大小 # bins = NULL, #分成多少个窗口 # mapping = NULL, #y 轴是什么，数目。.count.. 密度。.density.. #) # 以下两种方法等价 p1 + geom_histogram(binwidth = 200,aes(x = Length, y = ..count..)) p1 + stat_bin(binwidth = 200, aes(x = Length, y = ..count..)) # 我们需要展示出某个变量的某种统计特征的时候，需要用到统计变换，生成变量的名字必须用点号围起来。 对待单变量数据，如果是离散性变量可以使用 stat_count 计数，如果是连续性变量可以使用 stat_bin 。 常用简单图形 双变量无统计变换 geom_point: 散点图 geom_bar: 条形图 geom_line: 折线图（需指定分组信息） geom_area: 面积图 geom_text: 添加标签 位置调整参数 stack 图形元素堆叠 dodge 图形并排放置 fill 堆叠图形元素并将高度标准化 identity 不做调整 jitter 避免点重合 查看具体数据 ggplot_build() 标度 scale 什么是标度 Scales control the details of how data values are translated to visual properties. Override the default scales to tweak details like the axis labels or legend keys, or to use a completely different translation from data to aesthetic. 标度控制控制数据到图形属性的映射，将数据转换为颜色位置和大小，并且提供坐标轴和图例（引导元素）信息。 标尺函数：scale_图形属性_标尺名称 图形属性 离散型（因子、字符、逻辑值） 连续型（数值） 颜色 (color) 和 (fill) 填充 hue/brewer/grey/identity/manual gradient/gradient2/gradientn 位置 (position)(x,y) discrete continuous/date 形状 (shape) shape/identity/manual 线条类型 (line type) linetype/identity/manual 大小 (size) identity/manual size #name: 修改引导元素名称 p + scale_x_discrete(name = &quot;Sample Name&quot;) + scale_y_continuous(name = &quot;Gene Expression&quot;) + scale_color_hue(name = &quot;Gene Name&quot;) + scale_size_continuous(name = &quot;Gene length&quot;) p + labs(x = &quot;Sample Name&quot;, y = &quot;Gene Expression&quot;, color = &quot;Gene Name&quot;, size = &quot;Gene Length&quot;) #limits: 设定标度定义域 p + scale_x_discrete(limits = c(&quot;S1&quot;, &quot;S3&quot;, &quot;S5&quot;)) + scale_y_continuous(limits = c(0, 1500)) scale_color_hue(limits = c(&quot;G1&quot;, &quot;G3&quot;, &quot;G5&quot;)) #限制颜色 # 指定取值范围和显示样本 # 下面和上面等同 p + xlim(&quot;S1&quot;, &quot;S3&quot;, &quot;S5&quot;) p + ylim(0, 1500) #breaks: 设置引导元素的刻度 limits &lt;- p + scale_x_discrete(limits = c(&quot;S1&quot;, &quot;S3&quot;, &quot;S5&quot;)) breaks &lt;- p + scale_x_discrete(breaks = c(&quot;S1&quot;, &quot;S3&quot;, &quot;S5&quot;)) # breaks 都显示但是坐标轴只显示 # limits 只显示 #grid.arrange(limits, breaks, ncol = 2) p + scale_y_continuous(breaks = seq(0,2000, 200)) #200 换刻度 p + scale_x_discrete(labels = paste(&quot;Sample&quot;, 1:9, sep = &quot;&quot;)) # 改标签 library(scales) # 改变 Y 轴标签 p + scale_y_continuous(labels = scientific) #comma, percent, dollar, and scientific 坐标系 支持的坐标系内容如下： 坐标系 描述 cartesian 笛卡尔坐标系 equal 同尺度笛卡尔坐标系 flip 翻转笛卡尔坐标系 trans 变换笛卡尔坐标系 polar 极坐标 map 地图投影 同尺度坐标系让 X 和 Y 轴比例一致，coord_equal(ratio = 1) 用来调整比例。 翻转坐标系：coord_flip()，x 随 y 的变化趋势。 标度和坐标系范围的不同 coord_cartesian(xlim = c(0, 1000), ylim = c(0, 1000)) 标度设置范围：剔除范围外数据，再统计绘图 坐标系设置范围：仍使用所有数据统计变换 ，相当于对图形的局部放大。 主题设置与美化 ggplot 内置 9 个主题，其中 bw，light 和 classic 是科研常用主题。 全局设置主题：theme_set(theme_bw) 处理设置全局的主题，还可以定制图中的某些元素，比如文本直线和矩形元素的边框颜色填充颜色 # 修改标题 大小和居中 p + labs(title = &quot;Density distribution&quot;) + theme(plot.title = element_text(size = 20, hjust = 0.5)) # x 标题斜体 p + labs(x = &quot;expression&quot;) + theme(axis.title = element_text(face = &quot;italic&quot;), axis.text.x =element_text(angle = 45, vjust = 0.5)) # 修改图例、 p + theme(legend.position = c(0.9,0.7),legend.background = element_rect(fill = &quot;gray&quot;)) 一页多图 使用包 gridExtra 即可实现复杂布局。 终极总结 完整的 ggplot 如下所示有 7 个参数，但是通常不需要我们全部添加进去，必须的是 data, mappings 和 geom function。 ggplot(data = &lt;DATA&gt;) + &lt;GEOM_FUNCTION&gt;( mapping = aes(&lt;MAPPINGS&gt;), stat = &lt;STAT&gt;, position = &lt;POSITION&gt; ) + &lt;COORDINATE_FUNCTION&gt; + &lt;FACET_FUNCTION&gt; 完整的画图思路如下 数据导入并进行转换 选择几何对象展示数据中的变量 选择合适的坐标系放置几何图形 参考资料 http://ggplot2.tidyverse.org/ http://r4ds.had.co.nz/data-visualisation.html 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-12-13-rggplot/"},{"title":"R 语言可视化之案例","content":"qplot 使用 导入所需数据格式为 data.frame data(mtcars) df &lt;- mtcars[, c(&quot;mpg&quot;, &quot;cyl&quot;, &quot;wt&quot;)] head(df) qplot() 基本用法 qplot(x, y=NULL, data, geom=&quot;auto&quot;, xlim = c(NA, NA), ylim =c(NA, NA)) # geom 画什么图；main 题目；xlab,ylab xy 轴标签 # color 颜色；size 点大小；shape 点形状 Scatter plots 散点图 library(ggplot2) # 基本款 qplot(mpg, wt, data=mtcars) # 增加 standard error 和 smoothed line qplot(mpg, wt, data = mtcars, geom = c(&quot;point&quot;, &quot;smooth&quot;)) # 分组增加 smoothed line qplot(mpg, wt, data = mtcars, color = factor(cyl), geom=c(&quot;point&quot;, &quot;smooth&quot;)) boxplot violin plot boxplot geom=&quot;boxplot&quot; dotplot geom=&quot;dotplot&quot; violin geom=&quot;violin&quot; # Basic box plot from data frame qplot(group, weight, data = PlantGrowth, geom=c(&quot;boxplot&quot;), fill = group) # fill 填充颜色 # Dot plot qplot(group, weight, data = PlantGrowth, geom=c(&quot;dotplot&quot;), stackdir = &quot;center&quot;, binaxis = &quot;y&quot;,color = group, fill = group) # Violin plot qplot(group, weight, data = PlantGrowth, geom=c(&quot;violin&quot;), trim = FALSE, fill = group) histogram density plot qplot(Sepal.Length, data = iris, geom = &quot;histogram&quot;, binwidth=0.1) qplot(Sepal.Length, data = iris, geom = &quot;density&quot;, color = Species, main = &quot;test&quot;, xlab = &quot;x_test&quot;, ylab = &quot;y_test&quot;) ggplot2 box plot ToothGrowth$dose &lt;- as.factor(ToothGrowth$dose) # notched box plot ggplot(ToothGrowth, aes(x=dose, y=len)) + geom_boxplot(notch=TRUE, outlier.color = &quot;red&quot;) 改变线颜色 三种方法 p&lt;-ggplot(ToothGrowth, aes(x=dose, y=len, color=dose)) + geom_boxplot() p p+scale_color_manual(values=c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;)) p+scale_color_brewer(palette=&quot;Dark2&quot;) 改变箱颜色 p&lt;-ggplot(ToothGrowth, aes(x=dose, y=len, fill=dose)) + geom_boxplot() p # Use custom color palettes p+scale_fill_manual(values=c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;)) # use brewer color palettes p+scale_fill_brewer(palette=&quot;Dark2&quot;) # 改变横坐标展示顺序 p + scale_x_discrete(limits=c(&quot;2&quot;, &quot;0.5&quot;, &quot;1&quot;)) 多组展示 ggplot(ToothGrowth, aes(x=dose, y=len, fill=supp)) + geom_boxplot() 定制 bp &lt;- ggplot(ToothGrowth, aes(x=dose, y=len, fill=dose)) + geom_boxplot()+ labs(title=&quot;Plot of length per dose&quot;,x=&quot;Dose (mg)&quot;, y = &quot;Length&quot;) bp + theme_classic() bp + scale_fill_brewer(palette=&quot;Blues&quot;) + theme_classic() bp + scale_fill_brewer(palette=&quot;Dark2&quot;) + theme_minimal() violin plots ToothGrowth$dose &lt;- as.factor(ToothGrowth$dose) # trim p &lt;- ggplot(ToothGrowth, aes(x=dose, y=len)) + geom_violin() p # no trim p2&lt;-ggplot(ToothGrowth, aes(x=dose, y=len)) + geom_violin(trim=FALSE) p2 显示范围 # 显示范围 p + scale_x_discrete(limits=c(&quot;0.5&quot;, &quot;2&quot;)) 添加描述统计量 使用stat_summary() # violin plot with mean points p + stat_summary(fun.y=mean, geom=&quot;point&quot;, shape=23, size=2) # 加箱线图 p + geom_boxplot(width=0.1) 修改颜色 和 box plot 类似 p&lt;-ggplot(ToothGrowth, aes(x=dose, y=len, color=dose)) + geom_violin(trim=FALSE) p # Use custom color palettes p+scale_color_manual(values=c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;)) # Use brewer color palettes p+scale_color_brewer(palette=&quot;Dark2&quot;) 定制 dp &lt;- ggplot(ToothGrowth, aes(x=dose, y=len, fill=dose)) + geom_violin(trim=FALSE)+ geom_boxplot(width=0.1, fill=&quot;white&quot;)+ labs(title=&quot;Plot of length by dose&quot;,x=&quot;Dose (mg)&quot;, y = &quot;Length&quot;) dp dp + scale_fill_brewer(palette=&quot;Blues&quot;) + theme_classic() histogram 直方图 基础 #构造数据 set.seed(1234) df &lt;- data.frame( sex=factor(rep(c(&quot;F&quot;, &quot;M&quot;), each=200)), weight=round(c(rnorm(200, mean=55, sd=5), rnorm(200, mean=65, sd=5))) ) # 基础 ggplot(df, aes(x=weight)) + geom_histogram() # 加 density ggplot(df, aes(x=weight)) + geom_histogram(aes(y=..density..), colour=&quot;black&quot;, fill=&quot;white&quot;)+ geom_density(alpha=.2, fill=&quot;#FF6666&quot;) 修改颜色并分组 # Change histogram plot line colors by groups ggplot(df, aes(x=weight, color=sex)) + geom_histogram(fill=&quot;white&quot;) # Overlaid histograms ggplot(df, aes(x=weight, color=sex)) + geom_histogram(fill=&quot;white&quot;, alpha=0.7, position=&quot;identity&quot;) ggplot(df, aes(x=weight, color=sex)) + geom_histogram(fill=&quot;white&quot;, alpha=.7, position=&quot;dodge&quot;) library(plyr) mu &lt;- ddply(df, &quot;sex&quot;, summarise, grp.mean=mean(weight)) p&lt;-ggplot(df, aes(x=weight, color=sex)) + geom_histogram(fill=&quot;white&quot;, position=&quot;dodge&quot;)+ geom_vline(data=mu, aes(xintercept=grp.mean, color=sex), linetype=&quot;dashed&quot;)+ theme(legend.position=&quot;top&quot;) p # Use custom color palettes p+scale_color_manual(values=c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;)) # Use brewer color palettes p+scale_color_brewer(palette=&quot;Dark2&quot;) 填充 # Use semi-transparent fill p&lt;-ggplot(df, aes(x=weight, fill=sex, color=sex)) + geom_histogram(position=&quot;identity&quot;, alpha=0.5) p p+scale_color_manual(values=c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;))+ scale_fill_manual(values=c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;)) 定制 ggplot(df, aes(x=weight, color=sex, fill=sex)) + geom_histogram(aes(y=..density..), position=&quot;identity&quot;, alpha=0.5)+ geom_density(alpha=0.6)+ geom_vline(data=mu, aes(xintercept=grp.mean, color=sex), linetype=&quot;dashed&quot;)+ scale_color_manual(values=c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;))+ scale_fill_manual(values=c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;))+ labs(title=&quot;Weight histogram plot&quot;,x=&quot;Weight(kg)&quot;, y = &quot;Density&quot;)+ theme_classic() desnsity plot p&lt;-ggplot(df, aes(x=weight, fill=sex)) + geom_density(alpha=0.4) p # Add mean lines p+geom_vline(data=mu, aes(xintercept=grp.mean, color=sex), linetype=&quot;dashed&quot;) scatter plots mtcars$cyl &lt;- as.factor(mtcars$cyl) # Change the point size ggplot(mtcars, aes(x=wt, y=mpg)) + geom_point(aes(size=qsec)) # Add the regression line ggplot(mtcars, aes(x=wt, y=mpg)) + geom_point()+ geom_smooth(method=lm) # Remove the confidence interval ggplot(mtcars, aes(x=wt, y=mpg)) + geom_point()+ geom_smooth(method=lm, se=FALSE) # Loess method ggplot(mtcars, aes(x=wt, y=mpg)) + geom_point()+ geom_smooth() 添加 Error bar #+++++++++++++++++++++++++ # Function to calculate the mean and the standard deviation # for each group #+++++++++++++++++++++++++ # data : a data frame # varname : the name of a column containing the variable #to be summariezed # groupnames : vector of column names to be used as # grouping variables data_summary &lt;- function(data, varname, groupnames){ require(plyr) summary_func &lt;- function(x, col){ c(mean = mean(x[[col]], na.rm=TRUE), sd = sd(x[[col]], na.rm=TRUE)) } data_sum&lt;-ddply(data, groupnames, .fun=summary_func, varname) data_sum &lt;- rename(data_sum, c(&quot;mean&quot; = varname)) return(data_sum) } df2 &lt;- data_summary(ToothGrowth, varname=&quot;len&quot;, groupnames=c(&quot;supp&quot;, &quot;dose&quot;)) # Convert dose to a factor variable df2$dose=as.factor(df2$dose) library(ggplot2) # Default bar plot p&lt;- ggplot(df2, aes(x=dose, y=len, fill=supp)) + geom_bar(stat=&quot;identity&quot;, color=&quot;black&quot;, position=position_dodge()) + geom_errorbar(aes(ymin=len-sd, ymax=len+sd), width=.2, position=position_dodge(.9)) print(p) # Finished bar plot p+labs(title=&quot;Tooth length per dose&quot;, x=&quot;Dose (mg)&quot;, y = &quot;Length&quot;)+ theme_classic() + scale_fill_manual(values=c('#999999','#E69F00')) # Default line plot p&lt;- ggplot(df2, aes(x=dose, y=len, group=supp, color=supp)) + geom_line() + geom_point()+ geom_errorbar(aes(ymin=len-sd, ymax=len+sd), width=.2, position=position_dodge(0.05)) print(p) # Finished line plot p+labs(title=&quot;Tooth length per dose&quot;, x=&quot;Dose (mg)&quot;, y = &quot;Length&quot;)+ theme_classic() + scale_color_manual(values=c('#999999','#E69F00')) 资料来源 http://www.sthda.com/english/wiki/ggplot2-essentials 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-12-14-rggplotexample/"},{"title":"多快好省用 R 处理数据","content":" 很早之前我一直都是使用命令行来处理软，cut,sed 再 grep 再加上终极 awk 基本上就可以随意的按照需求处理各种软件跑出来的文本文件了，再后来就要开始学习 python，python 学的怎么样了呢？呵呵。 虽然做过统计学课的助教，上课的时候用的也是 R 语言，但是博客里并没有几篇 R 相关的文章。印象中一篇是 给初学者的 R 语言介绍（写这篇文章当时是为了激发一点学生学习 R 语言的热情），另一篇是 R 必备基础知识（写这篇文章当时是因为在写 R 与统计学基础系列文章，就不得不总结一些 R 语言的基础知识）。 说实话，我本身对 R 还是非常喜欢和欣赏的，但是日常的使用需求并不高。就拿最基本的文本处理来说，基本上都可以在 shell 中进行随心所欲地增删改成，处理成很多 R 相关软件需要的文本格式，用需要的 R 包跑一两个命令就可以了。但是目前已经有点厌倦了这样的生活，我后期打算有机会的话用 R shiny 写一点网页工具给大家娱乐，也打算精进一下 R 的画图技能。这里就 have to 用 R 去做一些数据处理，于是就有了这样一系列文章。这篇是关于如何用 R 多快好省的进行数据处理。另外，说句题外话，从我这几天的实际处理数据情况来看，R 有些工作做起来，还是太慢了，也可能是我的业务不够娴熟吧。 Tidyverse Tidyverse 是一系列大名鼎鼎的 data science R 包合集，学会了 Tidyverse 就可以说学会了用 R 进行数据分析，因为它包括的包有 readr, tidyr, dplyr, ggplot2 和 purrr。可以说从读文件到编辑文件再到可视化展示再到编写函数都涉及到了。 数据分析工作主要涉及的内容就是如下几方面的工作。 这篇文章主要涉及输入 (import), 整理 (tidy) 和转换 (transform) 三个部分，这三步合起来也可以称作** data wrangling** 或者 data munging，而正在做这项工作的我们则被称为** data wrangler**。 优雅地读取数据 在 R 中，最基本的文件读取命令是 read.table 和 read.csv。我们这里使用的是更加牛 X 的 readr 包。 readr 解决的关键问题是把 flat file 解析为 tibble。 主要包括如下三个步骤 The flat file is parsed into a rectangular matrix of strings. The type of each column is determined. Each column of strings is parsed into a vector of a more specific type. 主要优点 是 R 基础命令速度的 10 倍左右。 直接用行名生成 tibbles 格式，不会把 character vectors 转换为 factors（R 基础命令最坑的一点） 比 R 基础命令有更高的稳定性和可重复性，不会收到不同配置环境的影响。 安装及加载命令 install.packages(&quot;tidyverse&quot;) library(tidyverse) reader 支持 7 中文本格式，但是常用的读取命令主要有如下三个 read_csv(): comma separated (CSV) files read_tsv(): tab separated files read_delim(): general delimited files read_table(): tabular files where colums are separated by white-space. read_*(file, col_names = TRUE, col_types = NULL, locale = default_locale(), na = c(&quot;&quot;, &quot;NA&quot;), quoted_na = TRUE, quote = &quot;\\&quot;&quot;, comment = &quot;&quot;, trim_ws = TRUE, skip = 0, n_max = Inf, guess_max = min(1000, n_max), progress = show_progress()) 使用实例和方法 多数情况下，如果数据是正规的格式，只需要加入文件路径和名字即可，会根据前 1000 行数据判断数据类型。读取完成后可以使用calss()查看一下数据类型，已经是 tbl 格式。 data_h3k4 &lt;- read_tsv(&quot;46_AB_h3k4_raw.matrix&quot;) # 结果如下 #Parsed with column specification: #cols( # peak = col_character(), # `TAA10-H3K4me3-1-2` = col_integer(), # `TD265-H3K4me3-1` = col_integer(), # `Tetra-H3K4me3-1` = col_integer(), # `TTR13-H3K4me3-1-2` = col_integer(), # `XX329-H3K4me3-1` = col_integer() #) class(data_h3k4) #结果如下 #[1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; 自信地整理数据 为什么要 tidy，因为数据按照一个规矩统后，我们就不用再为数据的各种格式困扰。正所谓，做事之前先立规矩，就是这个道理。 “Happy families are all alike; every unhappy family is unhappy in its own way.” –– Leo Tolstoy “Tidy datasets are all alike, but every messy dataset is messy in its own way.” –– Hadley Wickham 所谓 tidy 的含义其实就是**每一列是一个变量 (variable)，每一行是一个观测结果 (observation)。**这个数据格式是后续使用 ggplot 等工具需要的默认格式。 Each variable must have its own column. Each observation must have its own row. Each value must have its own cell. 如下图所示： 这里我们要使用的工具是** tidyr**, 是 tidyverse 的几个牛包之一。 library(tidyverse) 用脚想一下，tidy 的数据要求是一个变量在一列，一个观测值在一行，如果我们的数据不满足 tidy 条件，会有什么情况。通常情况下无非是以下两种情况之一。 一个变量分布在不同的几列 一个观测值分布在不同的几行 数据由宽变长：gather() 通常我们会把多个样本的基因表达值构造成为一个矩阵，这时存在的问题就是一个变量分布在不同的几列，每一列是不同的样本名，而并非变量名（变量名应该是基因表达量和样本）。类似于下图有图的问题。 这个时候我们可以使用** gather** 命令进行数据格式转换（数据由宽转长）。 原始数据 gather(data, key, value, ..., na.rm = FALSE, convert = FALSE, factor_key = FALSE) #data：需要被转换的宽形表 #key：将原数据框中的所有列赋给一个新变量 key #value：将原数据框中的所有值赋给一个新变量 value #…：指定对哪些列进行操作 #na.rm：是否删除缺失值 # 下面的两种写法等效 tmp_tbl &lt;- gather(tmp_data,key = &quot;sample&quot;, value = &quot;expression&quot;, -peak) tmp_tbl &lt;- gather(tmp_data,key = &quot;sample&quot;, value = &quot;expression&quot;, c(2:6)) 数据由长变宽 spread() spread() 和 gather() 方法类似 原理如下图所示 spread(data, key, value, fill = NA, convert = FALSE, drop = TRUE, sep = NULL) &gt; spread(tmp_tbl,key = &quot;sample&quot;, value = &quot;expression&quot;) #结果如下所示 # peak TAA10-H3K4me3-1-2 TD265-H3K4me3-1 Tetra-H3K4me3-1 TTR13-H3K4me3-1-2 XX329-H3K4me3-1 #1 TraesCS1A01G000100 0 0 0 0 0 #2 TraesCS1A01G000200 4 0 13 7 9 #3 TraesCS1A01G000300 2 0 0 3 0 #4 TraesCS1A01G000400 2 0 2 0 0 #5 TraesCS1A01G000500 10 0 12 18 10 #6 TraesCS1A01G000600 14 12 46 51 20 分列：separate 有些时候我们需要将某一列数据分为两列， separate(data, col, into, sep = “[^[:alnum:]]+”, remove = TRUE, convert = FALSE, extra = “warn”, fill = “warn”, …) #data：为数据框 #col：需要被拆分的列 #into：新建的列名，为字符串向量 #sep：被拆分列的分隔符 #remove：是否删除被分割的列 separate(tmp_tbl, peak, into = c(&quot;species&quot;,&quot;geneid&quot;), sep = &quot;CS&quot;) # species geneid sample expression #1 Traes 1A01G000100 TAA10-H3K4me3-1-2 0 #2 Traes 1A01G000200 TAA10-H3K4me3-1-2 4 #3 Traes 1A01G000300 TAA10-H3K4me3-1-2 2 #4 Traes 1A01G000400 TAA10-H3K4me3-1-2 2 #5 Traes 1A01G000500 TAA10-H3K4me3-1-2 10 #6 Traes 1A01G000600 TAA10-H3K4me3-1-2 14 #7 Traes 1A01G000100 TD265-H3K4me3-1 0 #8 Traes 1A01G000200 TD265-H3K4me3-1 0 #9 Traes 1A01G000300 TD265-H3K4me3-1 0 列合并：unite unite(data, col, ..., sep = “_”, remove = TRUE) #data：为数据框 #col：被组合的新列名称 #...：指定哪些列需要被合并 #sep：组合列之间的连接符（默认下划线） #remove：是否删除被组合的列 separate(tmp_tbl, peak, into = c(&quot;species&quot;,&quot;geneid&quot;), sep = &quot;CS&quot;) %&gt;% unite(peak, c(1:2)) # peak sample expression #1 Traes_1A01G000100 TAA10-H3K4me3-1-2 0 #2 Traes_1A01G000200 TAA10-H3K4me3-1-2 4 #3 Traes_1A01G000300 TAA10-H3K4me3-1-2 2 #4 Traes_1A01G000400 TAA10-H3K4me3-1-2 2 #5 Traes_1A01G000500 TAA10-H3K4me3-1-2 10 #6 Traes_1A01G000600 TAA10-H3K4me3-1-2 14 tidyr 其它简单命令 从容地进行数据筛选 在进行数据分析时，我们通常会对原始的输入数据进行一些处理后再进行下游分析，比如会根据基因的表达量或者基因在不同组间的变异系数对矩阵进行筛选后再进行分析，也可能想要提出某一些有共同特征（同一条染色体的基因）进行后续分析。这些操作都可以通过** dplyr** 方便地完成。 dplyr 主要有以下几个函数，默认情况以下函数会针对整个数据集进行操作，如果使用了group_by() 则会分组分别进行操作。 Pick observations by their values (filter()). 筛选行 Reorder the rows (arrange()). 排序行 Pick variables by their names (select()). 筛选列 Create new variables with functions of existing variables (mutate()). 增加列 Collapse many values down to a single summary (summarise()). 汇总计算 当我打算展开写这部分内容的时候我发现自己实在无法下笔，因为 Rstudio 的 Cheat Sheets 写的实在是太精炼太好，我再整理一遍就是浪费时间了。 dplyr Cheat sheets 下载地址 https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf 其他参考资料 http://readr.tidyverse.org/articles/readr.html http://r4ds.had.co.nz/data-import.html#data-import https://github.com/tidyverse/readr 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-12-12-rtidyverse/"},{"title":"R 语言必备基础知识","content":" 写着写着 R 与统计基础莫名其妙地又写开 R 基础了，一起写吧。 R 编程基础 算数运算 常用的+ - * \\ ^ 可以直接在 console 中计算 计算函数 常用的log2(x) log10(x) exp(x) sin(x) tan(x) abs(x) sqrt(x) 也可以直接计算 变量赋值 a &lt;- 3;a &lt;- &quot;b&quot;赋值符号是&lt;-, 使用 ls() 可以显示当前已经创建的对象 基本数据类型 数值型字符型和逻辑值，使用calss()查看变量类型。或者用is.numeric(), is.character(), is.logical() 判断是否是某一类具体类型。如果要改变变量类型，可以使用 as.numeric(), as.character(), as.logical()…… 向量 向量是多个值的集合，根据变量类型的不同可以分为数值型向量，字符型向量和逻辑向量。构建向量使用函数 c()。使用 names() 函数可以为向量中的元素命名。使用 length() 函数可以返回向量长度。 获取向量子集的方法： 通过位置（index） a[1],a[2,4],a[2:4] 通过名字 a[b] 排除选择（不要某个元素） a[-2],a[-c(2:4)] 通过逻辑向量选择 a[b == TURE],a[c &gt;= 3],a[c !=3] 针对向量的其他常用函数 range(a) length(a) sum(a) prod(a) mean(a) sd(a) var(a) sort(a) #[1] 2 7 #[1] 4 #[1] 18 #[1] 280 #[1] 4.5 #[1] 2.081666 #[1] 4.333333 #[1] 2 4 5 7 矩阵（martix） 矩阵可以理解为多行多列的表格，通常，列表示变量，行表示个体或者观测值。构造矩阵可以通过matrix()函数。使用方式是： matrix(data = NA, nrow = 1, ncol = 1, byrow = FALSE, dimnames = NULL) 构造一个两行三列的矩阵 mdata &lt;- matrix( data = c(1,2,3,4,5,6,7,8,9,10,11,12), nrow = 3, byrow = TRUE, dimnames = list(c(&quot;r1&quot;, &quot;r2&quot;,&quot;r3&quot;), c(&quot;c1&quot;, &quot;c2&quot;, &quot;c3&quot;,&quot;c4&quot;)) ) mdata # c1 c2 c3 c4 # r1 1 2 3 4 # r2 5 6 7 8 # r3 9 10 11 12 nrow() and ncol()可以返回矩阵的行数和列数，rownames()和colnames()可以返回或者设置矩阵的行名和列名。 从一个矩阵中提取子集的方法和向量类似，只不过分为行和列两个参数，行和列各自的提取方式和向量相同，[] 内第一个参数行位置，第二个参数代表列位置。 通过行列位置提取 mdata[1,] mdata[,2] mdata[c(1,2),2] #c1 c2 c3 c4 # 1 2 3 4 #r1 r2 r3 # 2 6 10 #r1 r2 # 2 6 通过名字提取 mdata[,&quot;c2&quot;] #r1 r2 r3 # 2 6 10 反向选择 mdata[-3,&quot;c4&quot;] #r1 r2 # 4 8 逻辑值筛选 mdata[&quot;r3&quot;&gt;10,c(3,4)] # c3 c4 # r1 3 4 # r2 7 8 # r3 11 12 rowSums() colSums()可以用来为矩阵的行列分别求和，rowMeans() 和 colMeans()则用来计算均值。 如果想使矩阵的行列互换，只需要使用t()函数即可。 因子 (factor) 在 R 中，变量可以是连续型变量，名义型变量（无需：a,b,c）和有序变量（上，中，下）。名义型变量和有序变量也叫作因子，通过factor()函数可以设置因子，并以数组形式储存。 数据框（data.frame） 数据框和矩阵形式类似，但是可以接受列的类型不同。其中行代表观测值或者个体，列代表变量。构建数据框可以使用data.frame()函数。 在 R 中，内置了众多各种类型的数据，可以通过data()查看所有的内置函数，通过?dataname可以了解数据相关信息。比较常用到的内置数据集有 mtcars, iris, ToothGrowth, PlantGrowth 和 USArrests。 我们使用 ToothGrowth 数据集来了解 data frame。 summary(ToothGrowth) is.data.frame(ToothGrowth) is.factor(ToothGrowth$supp) tapply(ToothGrowth$len, ToothGrowth$supp, mean) # len supp dose # Min. : 4.20 OJ:30 Min. :0.500 # 1st Qu.:13.07 VC:30 1st Qu.:0.500 # Median :19.25 Median :1.000 # Mean :18.81 Mean :1.167 # 3rd Qu.:25.27 3rd Qu.:2.000 # Max. :33.90 Max. :2.000 #[1] TRUE # OJ VC #20.66333 16.96333 可以发现，该数据集中 supp 为因子，分别是 VC 和 OJ(orange juice)。且两组的均值分别是 20.66333 16.96333。 同样，数据框也可以通过位置和名字信息以及逻辑值来提取子集。 通过位置提取 ToothGrowth$len ToothGrowth[c(1:5),c(&quot;dose&quot;)] #[1] 0.5 0.5 0.5 0.5 0.5 通过逻辑值提取 ToothGrowth[ToothGrowth$len&gt;=30,c(&quot;len&quot;)] # [1] 33.9 32.5 30.9 有没有提取矩阵或者数据框更简便通用的方法呢？在 R 中，使用subset(x, subset, select, drop = FALSE, ...)函数可以轻松帮我们实现提取子集的目的，通过 subset 筛选行，通过 select 来筛选列。 subset(ToothGrowth, len&gt;=20, select = supp) subset(ToothGrowth, supp==&quot;OJ&quot;) 关于 R 包的几个常用操作 install.packages(“package_name”): 安装 library(“package_name”): 加载使用 detach(“package_name”, unload = TRUE): 卸载 remove.packages(“package_name”): 从本地删除 update.packages(oldPkgs = “package_name”): 升级 准备数据输入数据 尽管 R 可以直接输入数据，但通常会将文本文件（csv 或者 tsv）导入后进行处理。因为数据框的特点，在准备数据时，一般将第一行作为每一列的列名，而每一列代表一个变量；将第一列作为行名，而每一行代表一个观测值，且不应该出现重名。同时，行名和列明中最好用下划线代替空格，避免一些特殊符号的存在。 常用的文件格式有 txt(tab 分割），csv(, 分割）以及 Excel 生成的文件。读取两类文件，最简单的方式是通过read.table()可以设置任意你需要的分隔符，不过也有特殊的读取函数和上述两种文件分别对应。 read.csv(): 读取“,”作为分隔符的文件 (&quot;.csv&quot;). read.delim(): 读取“\\t”作为分隔符的文件 (&quot;.txt&quot;) 上述两个命令，有几个通用的参数 file: 要读入的文件，需要确保路径正确 sep: 分隔符 “\\t” header: 如果第一行不是列名则使用 F dec: 用什么作为小数点（默认即可） 对很多初学者而言，读文件往往找到不到正确的路径，在使用 Rstudio 时可以尝试使用my_data &lt;- read.delim(file.choose())命令，会有想不到的惊喜。另外，如果输入文件中，某一列是文本，R 会将其默认为因子，可以通过stringsAsFactor = FALSE参数拒绝转换。 readr 包是一个专门用来读取数据的包，其读取文件的速度比自带函数要快 10 倍，它可以对输入数据类型进行自动判断，也可以使用read_lines指定行数读取。 针对 Excel 产生的文件，可以使用 readxl 或者 xlsx 包进行读取。这两个包针对 Excel 文件进行了优化，readxl 可以通过sheet参数指定要读入的表单，xlsx 则是通过sheetIndex确定。 输出数据 如果需要把处理过的矩阵或者数据框输出到新的文件中，可以使用write.table() write.table(x, file, append = FALSE, sep = &quot; &quot;, dec = &quot;.&quot;, row.names = TRUE, col.names = TRUE) #例如 write.table(data, file = &quot;data.txt&quot;, sep = &quot;\\t&quot;, row.names = TRUE, col.names = NA) readr 包的write_tsv()函数也可以完成同样的工作。如果想要保存为 Excel 文件，调用前面提到 xlsx 包，使用write.xlsx()即可。 如果在保存数据的同时还需要保存数据类型和结构，可以使用saveRDS(object, file = &quot;my_data.rds&quot;)将当个项目保存为 R 特有的数据格式。如果想要重新调用，使用readRDS(file = &quot;my_data.rds&quot;)。 如果想要保存完整的工作区，可以使用save.image(file = “my_work_space.RData”)，加载时使用load()。如果使用 Rstudio，关闭时会提醒你是否保存。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-12-11-rbasic/"},{"title":"每周文献-181208-DNA 甲基化和几个工具","content":"文献信息 标题： A DNA methylation reader complex that enhances gene transcription DOI(url): 10.1126/science.aar7854 发表日期： 07 Dec 2018 关键词： DNA methylation; reader complex; SUVH1 and SUVH3; activate 文献概述 emmm , 挺长时间没有植物甲基化的文章发表在 science 上了，文章的通讯作者是美国科学院院士。 DNA 甲基化（DNA methylation）是最早发现的表观修饰遗传标记。DNA 甲基化在调控基因表达、维持染色质结构、基因印记以及胚胎发育等生物学过程中发挥着重大的作用。在真核生物中，DNA 甲基化通常标记转座元件。在植物中，RNA 介导的 DNA 甲基化（RNA-directed DNA methylation, RdDM）是一种重要的甲基化途径，植物中有三种甲基化形式 CG、CHG、CHH。CG 由 DNA 甲基化转移酶 MET1 维持，在植物中 DNMT1 的同源蛋白；植物特异的 CMT3 结合 H3k9me2 促进 CHG 甲基化；CHH 由 DRM2 及 CMT2 维持。转座子的插入可以对邻近的基因在转录水平产生影响，启动子的甲基化通常来说会抑制这些基因的表达，但也存在 DNA 甲基化促进基因表达的例外情况。 文章鉴定了拟南芥中的蛋白质复合物 SUVH1 和 SUVH3，其通过 DNA 甲基化被募集到染色质中，SUVH 蛋白与甲基化 DNA 结合并募集 DNAJ 蛋白以增强近端基因表达。SUVH1 和 SUVH3 在体外结合甲基化 DNA，与体内常染色质甲基化有关，并与含有两个含 DNAJ 结构域的同源物 DNAJ1 和 DNAJ2 形成复合物。 DNAJ1 的异位募集增强了植物，酵母和哺乳动物的基因转录。 因此，SUVH 蛋白结合甲基化 DNA 并募集 DNAJ 蛋白以增强近端基因表达，从而抵消转座子插入基因附近的抑制作用。通过平衡抑制和激活转录效应，DNA 甲基化可以起到微调基因表达的作用。 笔记 在拟南芥中分离出与 DNA 甲基化结合的蛋白质 首先挑选了 10 个和不同种类甲基化位点结合紧密的蛋白。其中 SUVH1 SUVH3 以及 DNAJ 蛋白的研究较少。 SUVH1 由 RdDM 相关的 mCHH 募集 ChIP-seq 数据显示，SUVH1 和 SUVH3 在基因组上的定位基本相同。且这两个蛋白的位置与通过 RdDM 途径相关的 CHH 甲基化共定位。从下图中的 drm1/2 突变体可以观察到。同时 SUVH1 也富集在 NRPE1 (RNA polymerase V 的最大亚基） 的 peak 区域，且在短 TE 和长 TE 的边缘处显示出更强的富集，这些位置也是 RdDM 定位的标志。使用随机森林回归 (random forest regression) 发现 mCHH 是体内 SUVH1 结合的最强预测因子。同时在 RdDM 相关的突变体中 SUVH1 的富集基本消失。 SUVH1，SUVH3，DNAJ1 和 DNAJ2 相互作用、共定位且是临近基因表达必需的 通过 IP 实验和 ChiP-seq 发现这四个蛋白可以相互作用和共定位，而且突变体中，离他们越近的基因表达受影响越明显。表明 DNAJ1 和 DNAJ2 与 SUVH1 和 SUVH3 相互作用，被募集到 RdDM 的位点，并促进近端基因的表达。然后使用 DNAJ1 的过表达突变体发现上调的基因和 DNAJ1 的结合位点有显著的富集。 方法 文章正文比较短，图也很紧凑，但是附件有很多的数据和结果，一共有 55 页。从方法部分来看，能做的高通量分析基本都做了。比如质谱，ChIP-seq, ATAC-seq，Whole Genome Bisulfite Sequencing (WGBS) 和 RNAseq。 不出意外的是，RNA-seq 的 mapping 还是用的 TopHat2，差异表达用的还是 DEseq 第一版，WGBS 用的是 BSMAP。因为不同重复中甲基化差距不同，在下游分析中作者将重复合并在一起进行后续分析。画热图用的包是 ComplexHeatmap。ATAC-seq mapping 用的是 bowtie , ChIP-seq 用 bowtie2, call peak 使用 MACS 而不是第二版。可视化的几个图用了 NGS.plot DeepTools 这两个包。 对 SUVH1 的结合位点进行预测使用了随机森林回归算法。相关方法来自于 https://www.nature.com/articles/ncomms11025 这篇文章。 相关文献 https://www.nature.com/articles/s41556-018-0089-0 https://www.nature.com/articles/nature12931 https://www.ncbi.nlm.nih.gov/pubmed/27903897?dopt=Abstract https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1005998 https://www.nature.com/articles/nsmb.2354 其它几篇方法文章 植物 miRNA 分析流程 文献题目：miRDeep-P2: accurate and fast analysis of the microRNA transcriptome in plants DOI(url): https://doi.org/10.1093/bioinformatics/bty972 发表日期： 2018 Dec 6 关键点 Two major challenges to identify microRNAs (miRNAs) in plants how to minimize the false-positive inheritable to computational predictions; how to minimize the computational time required for analyzing the miRNA transcriptome in plants with complex and large genomes. miRDP2: Based on ultra-deep sampling of small RNA libraries by next generation sequencing, miRDP2 is able to identify miRNA genes in plant species, even for those without detailed annotation, with extremely high speed and reliable performance. http://sourceforge.net/projects/mirdp2/. 参考意义 流程有待测试，作者来自北京农科院。我对这个地方的印象就是虽然在北京，但是感觉已经快到我老家了。 BAM 文件过滤信息统计及注释工具 文献题目： Alfred: Interactive multi-sample BAM alignment statistics, feature counting and feature annotation for long- and short-read sequencing DOI(url): 10.1093/bioinformatics/bty1007 发表日期： 2018 Dec 6 关键点 主要功能：Alfred uses subcommands for quality control (qc), feature counting (count_dna, count_rna, count_jct), feature annotation (annotate, tracks), alignment (pwalign, consensus) and haplotype-resolved analysis (split, ase). 网址：https://gear.embl.de/docs/alfred/ 参考意义 看起来功能挺多，与 samtools 相比更注重一些下游的分析。 CNV 预测工具 文献题目： CODEX2: full-spectrum copy number variation detection by high-throughput DNA sequencing. DOI(url): 10.1186/s13059-018-1578-y 发表日期： 2018 Nov 26 关键点 CODEX2, as a statistical framework for full-spectrum CNV profiling that is sensitive for variants with both common and rare population frequencies and that is applicable to study designs with and without negative control samples. We demonstrate and evaluate CODEX2 on whole-exome and targeted sequencing data, where biases are the most prominent. CODEX2 outperforms existing methods and, in particular, significantly improves sensitivity for common CNVs. https://github.com/yuchaojiang/CODEX2 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-12-08-weeklypaper/"},{"title":"每周文献-181130-lncRNA","content":"文献信息 标题：Global identification of Arabidopsis lncRNAs reveals the regulation of MAF4 by a natural antisense RNA DOI(url): 10.1038/s41467-018-07500-7 发表日期：29 November 2018 关键词：lncRNA, H3K4me3, natural antisense transcripts, concordantly expressed 文献概述 鉴定了 6510 个 lncRNA ，其中包括 4050 个 NAT-lncRNA 以及 2460 个 lincRNA 在不同组织或逆境处理条件下，很多 NAT-lncRNA 与邻近蛋白编码基因的表达呈现正相关趋势。 通过人工 miRNA 沉默部分 NAT-lncRNA 表达可导致邻近蛋白编码基因表达下降，表明 NAT-lncRNA 可正向调控邻近基因的表达。 拟南芥成花抑制基因 MADS AFFECTING FLOWERING4(MAF4) 基因位点有一个 NAT-lncRNA，MAS。 MAS 受冷处理诱导并在转录水平激活 MAF4 表达，抑制拟南芥过早开花。MAS 对 MAF4 的激活依赖于一类参与组蛋白 H3K4me3 修饰的 COMPASS-like 复合体。 MAS 与复合体中的一个核心蛋白组分 WDR5a 结合并辅助该复合体招募到 MAF4 基因位点，促进 H3K4me3 修饰，从而促进 MAF4 表达。 笔记 文章主要内容和结论 测序和建库类型，作者使用了三种建库方式，分别是去 rRNA, poly(A)+ 和 poly(A)− 。 using high-depth strand-specific RNA sequencing (ssRNA-seq). We generated cDNA libraries for rRNA-depleted total, polyadenylated [poly(A)+] and non-polyadenylated [poly(A)−] RNAs in whole cell extract, nuclear and cytosolic fractions 对转录本进行拼接，从 64,987 genomic loci 找到了 106,421 unique transcripts。 106,421 unique transcripts from 64,987 genomic loci. Among these, 25,245 were previously annotated protein-coding transcripts 去除掉编码 RNA，已知的非编码 RNA，短于 150bp 以及最大 FPKM &lt; 1 的转录本以及编码能力大于 0 的转录本以及和编码 RNA 在同一个方向并且有部分重叠的部分，剩下一共注释了 6510 个 lncRNAs。这里面的数据包括了不同组织和不同胁迫处理。 找到了 lncRNA 之后必然需要进行一些泛泛的统计和分类。首先作者把 NAT lncRNA 分成了 3 类：overlapping (2117), divergent (1296) and convergent (637)。具体每一类的特点如下图所示。 随后作者统计了 lncRNA 特征并和可以翻译的进行了对比，总之就是长度短外显子少 isoforms 也少，当然表达量也低。作者也检查了植物（拟南芥）里的 lncRNA 到底有没有 polyA 尾巴。在我之前的认知里感觉很多 lncRNA 是没有 polyA 的，但是作者的通过对两种建库方式进行严格筛选后发现大部分的 lncRNA 其实是有 polyA 尾巴的。具体信息如下： we found that 1352 lncRNAs were significantly enriched in the poly(A)+ fraction, whereas 198 lncRNAs were significantly enriched in the poly(A)− fraction 我没有想到的一个统计指标是作者对 lncRNA 的核质分布情况进行了分析，发现细胞核比细胞质多的 lncRNA 要多一些。 239 lncRNAs had significantly higher levels in the nuclear fraction than that in the cytosolic fraction, whereas only 43 lncRNAs were more abundant in the cytosolic fraction lncRNA 的表达特异性自然肯定也是要做的，包括不同组织和不同胁迫条件，文章特别提到了也验证出 COOLAIR 冷处理后表达量会升高。 至此都是比较平淡的信息，随后的结论就开始逐渐接触正题。 关于 lncRNA 和 adjacent genes 的关系一直争论，有抑制的也有促进的，各自都有一些实验结果支撑。可能目前的结论就是二者都有。作者计算了他找到的 lncRNA 和对应的基因之间的相关性，发现只要 NAT 相关性系数就要比不是 NAT 的高很多，而且还是正相关。 整个文章中所有的高通量分析数据作者每一步都挑了若干个 RT-qPCR 进行验证。不知道是不是 review 的要求。 We found that the p.c.c. values of overlapping NAT-lncRNA/sense gene pairs were significantly higher than the values between adjacent protein-coding pairs (Fig. 3a), suggesting that overlapping NAT-lncRNAs have a stronger tendency to have positively correlated expression patterns with their sense overlapping genes 正相关还说明不了什么。为了证明是正调控，作者使用 artificial microRNAs knocked down 21 NAT-lncRNAs。 发现，其中 15 个 cognate sense genes 显著下调，3 个上调。 有了现象就要解释结论，目前关于 lncRNA 的作用机制其实已经有不少了，比如当做一个靶点替编码基因吸引敌人，或者通过 R-loop 来发挥作用。当然，如果一个现象用正常的方法很难解释，有一个挺不错的万金油就是用表观遗传学来解释，这里的万金油是个中性词，我自己就是做表观遗传的。 作者想要说明 lncRNA 能够正向调节对应的编码基因，那么最好的方法就是看看是不是和一些类似于 H3K4me3 的激活型修饰联系起来。随后作者很「自然」的 focus 到了一个叫做 MAF4 的基因，对应的 NAT 叫做 MAS，至于为什么要做这个基因也没什么解释。 首先作者用实验证明了这两个转录本到底是编码的调控了非编码的还是反之，然后尝试分析了一些机制，比如会不会双链 RNA 产生的 sRNA，或者影响了编码 RNA 的稳定性。然后通过若干的实验证明了顺式作用 MAS 在转录水平激活 MAF4 表达。 因为已知 H3K4me3 参与了 MAF4 的激活，所以作者就像是不是可以把这个 NAT 和 H3K4me3 联系一下。然后又进行了一系列实验验证。表明确实在 MAS 的突变体中这个表观修饰有变化且一个相关的复合体因子很重要。 讨论部分几点信息 从讨论部分可以发现，作者找到的组蛋白 H3K4me3 修饰的 COMPASS-like 复合体核心蛋白组分 WDR5a 之前已经在 Nature 中被报道过和其它的 lncRNA 存在作用，但是找到的机制不同。另外，作者的结果与先前的发现一致，即相邻基因通常具有相关表达，而与其方向无关。 另外，作者也提到了基因之间的“ripple effects ”, 至于原因可能是因为 NAT-lncRNA 的 TSS 与其配对基因之间的平均距离较小，也可能是 NAT-lncRNAs 在激活其配对基因的表达中确实起着至关重要的作用。 主要方法 作者在计算表达量的时候用的还是 Cuffidff, 我并不是反感 Cuffdiff 但是我看到它就会想到 Tophat2 ，果然在 2018 年作者使用的 mapping 软件还是 TopHat2。转录组拼接用的也是 cufflinks 和 cuffmerge 那一套。 R 的版本是 3.1.0, 这一版 R 的更新日期要追溯到 2014 年 4 月 10 号 了，我猜测要么是这个文章的时间跨度确实已经有三四年了，或者是他们实验室没有一个真正做生物信息且对软件版本有强迫症的人。不过从使用的比对软件来看，也有可能是一个 pipeline 流传了很多年，祖传代码。 相关性计算使用的是 Pearson correlation coefficients，sRNA-seq 用的是 bowtie allowing no mismatches，然后定量单位是 reads per million (RPM)。 比较关心的几个问题 RT-qPCR 的时候如何区分正负链 如何保证 amiRNAs 影响反义链的时候不影响正义链的基因表达 关于这个问题，作者在文章中给了正面的回答 Alteration of sense gene expression in amiRNA knockdown lines was not due to targeting of sense genes by amiRNA*s. Eight out of 21 amiRNA*s do not base pair with sense mRNAs at all. The rest of the amiRNA*s have mismatches to corresponding sense mRNAs at critical positions。 Furthermore, most of the amiRNA*s do not have 5’ terminal uridine , making it less likely that they are loaded into the effector AGO1 to suppress gene expression 作者在文章中看似自然的从宏观层面过度到了一个具体的基因，然后讲了一个 NAT 和表观的故事。比较好奇的是其他十几个也找到正向调控的几组为什么都没有提到呢？如果按照正常的套路，一方面可能是他们先做了这个基因然后发现有 lncRNA 可能参与才有了文章开头的高通量试验，另一方面可能是其他的基因也做了，但是似乎表观又解释不了。 文章中关于 ChIP 的部分并没有做高通量试验，或者做了至少没有放在文章中，只是用 ChIP-qPCR 去验证。只要做一个 ChIP-seq 的实验很容易看看其他十几个基因的修饰情况，甚至可以 K27, K36 这些修饰都做一做。如果能有一半的基因做出表观的相关性，我都会更相信这个机制。 review 怎么看 nature 系列的杂志目前似乎可以公开作者和文章 review 之间的质疑和回应内容，在这篇文章的附件中可以看到完整的 review 意见，其中「如何保证 amiRNAs 影响反义链的时候不影响正义链的基因表达」也是 review 的问题。 个人感觉仔细阅读 review 和 作者之间沟通的这个记录比阅读原文更有意思。 相关文献 植物中研究的比较多的几个 lncRNA COLDAIR: Swiezewski, S., Liu, F., Magusin, A. &amp; Dean, C. Cold-induced silencing by long antisense transcripts of an Arabidopsis Polycomb target. Nature 462, 799–802 (2009). APOLO: Ariel, F. et al. Noncoding transcription by alternative RNA polymerases dynamically regulates an auxin-driven chromatin loop. Mol. Cell 55, 383–396 (2014). ELENA: Seo, J. S. et al. ELF18-INDUCED LONG-NONCODING RNA associates with mediator to enhance expression of innate immune response genes in Arabidopsis. Plant Cell 29, 1024–1038 (2017). 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-11-30-weeklypaper/"},{"title":"优秀到不能被忽视 读书笔记","content":"基本信息 原作名：So Good They Can't Ignore You 作者：卡尔·纽波特 页数：226 整理：思考问题的熊 规则一：不要追随自己的激情 乔布斯漏掉了什么 以乔布斯为例引出激情假设的错误 乔布斯 年轻时追求心灵启迪，喜欢西方历史和舞蹈，涉猎东方神秘主义 接触电子行业不过是为了赚点快钱 只做热爱的工作应该是一位禅修中心老师 苹果诞生不是出于激情而是出于一个「赚快钱」中的幸运转机 「追随自己的激情」对他自己并没有用 职场建议现状 职场书籍和自称职场大师的人都宣称：要想幸福，你必须追随自己的激情 职业咨询座右铭：做自己爱做的事，钱就来了 激情假设（The passion hypothesis） 要获得职业幸福，关键是首先搞清楚自己的激情所在，然后找到一份与这种激情相匹配的职业。这种假设既是错误的，也是有潜在危害的。 激情是精通的副产品 结合访谈和科学研究说明激情并不重要 - 访谈总结 - 强迫自己完成工作和强迫技能形成是最难的 - 有吸引力的职业通常有错综复杂的起源，不是只要追随自己的激情可以 - 科学研究 - 职业激情是稀缺的 - 2002 年，Robert J.Vallerand - 在确认出的所有激情中，只有不到 4% 与工作或教育有关，96% 都是某种爱好或兴趣，如运动和艺术 - 激情需要时间 - 耶鲁大学 瑞斯奈斯基 - 最快乐最有激情的员工不是将激情化为工作的人，是做得足够久从而擅长于所做事情的人 - 「自我决定理论」（Self- Determination Theory, SDT） 激情是精通的副产品 - 不管是在工作场合还是其他场合，如果想要获得动机都要满足三种基本心理需求 这些需求是个人在工作中感受到内在动机所必需的「营养物质」 - 自主：感觉对生活拥有控制力且自己的所作所为是重要的 - 胜任：感觉自己擅长于所做的事情 - 归属：感觉自己能与他人建立联系 - 「正确地工作」胜过「找到正确的工作」 激情会带来困扰 美国 过去 20 年无论经济是增长还是衰退职业满意度均持续下降 两代人「以激情为中心」的职业规划实验表明：越注重于热爱自己所做的事情，最后越不喜欢去做 激情假设 盲目的乐观主义 让人饱受困惑和忧虑之苦的职业的开始 激情有效条件 更常见于有天赋的人身上比如职业运动员 个别成功案例不能说明普遍有效的 稀缺性说明对于大多数人「追随自己的激情」是糟糕的建议 思考 在做所有事情之前总是试图抽象地作出评判是一个可悲的错误 对于自己想做什么，我真的很困惑，困惑到连自己付出了什么代价都没有意识到 人们总是急于开始生活，但这是个悲哀 要在某方面有所擅长，但这需要时间 规则二：工匠思维胜过激情思维 没人欠你一份好工作 - 人物事例 - 蓝草乐手 Jordan Tice：为练习设置「技术关注点」（technical focus），用高强度和稍快于舒适点的速度连续弹两三个小时，大致重复一个月 - 喜剧演员 Steve Martin：用 10 年时间形成自己的表演体系后便获得了巨大成功。要是你一直在琢磨「我如何才能变得真正优秀」这个问题别人就会找上门来。 - 录音棚乐师 Mark Casstevens）：执着于作品的质量是专业音乐圈的规则，它比你的外貌、乐器、个性以及关系网都重要。录音带不会说谎，录完音后马上就会回放，你的能力一览无遗。 - 不要太注重自我介绍 - 不要注重自我介绍这些小细节而要注重让自己更加优秀 - 注意力从个人网站转移到追踪每月花在对所研究问题进行专门思考的小时数 - 对待职业生涯的两种方式 - 工匠思维（ The craftsman mindset） - 以产出为中心的职业观，关注自己给世界（工作）带来的价值 - 对从事的工作类型持不可知论的立场 - 对于打造自己所热爱的事业至关重要 不必对是不是找到了自己的使命而感到焦虑，几乎任何工作都可发展成为一份有吸引力的工作。 - 激情思维（The passion mindset） - 关注世界（工作）给自己带来的价值 - 会导致长期的不满并让人不切实际地幻想还有更好的工作 - 工匠思维具体内容 - 不要以自我为中心，不要去担心工作是不是「刚好合适」 - 要俯下身子努力让自己真正优秀起来 - 没人欠你一份好工作，要自己去努力争取，而这个过程不会一帆风顺 技能胜过激情 成就大事的特质 创造力：格拉斯拓展广播领域的界限 影响力：乔布斯改变数字时代生活方式 自主力：梅里克经常去海滩冲浪 职场资本（ Career capital） 对个人所拥有的、在职场中属于稀缺而宝贵的技能的描述，是创建自己热爱的工作的关键通货。 职场资本理论（The career capital theory of great work） 来源于经济学供给与需求理论（ Supply and Demand） 成就大事的特质稀缺而宝贵，需要提供稀缺而宝贵的技能作为交换。 工匠思维不断专注于让自己「优秀到不能被忽视」是一种非常适合于获取职场资本的策略 勇气文化（Courage culture） 只要鼓起勇气脱离预期的职业轨道就能找到梦寐以求的工作 低估了以职场资本来支撑职业抱负的重要性 工匠精神不适用条件 该工作无法让你有机会通过发展稀缺宝贵的相关技能与他人区别开 你认为该工作所关注的内容是无用的或者可能对世界有害 该工作迫使你与自己非常不喜欢的人一起工作 刻意练习做好工匠 - 走出舒适区 - Jordan Tice：我练得越苦，弹得就越轻松，听起来也越好 - 专注于持续拓展能力范围的并获取即时的反馈 - 在任何领域都是成功获取职场资本的关键 - 一万小时定律 - 要在某项复杂任务上表现卓越，就需要进行时长至少达到最低限度的关键练习。造就真正专家的神奇数字是 10,000 小时。 - 有效和无效练习 - 有效：注重进行经过挑选的有难度的活动且可以拓展最需要改善的能力并能提供即时反馈 - 无效：有趣且令人兴奋但并不一定提高水平 - 刻意练习（Deliberate practice） - 正确的时间正确的地点积累大量练习 - 一项通常由一位老师所设计的、以有效改善某一个体的某方面表现为唯一目的的活动。它要求将自身能力拓展到舒适范围以外，然后不断接收反馈。 - 刻意练习也许是快速让自己变得“优秀到不能被忽视”的关键所在。 - 绩效高原（Performance plateau） - 大多数一开始就活跃于专业领域的个体都会在有限时间内改变自己的行为并且提升自己的绩效，直到达到某种可以接受的水平。然而在此之后进一步的改善似乎无法预知，工作年数不足以预测一个人所能达成的绩效。 - 时间花在重要的事情上 - 把时间花在重要的事情上，而不是花在紧急的事情上 - 每周结束时统计时长然后以此作为下一周的参考。 - 刻意练习的 5 个步骤 - 判断身处哪种职场资本市场（Career capital markets） - 赢者通吃型：只有一种职场资本可以获取，并且有很多不同的人在争夺这种资本 例如个人技术博客 - 拍卖型：有很多不同类型的职场资本，并且每个人可以生成他们自己独有的资本 - 识别自己的资本类型 - 处在拍卖型市场要寻找窗口：已经敞开的积累资本的机会 比如毕业做博后，更容易进入角色 - 学会定义优秀 - 有明确的目标，没有目标就没有措施 - 拉伸与摧毁 - 刻意练习通常是令人愉悦的对立面，感觉就像是做「拉伸运动」 - 积极接受真诚甚至犀利的反馈，「摧毁」自认为的优秀 - 要有耐性 - 职场资本的获取需要时间 思考 别转身逃离自己目前工作的桎梏，而是开始获取必需的职场资本，从而将自己从桎梏下解放出来。 伟大的成就不在于天赋，而在于在正确的时间、正确的地点积累到如此大量的练习。 规则三：幸福来自于自主力 自主力是理想工作的万灵药 自主力（Control） 对自己的工作内容和工作方式拥有发言权，是在创建自己热爱的工作时需要靠职场资本来获取的最重要的特质之一 没有成果就没有工作，通过在工作内容和工作方式上赋予人更多的自主力会提高人们的幸福感、投入程度以及满足感 自主力两个陷阱 第一自主力陷阱（The first control trap） 自主力若不以职场资本而取得则不具备可持续性 热情本身不是稀缺而宝贵的东西因此并不能换来多少职场资本 第二自主力陷阱（The second control trap） 当你拥有足够的职场资本来获取对职业生涯的合理控制时当前雇主会想方设法防止你做出改变 做有人愿意埋单的事 Derek Sivers 事例 金钱方面的一条原则凌驾于其他人生原则之上：要做有人愿意埋单的事，钱是中性的价值指标，赚钱的目的是让自己有价值。 财务可行性法则（The law of financial viability） 在决定是否追求某项有吸引力的活动从而给自己的职业生涯增加自主力时，应该问问自己别人是否愿意为之埋单。如果愿意，那就继续追求；如果不愿意，那就维持现状。 规则四：使命感带来意义 有意义的使命与有价值的人生 进化生物学家 Pardis Sabeti 生物学容易把一个年轻教授变成一个脾气暴躁的工作受虐狂，会把休息视为失败、把同行的成就视为自己的悲剧。 职业动力来源于明确的使命：利用新技术对抗古老的疾病 使命的重要性 拥有使命是在事业上拥有一个起到统领作用的重心，使命比某种具体的工作更为笼统且可以贯穿多个职位 感受到自己事业的重要会对自己的职业生涯感到更加满足且更能承受住辛苦工作所带来的压力 让人将精力都集中到某个有用的目标之上，反过来在自己所处的领域里影响力最大化，影响力是热爱自己工作的关键因素之一 使命（Mission） 使命是在创建自己热爱的工作时需要靠职场资本获取的另一个重要特质，它比某种具体的工作更笼统，而且可以贯穿多个职位。它回答了“我的人生应当怎样度过”这个问题，能够使你将精力都集中到某个有用的目标之上。 在前沿地带找到使命感 几个人作出同样发现的原因 相邻可能（The adjacent possible） 在任何领域，下一个伟大的创意通常就出现在当前发展前沿之外的相邻区间，而这个区间包含了对现有想法的各种可能的新组合。 关键是必须达到某一领域的前沿，然后这种相邻可能以及它所包含的创新才会显现。 创新其实更具系统性 科学家们一点一点将科技前沿向外扩展，在相邻可能中发现新问题 新问题的解决又会将前沿再向外扩展一些，产生更多的新问题，这样周而复始 使命达成需要资本 想要拥有使命，你需要首先获取资本 好的职业使命也是一种创新，而这种创新存在于你所在工作领域的相邻可能之中 想在自己职业生涯中找到某种使命必须首先达到前沿 用正确的顺序做事 往小处想：在相当长一段时间内专注于很少的几个课题，达到某一领域的前沿水平是往「小处」想 往大处做：一旦达到了前沿并且在相邻可能中找到了一项使命必须以极大的热情去追求，即往「大处」做 使命需要「小赌」 小赌（Little bets） 不一定要以一项伟大的创意开始，或者事先做好全盘规划，而是通过一系列有条不紊的“小赌”探索出一个可能不错的方向，并且从大量的小失误以及那些意义重大的小成功中汲取关键信息。 小赌策略使命的成功实现成为可能 需要引人注目 事例 鲍凯特 想要打造一份可以持续发展的事业必须生产引人注目而且能够迫使人们传播的项目 致力于达成“将艺术世界与 Ruby 编程世界结合起来”使命 发布了「始祖鸟」（Archaeopteryx）的开源人工智能程序 把自己作为程序员推销出去的最佳方法：开发引人注目的开源软件 引人注目法则（The law of remarkability） 使命驱动型项目想获得成功必须在两个方面引人注目 必须迫使接触过它的人向他人进行评论 必须在一个利于这种评论发生的场合启动 博客是一个引人注目的场所同时内容要有话题点 五个补充 以效率为中心变成以技能为中心 以效率为中心：「完成工作」是优先考虑的事情。如果以这种效率思维来考虑问题往往就会回避刻意练习导向的工作，因为此类工作的完成方式不明确，而且还需要忍受精神紧张而带来的不适感。 以技能为中心：「让自己越来越优秀」成了最重要的事情，想要变得优秀就需要经受刻意练习所带来的精神紧张。一旦接受了这种方式职业轨迹就会发生深刻的变化。 作者刻意练习的三个习惯 研究圣经 要求自己每周写一篇论文总结，而且这篇论文是认为可能与自己研究有关的 总结必须包括对论文结果的描述、与前人工作的比较，以及取得这一结果所运用的策略 时数记录表 每行是一个月，记当月处于刻意练习状态的总时数 理论笔记本 极贵的笔记本的高成本表明了我所要写下的内容的重要性 来迫使自己进入精神紧张的状态，从而总结、整理自己的思路 使命培育金字塔体系 顶层：探索性研究使命 中间层：试探性研究 一个小赌项目 规模要足够小能够在一个月以内完成 迫使你去创造新价值即掌握某项新技能并且产生前所未有的新结果 可以产生实实在在的结果从而收到实实在在的反馈 底层：背景研究 操作方法 底层描述的过程中会产生一些想法，通过“小赌”来对其中最有前景的想法进行探索 一次只进行两三个“小赌”从而集中投入精力 采用期限管理并在计划中用黄色标明，以示完成项目的紧迫性 通过时数记录表来追踪花在“小赌”上的时间 在一项“小赌”完成后用它带来的实际反馈指导下一步工作 为完成“小赌”所付出的努力增加了刻意练习的次数 遇到抗拒心理如何解决 培养技能的过程非常艰难 遇到困难心里立即产生抗拒，信号先是隐约可以察觉，但随着坚持越久强度也越大且不断注意力造成冲击。 时间结构 我要在这上花一小时，不管我会晕在这上面，还是一无所获，都无所谓。在下一个小时里，这就是我的整个世界。 信息结构 以有用的形式来体现自己通过艰苦努力所取得的成果 首先构建一张论证图，展示了论文各个不同的论证过程之间的从属关系 做一些简短的自我测验，强迫自己对论证所用到的关键定义进行记忆 获得一些理解，对解析后面复杂的数学计算至关重要 正确地工作胜过正确的工作 「追随自己的激情」是个糟糕的建议，对于大多数人而言并没有一个事先存在的激情等待被发掘，然后去和某个工作相匹配。要想找到职业幸福感需要的不是什么完美的工作，而是以一个更好的方式来对待现有的工作。只要继续坚持在探求过程中发现的那些想法，这份热爱只会加深不会减弱。 那些从事着有吸引力的职业的人是通过让自己在某些稀缺而宝贵的方面有所擅长，即建立“职场资本”然后将其“兑现”为成就大事的特质，从而开创了一番事业。与「正确地工作」相比「找到正确的工作」显得无足轻重。 一旦你积累到了这些技能所产生的职场资本，就要明智地运用好它。你可以用它来获取在工作内容和工作方式上的自主力，以及用来找到并实践某项改变人生的使命。 想要找到真正的使命，首先要有职场资本，而职场资本的积累则需要耐心；其次要不断关注自己所在领域的相邻可能区间（而这个区间始终都在变化），从而找到下一项伟大的创意。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-11-13-sogoogtheycantignoreyou/"},{"title":"你的灯亮着么 读书笔记","content":"基本信息 原作名：Are Your Lights On? How to Figure Out what the Problem Really is 作者：唐纳德·高斯；杰拉尔德·温伯格 主要内容：如何能更好的解决问题，通过 20 个故事讲 6 个道理 问题是什么 定义问题 不要在没有定义好问题时仓促给出解决方案 不要在已有的定义上反复犹豫不前 多重思维 谁碰到了问题 问题的本质是什么 问题角度 境遇和地位不同时同一事情认为的问题也不同 你感觉的问题未必是其他人的问题 问题本质 理想状态和现实状态之间的差别 你感觉到的任何不顺都是问题 这次的问题是什么 不要把别人的解决方法当成问题的定义 协助别人解决问题时要知道整个问题 不是他们已经解决到自己完成不了的部分 如果解决问题太过神速别人根本不会相信你解决了问题 面对有利可图的问题时道德考量很可能烟消云散 别把自己对问题的解决方案误当作问题的定义 当这个解决方案是由你提出的时候尤其如此。不要把问题用你的解决方法来定义，因为这样会很大程度上限制你解决问题的灵活性。 不要仓促下结论但也不要忽视第一印象 即使问题已经解决也无法确定问题的定义是否正确，但是永远不要停下寻找正确定义的脚步 问题到底是什么 每一个问题的解决方案都是下一个问题的来源 因为任何一个问题都是理想状态和现实状态之间的差别，当人们通过改变状态“解决”一个问题的时候，常常会新制造出一个或几个问题来。 某些问题最困难的部分在于发现问题 一旦发现问题问题就解决了 任何一个问题的定义都有大量信息被忽略所以找出至少三个疑点 每转换一次视角都可以发现问题的不协调之处 解决某些群体问题的代价常常是引发另一个群体的灾难 变换问题的表述方式可以得到不同的解决方案 增加不同的条件辅助思考 回顾对问题的理解是否正确 注意表达可能产生的歧义 用文字表述问题时要确信在每个人的脑中都是同一个意思 问题该由谁解决 当别人可以妥善解决自己的问题时千万不要越俎代庖 问题相关方对问题了解更深入感受更真切 他们更愿意参与到自己提出的解决方案中 如果这是别人的问题就把它当成是别人的问题 如果一个人处于解决问题的位置却不受问题困扰就采取行动使他能亲身体验到问题 有时对方并不是没有能力解决问题而是暂时没有意识到存在问题 只需要提醒而不用提供方案 如果是白天，而且车灯亮着，那就把车灯关上； 如果是晚上，而且车灯关着，那就把车灯打开； 如果是白天，而且车灯关着，那就让它关着； 如果是晚上，而且车灯亮着，那就让它亮着。 隧道出口，“你的灯亮着么”一个小小的提醒可能比复杂的关灯开灯方案更有效。（书名来由） 问题来自哪里 永远不要把问题归结于人的天性 大多数时候问题的根源在自己身上 定义错问题 误判了情况 世界上有两种人 一种人做事，另一种人制造出事来让其他人做。远离那些找事让别人做的人，你就能好好过日子了。 一种人做事，另一种人领赏。做第一种人吧，那里的争斗比较少。 你真的想解决问题吗 应试教育把我们培养成了一个急着去解决问题但其实并不确切知道问题是什么的人 当你感觉自己有问题的时候就是真的有问题了，但这并不意味着知道问题是什么 无论表面上表现得如何，在你提供别人所要求的东西之前，他们极少知道自己想要什么 很多时候从最后的情况看想要真正解决问题的人并不是很多 在思考问题的时候已经习以为常的事物总会被忽略，不纳入考虑范围。只有当解决方案出现、那些习惯了的因素被移除的时候，人们才会感到震惊。 在为解决问题而惊叹不已的时候你可能会忽略自己是不是能在道德上支持某一解决方案。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-11-10-areyourlightson/"},{"title":"VScode 系列 1：提升 R 和 Python 使用体验","content":" 已经攒了一系列 VS Code 写作计划和素材，之前也发过几篇基础知识的思维导图（见文末）。不过一直不知道该从哪里开始第一篇文章，如果推荐给身边的人，他们可能最关心的是用 VS Code 日常写简单的 R 和 Python 代码体验如何。那就从这里开始吧。 本文以 PC 作为安装配置示例，Mac 基本类似且部分内容体验可能更优。 为什么是 VS Code 既然是系列文章的开篇，姑且对主题按下不表先介绍一下 VS Code。 VS Code 的全称是 Visual Studio Code，官方给他的定义是官方定义是一个免费的、开源的跨平台编辑器。相对于各种 IDE 而言，编辑器则相对更轻量，更侧重于文件或者文件夹而非宏大的项目。 2011 年底，微软从 IBM 请 《设计模式》的作者同时也是 Eclipse 掌舵人之一的 Erich Gamma 来开发一款优雅的在线开发工具（后来的 Manaco Editor），2015 年他把这款在线工具移植到了桌面平台，也就有了如今 VS Code 。师承 Eclipse 同时又吸取 Eclipse 的教训，他们决定核心只做一个高性能的轻量级编辑器，个性化功能交给插件系统来完成且要把插件系统运行在主进程之外。同时，VS Code 希望让开发者在编辑器里拥有 IDE 类似的开发体验，比如对源代码的智能理解、图形化调试工具和版本管理等等。总之，就是在 IDE 和编辑器中找到一个比较理想的平衡。 在很多人的印象中，微软一直是一个站在开源世界对立面，靠专利官司和垄断挣钱的公司，但其实微软近几年一直是 GitHub 贡献开源代码最活跃的公司，活跃到现在已经把 GitHub 收购了（黑人问号脸）。而在所有微软的开源项目中，star 最高的 repo 就是 VS Code 编辑器。VS Code 以 MIT 协议开源，所有的开发过程和反馈渠道完全在 GitHub 开放，同时 VS Code 提供了统一的 Language Server Protocol 和 Code Debugging Protocol API，所有语言的开发和都能够通过实现两个 API 在 VS Code 上得到类似 IDE 的开发和调试体验。 如果你是一个 R 语言用户，RStudio 一定是首选 IDE，如果你是一个 Python 用户，Pycharm 则是大多数人的编辑器。但如果你平时既要用点 R，也要用点 Python，偶尔感觉这些 IDE 有点臃肿或者不想在两个 IDE 中反复切换，那么 VS Code 是一个不错的选择。 VS Code 有两个不同版本：稳定版（Stable）每月发布更新一次；预览版（Insiders）每个工作日更新一个版本。当然，你也可以同时安装两个版本互不影响。 虽然我一直不喜欢微软的 office ，但是 VS Code 又让我对微软增加了不少好看。现在我日常工作中，轻度码字、写脚本、阅读 PDF 和 Excel 文本甚至查看压缩文件等工作都可以在它上面完成。离「只用一个 VS Code 完成所有事情」的目标已经不太远了。当然，如果还有什么需求没有实现，最牛的是学习自己去写一个插件。 安装 R 和 Python 因为这篇文章的写作目的是「用 VS Code 愉快地使用 R 和 Python 」，所以默认看官已经可以自主地在电脑上安装 R 和 Python ；因为是系列文章的首篇，所以暂且不涉及复杂操作和各种使用技巧；因为默认大家是同时轻度使用 R 和 Python 所以暂时不涉及代码调试和版本管理等内容。在后面的文章中这些都会提到。 对于 Windows 用户 R 可以在 官网 下载，Python 建议安装 anaconda 的 Python3 版本。另外这里有一篇 关于 R 安装注意事项 的文章可以作为参考。 配置 R 插件 VS Code 对语言的支持方式是提供统一的开发 API，即 Language Server Protocol。各种语言可以能够通过这个 API 在 VS Code 上得到类似 IDE 的体验，这种服务在 VS Code 中称为语言服务。 语言服务会根据我们的项目、当前文件和光标所在位置为我们提供一个建议列表，包括在当前光标位置下我们可能会输入的各种代码函数。随着字符的输入 VS Code 会根据字符输入内容自动对列表进行过滤。 目前 JavaScript、Python、PHP 等几大主流语言在 VS Code 中都已经有很完善的支持，但是 R 核心插件还是第三方贡献的，想要配置的顺手还需要一些操作。实现 R 语言服务必需要有如下前两个插件（插件管理可以在左侧侧边栏找到，然后在搜索框里搜索R即可）。 R support for Visual Studio Code 这个插件是 VS Code 中 R 的核心插件，具有语法高亮，基础代码片段和代码执行等功能。例如你可以在编辑器中选择某几行内容，然后使用ctrl + enter将代码发送到终端执行。 R LSP Client 这个插件在主页的介绍是 R language support for VS Code, powered by the R language server. 也就是我们上文提到的「Language Server Protocol」，有了这个它就可以进行代码补全、查看函数定义以及参数预览了。不过想让它生效还需要下面几个小步骤： 在 R 中安装 languageserver 包 install.packages(&quot;languageserver&quot;)，只有安装了这个包才能实现 R 和 编辑器的同步。 在 VS Code 中设置正确的 R 路径 打开设置界面，在搜索框中输入 r.rterm，找到 Rterm:Windows ，在编辑栏中输入你的 R 可执行文件位置。如果是默认安装的 R 3.5.1 版本，位置应该是C:\\Program Files\\R\\R-3.5.1\\bin\\x64\\R.exe 在 VS Code 中设置正确的 R LSP 路径 和上面的方法相同，只不过这次搜索r.rpath.lsp，目录和你的r.rtrem.windows 一致即可。 完成上面几项设置，接下来使用ctrl+shist+p 调出命令面板，然后输入reload，选择 Reload Window 执行 ，重启 VS Code 即可。 目前 VS Code 已经实现了界面化设置，但是其本质是一个 json 格式的配置文件，你也可以在配置文件中进行修改和编辑。 rtichoke RStudio 中的 R Console 本身具备参数提示和补全等功能，很多人非常喜欢。然而到目前为止，如果直接在 VS Code 中执行 R 代码，它默认调用的是我们之前设置过的官方 R 终端，这个终端非常古老而且不友好。不过好在我们的「21 世纪 R console」rtichoke 即将登场。 说到 rtichoke 有不少人都知道它可以实现多行编辑、语法高亮和自动完成等功能，用起来基本不输 RStudio。不过他们中 99% 的人都是在 Linux 或者 macOS 中使用。因为这个软件本身是 Python 写的并且需要用命令行pip安装，很多 windows 用户心理嘀咕一句「tmd，windows 竟然不能用」然后卒，其实你是自己把自己放弃了。好在我还是那剩下的 1% 里在 Windows 使用 rtichoke 的用户，使用方法如下。 在上文中你应该已经成功使用 anaconda 在你的电脑里装好了 Python，现在打开Anaconda Prompt，也就是 anaconda 自带的命令行工具。 输入pip install -U rtichoke 安装 rtichoke 安装完成后输入rtichoke测试是否调用成功 找到并进入你电脑里的 anaconda scripts 目录，正常情况下是 C:\\Users\\youname\\Anaconda3\\Scripts\\ 不出意外里面应该有一个 exe 文件，叫做 rtichoke.exe，找到它并复制它的路径 在 VS Code 中重新设置r.term.windows为 rtichoke.ext 路径 找到r.rterm.option 选项，并在配置文件（json 格式）中注销掉这个选项下的--no-save和no-restore参数 重启 VS Code 后大功告成 R 运行使用效果 现在 R 运行的配置工作已经完成，一起来看下效果。首先，我在工作项目中打开一个 R 脚本 test.R，里面是一段plotly 测试代码。 鼠标放在一个函数上自动出现函数功能和使用方法 鼠标放在一个内置数据集自动出现数据集介绍 鼠标放在一个 R 包上自动出现 R 包介绍 输入部分函数自动提示 鼠标在函数括号里自动出现参数提示 选中部分代码，按一次ctrl+enter 自动进入集成终端，也就是 rtichoke 再按一次ctrl+enter 自动执行代码并输出结果 如果想调用 View 等外部输出也是可以的，比如View(tmp2) 会弹出一个 R 默认终端的独立显示框，比如测试代码最后是print 一个 plotly 的绘图结果，那么它会自动调用你的默认浏览器进行输出。 自定义 R 必备快捷键 如果你是一个老实的 R 语言用户，那么一定不会用 = 代替 &lt;-，但是 &lt;- 需要按两下键盘而且这两个键位置还挺远，更难过的是因为你用了语法提示如果你在&lt;- 两端没有加上空格它还会给你出现「大破浪」下划线恶心你。在 RStudio 中你可以使用 alt + - 一气呵成输入这四个符号&lt;-，在 VS Code 中必须也可以。 打开 Keyboard Shortcuts （快捷键是 ctrl+k ctrl+s)，在搜索框中搜索alt+s，这个时候你会看到这个快捷键已经被绑定了（别慌），点开 json 文件我们去给这个快捷键设置不同情境下新的含义。 点开快捷键配置文件之后不要管左边的内容，直接去右边设置就好，配置方法如图（至于为什么这么写，后面会写专门的快捷键相关文章）。从此以后在 R 或者 Rmd 文件里alt+-就变成了和 RStudio 一样的快捷键。 配置 Python 插件 如果把 R 的配置搞定，Python 的配置就显得很简单了。想愉快地使用 Python 只需要安装一个 Python 插件即可。 接下来设置默认的 Python 路径，如果是用 anaconda 默认安装路径应该是C:\\Users\\yourname\\Anaconda3\\python.exe ，这时使用的是默认 Python 解释器；与 R 同理，如果你想使用 anaconda 中的 ipython 那么可以把路径设置为 C:\\Users\\yourname\\Anaconda3\\Scripts\\ipython.exe。 错误提示和格式化 安装和配置 Python 默认的语法提示工具是 PyLint，也可以选择其他的 linter 工具，比如 flake8，flake8 是 Python 官方发布的一款静态代码检查工具，如果想使用它的话首先在 anaconda 的命令行工具中安装pip install flake8；另外，在保存代码的时候 VS Code 可以自动进行 code formatting ，这个功能默认是关闭的且工具是 autopep8 , 如果想使用 yafp，则继续在命令行工具中安装 pip install yapf。 安装好这两个工具之后在 VS Code 的配置文件中进行设置： &quot;python.linting.enabled&quot;: true &quot;python.linting.flake8Enabled&quot;: true, &quot;python.formatting.provider&quot;: &quot;yapf&quot; 查看错误和修改 在集中终端的 PROBLEMS 可以查看代码中存在的问题。如下图所示，错误报告中会提示问题，错误编号和所在行数位置，点击某一个具体的问题后编辑器就会自动定位到相应的行数。 禁止对某些文件进行检查 从上面的截图可以发现，我一个文件中竟然有 915 处问题，看来我这个智商基本就告别 Python 了。如果为了自我麻痹，我可以在设置中关闭代码检查，但真实情况是这个文件并不是一个真正的 Python 脚本，我只是想借用 Python 的语法高亮而已。 针对这种情况，我们可以选择单独对某一类（后缀）文件排除语法检查。比如我用 Python 语法高亮的这类非 Python 文件后缀通常我会被我命名为 snakefile ，那就可以进行如下设置： &quot;python.linting.ignorePatterns&quot;: [ &quot;.vscode/*.py&quot;, &quot;**/site-packages/**/*.py&quot;, &quot;*.snakefile&quot; ] 重启之后，在打开原文件，满屏的大波浪红线就无影无踪了。 当然，因为 VS Code 对 Python 的完善支持，在设置中还有非常多的相关参数可以调整，你可以在设置的搜索框中输入python 浏览一下，但因为我们本文预设是轻度编写代码就不在展开了。 另外，也可以参考官方的一些 Python 使用介绍 https://code.visualstudio.com/docs/languages/python https://code.visualstudio.com/docs/python/python-tutorial https://code.visualstudio.com/docs/python/linting windows 用户的一个痛点 在文章开始，我说「本文以 PC 作为安装配置示例，Mac 基本类似且部分内容体验可能更优」，现在就表达一下这个小小的遗憾。随着 win10 的升级，Windows 已经可以安装自己的 Ubuntu 系统 「Windows Subsystem for Linux」，但是系统自带的 bash 那叫一个丑陋和难用。由于 VS Code 在集成终端上下了不少功夫，其实我一直都把它当成我的简洁版「XShell」来使用，体验也非常好。如果你想试试，只需要在配置文件中把terminal.integrated.shell.windows 由默认的C:\\\\Windows\\\\System32\\\\cmd.exe 改为C:\\\\Windows\\\\System32\\\\bash.exe，这个具体内容以后再写。但是如果 在这个 bash 里调试 Python 是会出问题的，修改起来即便能姑且使用也是拆了东墙补西墙。我暂时的解决方法是在预览版的 VS Code 中修改了默认的 terminal，在稳定版里还用 cmd.exe。 VS Code 基础知识思维导图见上一篇博客。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-10-28-userpythoninvscode/"},{"title":"66 种测序数据分析方法和流程","content":" 写在前面：看了标题进来的老铁，这里不可能在一篇文章里写好 66 个 pipeline 给你，实际上我就是给你推荐一个网站。 闲着乱看的时候发现在** bioinformatics** 上发表了一篇文章** SequencEnG: an Interactive Knowledge Base of Sequencing Techniques**，再一看 Abstract，写道 Next-generation sequencing (NGS) techniques are revolutionizing biomedical research by providing powerful methods for generating genomic and epigenomic profiles. The rapid progress is posing an acute challenge to students and researchers to stay acquainted with the numerous available methods. We have developed an interactive online educational resource called SequencEnG (acronym for Sequencing Techniques Engine for Genomics) to provide a tree-structured knowledge base of 66 different sequencing techniques and step-by-step NGS data analysis pipelines comparing popular tools 艾玛，原来现在已经有至少 66 种不同测序技术了？ 掰着手指想了想，知道的做过的撑死也超不过一双手啊。这 66 种测序技术都是啥，于是点开了 这篇文章的网站 想探探路。嗯，果然很多没听说过：) 这个项目是来自 NIH &quot;Knowledge Engine for Genomics&quot; 下的一个子项目，主页是这样式儿的。 提供了一个树状测序列表和分析流程的选择栏，两者之前可以相互跳转。这个树状测序列表是这样式儿的。 从大的分支来说包括 DNA, RNA 和 Epigenetics 三部分，每部分又延伸出若干分支。随便找到一个子类进去看看，譬如 ATAC-seq? 首先会给一个关于该技术的简单介绍和流程图，是这样式儿和这样式儿的： 点一下 pipeline（如果有），就可以去看分析流程了，一个总体分析流程： 接下来点击一个具体的分析步骤，会给一个可以分析该部分内容的工具列表，比如我们点击 Peak calling，下面的截图是表格一部分。 嗯，差不多了，接下来你可以自己去试试。顺便提一下，这个网站还有一些其它的小功能也可以留意。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-09-27-sequence66/"},{"title":"VScode 学习记 1-4","content":" 使用 VSCode 作为自己的主力编辑器已经有一年的时间，但是总感觉没有很系统的了解过日常的这个工具，也就不知道自己的使用是否高效。最近再跟极客时间上的一个 VS Code 付费连载，那就顺便把它好好安排一下，记录一些学习笔记。学习记录将主要分为两种形式，偏文字的部分会整理为思维导图，偏代码的部分会整理为文章。 如何快速掌握新编辑器 VS Code 前世今生及设计哲学 第二讲内容是从学习路径上介绍** VS code 的 Why How 和 What**，依旧整理成了思维导图的形式 如何快速上手 VS Code 第三讲内容主要是针对第一次使用的用户，介绍了如何快速上手 VS code，不过命令行的部分确实是我之前使用过程中忽略掉的，其实功能很强大。 依旧整理成了思维导图的形式，但从今天开始必须要动手实践，只看一张图没啥意思。 如何双手不离开键盘 无论我们提倡使用 markdown 还是使用快捷键，主要目的都是提高效率，尽量让双手不离开键盘。对于编辑器中快捷键的使用，一开始看似是一件更浪费时间的事情，但是随着肌肉记忆和熟练度增加，效率将会大大提高。本节内容主要涉及 VS Code 的常用快捷键以及如何定制。 如果你是从其他编辑器转到 VS Code，那你完全可以移植你之前熟悉的快捷键配置，比如 Vim, Atom 或者 sublime。如果你其它快捷键也不熟悉不如就专心学会 VS Code 的常用快捷键。 把自己日常经常用到的快捷键整理成了导图。如果能把下面图中的快捷键用熟练，每天省下 20-30% 使用编辑器的时间不是问题。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-09-20-vscode-note1-4/"},{"title":"SRA 数据下载自救指南","content":" 还在羡慕海峡那边的朋友下载 SRA 快到飞起？还在难过用 wget 下载数据经常下载不完整？用了官方的下载工具还是慢的不行？这里有一个 SRA 下载自救尝试指南供你参考。 需要用到两个工具 SRA Toolkit IBM aspera 高速文件传输工具 因为这是一篇极简自救指南，所以一切都不解释，直接给出链接，不明白的自行学习（爱学不学）。 SRA Toolkit 网址：https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=toolkit_doc aspera 网址：https://support.asperasoft.com/hc/en-us aspera 官方对于下载 NCBI 数据的说明 https://support.asperasoft.com/hc/en-us/articles/216125898-Downloading-data-from-NCBI-via-the-command-line SRA Toolkit 官方对于使用 aspera 的说明： https://www.ncbi.nlm.nih.gov/books/NBK242625/ https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=toolkit_doc&amp;f=prefetch 快速自救前奏 下载 aspera （选择 linux 版本） https://downloads.asperasoft.com/en/downloads/8?list 安装 aspera wget https://download.asperasoft.com/download/sw/connect/3.8.1/ibm-aspera-connect-3.8.1.161274-linux-g2.12-64.tar.gz # 小心版本号有变动，不要直接复制上面的命令 tar zxvf ibm-aspera-connect-3.8.1.161274-linux-g2.12-64.tar.gz bash ibm-aspera-connect-3.8.1.161274-linux-g2.12-64.sh # 默认安装路径 /home/user/.aspera 安装 sra toolkit 具体命令省略，注意一定要安装最新版本：） 正式开始自救 目前中文关于使用 aspera 下载 sra 数据的几篇教程都写的婆婆妈妈乱七八糟，千万不要再看了！ 记住，正式的自救只需要两步，其它写一大串的文章都是“耍流氓”。 把要下载的数据 SRR 号写入一个文件 srr.txt，每行是一个 SRR id 利用 SRA toolkit 的 prefetch 下载，并指定下载方式为 ascp，命令如下，各种参数的含义自行查看文档（爱看不看） prefetch -t ascp -a &quot;/home/user/.aspera/connect/bin/ascp|/home/user/.aspera/connect/etc/asperaweb_id_dsa.openssh&quot; --option-file srr.txt -O /opt/user/ncbi 其中-a 参数中必须要用绝对路径写上 ascp 所在的位置和 previte KEY 的位置，如果是正常安装只需要把 user 替换为自己的用户名。 自救效果测试 下载了八个 SRR 文件，平均一个大小 5G 左右，使用时间如下： 2018-09-05T14:14:33 prefetch.2.9.2: 1) Downloading 'SRR******'... 2018-09-05T14:14:33 prefetch.2.9.2: Downloading via fasp... SRR****** 2018-09-05T14:16:58 prefetch.2.9.2: fasp download succeed 2018-09-05T14:16:58 prefetch.2.9.2: 1) 'SRR******' was downloaded successfully 2018-09-05T14:17:01 prefetch.2.9.2: 2) Downloading 'SRR******'... 2018-09-05T14:17:01 prefetch.2.9.2: Downloading via fasp... SRR****** 2018-09-05T14:19:25 prefetch.2.9.2: fasp download succeed 2018-09-05T14:19:25 prefetch.2.9.2: 2) 'SRR******' was downloaded successfully 2018-09-05T14:19:28 prefetch.2.9.2: 3) Downloading 'SRR******'... 2018-09-05T14:19:28 prefetch.2.9.2: Downloading via fasp... SRR****** 2018-09-05T14:22:31 prefetch.2.9.2: fasp download succeed 2018-09-05T14:22:31 prefetch.2.9.2: 3) 'SRR******' was downloaded successfully 2018-09-05T14:22:35 prefetch.2.9.2: 4) Downloading 'SRR******'... 2018-09-05T14:22:35 prefetch.2.9.2: Downloading via fasp... SRR****** 2018-09-05T14:25:14 prefetch.2.9.2: fasp download succeed 2018-09-05T14:25:14 prefetch.2.9.2: 4) 'SRR******' was downloaded successfully 2018-09-05T14:25:17 prefetch.2.9.2: 5) Downloading 'SRR******'... 2018-09-05T14:25:17 prefetch.2.9.2: Downloading via fasp... SRR****** 2018-09-05T14:26:46 prefetch.2.9.2: fasp download succeed 2018-09-05T14:26:46 prefetch.2.9.2: 5) 'SRR******' was downloaded successfully 2018-09-05T14:26:49 prefetch.2.9.2: 6) Downloading 'SRR******'... 2018-09-05T14:26:49 prefetch.2.9.2: Downloading via fasp... SRR****** 2018-09-05T14:28:13 prefetch.2.9.2: fasp download succeed 2018-09-05T14:28:13 prefetch.2.9.2: 6) 'SRR******' was downloaded successfully 2018-09-05T14:28:16 prefetch.2.9.2: 7) Downloading 'SRR******'... 2018-09-05T14:28:16 prefetch.2.9.2: Downloading via fasp... SRR****** 2018-09-05T14:29:56 prefetch.2.9.2: fasp download succeed 2018-09-05T14:29:56 prefetch.2.9.2: 7) 'SRR******' was downloaded successfully 2018-09-05T14:30:00 prefetch.2.9.2: 8) Downloading 'SRR******'... 2018-09-05T14:30:00 prefetch.2.9.2: Downloading via fasp... SRR****** 2018-09-05T14:31:58 prefetch.2.9.2: fasp download succeed 2018-09-05T14:31:58 prefetch.2.9.2: 8) 'SRR******' was downloaded successfully 喏，5G 的文件，即便是在（你懂的）这种网络状况下，一个也只需要不到 2 分钟。 自救成功，祝好！ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-09-19-downloadsrafast/"},{"title":"转录组时间序列数据小结","content":" 针对转录组数据，平时分析中最常见两组之间的比较，比如不同处理或者不同突变体。面对这样的数据用用 DESeq2 或者 edgeR 基本就差不多。如果样本量或者不同条件很多的话可以还做 WGCNA 的分析。但是生物体的生长发育和时间这个维度有着非常密切的关系。如果碰上了一组和时间有关系的数据可以怎么处理呢？ 时序分析 所谓时序分析 (time series analysis) 在 data science 中是非常重要的一个方向。对大多数商业行为而言如果能够通过已有不同时间数据来进行预测就有可能大大提高自己的胜率。通常时间序列数据会包括趋势部分和不规则部分， 我们需要做的就是剔除不规则部分然后找到趋势所在，再进行预测。在预测过程中通常可以采用移动平均法、局部加权回归法、指数平滑法和自回归整合移动平均等方法。 生物学时序分析 生物学的时间相关数据本身预测属性和商业数据相比要弱很多。一种是单一条件的纯时间序列，主要看不同基因的表达模式，根据相似的表达谱将基因归为多个类有助于找到功能相似的基因。另一种情况是含有对照和处理的时间序列，需要再考察不同条件的差异基因。 可用的分析时间序列工具 关于时间序列转录组数据分析的工具，近三年来有两篇偏综述和测评类的文章（一个人写的）。 Dynamics in Transcriptomics: Advancements in RNA-seq Time Course and Downstream Analysis Comparative analysis of differential gene expression tools for RNA sequencing time course data 在这两篇文章中还是提到了一些工具，但其中有一些用到 matlab（这软件贵啊），有一些年久失修或者不维护或者和最新 R 版本不兼容，筛筛捡捡能用的且文章里认为还不错的也就剩下三四个。 主要模型 负二项分布 NB 来自于 DESeq 的方法，下文中提到的 ImpluseDE2 和 MaSigPro 都使用了这种模型。 多项式回归 PR 来自于 maSigPro 方法，所谓多项式回归区别常见的线性回归，会把一次特征转换成高次特征的线性组合多项式，比使用直线拟合更加准确。但是到底用几次方需要具体分析，次数过高会出现过拟合。在能够解释自变量和因变量关系的前提下，次数应该是越低越好，这也算是奥卡姆剃刀原则吧。 自回归隐马尔可夫模型 AR-HMM 所谓自回归是统计上一种处理时间序列的方法，用x1x_1x1​ 至 xt−1x_{t-1}xt−1​ 来预测本期 xtx_txt​ 的表现并假设它们为线性关系。简单说就是用自己来预测自己，因为是从回归分析中线性回归发展而来只是用 x 预测 x，所以叫自回归。 差异基因检测方法 对数似然比 log likelihood ratio 同样是来自于 DESeq 的方法，下文中提到的 ImpluseDE2 和 MaSigPro 也都使用了这种方法。 似然比检验 (likelihood ratio test,LRT) 用于比较两个模型的拟合优度进而确定哪个模型与样本数据拟合的更好。其中一个是具有一定数量项的完整模型，另一个是删掉完整模型中一部分项的简化模型。LRT 检验中，自由度等于在简化模型中减少的模型参数数目，LR 近似符合卡方分布。一个相对复杂的模型与一个简单模型比较，如果可以显著地适合一个特定数据集，那么这个复杂模型的附加参数就能够用在以后的数据分析中。 The LRT examines two models for the counts, a full model with a certain number of terms and a reduced model, in which some of the terms of the full model are removed. The test determines if the increased likelihood of the data using the extra terms in the full model is more than expected if those extra terms are truly zero. 为了测试多个时间点的任何差异，可以使用包含时间因子的设计和时间因子在简化公式中被删除的另一个设计。对于包括对照和实验组的时间序列，可以使用包含条件因子，时间因子和两者相互作用的公式。在这种情况下，使用具有不包含相互作用项的简化模型的似然比检验将测试该条件是否在参考水平时间点（time 0）之后的任何时间点可以诱导基因表达的变化。 经验贝叶斯 empirical Bayesian EBseq-HMM 采用的方法，来自于 BEseq。 具体应用 Mfuzz 这个软件最早发表在 2007 年，相对老一些好在目前仍然在维护，其主要目的是给时序数据进行基于模糊聚类算法的聚类。我们常见的聚类算法可以分为严格聚类 (hard clustering) 和模糊聚类 (Fuzzy clustering )（也叫做宽松聚类 soft clustering)。严格聚类会将一个基因只聚到一类中，kmeans 就属于严格聚类。而模糊聚类允许同一数据属于多个不同的类，其聚类结果是一个数据对聚类中心的隶属度，0 到 1 之间。对于分类很开的数据使用严格聚类是没问题的。但对于时序表达量数据来说，不同的类常常会有重叠，所以可以尝试宽松聚类方法。算法需要首先设定一些参数，若初始化参数不合适，可能影响聚类结果的正确性。 在使用 Mfuzz 时首先应该进行数据标准化处理 ，可以使用类似于 FPKM 或者 TPM 的表达结果也可以使用 DESeq2 矫正后的结果进行比较分析，另外不支持值为 0 的数据，所以需要加上 pseudocount 。除此之外，Mfuzz 接受的数据格式为 ExpressionSet，需要对矩阵进行转换。 这个包只能进行聚类，是找不了有处理对照组的差异基因的。需要注意。 library(Mfuzz) library(RColorBrewer) # 读取数据 tpm &lt;- read.table(&quot;sample_tpm_mean.txt&quot;, header=T, stringsAsFactors=F) # 过滤极端值 tpm &lt;- tpm[rowMeans(tpm)&gt;1,] tpm &lt;- tpm[rowMeans(tpm)&lt;10000,] # 添加 pseudo tpm pseduo &lt;- 0.01 tpm &lt;- tpm+pseduo tpm &lt;- as.matrix(tpm) # tarns2Eset tpminput &lt;- new('ExpressionSet', exprs=tpm) # 过滤变化小的数据 tpminput &lt;- filter.std(tpminput, min.std=1) # 类似于 z-score tpminput.s &lt;- standardise(tpminput) # 分不同个数的进行分析，提取高可信度基因并画图然后输出每个类的结果 for (i in seq(8,16,2)) { assign(paste(&quot;tpmcl&quot;, i ,sep = &quot;_&quot;), mfuzz(tpminput.s,c = i, m = mestimate(tpminput.s))) assign(paste(&quot;tpmclfilter&quot;, i ,sep = &quot;_&quot;), acore(tpminput.s, cl = get(paste(&quot;tpmcl&quot;, i ,sep = &quot;_&quot;)), min.acore = 0.5)) pdf(file = paste(&quot;mfuzz&quot;,i,&quot;cluster.pdf&quot;,sep = &quot;_&quot;), width = 12, height = 8) mfuzz.plot2(tpminput.s,cl = get(paste(&quot;tpmcl&quot;, i ,sep = &quot;_&quot;)), mfrow = c(3,3), centre = T,time.labels = c(paste(c(0,1,2,4,8,12),&quot;h&quot;)), colo = brewer.pal(9,&quot;Blues&quot;), x11 = F) dev.off() for (k in 1:length(get(paste(&quot;tpmclfilter&quot;, i ,sep = &quot;_&quot;)))) { write.table((get(paste(&quot;tpmclfilter&quot;, i , sep = &quot;_&quot;)))[[k]], paste(&quot;mfuzz&quot;, i ,&quot;cluster&quot;, k,&quot;gene.txt&quot;, sep = &quot;_&quot;), quote = F, sep = &quot;\\t&quot;, row.names = F, col.names = T) } } 关于上面的 R 代码，我深知在 R 中写 for 循环的丑陋，但是目前还没有掌握向量结构化处理变量和输出的方法。 MaSigPro 运行 masigpro 主要有四步： 确定回归模型 找到显著基因 找到显著差异 获得显著基因集 有两点内容需要注意：对于无对照的单一时序数据处理方法；以及处理转录数据时的特殊参数。因为这个包不会对数据进行标准化，所以应该提前做好，使用 DESeq2 即可。 另外，在实际分析的时候可能会出现 glm.fit: algorithm did not converge 的警告。这是由于进行 logistic 回归时，依照极大似然估计原则进行迭代求解回归系数，glm 函数默认最大迭代次数是 25，当数据不太好时 25 次迭代可能还不收敛，一方面可以增大迭代次数。但当增大迭代次数仍然不收敛就需要对数据进行异常值检验等进一步处理。通常把一些表达量极低或者极高的基因删除掉，这个问题就可以解决。 ImpulseDE2 ImpulseDE2 是最近才出来的一个 R 包，在前面提到的综述评测文章中认为这个包找时序数据中的差异基因效果最好，它可以用来解决两类问题。 Case-only differential expression analysis tests, whether the expression level of a gene changes over time. Case-control differential expression analysis tests, whether the expression trajectory of a gene over time differs between samples from a case and samples from a control condition. 这个包中，有一个plotHeatmap 函数，可以借助 ComplexHeatmap 对数据整体进行热图的绘制同时提取不同类的基因，也可以使用plotGenes看某一个基因的表达情况。 在展示的热图中会出现四部分，包括 transient and transition trajectorie，其中每一种 tarjectorie 又包括 up 和 down 两类。所谓的 transient 可以理解为时序数据在中间某一个时间点存在 up 或者 down peak，即在某一个时间点存在表达的最大或者最小值；而所谓的 transient 可以理解为一个持续的变化，比如持续的升高或者持续的降低。 EBSeq-HMM EBSeq-HMM 是基于 EBSeq 二次开发的工具，主要用于分析时序数据。在计算的时候首先基于负二项分布对参数进行估计，然后利用自回归隐马模型将基因的表达进行分类。比较神奇的是，最终给到的结果会标示为 Up-Up-Down-Down-Down 之类的若干 path，然后你可以选出你感兴趣的 path 进行后续分析。 后续感受 因为目前做的数据是没有对照的单一时间序列数据，所以还不能体会哪一个找出的差异基因更准确些。但是如果只是想把所有的基因根据不同的时间点分为若干表达 pattern，似乎结合 Mfuzz 和 ImpulseDE2 就可以了。 当然，涉及到聚类，尤其是非监督聚类的时候通常主观因素还是较强，如果能对关键基因或者数据有一个大致的估计预判操作起来会相对轻松些，如果没有，可能就需要结合不同类的生物学意义等角度来找合适的聚类数目了。 参考资料 http://a-little-book-of-r-for-time-series.readthedocs.io/en/latest/src/timeseries.html http://a-little-book-of-r-for-biomedical-statistics.readthedocs.io/en/latest/ https://laranikalranalytics.blogspot.com/2018/07/time-series-analysis-with-documentation.html https://www.displayr.com/smoothing-time-series-data/?utm_medium=Feed&amp;utm_source=Syndication https://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-08-25-rnaseqtimedata/"},{"title":"生物信息学简史","content":" 前几天看到 Briefings in bioinformatics 发了一篇 文章 介绍生物信息学发展历史。个人有两个感慨，一是这样的文章也可以发表（不禁想给自己的博客投稿），二是感慨生物信息学发展之快。对整篇文章进行了粗糙的翻译整理，供大家了解。 起源：1950-1970 20 世纪 50 年代早期，DNA 的历史地位还没有被建立，那个时候人们普遍认为蛋白质才是遗传信息的载体。直到 1952 年的噬菌体感染实验，人们才第一次证明 DNA 是真正的遗传物质。因为这个历史原因，生物信息学在 DNA 中的应用要落后于蛋白质研究将近 20 年时间。 生物信息从蛋白质研究开始 50 年代后期，人们得到了胰岛素的蛋白质序列，这一成就激励人们去开发获得蛋白质序列更有效的方法。Edman 降解法就是其中之一，肽链的第一个 N-末端氨基酸用异硫氰酸苯酯（PITC）标记，然后通过降低 pH 来进行切割。通过重复该过程，一次一个 N-末端氨基酸进而可以确定肽序列。 第一位生物信息学家 Margaret Dayhoff（1925-1983）是一位美国物理化学家，他开创了计算方法在生物化学领域的应用。Dayhoff 对这一领域的贡献非常重要，NCBI 前主任 David J. Lipman 称她为”生物信息学的母亲和父亲” 。1960 年，她成为国家生物医学资源基金会的副主任。与 Robert S. Ledley 一起开发出了第一个生物信息学软件：COMPORTEIN , 用于使用 Edman 测序数据确定蛋白质的一级结构，使用 fortran 语言开发并运行在打孔卡上，完全运行在这个软件运行在 IBM 7090 大型机上，如下图 A 所示。 在 COMPROTEIN 软件中，输入和输出氨基酸序列以三个字母的缩写表示（例如赖氨酸的 Lys，丝氨酸的 Ser）。为了简化蛋白质序列数据的处理，Dayhoff 后来开发了目前仍在使用的单字母氨基酸代码。这个单字母代码最初用于 Dayhoff 和 Eck 的 1965 年蛋白质序列和结构图谱，而它是有史以来第一个生物序列数据库。第一版包含 65 种蛋白质序列，其中大部分是少数蛋白质的种间变异。 计算机算法的出现 1970 年，Needleman 和 Wunsch 开发了第一个成对蛋白质序列比对的动态编程算法，80 年代早期，做为 Needleman-Wunsch 算法的推广，第一个多序列比对（MSA）算法首次公布，但是这个算法并没有太大的价值，因为其时间复杂度是O(LN)O(L^N)O(LN)，L 代表序列长度，N 代表序列数量。找到最佳比对的时间与序列长度的序列数量次幂成正比。 多序列比对第一个真正成熟的算法由 Da-Fei Feng 和 Russell F. Doolitle 于 1987 年开发，流行的 MSA 软件 CLUSTAL 开发于 1988 年，作为 Feng-Doolittle 算法的简化至今仍在使用和维护。 ##蛋白质到 DNA: 1970-1980 1968 年，64 个密码子都被解析出来，DNA 成为可读信息后要求我们能都快速获得 DNA 序列。 读取 DNA 序列 第一种被广泛采用的 DNA 测序方法是 1976 年发表的 Maxam-Gilbert 测序方法。由于该方法使用了放射性和危险化学品， 同时其固有的复杂性在很大程度上阻碍了其用于支持 Frederick Sanger 实验室开发的方法。Sanger 团队在 1977 年开发出名为“plus and minus” 的 DNA 测序方法，这是第一个要依赖 DNA 聚合酶进行而成的方法，对该方法进行改进后诞生了目前常见的 Sanger 双脱氧链终止法 ，即使在成立 40 年后的今天它仍在广泛使用中。 第一个专门用于分析 Sanger 测序读数的软件由 Roger Staden 于 1979 年发表。该程序集可分别用于 搜索 Sanger 凝胶读数之间的重叠； 验证，编辑和连接序列读数到重叠群； 注释和操作序列文件。 Staden Package 是第一个包含附加字符（Staden 称为“不确定代码”）的序列分析软件，以用于记录序列读取中的非确定性碱基。这种扩展的 DNA 字母表是现代 IUBMB（国际生物化学和分子生物学联合会）命名法的前身之一，用于核酸序列中未完全指定的碱基。 DNA 序列应用于系统发育推断 Felsenstein 是第一个利用最大似然（ML）方法从 DNA 序列推断系统发育树的软件。在 Felsenstein 之后已经开发出了若干种使用 ML 的生物信息学工具以及用于评估节点稳健性的新统计方法。从某种程度上，在 20 世纪 90 年代人们因此受到启发，将贝叶斯统计应用在分子系统发育中并使用至今。 在 20 世纪 70 年代后半期，人们又必须克服一些技术限制以扩大计算机在 DNA 分析中的应用（更不用说 DNA 分析本身）。接下来的十年是解决这些问题的关键。 生物学和计算机并行发展：1980-1990 靶向和扩增特定基因 与蛋白质和 RNA 不同，基因不能进行生物化学分级然后单独测序，因为它们都是连续地在每个细胞的少量 DNA 分子上连续存在。基因通常以每个细胞一个或几个拷贝存在，基因的数量级比它们编码的产品的数量级少很多，可以说 DNA 是可以测序的最不丰富的大分子细胞成分。 1972 年当 Jackson，Symons 和 Berg 使用限制性核酸内切酶和 DNA 连接酶切割并将环状 SV40 病毒 DNA 插入 λDNA 并用该载体转化大肠杆菌细胞时，该问题得到了部分解决。插入的 DNA 分子在宿主生物中复制时也随着大肠杆菌培养物的生长而扩增，产生出数百万拷贝的单个 DNA 插入物。该实验开创了独立于来源生物的基因的分离和扩增技术。然而，因为 Berg 非常担心这其中存在的伦理问题，因为他曾要求暂停使用 DNA 重组技术，并在 1975 年组织建立了一系列用于现代遗传学实践的指南。 操纵 DNA 的第二个里程碑是聚合酶链式反应（PCR）的出现，它允许在没有克隆程序的情况下扩增 DNA。尽管使用 DNA 聚合酶进行&quot;修复合成&quot;的描述是在 1971 年由 Kjell Kleppe 等人首次提出的。但 PCR 的发明却要归功于 Kary Mullis，因为他对该方法进行了大量优化，特别是使用热稳定 Taq 聚合酶，以及开发热循环仪。 基因克隆和 PCR 现在常用于 DNA 文库制备，这对于获得序列数据至关重要。20 世纪 70 年代后期 DNA 测序的出现，以及增强的 DNA 操作技术，已经产生了越来越多的可用序列数据。与此同时，20 世纪 80 年代，人们开始越来越多地使用计算机和相关生物信息学软件。 使用计算机和专用软件 在 20 世纪 70 年代之前， 所谓的“小型计算机”仍然相当于一台小型家用冰箱的尺寸和重量（如下图所示），而且还不包括终端和存储单元。这样的体积限制使得个人或小型工作组的计算机购置变得异常繁琐。而且使用起来也异常的不友好。 第一波即用微型计算机于 1977 年进入消费市场。这一波浪潮出现的首批计算机包括三种型号：Commodore PET，Apple II 和 Tandy TRS-80，在比试，它们代表着体积小，价格低廉和用户友好。这三种计算机都具有一个内置的 BASIC 解释器，这 对于非程序员而言是一种简单的语言。 生物学计算机软件亦开始迅速发展。1984 年，威斯康星大学遗传学计算机课题组 (Genetics Computer Group) 发表了与他们同名的“GCG”软件合集。GCG 软件包是包括 33 个命令行工具的集合，可以用于操作 DNA，RNA 或蛋白质序列。要记住，这是为序列分析开发的第一个软件集合。 生物信息学和自由软件运动 1985 年，Richard Stallman 发表了 GNU 宣言，概述了他创建名为 GNU（基于 Unix）免费操作系统的动机。这一运动后来成长为自由软件基金会 ( Free Software Foundation )，该基金会倡导”用户可以自由运行，复制，分发，研究，改变和改进软件”的理念。 Stallman 倡导的自由软件哲学是生物信息学的若干倡议的核心，其它的倡议还包括如欧洲分子生物学开放软件套件，其发展始于 1996 年，作为自由和开放源码用来替代 GCG。 最重要的是，在此期间欧洲分子生物学实验室（EMBL），GenBank 和日本 DNA 数据库（DDBJ）开始联合起来（1986 年 EMBL 和 GenBank 加入，1987 年 DDBJ 加入）。为了规范化数据格式定义了报告核苷酸序列的最简信息，并促进数据库之间数据共享。 20 世纪 80 年代也是生物信息学在现代科学中存在感足以获得专门期刊的时刻。鉴于计算机可用性大幅提高以及在生物领域进行计算机辅助分析的巨大潜力，专门针对生物信息学的期刊* Computer Applications in the Biosciences(CABIOS)* 于 1985 年成立，现在这个期刊已经更名为为* Bioinformatics*。 自由软件运动和专用科学期刊的出现拓宽了生物学中计算机的使用范围。然而，对于诸如全基因组和基因目录的大型数据集，使用小型大型计算机而不是微型计算机。这些系统通常在类 Unix 操作系统上运行，并且使用不同于微型计算机上常用的编程语言（例如 C 和 FORTRAN）（例如 BASIC 和 Pascal）。因此，为微型计算机制造的流行序列分析软件并不总是与大型计算机兼容，反之亦然。 台式计算机和新的编程语言 随着 20 世纪 80 年代早期 x86 和 RISC 微处理器的出现，出现了一类新的个人计算机。桌面工作站专为技术和科学应用而设计，具有与微型计算机相当的尺寸，但具有更高的硬件性能，以及更类似于大型计算机的软件架构。事实上，桌面工作站通常运行在 Unix 操作系统和衍生产品上，如 HP-UX 和 BSD（图 3）。 20 世纪 80 年代中期出现了几种脚本语言，这些语言在今天的生物信息学家中仍然很受欢迎。这些语言抽象了计算系统的重要领域并利用了自然语言特征，从而简化了程序开发的过程。用脚本编写的程序通常不需要编译（即它们在启动时被解释），但执行速度比从 C 或 Fortran 代码 [61] 编译的等效程序要慢。 Perl（实用提取和报告语言）是一种高级，多范式，解释性脚本语言，由 Larry Wall 于 1987 年创建，作为 GNU 操作系统的补充，以便于解析和报告文本数据 [62]。其核心特征使其成为操纵生物序列数据的理想语言，其在文本格式中得到很好的体现。用 Perl 编写的最早出现的生物信息学软件可以追溯到 1994 年（表 2）。直到 21 世纪后期，由于其极大的灵活性，Perl 无疑是生物信息学的通用语言 [ 63]]。正如拉里·沃尔（Larry Wall）所说，“实现目标的方法不止一种”。BioPerl 于 1996 年的发展（以及 2002 年的首次发布）促成了 Perl 在生物信息学领域的普及 [64]。该 Perl 编程接口提供便于典型但非平凡任务的模块，例如（i）从本地和远程数据库访问序列数据，（ii）在不同文件格式之间切换，（iii）相似性搜索，以及（iv）注释序列数据。 但是，Perl 的灵活性，加上其严格的语法，很容易导致代码可读性低下。这使得 Perl 代码维护变得困难，特别是在几个月或几年后更新软件。与此同时，另一种高级编程语言将成为生物信息学领域的主要参与者。 Python 就像 Perl 一样，是一种高级的多范式编程语言，最初由 Guido van Rossum 于 1989 年开发。Python 更简单的语法使代码读取和维护更容易。2000 年之后，Python 才开始逐渐成为生物信息学中的主要编程语言。除了 Perl 和 Python 之外，一些非脚本编程语言起源于 20 世纪 90 年代早期，后来也加入了生物信息学领域。 基因组学、结构生物信息学和信息高速路：1990-2000 基因组学时代的黎明 首个全基因组测序项目是 1995 年由遗传学家 J. Craig Venter 领导的对流感嗜血杆菌进行的测序，然而正如我们所知道的那样，开始基因组时代的真正转折点是人类基因组在 21 世纪初的正式公布。 人类基因组计划于 1991 年由美国国立卫生研究院（NIH）发起，13 年内耗费 27 亿美元。1998 年，Celera Genomics（一家由 Venter 运营的生物技术公司）领导了一项竞争性私人形式的人类基因组测序组装项目。最终 Celera 支持的该计划用 NIH 项目花费的十分之一成功完成人类基因组进行了测序和组装。两者成本之间的 10 倍差异主要是由于不同的实验策略和 Celera 项目使用了部分 NIH 的数据。 尽管科学界正在经历一段非常激动的时期，但全基因组测序仍需要数百万美元和数年才能完成，甚至对于细菌基因组也是如此。相比之下，如今进行一个人类基因组测序只需花费 1000 美元和不到一周的时间。这种巨大的差异并不令人惊讶，那时即使存在各种文库制备方案，但测序的 reads 仍然要使用 Sanger 毛细管测序仪产生（如下图所示）。最大的测序量也不过是每个 run 产生 96 个长度 800 bp 的 reads，这比二代测序仪要低几个数量级。对人类基因组进行测序（3.0 Gbp）需要大约 40 000 个 runs 才能得到一倍的覆盖率。 除了费力的实验程序外，科学家还必须设计专门的软件来应对这种前所未有的数据量。几个早先基于 Perl 的软件就是在 20 世纪 90 年代中后期开发用于组装全基因组测序 reads 的，比如：PHRAP，Celera Assembler，TIGR Assembler，MIRA，EULER 等等。 基因组学时代的早期，20 世纪 90 年代初出现全球化的信息网络扮演者另一个重要角色。正是通过这个网络，NIH 资助的人类基因组测序项目可以公开其数据。很快，这个网络将在科学界无处不在，特别是在数据和软件共享方面。 生物信息学在线 20 世纪 90 年代初，Tim Berners-Lee 在欧洲核子研究中心（CERN）担任研究员时发起了万维网，这是一个由相互关联的文件组成的全球信息系统。自 20 世纪 90 年代中期以来，网络已经彻底改变了文化，商业和技术，并在人类历史上第一次实现了近乎即时的通信。 该技术还促成了世界各地许多生物信息学资源库的创建。例如于 1993 年在网上公布的世界上第一个核苷酸序列数据库 EMBL Nucleotide Sequence Data Library。几乎同时，1992 年 GenBank 数据库也成为 NCBI 负责的主要内容之一。然而，那个时候的 GenBank 与今天截然不同，其首次发行是以印刷品和 CD-ROM 的形式。此外，NCBI 于 1994 年开始提供在线服务，随后建立了今天仍在使用的几大主要数据库：Genomes（1995），PubMed（1997）和 Human Genome（1999）。 生物信息学软件通常需要先前了解类 UNIX 操作系统，还需要使用命令行（用于安装和使用）和安装多个软件库（依赖项）才能使用，即使对熟练的生物信息学家而言谈不上直观。但是 Web 资源的兴起扩大并简化了对生物信息学工具的获取，人们可以通过友好的图形用户界面在 Web 服务器上进行操作。越来越多的开发人员尝试通过易于使用的图形 Web 服务器向科学界提供他们的工具，从而无需执行严格的安装过程即可分析数据。核酸研究 杂志每年都会发布关于这些工具的特刊。 超越序列分析：结构生物信息学 蛋白质的第一个三维结构，即肌红蛋白的三维结构，是在 1958 年使用 X 射线衍射实验确定的。然而，Pauling 和 Corey 在 1951 年提出关于蛋白质结构预测并发表了两篇报道 α-螺旋和 β-折叠预测的文章才是第一个真正意义的里程碑。现在，人们可以使用计算机进行计算并预测蛋白质的二级和三级结构。 尽管现代计算机的计算能力不断增加，但对于许多生物分子而言，计算资源仍然是在合理的时间尺度上进行分子动力学模拟的最大困难。好在现在也出现了一些创新，如使用的图形处理单元（GPU）去进行分子动力学模拟，此外，GPU 也开始在需要大量计算能力的其它生物信息学领域发挥作用。 高通量生物信息学：2000-2010 二代测序 DNA 测序随着二代测序（也称为新一代测序或 NGS）的出现而平民化。这种测序始于 454 焦磷酸测序技术，该技术允许在一台机器对数千至数百万个 DNA 分子进行测序。处理来自 454 数据的黄金标准工具 Newbler 至今仍然由 Roche 维护，直到 2016 年 454 逐步被淘汰。现在其他几家公司和技术正活跃在市场，也有众多工具可用于处理这些数据。 事实上现在有太多的工具以至于很难选择究竟应该用什么。如果这种趋势持续下去，不同团队比较彼此研究结果和重复其他研究组的结果将变得越来越困难。此外，转换到更新和（或）不同的生物信息学工具也都需要额外的培训和测试，这使得研究人员通常不愿放弃他们熟悉的软件。因此必须通过降低计算时间或显着提高质量的结果来证明新工具值得掌握。不过随着公共数据库中存储的生物数据的指数级增加，可用工具的数量增加也相形见绌。 生物大数据 自 2008 年以来，摩尔定律不再是 DNA 测序成本的准确预测因子，因为它们在大规模并行测序技术（https://www.genome.gov/sequencingcosts/）到来后下降了几个数量级。这导致公共数据库（如 GenBank 和 WGS ）中的序列呈指数增长（如下图所示），引发了人们对大数据问题的进一步关注。事实上，科学界现在已经产生了超过 exabyte（10 的 18 次方）的数据。 高性能生物信息学和协作计算 生物信息学项目的繁荣加上数据量呈指数增长需要资助机构逐渐适应。对于绝大多数科学研究，生物信息学项目当然也需要资源。虽然在某些情况下简单的台式机就足够了，但一些项目需要更加强大、昂贵且需要特殊专业知识的基础设施。一些政府资助的专门从事高性能计算的资源已经出现，例如： Compute Canada（https://www.computecanada.ca/). 负责管理加拿大研究人员对计算服务的需求和访问 纽约高性能计算计划（https://esd.ny.gov/new-york-state-high-performance-computing-program） 欧洲高性能计算技术平台（http://www.etp4hpc.eu/） 中国国家高性能计算中心（http://www.nchc.org.tw/en/） 高性能计算的重要性也促使一些公司，如亚马逊和微软提供生物信息学服务。 现在和未来的前景：2010 年至今 明确定义生物信息学专业 最近与生物信息学相关的一项“进化”是专门研究该领域的研究人员的出现：生物信息学家（bioinformaticians）。不过即使经过 50 多年的生物信息学研究，对什么是生物信息学家仍然没有明确的共识。 例如，一些作者建议将“生物信息学家”这一术语保留给生物信息学领域的专业人士，包括那些开发，维护和部署生物信息学工具的人。另一方面，还有人建议任何生物信息学工具的使用者都应被授予生物信息学家的地位。当然，还有另一个试探性的方法（可能是为了幽默），即通过反面来定义如何不成为一个生物信息学家。 然而可以肯定的是，随着用户友好型工具的显着增加，通常可通过 Galaxy 等综合 Web 服务器获得，以及诸如 SEQanswers 和 BioStar] 等社区的发展。在学术和企业就业市场上，生物信息学家也存在着爆炸性的需求。为了满足这一需要，有必要督促大学调整其生物科学课程的设置。 现在，那些不直接参与生物信息学项目的生命科学家也需要熟练掌握基本概念以了解生物信息学工具的精妙之处，同时避免滥用和错误地结果解读。 国际计算生物学学会根据三个用户类别（生物信息学用户，生物信息学科学家和生物信息学工程师）发布了在其课程中应具备的核心能力指南和建议。所有三个用户类别都包含核心竞争力，例如： 使用计算生物学实践所需的现有技术，技能和工具 应用分子生物学，基因组学，医学和群体遗传学研究中的统计研究方法和一般生物学知识 至少对生物学领域有深入了解，以及对生物数据生成技术的理解 为剩下的两个类别还定义了额外的能力，例如： 生物信息科学家：分析问题并确定和定义适合其解决方案的计算要求 生物信息工程师：在建模和设计计算系统时应用数学基础，算法原理和计算机科学理论 “生物信息学”一词现在已经过时了吗 在尝试定义生物信息学专业之前，生物信息学这个词本身可能需要适当的定义。事实上计算机的使用已经在生物学以及大多数自然科学（物理学，化学，数学，密码学等）中普遍存在，但有趣的是只有生物学有一个特定的术语来指代计算机的使用。为什么？ 首先，生物学在历史上被认为处于“硬”和“软”科学的分界线上。其次，在生物学中使用计算机需要对大分子（即核酸和蛋白质）结构有一定了解。这导致生物学比其他“硬”科学（如物理学和数学）更晚地计算机化。毕竟第一台计算机就是专门用于解决物理领域的数学计算问题。 这些因素的结合可能会解释为什么生物学和计算机之间的联系并不是显而易见的。这也可以解释为什么“生物信息学”一词的使用仍然是常用的。今天，当几乎任何研究工作都需要使用计算机时，人们可能会怀疑这个术语在未来的合理性。生物信息学家 C. Titus Brown 在第 15 届年度生物信息学开源会议上对此进行了有趣的思考，他介绍了当前生物信息学的历史，不过是从 2039 年的一个生物学家角度进行讲述了这一点。在他假设的未来，生物学和生物信息学紧密交织没有必要区分彼此，大家都被称为生物学。 将生活整体建模：系统生物学 20 世纪后期见证了生物学中计算机的出现，它们的使用以及不断改进的实验室技术使得研究工作日益复杂。尽管对单个蛋白质或基因的测序可能是 20 世纪 90 年代早期的博士论文主题，但博士生现在可以在他/她的研究生阶段就分析许多微生物群落的集体基因组。当时确定蛋白质的一级结构都是复杂的，但是现在可以识别样品的整个蛋白质组。生物学现在已经采用了很多整体方法，但在不同的大分子类别（例如基因组学，蛋白质组学和糖组学）中，每个子学科之间还鲜有交叉。 人们可以预见到下一个飞跃：不是独立研究整个基因组，整个转录组或整个代谢组，而是对整个生物体及其环境进行计算建模，同时考虑所有分子类别。事实上，这一壮举已经在生殖支原体的全细胞模型中实现，其中所有基因，它们的产物和已知代谢相互作用都已在计算机中重建。也许我们很快就会见证一个电子计算机多细胞生物模型。尽管对于数百万到几万亿的细胞建模似乎是不可行的，但必须记住我们现在做的也是十年前在计算能力和技术上认为不可能实现的事情。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-08-15-bioinfohistory/"},{"title":"3D 基因组与生物信息","content":"重要的 Hi-C 相关文献 第一篇 Hi-C 文章： Comprehensive Mapping of Long-Range Interactions Reveals Folding Principles of the Human Genome； DOI: 10.1126/science.1181369 TAD 提出： Topological Domains in Mammalian Genomes Identified by Analysis of Chromatin Interactions ；doi: 10.1038/nature11082 高分辨率 Hi-C： A 3D Map of the Human Genome at Kilobase Resolution Reveals Principles of Chromatin Looping https://doi.org/10.1016/j.cell.2014.11.021 单细胞 Single cell： Hi-C reveals cell-to-cell variability in chromosome structure doi: 10.1038/nature12593；3D structures of individual mammalian genomes studied by single-cell Hi-C doi:10.1038/nature21429 综述：老师所讲 Hi-C 相关基础知识主要来自于综述 Organization and function of the 3D genome，doi:10.1038/nrg.2016.112 Chromatin interaction in different resolutions 不同分辨率 Hi-C 可以看到的内容不同 5KB 可以看到各种 loop 10KB 可以看到 TAD 50kb 可以看到 TAD 之间的关联 在整个染色体的水平可以看到染色质的位置分布 什么造成了所谓的 TAD cohesin complex Cohesin is a protein complex that regulates the separation of sister chromatids during cell division, either mitosis or meiosis. Cohesins hold sister chromatids together after DNA replication until anaphase when removal of cohesin leads to separation of sister chromatids. CTCF proteins 转录阻抑物 CTCF CTCF 与靶顺序因子的结合可阻断增强子和启动子的相互作用，从而将增强子的活性限制在一定的功能区域 除了阻断增强子外，CTCF 还可作为染色质屏障阻止异染色质的传播 Predicting enhancer-promoter loops 如何预测 EPL 两种类似的算法 TargetFinder(Whalen et al. Nat Gen 2016)— an algorithm that uses many functional genomic datasets, including DNase-seq, histone marks, transcription factor (TF) ChIP-seq, gene expression, and DNA methylation data etc. Enhancer–promoter interactions are encoded by complex genomic signatures on looping chromatin ,doi:10.1038/ng.3539 pipeline RIPPLE (Roy et al. NAR 2016) — Also uses functional genomic datasets for feature extraction. A predictive modeling approach for cell line-specific long-range regulatory interactions , https://doi.org/10.1093/nar/gkv865 二者共同的发现 signals from these functional genomic data are informative to computationally distinguish enhancer-promoter interactions from noninteracting enhancer-promoter pairs. PEP 只用序列信息来进行分析（马坚实验室） Hi-C 分析流程 Analysis methods for studying the 3D architecture of the genome ，https://doi.org/10.1186/s13059-015-0745-7 流程 contact map 定义：A contact map is a matrix with rows and columns representing non-overlapping ‘bins’ across the genome. Each entry in the matrix contains a count of read pairs that connect the corresponding bin pair in a Hi-C experiment. How to determine bin size No standard rule. Rao et al. 2014 suggests using a bin size that results in at least 80% of all possible bins with &gt;1000 contacts. Two types of approaches to correct bias in the contact map Explicit approach — assuming some known bias - Restriction enzyme fragment lengths, GC content, and sequence mappability are three major sources of biases in Hi-C data (Yaffe and Tanay, Nat Genet 2011) - HiCNorm — simpler and faster (Hu et al. Bioinformatics 2012) Implicit approach — assume no known source of bias and that each locus receives equal sequence coverage after biases are removed - In other words, if there is no bias, the total genome-wide contact summation for each locus will be a constant, i.e., each locus has 'equal visibility' Contact matrix normalization 如何进行标准化 鉴别 TAD 的算法 HMM（任兵） Arrowhead 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-08-11-longxing-bioinfo-hic/"},{"title":"一位印象大使的印象笔记使用心得","content":"无纸化的尝试与优势 在大学，每到考试周我的书包里就会多出不少笔记本，但因为自己从小写字潦草经常会出现第二天认不出前一天记了什么的尴尬场景，在准备考研的阶段我还不幸有过笔记丢失的悲惨经历。写字太乱加上笔记本买买丢丢，是我最初产生把纸质笔记转变为电子笔记的原因。另外，纸笔形式更适合短期高强度的记录，高中大学之后类似于考试周之类的场景愈发减少。 对于一部分人来说，笔尖划过纸面的感觉是他们舍弃不掉的，不过现在屏幕和纸笔的体验其实已经越来越接近，如 kindle 之于纸质书，iPad pro 配上手写笔之于传统纸笔。 你可以回忆下自己三天前在笔记本上记录过什么，或者回忆下上一个笔记本写过什么。传统的纸笔记录本身存在一个不可逾越的物理界限，即不同笔记本之间的必然分离。你不可能拥有一个无限厚的笔记本，也很难把所有笔记本都随身携带。而无纸化可以满足你随时记录和同步的需求，它让笔记之间，笔记本之间不再存在物理界限，这是无纸化相对于传统纸笔而言最大的优势。 什么是印象笔记 西方有一句古老的谚语an elephant never forgets，说的是大象相比于其它生物而言具有极强的记忆力。而印象笔记（最早为诞生于 2008 年的 evernote) 作为一款笔记软件，可以让你随时随地在所有平台或设备上记录所思所想，所见所得，并能迅速的搜索到任何记忆。印象笔记作为一个人的第二大脑，不仅可以成为你的个人资料库，也是认知和思维工具。 印象笔记的三大优势 如果一定要列出印象笔记的三个优势，我想第一个是连接一切，即所有你能看见的东西都可以放进印象笔记；第二个是搜索一切，即所有你印象笔记里存在的内容都可以搜索；第三个是其它，原谅我在这里抖个机灵，因为印象笔记的历史版本、Office 和图片深度扫描、格外惊喜的 pdf 编辑器和不时之需的演示器功能等等都让我爱不释手。（下面四幅图示来自官网） 信息录入整理与输出 信息的录入整理和输出是非常大的话题，其中每一部分拿出来都可以变成一次完整分享。在这里只能挂一漏万，挑重点写写。 录入 对于录入而言，我们要把握的一个原则是不害怕做加法。 考虑到你或许还没有开始自己的无纸化记录之路，我们有必要先说两点题外话。一是一个人的记录习惯一定不始于印象笔记，例如回忆下自己杀马特的 QQ 空间，略显侨情的人人主页或者曾经过的博客，这些都是你记录开始的地方。 二是如果你不知道从哪儿下手，不妨先为自己的兴趣（或者工作）建立一个电子笔记本。如果有旅游计划，你可以把搜集到的攻略、行程安排和路途见闻及照片存到印象笔记；如果最近在健身，可以把平时自己查到的健身知识、健身感悟和健身效果存到印象笔记；如果迷上了一款游戏，不妨把游戏攻略、通关心得以及最重要的胜利截图存到印象笔记。 接下来首先谈谈大多数人每天必不可少的微信，微信端印象笔记有非常全面的保存机制，既可以保存聊天记录，也可以一件保存公众号文章。除此之外，印象笔记的待办清单小程序也可以和印象笔记无缝衔接。 读屏时代我们每天看到的内容大部分都是一个又一个网页。针对网页保存，印象笔记为大多数浏览器适配了剪藏插件。使用剪藏插件可以直接对网页内容进行标注，用一段时间后它还会自行匹配笔记本，更加重要的是剪藏插件提供了多种网页保存形式，让我们免受页面广告的干扰并美化格式。 从前的日子很慢， 车，马，邮件都慢。但电子时代来临之后人们对于重要信息的传递方式发生了快速的更迭，先是从电话比短信正式进化为短信比微信正式，紧接着又从短信比微信正式进化为邮件比微信正式。我们每天收到的各种工作或者交流邮件中都存在这大量的重要信息需要记录。对于邮件的保存，印象笔记也有着一套完整的方法。 注册之后你会拥有一个专属印象邮箱（可以在个人的设置界面查看），收到别人发来的重要邮件可以直接转发给印象邮箱，如果要发送重要的邮件可以直接密送印象邮箱。这样一来，邮件连同其中的发件收件人信息和附件都会一并保存在你的印象笔记中。 整理 如果说录入需要不怕做加法，那整理就是要学会做减法。下面是几个基本的笔记整理思路。 首先最直观的是笔记本，笔记本的概念来自于传统的纸笔记录所以使用起来非常易于接受。我经常会听到一些关于印象笔记笔记本只支持三个层级（笔记，笔记本，笔记本组）的抱怨。笔记本在电子笔记中存在的意义更多应该是方便日常浏览，而不是搜索和具体分类。因此三个层级对于大多数人来说足够，从印象笔记上限支持 250 个笔记本来看也能对它的功能重点略有体会。 在这个部分，我想特别强调的是如果在印象笔记中你过度依赖笔记本这个层面的功能，只能说明你还停留在传统的纸笔思维中，笔记本间的“物理界限”依旧没有被打破，也就注定无法做到高效。 标签是印象笔记最为重要的工具，从每条笔记上限支持 100 个标签，每个账户上限支持 100000 个标签来看，你也可以感受到它相对于上限为 250 个的笔记本而言拥有更高的权重和可操作性。在印象笔记中，标签本身也支持层级结构，可以用来筛选和搜索，我们可以把标签理解为一个和笔记相关的关键词。 笔记每添加一个标签其本质上就被赋予了一个不同的维度。这个维度可以是笔记来源，可以是笔记涉及的知识类型，可以是某个项目的进展情况，也可以是任何你能想到的东西。正是标签的存在，让笔记和笔记之间跨越了物理界限，能否用好标签是能否用好印象笔记的关键所在。 关于笔记本和标签可以简单总结为：笔记本用来大致区分，标签用来详细关联。 除了笔记本和标签，在整理的过程中我们还应该学会利用笔记合并功能以及笔记内关联功能。利用笔记内关联功能可以在任一条笔记中插入其它笔记，甚至可以为一系列笔记制作一个目录。 输出 在输出层面，首先可以利用笔记本组功能进行管理。如为了保证多项目顺利并行可以命名一个“项目”笔记本组，并在其中添加“待开展”，“开展中”和“已完整”笔记本，从而方便在不同项目间切换；也可以命名一个“写作”笔记本组，在其中添加“有想法”，“半成品”和“可公开”笔记本，从而知道有哪些文章写了一半，又有哪些可以同步到博客上去。 在此基础上还可以利用标签把自己的项目，文章和素材等不同的笔记统统联系起来。让同一个笔记具有不同的维度，不同的笔记具有同一个维度。 高级操作与规避雷区 高级操作 这一部分，我们谈谈使用印象笔记应该了解的一些操作技巧以及应该规避的雷区。首先是高级操作，依旧从录入整理和输出三个层面来罗列，为了节省篇幅很多内容无法展开，建议读到文章的你打开客户端去亲自试试。 录入 Markdown 支持 Markdown 做为一种轻量级的标记语言，可以用简洁且简单的标记语法代替鼠标“指指点点”的操作。其最大的特点是易读和易写，所谓易读是指 Markdown 格式文件不会像 HTML 文件那样满屏幕充满括号和各种缩进；而易写一方面是指相对于复杂的 HTML 标记语言，Markdown 语法简单学习成本较低，另一方面是指熟悉相关的语法规则后，写作时可以脱离对鼠标的依赖享受沉浸式写作的高效与乐趣。 对于程序员或重度文字工作者而言， 过去很长一段时间印象笔记对于 Markdown 的“无动于衷”已经成为了他们内心深处的痛，彼时想在印象笔记中使用 Markdown 不得不借助第三方工具或者插件。 不过在今年 8 月印象笔记正式独立运营后，做为软件的一大更新亮点，Mac 最新测试版客户端已经内置支持创建 Markdown 笔记，作为印象笔记和 Markdown 的重度用户我也在第一时间进行了深度体验，主要有如下几个特点： 印象笔记全面支持 CommonMark 和 GFM (GitHub Flavored Markdown) 标准 列表，TOC，多种图表和数学公式友好支持 内置多种主题和编辑模式可以所以切换 当然，后续 Windows 等其它客户端也会相继支持，那个时候就可以做到真正的跨平台编辑和同步了，先小小地期待一下。 客户端对文本拍照自动扫描 或许你的手机里有不少拍照扫描类应用，快去试试印象笔记自带的拍照功能，可以自动识别文本和边框，也能自动扫描保存。 Inoreader(RSS 聚合阅读应用） 保存文章到印象笔记 结合 RSS 和 IFTTT，会大大增加你的信息收集效率。另外，类似于 Inoreader 这类 RSS 应用也支持直接把文章存到印象笔记。 学习淘宝命名方式增加题目信息量 如果不会给笔记命名不妨多去翻看淘宝店主的命名方法，没准能得到些启发。 使用邮件保存时，标题中可以用 @ 指定笔记本 # 指定标签 整理 为笔记本排序，建立编码体系 印象笔记的笔记本有一套自己的排序规则，但这不代表我们不能自己做主。另外，对笔记本建立自己的编码体系也是十分重要的，可以大大提高我们的阅读和查找效率。 在名字前添加数字可以解决笔记本不能自动排序问题，比如“01 默认笔记”“02 读书笔记” 笔记本组和笔记本的编码体系：例如笔记本组“1 项目”，内部笔记本“1.1 待开展；1.2 开展中；1.3 已完成” 同类笔记本添加相同前缀可以间接自动聚合，例如“工作_XXX” 充分利用快捷方式；通过添加提醒实现置顶功能 如果你感觉自己笔记本太多，一定要学会用快捷方式把常用笔记本优先级提前。还可以为某条笔记设置提醒（不设置具体时间），从而间接实现置顶功能。 先笔记本后标签 这是为了即照顾自己的记录习惯又能控制印象笔记中的笔记本数量，举例如下 笔记本：读书笔记 标签：书籍类型+作者+其它维度 前期使用笔记本形式进行记录，后期删除笔记本添加标签整理，可以按照月为单位操作。 学会使用简化格式功能 从网页或者微信公众号中保存到印象笔记的内容往往具有非常复杂和奇怪的格式，可以使用简化格式功能，删除不必要的图片动图等内容，增加阅读流畅度。 巧用代码块 代码块顾名思义是给程序员放代码的地方，但是对于暂时不支持语法高亮的印象笔记而言代码块反而不适合存放大量代码，不过你可以把一些笔记批注放在其中，使用代码块来区分笔记正文、批注和想法，效果很好。 表格的使用 虽然优化了不少次，但是表格在不同的客户端查看效果依旧不统一，因此建议慎重使用表格功能，如果要用最好也不要超过两列。其实只有两列也有不少应用场景，例如你可以对自己的论文稿件进行版本控制，左栏记录版本时间，右栏放入你的论文附件；当笔记涉及比较内容时，也可以用双栏表格当成左右布局来使用。 搜索技巧若干 如果你使用 Chrome+剪藏，在 Google 中搜索时会自动匹配出印象笔记里相关的内容；你还可以在印象笔记中设置全局状态下的搜索快捷键。印象笔记可以搜索一切，包括但不限于题目、标签、时间、位置等等，但需要你多了解一些 高级搜索语法，很多规则多使用几次也就熟能生巧，下面简单试举两例： 查找最近 30 天更新过的“专业知识”笔记本中含有“shell”标签且内容中包括“fastqc”的笔记（多个条件使用空格分隔）: updated:day-30 notebook: 专业知识 tag:shell fastqc 查找是否存过 DESeq2（一个专业软件）的 pdf 使用说明 :resource:application/pdf deseq2 如果一个包含若干条件的复杂搜索使用频率很高，还可以对搜索进行保存。在菜单栏的文件中选择新建已保存搜索，然后依次命名和输入搜索条件即可。 输出 使用对方注册邮箱共享某条笔记 添加若干其他人注册邮箱进行工作群聊 2018 年底官方将会支持微信和 QQ 空间的笔记分享 规避雷区 让专业的工具做专业的事情 代码尽量不要写在印象笔记 Markdown 功能官方正式增加后会支持语法高亮，可以在 md 中加入部分代码保存。 可以使用 git+vs code 等专业编辑器和版本控制工具对代码进行管理 大文件不要存在印象笔记 如果你是高级用户，那每月拥有 10G 上传流量，单条笔记可以达到 200MB。这对于在一条笔记中存储海量文字信息和十几张图片以及一些小的文件附件来说实在绰绰有余。但如果一条笔记过大，印象笔记的数据存储和加密机制会使其在打开过程中出现一定程度卡顿。 大于 20M 的文件可以存在坚果云等支持增量备份的工具中 大于 1G 的文件存还是在微云这类云盘里 本地大文件另类“保存”骚操作 网页资源可以插入链接，其实如果想在一条笔记中保存一个本地文件（的位置）也可以。一种方法是把某个大文件的快捷方式作为附件保存，另一种方法是在插入链接功能中输入文本地址。你可以首先通过鼠标右键查看文件属性，复制文件地址。在笔记中插入的格式为：file:///C:/Users/fei/Desktop/schaid2018.pdf 思维导图可以选择认可度高的工具：XMind 大纲笔记可以使用体验很好的工具：幕布 第二大脑变为随身垃圾桶 曾经有朋友和我说他放弃印象笔记的原因是因为里面的笔记太多了，这就是典型的把“第二大脑”用成了“随身垃圾桶”。虽然录入阶段不用害怕做加法，但这不等于不需要做筛选和整理。 人为给电子笔记添加物理界限 只用笔记本不用标签或者只会记录不会搜索都等于人为又给电子笔记增加了物理界限。如果你每次找一条笔记都是从笔记本组到笔记本再一条条翻，就需要转变自己的使用观念了。 工具之上的意识方法 这一部分内容作为文章结尾，也是整篇文章最主要的部分。我们学习一个工具的用法其本质是学习其所代表的思路和方法。我们研究工具但不应该被工具所裹挟，我们追求高效率但是这条路通常没有尽头，某种程度上的适可而止也不失为一种高效率策略。 在各种各样的效率类文章中我们总能看到类似于“高效”、“体系”这类字眼，在各种各样的笔记类文章中我们总能看到各种类型的笔记。 什么是高效 关于什么是高效，我个人有三点理解。 分散信息流能尽量集中 现在获取信息的途径实在太多，把分散的信息流集中是提高效率的关键。接收信息的来源最好不超过 5 个，信息从接收到录入印象笔记最多不超过 2 级。 我目前的信息源包括： 微信消息和公众号 RSS 订阅工具 邮箱短息等通讯工具 得到、极客时间知识类应用 锤子阅读这类聚合资讯应用 信息流一般是三个途径： 专业类博客和文章：RSS(Inoreader) 粗读 + 加星标记 &gt; 印象笔记 微信消息公众号：标题快速筛选 + 文章首尾段粗度 &gt; 印象笔记 其它：手机自带便签 &gt; 印象笔记 集中信息可以快速搜索 这需要掌握各种搜索技巧，包括但不限于印象笔记、搜索引擎和本地文件等等。 搜索结果能有效使用 这需要对信息定期整理，删除冗余内容，增加信息间关联。 什么能记录 如果不知道笔记里能记录什么，不妨想想自己所处的角色和责任，如社会角色、工作角色、家庭角色和自我角色等等。每一个角色都会有不同的关注点，例如作为工作角色，我有在读博士，博客作者等几个身份，从每一个身份出发都可以找到不同的需要记录的内容。 此外，我们还可以每天重复一件简单的事情，例如每天用 100 字总结当日收获，每天拍摄一张照片加上 10 字以内说明。这次参加印象笔记六周年生日会，东东枪老师关于照片记录生活的分享内容就给了我很大的触动。每天一张照片，记录生活看似平常的点滴，一年时间你就可以出一个只属于自己的摄影展。 什么是体系 概念和关联是我们认识世界的基础，价值观和方法论是在基础上进一步行动的前提，而基于价值观和方法论的践行则是我们感受世界和自我迭代的唯一途径。 所谓体系，首先要有秩序，这个秩序可能是时间维度也可能是逻辑维度，比如事情是需要做还是想要做，来源是自我总结还是二次加工。 其次要有关联，体现在印象笔记中就是笔记内部链接和相似笔记推荐功能以及标签体系赋予的不同笔记同一维度。 之后要有实践，所谓实践就是没有任务创造任务也要上。针对一个被动接受的任务，我们可以依次进行概念回忆、笔记搜索、思路整理、任务尝试和效果复盘；针对一个主动创造的任务（例如写作），我们可以依次确定主题、罗列概念和相关笔记、整理思路、初步写作、修改发表和总结反馈。 实践后的终极目标则是有迭代，根据实践效果或者文章读者反馈来进一步完善和升级自己的知识体系。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-08-05-ecluseevernote/"},{"title":"R 安装升级后的若干规定动作","content":"两个地址 R cran 镜像地址 https://cran.r-project.org/mirrors.html bioconductor mirror 地址 https://www.bioconductor.org/about/mirrors/ 第一步：给 R 包一个家 通过 Renviron 文件为 R 自身设置一些环境变量，仅对 R 有效。 file.edit('~/.Renviron') 打开文件 R_LIBS_USER=&quot;E:/Rlib&quot; # 指定 R 的附加包安装目录 第二步：给 R 包指两条路 .Rprofile 文件在 R 启动时会被首先执行。 file.edit('~/.Rprofile') 打开文件 在文件末尾添加两行 options(BioC_mirror=&quot;https://mirrors.ustc.edu.cn/bioc/&quot;) #bioconductor options(&quot;repos&quot; = c(CRAN=&quot;https://mirrors.tuna.tsinghua.edu.cn/CRAN/&quot;, CRANextra = &quot;http://www.stats.ox.ac.uk/pub/RWin&quot;)) #cran 如果上面两步设置好后在安装 bioconductor 还有问题，可以再用第三步。 第三步：安装 BiocInstaller 把 https://bioconductor.org/biocLite.R 下载到本地并打开，在文件开头加入如下两行命令并保存。 optionsoptions(BioC_mirror=&quot;https://mirrors.ustc.edu.cn/bioc/&quot;) #bioconductor options(&quot;repos&quot; = c(CRAN=&quot;https://mirrors.tuna.tsinghua.edu.cn/CRAN/&quot;, CRANextra = &quot;http://www.stats.ox.ac.uk/pub/RWin&quot;)) #cran 然后使用 source 调用本地 biocLite.R 文件安装 bioclnstaller，再进行安装 source(/your/path/biocLite.R) BiocInstaller::biocLite() 第四步：Windows 的中文坑 Windows 配置文件 Rconsole，通过 R 代码查找路径：file.path(R.home('etc'), 'Rconsole')，把文件里的 languange 改为 en language = en 。 第五步： Windows 的 Unicode 坑 windows 安装 EBSeq 会发现一个神奇的报错 unexpected INCOMPLETE_STRING 修方式参考 https://github.com/rstudio/shiny/pull/968 依次输入命令 Sys.setlocale(,'English') &quot;\\u2264&quot; iconv(&quot;\\u2264&quot;, &quot;UTF-8&quot;) 第六步：给自己一个 Rlib 权限 在 windows 里经常会看到关于权限的报错或者警告，可以通过设置给自己一个权限。 打开 R 的安装文件夹，右击鼠标选择属性然后选择安全设置，给 Users 添加三个之前没有的权限。 针对 Linux 系统 针对 linux 服务器，R 的升级需要你首先得有 Linux sudo 权限。根据谢神的忍者指南，R 的本身升级只需要下面几个命令。 sudo apt-add-repository -y &quot;deb http://cran.rstudio.com/bin/linux/ubuntu`lsb_release -cs`/&quot;sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E084DAB9 sudo apt-get update sudo apt-get install r-base-dev sudo apt-get build-dep r-base-dev 升级 R 之后依旧最好是设置 Renviron 和 Rprofile，需要更改为国内的两个镜像。 在对 R 包进行升级的时候，有时候会提示部分 R 包无法升级，是因为所在的 path 你本身没有权限修改，比如&quot;/usr/local/lib/R/site-library&quot;。这个时候可能就需要通过sudo R --vanilla登陆，然后把你没有权限的包先卸载掉，然后再正常登陆安装到自己有权限的默认路径里去。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-07-09-chineseuser/"},{"title":"《小岛经济学》告诉我们的","content":"他说的对还是不对 每一门学科都存在很多分支，研究同一个问题会有不同的解决方法，比如在生命科学领域要证明某个理论可以使用生物化学，分子生物的方法也可以使用生物信息学的方法，虽然研究的思路不同但目的相同。 而经济学做为一门社会科学和物理化学不同。通常物理化学（包括一部分生物学）是有明确的手段来验证一个结果是对或者不对的。做为经济学的门外汉，依我个人粗浅的理解：对于常见的物理化学问题而言，一个结论对还是不对我们通常可以（或者终究可以）去验证；而经济学往往是在既定事实的情况下进行一种总结和归纳，一种理论在已有事实的前提下提炼，如果遇到了新情况不能解释就会有另外一套理论产生。同一个问题在不同经济学派系看来可能有完全不同的解决方法。 所以经济学的不同派系之间很难说谁对谁错，这也是几大派系可以共存以及互相借鉴的原因。目前经济学主要有芝加哥学派，奥地利学派和凯恩斯主义 ，在此基础上也有很多新的分支。对于一个外行在了解经济学基础知识的时候，我们姑且不必较真”对不对“，主要还是关心”能不能“。一个观点和理论可以合理解释一个我们关心的问题，那就可以理解和借用。 在我目前接触到的有限经济学相关内容主要集中在奥地利学派，今天要说的《小岛经济学》作者彼得·大卫·希夫本身也是一个奥地利经济学派的支持者，而这本书则通过寓言故事展现了美国的经济发展和运行历史。作者借此提出了奥地利经济学派的几个重要观点，且更多地对美凯恩斯主义政策进行了批判。 所以，如果你还没看过这本书，需要明白它地倾向性非常之强，如果你读完之后对其中的道理深以为然，那也只能说明这本书对奥地利学派起到极好的宣传效果。 《小岛经济学》试图通过漫画和故事的形式来讲解经济学知识。通篇从一个岛和岛上三个人开始，书中出现的每个人物都可以对应到现实中的某个人或者某类人，而后半部分出现的不同岛则指向了不同的国家。 生产比消费更重要 这本书的前几章中，最早在岛上三个人因为没有任何工具每天只能靠一条鱼勉强过活，久而久之其中一位上进青年想要过好更好的生活，于是他冒着好几天挨饿的风险尝试去制作一个捕鱼的工具。在自己的想法成功之后，他开始向其它两位同伴出租自己多捕到的鱼，进一步让他们每个人都拥有了自己的渔网。大家的生活比以前更好了。 在这个制作捕鱼工具的过程里，上进青年向我们展示了一个基本的经济原则，这个原则可以提高人们的生活水平：消费不足，敢于冒险！ 所谓消费不足并不是说他不需要消费而是可供消费的鱼不够，实际上他非常爱吃鱼，但是为了以后捕到更多鱼他必须选择延迟消费；冒险是因为他并不知道自己的渔网是否一定会制作成功。 好在他通过自我牺牲（挨饿），换来了自己的资本（渔网）。所谓资本指的就是一种设备，这种设备的建设和使用本身没有什么意义，其意义在于利用设备建设和制造其他需要的东西。制作渔网的人想要的不是网而是鱼。这张网或许可以给他带来更多的鱼。因此，这张网就是一种资本，是有价值的。 努力使有限的资源产生最大的效益以尽可能满足人类的需求，是经济这一概念最简单的定义。工具、资本以及创新是实现这一目标的关键。找到了生产人类所需物品的更好方式就是经济增长的最根本原因。如果不提高生产只是给别人更多的钱，那么需求其实无法增加，只会让人们花更多的钱来购买已经生产出来的东西。 需要储蓄而非消费 社会处理鱼（货币）的方式有五种：存储、消费、借贷、投资和以上四种的结合。 社会首先需要积累储蓄，随后进行贷款，而储蓄和贷款也正是现代银行的核心功能。 其中借贷可以分为：商业贷款（用于生产东西／服务从而赚钱），消费贷款（用于个人消费）和应急贷款。从捕鱼的故事来说，上进青年可以把自己的鱼借给另外两个人让他们拿到鱼之后去度假（消费借贷），而度假者本身的生产力并没有提高，他们为了还鱼还不得不在度假之后的日子里忍饥挨饿。另一方面，他可以选择不把鱼借给别人去度假而是在这两个人突然得了大病之后把鱼借给他们应急。 储蓄创造了资本，资本可以扩大生产，所以经济状况不好时，更好的选择是储蓄而不是消费。储蓄不只是提高个人消费能力的简单手段，更是防止经济受到意外因素影响的重要缓冲器，用来应对风险。 而一味花钱往往营造的是虚假繁荣。 在经济学中，有一个基本概念叫做稀缺，因为资源有限，所以稀缺是这个社会的基本事实。我们不需要劝说他人去消费，因为人类最大的弱点是贪婪，在稀缺的同时我们自身的需求永远都不会满足。如果一个人不想要某样东西，那一定是有理由的。要么是产品不够好，要么是买不起。想一想你为什么已经不再愿意买地摊上的劣质盗版书或者还不买心仪已久的 MacBook Pro。不管是因为什么，推迟消费或者进行储蓄都是出于理性的考虑。 经济不会因为人们的消费而增长，而是经济增长可以带动人们的消费。 但是凯恩斯主义认为消费是促进经济增长的重要原因。近几十年（或者 08 年经济危机之前）美国人形成了超前消费的习惯，而反观中国是一个储蓄大国。 改善经济不靠通货膨胀 一开始人们是直接用鱼来进行消费，但是慢慢大家手里的鱼不再能应付小岛的发展，所以小岛政府就发行了“鱼邦储蓄券”来代替鱼。人们可以用卷来兑换鱼，也可以用卷来购买服务和其它产品。 人们越来越体会到纸币的方便，政府也逐渐意识到仓库里鱼的数目已经明显少储蓄卷的数量。为了掩盖券比鱼多的问题防止大家蜂拥而至去兑换真鱼，政府开始再鱼上做手脚，做出来比真鱼要小的官鱼用来兑换，同时立法还不让人们用真鱼和官鱼进行比较以防止穿帮。不过，随着鱼邦储蓄卷越来越多，官鱼越来越小，人们需要吃的鱼也就越来越多。官鱼做为货币，所有物价都要上涨来弥补鱼损失的营养。 很多人认为物价上涨就是通货膨胀，物价不上涨就是没有通货膨胀（其实很多时候只是因为生产率提高抵消了本该上涨的物价）。真实情况是价格上涨只是通货膨胀的结果。**通货膨胀是指货币供应量增加，通货紧缩指货币供应收紧。而价格自身其实不会膨胀或者紧缩，只会上涨或下跌。**所以膨胀的不是价格而是货币供应量。 书中其它精彩内容 关于慈善 没有了还款的压力，两个人最有可能做的是利用这份礼物享受闲暇时光。这样做并没有什么错（事实上，这也是大多数人类行为的目标），但是贝克和查理的假日时光并不能提高这座小岛的生产能力。因此，尽管慈善之举听起来颇有雅量，也会提升艾伯的人气，但这一举动却无法像商业贷款一样推动经济发展 。 关于商业 有人认为商业利益源于降低员工的薪资。但没有人会免费工作，没有利益，工作也便无从谈起。员工只要工作就有报酬，而企业主想得到回报则只能等到企业赢利，他们的收益是对承担风险的回报，也是对成功整合稀有资源的回报。对利润的不懈追求推动了产品创新、企业发展与经济增长。正是这样的推动力提高了每个人的生活水平。丰厚的利润正说明一个企业很擅长满足客户的需要，对这样的企业应当予以鼓励，而不应恶意诋毁。 关于早期中美贸易 美国人占了便宜：他们不用生产就可以得到商品，不必储蓄就可以得到贷款。而对于中国人来说，他们辛勤工作却不能消费自己生产的产品，他们努力储蓄却得不到贷款。 关于通货膨胀 在所有的这些例子中，引发恶性通货膨胀以及随后的经济灾难的原因都惊人地相似。这些国家都是通过降低货币价值偿还巨额外债，结果，本国的人民陷入了赤贫之中。 通货膨胀不过是把财富从以某种货币储蓄的人手中转移到以同种货币负债的人那里。如果遇到恶性通货膨胀，存款就会变得一文不值，负债却一笔勾销。（拥有固定资产的人情况会好一些，因为与以货币形式储蓄不同，固定资产的账面价值会暴涨。） 关于高工资 一名员工的具体价值主要取决于三个方面：需求（雇主是否需要这名员工所掌握的技能）、供应（有多少人具备这些技能）以及生产力（这名员工对那些任务的完成程度如何）。要想获得较高的薪资，这位员工必须提高其自身价值，要么掌握极少数人具备的急需技能（如医生），要么通过对本职工作精益求精来提高生产力，根本无捷径可走。 关于最低工资 尽管人们普遍认为最低薪资法规增加了低端工人的薪资，但实际上，这类法规只是增加了这个人群的求职难度。 最低工资反而增加了一部分人的就业难度。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-06-06-readingnotexdjix/"},{"title":"awk 入门与进阶 part2—模式动作输出与输入","content":"模式 BEGIN END 当 awk 从输入读取数据之前，首先执行 BEGIN 的语句；当所有输入数据读取完毕，最后执行 END 的语句。BEGIN 与 END 提供控制初始化与结尾的方式。FS 指定输入行分隔符；OFS 指定输出行分隔符。 任意一个表达式都可以作为任意一个运算符的操作数。如果一个表达式是数值形式而运算符要求字符串值，数值会自动转换成字符串；当运算符要求一个数值时字符串会自动转换成数值。 在一个关系比较中，如果两个操作数都是数值，关系比较将会按照数值比较进行；否则的话，数值操作数会被转换成字符串，再将操作数按字符串的形式进行比较。 符号 意义 &lt; 大于 &lt;= 大于等于 == 等于 != 不等于 &gt;= 大于等于 &gt; 大于 ~ 匹配 !~ 不匹配 两个字符串的比较以字符为单位进行，一个字符串小于另一个，指的是比另一个字符串更先出现。 cat awk2.txt USSR 8649 275 Asia Canada 3852 25 North_America China 3705 1032 Asia USA 3615 237 North_America Brazil 3286 134 South_America India 1267 746 Asia #提取 A 和 B 开头的行 awk '$1 &gt;= &quot;c&quot;' awk2.txt #如果都是字符串则比较哪一个字符首先出现 awk '$1 &gt; $4' awk2.txt 字符串与正则表达式 用斜括号包围，可以将一个正则表达式切换为一个模式。/test/, 正则表达式斜线中的空格是有意义的。 /regexpr/ 当当前输入行包含一段能够被 regexpr 匹配的子字符串时，该模式被匹配。 expression ~ /regexpr/ 如果 expression 的字符串值包含一段能够被 regexpr 匹配的子字符时，该模式被匹配。 expression !~ /regexpr/ 如果 expression 的字符串值不包含能够被 regexpr 匹配的子字符串，该模式被匹配。 awk '$4 ~ /Asia/' awk2.txt awk '$4 !~ /Asia/' awk2.txt 正则表达式的元字符包括： \\ ^ $ . [ ] | ( ) * + ? 基本的正则表达式包括下面几种： 一个不是元字符的字符，例如 A，这个正则表达式匹配的就是它本身。 一个匹配特殊符号的转义字符：\\t 匹配一个制表符。 一个被引用的元字符例如、*, 按字面意义匹配元字符。 ^ 匹配一行的开始。 $ 匹配一行的结束。 . 匹配任意一个字符。 字符类：[ABC] 匹配字符 A, B 或 C。 字符类可包含缩写形式：[A-Za-z] 匹配单个字母。 互补的字符类：[^0-9] 匹配任意一个不是数字的字符。 运算符： 选择：A|B 匹配 A 或 B。 拼接：AB 匹配紧跟 B 的 A。 闭包：A* 匹配 0 个或多个 A。 正闭包：A+ 匹配一个或多个 A。 零或一：A? 匹配空字符串或 A。 括号：被 (r) 匹配的字符串，与 r 所匹配的字符串相同。 # 匹配开始和结尾 ^c 匹配以字符 c 开始的字符串； c$ 匹配以字符 c 结束的字符串； ^c$ 匹配只含有单个字符 c 的字符串； ^.$ 匹配有且仅有一个字符的字符串； ^...$ 匹配有且仅有 3 个字符的字符串； ... 匹配任意 3 个字符； \\.$ 匹配以句点结束的字符串。 # 使用字符类进行匹配，使用连字符表示一个范围，无连字符为匹配其中任意一个字符。^ 表示互补。 ^[ABC] 匹配以 A, B, 或 C 开始的字符串； ^[^ABC] 匹配以任意一个字符（除了 A, B, 或 C) 开始的字符串； [^ABC] 匹配任意一个字符，除了 A, B, 或 C; ^[^a-z]$ 匹配任意一个有且仅有一个字符的字符串，且该字符不能是小写字母。 # 符号*, + 与 ? 是一元运算符，用来指定正则表达式的重复次数。 B* 匹配空字符串，或 B, BB, 等等。 AB*C 匹配 AC, 或 ABC, ABBC, 等等。 AB+C 匹配 ABC, 或 ABBC, ABBBC, 等等。 AB?C 匹配 AC 或 ABC [A-Z]+ 匹配由一个或多个大写字母组成的字符串。 (AB)+C 匹配 ABC, ABABC, ABABABC, 等等。 任意一个被一对斜杠包围的正则表达式都可以作为匹配运算符的右操作数，$2 !~ /^[0-9]+$/ 打印第 2 个字段不全是数字的行。 复合模式 逻辑运算符通过 ||(OR), &amp;&amp;(AND), !(NOT) 进行组合。 表达式 匹配 c 非元字符 c \\c 转义序列或字面意义上的 c ^ 字符串的开始 $ 字符串的结束 . 任意一个字符 [c1c2...] 任意一个在 c1c2... 中的字符。 [^c1c2...] 任意一个不在 c1c2... 中的字符。 [c1-c2...] 任意一个在范围内的字符，范围由 c1 开始，由 c2 结束。 [^c1-c2...] 任意一个不在范围内的字符，范围由 c1 开始，由 c2 结束。 r1|r2 任意一个被 r1 或 r2 匹配的字符串。 (r1)(r2) 任意一个字串 xy, 其中 r1 匹配 x, 而 r2 匹配 y; 如果当中不含有选择运算符，那么括号是可以省略的 (r)* 零个或连续多个能被 r 匹配的字符串。 (r)+ 一个或连续多个能被 r 匹配的字符串。 (r)? 零个或一个能被 r 匹配的字符串。 在这里括号可以省略。 (r) 任意一个能被 r 匹配的字符串 awk '$4 == &quot;Asia&quot; || $4 == &quot;North_America&quot;' awk2.txt awk '$4 ~ /^(Asia|North_America)$/' awk2.txt #选择运算符 范围模式 一个范围模式由两个被逗号分开的模式组成，如 pat1,pat2 一个范围模式匹配多个输入行，这些输入行从匹配 pat1 的行开始，到匹配 pat2 的行结束，且包括这两行；pat2 可以与 pat1 匹配到同一行，这时候模式的范围大小就退化到了一行。 awk 'FNR == 1, FNR == 5 { print FILENAME &quot;: &quot; $0 }' awk2.txt # FNR 目前读入的行数，FILENAME 当前输入文件名 动作 在一个模式–动作语句中，模式决定动作什么时候执行。有时候动作会非常简单如一条单独的打印或赋值语句。有些时候动作有可能是多条语句，语句之间用换行符或分号分开。 动作语句包括 expression, 包括常量，变量，赋值，函数调用等等。 print expression-list printf(format, expression-list) if (expression) statements if (expression) statements else statements while (expression) statements for (expression; expression; expression) statements for (expression in array) statements do statements while (expression) break continue 表达式 常量：包括字符串和数值。 变量：变量类型无需事先声明，内建变量都是大写，一个变量对应一个值。未初始化的变量值是空字符串与 0。 内建变量：ARG 命令行参数的个数；ARGV 命令行参数数组；FNR 当前输入文件记录个数；FS 输入行字段分隔符；NF 当前记录字段个数；NR 所读的记录数量（行数）；OFS 输出字段分隔符；RS 输入行记录分隔符。 字段变量：$1, $2, $(NF-1) 算术运算符：% 取余数，^ 指数运算符，比较运算符；逻辑运算符 &amp;&amp; 或 || 与。 条件表达式，一个条件表达式具有形式：expr1 ? expr2 : expr3。首先 expr1 求值。如果值为真，也就是值非零或非空，那么整个条件表达式的值就会是 expr2 的值；否则，如果 expr1 的值为假，那么条件表达式的值就会是 expr3。expr2 与 expr3 只有其中一个会被求值。 赋值运算符：共有六种方式。+=，-=，*=，/=，%=，以及^=。它们的意义都是类似的：v op = e 等价于 v = v op e，但是 v 只被求值一次。赋值表达式：pop = pop + $3 可以用+= 写成更加紧凑的形式：pop += $3 。 内建算术函数 函数 返回值 atan2(y,x) y/x 的反正切值 cos(x) x 的余弦值，x 以弧度为单位 exp(x) x 的指数函数 int(x) x 的整数部分；当 x 大于 0 时，向 0 取整 log(x) x 的自然对数（以 e 为底） rand() 返回一个随机数 r, 0&lt;r&lt;1 sin(x) x 的正弦值，x 以弧度为单位。 sqrt(x) x 的方根 srand(x) x 是 rand() 的新的随机数种子 返回 1-n 的一个随机数randint = int(n * rand()) + 1 第二个字段有且仅有数字：awk 'BEGIN { digits = &quot;^[0-9]+$&quot; }$2 ~ digits' awk2.txt 内建字符串函数 函数 描述 gsub(r,s) 将$0 中所有 r 替换为 s，返回替换发生的次数。 gsub(r,s,t ) 将字符串 t 中所有出现的 r 替换为 s，返回替换发生的次数 index(s,t) 返回字符串 t 在 s 中第一次出现的位置，如果 t 没有出现的话，返回 0。 length(s) 返回 s 包含的字符个数 match(s,r) 测试 s 是否包含能被 r 匹配的子串，返回子串的起始位置或 0; 设置 RSTART 与 RLENGTH split(s,a) 用 FS 将 s 分割到数组 a 中，返回字段的个数 split(s,a,fs) 用 fs 分割 s 到数组 a 中，返回字段的个数 sprintf(fmt,expr-list) 根据格式字符串 fmt 返回格式化后的 expr-list sub(r,s) 将、$0 的最左最长的，能被 r 匹配的子字符串替换为 s，返回替换发生的次数。 sub(r,s,t) 把 t 的最左最长的，能被 r 匹配的子字符串替换为 s，返回替换发生的次数。 substr(s,p) 返回 s 中从位置 p 开始的后缀。 substr(s,p,n) 返回 s 中从位置 p 开始的，长度为 n 的子字符串。 awk '{gsub(/USA/,&quot;united states&quot;);print}' awk2.txt awk '{ $1 = substr($1, 1, 3); print $0 }' awk2.txt 流程控制语句 Awk 提供花括号用于语句组合，if-else 用于判断，while，for，do 语句用于循环。 一条单独的语句总可以被替换为一个被花括号包围起来的语句列表，列表中的语句用换行符或分号分开，换行符可以出现在任何左花括号之后，也可以出现在任何右花括号之前。 if (expression) statements1 else statements2 { for (i = 1; i &lt;= NF; i++) print $i } do statements while (expression) do 循环执行 statements 一次，只要 expression 为真，就重复执行 statements。do 循环与 while , for 循环相比它的条件测试在循环体的底部，所以循环体至少会执行一次。 有两种语句可以影响循环的运行：break 会导致控制流马上从包围着它的循环内退出，循环可以是 while，for，或 do。continue 导致下一次迭代开始；它使得执行流马上进入 while 与 do 的测试表达式，或 for 的 expression. 关联数组 Awk 提供了一维数组，用于存放字符串与数值。数组与数组元素都不需要事先声明，也不需要说明数组中有多少个元素。就像变量一样，当被提及时，数组元素就会被创建，数组元素的默认初始值为 0 或空字符串&quot;&quot;。Awk 的数组与大多数其他语言最大的不同点在于数组元素的下标是字符串。 cat awk2.txt USSR 8649 275 Asia Canada 3852 25 North_America China 3705 1032 Asia USA 3615 237 North_America Brazil 3286 134 South_America India 1267 746 Asia awk '/Asia/ { pop[&quot;Asia&quot;] += $3 }; /North_America/ { pop[&quot;NA&quot;] += $3 } END { print &quot;Asian population is&quot;, pop[&quot;Asia&quot;], &quot;million.&quot;;print &quot;European population is&quot;,pop[&quot;NA&quot;], &quot;million.&quot;}' awk2.txt #Asian population is 2053 million. #European population is 262 million. 这里数组下标是字符串，且数量会累积到数组 pop[&quot;&quot;] 中，如果我们需要统计每个地方的人口总和，或者统计多倍体中每个 subgenome 的总和，这种聚合问题使用关联数组非常方便，其数组下标可以是任意表达式。对于上面的内容，我们可以把$4 作为下标，统计$3。 awk '{ pop[$4] += $3 }END{ for (name in pop) print name,pop[name]}' awk2.txt #North_America 262 #Asia 2053 #South_America 134 输入 getline 函数 awk 本质上是一个逐行处理过程，类似 for 循环，直到整个文件的每一行都被执行完毕。 getline 抓取下一个记录，按照通常的方式把记录分割成一个个的字段。它会设置 NF，NR，和 FNR; 如果存在一个记录，返回 1，若遇到文件末尾，返回 0，发生错误时返回-1 （例如打开文件失败）. 表达式 getline x 会读取下一条记录到变量 x 中，并递增 NR 与 FNR，不会对记录进行分割，所以不会设置 NF。 表达式 被设置的变量 getline $0, NF, NR, FNR getline var var, NR, FNR getline &lt;file $0, NF getline var &lt;file var cmd | getline $0, NF cmd | getlinevar var # 只打印奇数 seq 10 | awk '{getline; print $0}' # 只打印偶数 seq 10 | awk '{print $0; getline}' # 奇数偶数行交换 seq 10 | awk '{getline tmp; print tmp; print $0}' 同样的利用第一列信息判断，将第一列相同的第二列内容合并也可以使用 getline 函数。 cat awk3.txt a qw a we a wet b wer b klj b piu c eie c tmp c ike awk 'BEGIN{getline;a=$1;printf (&quot;%s\\t%s&quot;,$1,$2)}{if(a==$1){printf &quot;//&quot;$2}else{printf &quot;\\n%s\\t%s&quot;,$1,$2;a=$1}}END{printf &quot;\\n&quot;}' awk3.txt a qw//we//wet b wer//klj//piu c eie//tmp//ike 输出 print(f) 使用 print 输出时后面可以括号括住需要的内容，也可以不括住，但是当参数有关系运算符的时候必须使用括号才可以。默认的print 是print $0。打印空白行可以使用print &quot;&quot; awk 的默认输出字段分隔符 (OFS) 是空格，默认的输出记录分隔符 (ORS) 是换行符。 printf 用于产生格式化的输出，书写形式： printf format,expression1,expression2,..., expressionn printf(format,expression1,expression2, ..., expressionn) 参数 format 是一个变量，字符串值含有字面文本与格式说明符，字面文本会按照文本的字面值输出，格式说明符规定了参数列表中的表达式将被如何格式化地输出。每一个格式说明符都以% 开始，以转换字符结束，可能含有下面三种修饰符： - 表达式在域内左对齐 width 为了达到规定的宽度必要时填充空格 .prec 字符串最大宽度或十进制数的小数部分的位数 字符 打印 c ASCII 字符 d 十进制整数 e [-]d.ddddddE[+-]dd f [-]ddd.dddddd g 按照 e 或 f 进行转换，选择较短的 s 字符串 echo 5.55 |awk '{printf &quot;%d\\n&quot;,$1}' #5 echo 5.55 |awk '{printf &quot;%5d\\n&quot;,$1}' # 5 echo 0.5555555555 |awk '{printf &quot;%.3e\\n&quot;,$1}' #5.556e-01 echo 0.5555555555 |awk '{printf &quot;%.3f\\n&quot;,$1}' #0.556 echo 0.5555555555 |awk '{printf &quot;%.3g\\n&quot;,$1}' #0.556 echo 0.5555555555 |awk '{printf &quot;%-10g\\n&quot;,$1}' #0.555556 echo 0.5555555555 |awk '{printf &quot;%10g\\n&quot;,$1}' # 0.555556 输出到文件 重定向运算符&gt; 与&gt;&gt; 用于将输出重定向到文件，而不是原来的标准输出。 awk '{ print($1, $3) &gt; ($3 &gt; 100 ? &quot;big.txt&quot; : &quot;small.txt&quot;) }' # 第三列大于 100 输入到一个文件，小于 100 输入到另外一个 awk '{ print &gt;&gt; $1 }' tmp.gtf # 按照染色体分割文件 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-06-03-awk2/"},{"title":"awk 入门与进阶 part1—快速入门","content":"awk 的结构 由一个单独的模式–动作语句 (pattern-action statement) 组成。 pattern{ action } awk 的运行方式 awk 的基本操作是在由输入行组成的序列中，陆续地扫描每一行，搜索可以被模式匹配 (match) 的行。每一个输入行轮流被每一个模式测试。每匹配一个模式，对应的动作（可能包含多个步骤） 就会执行。然后下一行被读取，匹配重新开始。这个过程会一起持续到所有的输入被读取完毕为止。 执行 awk 方式 awk+执行语句+文件 awk 'program' input files awk+执行语句 在命令行上省略输入文件，在这种情况下，awk 会将 program 应用到接下来在终端输入的内容，直到键入文件结束标志 ctrl-d。 awk+脚本 awk -f progfile optional list of files 入门应知 输出 awk 从输入中每次读取一行，将行分解为一个个的字段（默认将字段看作是非空白字符组成的序列）。当前输入行的第一个字段叫作、$1，第二个是、$2，依次类推。一整行记为$0。每行的字段数有可能不同。 print 打印当前输出行，$0 表示整行，$1 表示第一个字段。在 print 语句中由逗号分隔的表达式，在输出时默认用一个空格符分隔。Awk 计算当前输入行的字段数量，并将它存储在一个内建的变量中，这个变量叫作 NF。$NF 表示打印最后一个字段。 用字段的值进行计算，并将计算得到的结果放在输出语句中。如{print $1*$2}。 另一个内建变量** NR**，这个变量计算到目前为止，读取到的行的数量。我们可以使用 NR 来表示行号。添加行号写法{ print NR, $0 }。添加文本，引号包围的文本会和字段和运算结果一起输出。 修改输出格式可以试用 printif。使用格式printf(format, value1, value2, ..。, valuen) format 是一个字符串，包含按字面打印的文本，中间包括格式说明符，格式说明符用于说明如何打印值。一个格式说明符是一个%，后面跟着几个字符控制一个 value 的输出格式。第一个格式说明符说明 value1 的输出格式，第二个格式说明符说明 value2 的输出格式，依次类推。使用 printf 不会自动产生空格符或换行符必须自己添加、n。 选择 通过比较和计算或者文本可以选择输出感兴趣的行。 $1 &gt;= 5 $1+$3 &gt; 10 $1==&quot;chr1&quot; 结合逻辑运算符进行组合选择。 || or; &amp;&amp; and; ! not 数据验证 真实的数据总是存在错误，检查数据是否具有合理的值，格式是否正确，通常称作数据验证 (data validation)，数据验证的本质是否定，也就是说打印出可以的行。比如想验证是不是每一行都有 4 列，即可以使用NF != 4 {print $0} BEGIN END 特殊的模式 BEGIN 在第一个输入文件的第一行之前被匹配，END 在最后一个输入文件的最后一行被处理之后匹配。 计算 #计数： awk '$2&gt;1{num=num +1}END{print num}' awk.txt #总数 awk 'END{print NR}' awk.txt #平均数 awk '{sum=sum + $2}END{print sum/NR}' awk.txt # 输出最大值（变量可以是字符串） awk '$2 &gt; max { max = $2; maxid = $1 }END { print max, maxid }' awk.txt # 字符串拼接 awk '{id = id $1 &quot; &quot; }END { print id }' awk.txt #字符个数 length awk '{ print $3,length($3) }' awk.txt 流程控制 if-else awk ' { n = $2; id =$1 } END { if (n &gt; 333) print n,id else print &quot;&lt; 333&quot; }' awk.txt for：大多数循环都包括初始化，测试，增值，而 for 语句将这三者压缩成一行。 awk ' { for(i=1;i&lt;= NR; i=i+1) print i,$2' awk.txt while：while 含有一个条件判断与一个循环体。当条件为真时，循环体执行。 awk '{ i = 1 while (i &lt;= NR) { print i, $1 i = i + 1 } }' awk.txt while 后面被括号包围起来的表达式是条件判断；循环体是跟在条件判断后面的，被花括号包围起来的的两条语句。 数组 Awk 提供了数组用来存储一组相关的值。 #逆序显示 awk'{ line[NR] = $0 } # remember each input line END { i = NR # print lines in reverse order while (i &gt; 0) { print line[i] i = i - 1 } }' awk.txt awk' { line[NR] = $0 } # remember each input line END { for (i = NR; i &gt; 0; i = i - 1) print line[i] }' awk 常用一行命令 #1. 输入行的总行数 END { print NR } #2. 打印第 10 行 NR == 10 #3. 打印每一个输入行的最后一个字段 { print $NF } #4. 打印最后一行的最后一个字段 { field = $NF } END { print field } #5. 打印字段数多于 4 个的输入行 NF &gt; 4 #6. 打印最后一个字段值大于 4 的输入行 $NF &gt; 4 #7. 打印所有输入行的字段数的总和 { nf = nf + NF } END { print nf } #8. 打印包含 Beth 的行的数量 /Beth/ { nlines = nlines + 1 } END { print nlines } #9. 打印具有最大值的第一个字段，以及包含它的行（假设$1 总是正的） $1 &gt; max { max = $1; maxline = $0 } END { print max, maxline } #10. 打印至少包含一个字段的行 NF &gt; 0 #11. 打印长度超过 80 个字符的行 length($0) &gt; 80 #12. 在每一行的前面加上它的字段数 { print NF, $0 } #13. 打印每一行的第 1 与第 2 个字段，但顺序相反 { print $2, $1 } #14. 交换每一行的第 1 与第 2 个字段，并打印该行 { temp = $1; $1 = $2; $2 = temp; print } #15. 将每一行的第一个字段用行号代替 { $1 = NR; print } #16. 打印删除了第 2 个字段后的行 { $2 = &quot;&quot;; print } #17. 将每一行的字段按逆序打印 { for (i = NF; i &gt; 0; i = i - 1) printf(&quot;%s &quot;, $i) printf(&quot;\\n&quot;) } #18. 打印每一行的所有字段值之和 D { sum = 0 for (i = 1; i &lt;= NF; i = i + 1) sum = sum + $i print sum } #19. 将所有行的所有字段值累加起来 { for (i = 1; i &lt;= NF; i = i + 1) sum = sum + $i } END { print sum } #20. 将每一行的每一个字段用它的绝对值替换 { for (i = 1; i &lt;= NF; i = i + 1) if ($i &lt; 0) $i = -$i print } 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-06-01-awk1/"},{"title":"R 的安装配置与升级","content":"这几天 R 语言升级到了 3.5 的版本，终于在小数点后面一位有了变化。关于新版本可以这这篇博客中查看 R 3.5.0 is released! (major release with many new features) 。 R 的安装配置和升级对大多数人来说都是比较痛苦的事情。这里简单总结一些的东西，希望对有需要的人有用。 安装最新版 R 永远可以通过后面的这个重定向链接直接下载：http://cran.r-project.org/bin/windows/base/release.htm windows 中默认安装目录带有 R 的版本号，比如 C:/Program Files/R/R-3.5.0/，这就意味着你没安装一次 R 都会出现一个新的默认目录。在设置安装目录的时候可以把 R 的版本号去掉。 windows 默认会把 R 安装在 C 盘，后面如果要安装很多其它包的话其实是没有写入权限的。这个时候最好使用 file.edit('~/.Renviron') 添加一个 R_LIBS_USER 变量，用来指定 R 的附加包安装位置。一来是为了避免安装时没有权限的尴尬，二来是将附加包和 R 分开，这样 R 的升级不会影响到附加包。如果输入。libPaths() 会看到两个目录，其中一个是附加包路径，另一个就是默认安装的 R 主程序路径。 windows 升级 R 推荐使用 installr，会提示你一步步升级然后帮你把旧版本里的主程序包拷贝到新的版本里。首先，install.packages(&quot;installr&quot;)，然后 installr::updateR() 正常来说接下来可以使用 rvcheck 包，对所有 R 中安装的各种包进行版本检查和升级。但是目前我测试发现 bioconductor 的默认镜像和网址似乎国内已经登陆不上去了。需要设置一下 bioconductor 的镜像 如果使用 R 来做生信分析，一定需要用到 bioconductor，在 windows 中它的升级也会遇到各种各样的问题。比如说：BiocInstaller version 3.x is too old for R version 3.x; 再比如说 InternetOpenUrl failed；再比如说 Error in read.dcf(file.path(pkgname, &quot;DESCRIPTION&quot;), c(&quot;Package&quot;, &quot;Type&quot;)) : cannot open the connection。 针对第一点，解决方法如下 重启 R; 运行命令 remove.packages(&quot;BiocInstaller&quot;, lib=.libPaths()) 直到 R 显示 there is no such package 再运行命令 source(&quot;https: //bioconductor.org/biocLite.R&quot;)；会对 bioconductor 进行升级 然后就是升级里面的 R 包 运行 biocValid() 查看哪些包可以继续用哪些需要升级 然后运行 biocLite(&quot;DESeq2&quot;) 进行升级即可 如果出现看起来是网络链接的错误或者包总是不能下载完整，那就需要设置镜像。 首先可以使用 biocinstallRepos()，查看一下目前再用的 repos： 目前可用镜像查看地址 https://www.bioconductor.org/about/mirrors/ chooseBioCmirror() chooseCRANmirror() source(&quot;https://bioconductor.org/biocLite.R&quot;) biocLite() 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-04-27-updateRinWindows/"},{"title":"vim 操作应知应会 10 点","content":" vim 包括 normal 和 insert 两种模式 normal 模式下所有按键都是功能键 在 insert 模式下可以正常的输入内容 进入 vim 后直接定位在某一行或者末尾 vim + test.txt 直接进入文本末尾 vim +5 test.txt 直接进入文本的第五行 显示和取消行号 显示行号 set nu 取消行号 set nonu 行内和行间瞬间移动（normal 模式） 行内 0 行头 $ 行尾 t. 到'.'符号前的第一个字符 f1 到下一个'1'的位置 w 到下一个单词开头 e 到下一个单词结尾 行间 :66 到第 66 行 gg 到第一行 G 到最后一行 5G 到第 5 行 屏幕瞬间移动 后滚一屏 ctrl+f 前滚半屏 ctrl+b 定位屏幕中间 zz zt 屏幕顶端 zb 屏幕底部 插入删除 另外起新行编辑 o 删除字符 x（光标所在处） 6x 删除 6 个字符 删除所在行 dd 删除到行首 d^; 行尾 d$ 复制与粘贴 复制所在行 yy 多行复制： 第一步：V 第二步： 移动光标自由选择 第三步：y 复制选择部分（d 为剪切） 粘贴：移动到想复制的位置，按 p 粘贴在光标后，P 为光标前 注释与取消注释 注释 按 Ctrl+v 切换可视模式 移动光标选中注释行开头 按大写 I 输入 # 按 Esc 取消 按 Ctrl+v 切换可视模式 选择要删除的注释符 按 d 或 x 删除 # 搜索 /whatyouneed 按 n 切换到下一个 替换 😒/a/b/g 替换当前行所有 a 为 b :%s/a/b/ 替换每行第一个 a 为 b :%s/a/b/g 替换每行所有 a 为 b 反悔模式 :%s/a/b/gc vim 匹配文字高亮并询问 y 表示替换当前 n 表示不替换当前 a 表示全部替换 q 表示退出不玩儿了 l 表示把当前替换后就不玩儿了。 重复与撤销 . 重复此前的操作 u 撤销此前的操作 5u 撤销此前的 5 个操作 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-04-20-vim10tips/"},{"title":"如何拯救你，我的 PPT","content":"审美的重要性 美究竟有没有一个标准这里不敢讨论。但是在长期的实践当中，人们大体总结出了一些形式美的规律，比如平衡、对称、对比、统一、变化以及黄金分割等。 做好 PPT 的前提其实在于能否分辨基本的丑和美。提高审美最好的方式是多去看美的东西。这里给大家推荐两个网站，学习累了可以浏览浏览。 https://design-milk.com/ https://ifworlddesignguide.com/design-excellence 关于“丑”的几个示例 😦 以上内容均来自 office 自带模板：( 关于美的极简示例 😃 PPT 类型 现在进入如何拯救 PPT 的正题，首先要明确的是 PPT 有哪些类型。很多时候我们做不好 PPT 的原因之一在于没有想清楚我们的 PPT 会用来干什么。 在很多模板网站里会看到类似于商业，学术等等这样的很多分类方式。其实，PPT 无非就是演示类型和阅读类型两种。 演示类型（讲给别人听） 一页只有一个焦点 阅读类型（发给别人看） 一页可以有多个焦点 混合型（先讲然后发给别人看） 一页可以有多个焦点 一次只强调一个焦点 通过动画 通过颜色和明暗 PPT 内容 封面 简约背景 与背景对比度高的文字 线条：直线，折线 蒙版和色块突出文字，模糊背景图 比如： 目录 并列关系 色块区分不同标题、 比如： 过度 增加线条或者色块让页面不单调 大标题配合小标题提示下文内容 小字（图）总结前面部分，大字（图）提示后面部分 例如 内容 以设计四原则为基本要求（见后文） 单一字体 小标题加大加颜色 行间距 1.5 尽量少写字，不能减少则根据亲密性区分关系 说到哪里突出哪里 修改前 修改后 封底 只写一个 Thanks 或者 谢谢观看 是最不推荐的选择 根据自己的目的合理的设计自己的封底 再次贴上自己的个人信息，方便别人找到你 再次贴上自己的产品，增加别人的记忆 根据下一个环节合理的设计封底 提问环节，增加所有小标题方便提问 PPT 元素 背景 学术报告不要加背景 不要用默认难看背景 使用冷色调微渐变背景 字体 尽量统一使用无衬线字体：微软雅黑，微软雅黑 light，华文细黑 中英文标点正确 黑体不要再使用加粗 关键信息点进行强调 颜色 大小 图片 多张图片须对齐 学会剪裁突出重点 学会加蒙版 不放任何和内容无关的图 一图胜千言，例如下图（不喜勿喷，仅举例） 图表 一定保证最远的人可以看清楚 对比度要高 重点要突出 图形 线条是好用的图形 保证图形的一致性 同一个页面只有一种图形 一套 PPT 不超过三种图形 配色 学术用途尽量单一冷色系：稳重 如果是煽动用途可以暖色系 使用取色工具保证颜色的一致性 动画 学术用不加换页动画，不加特效 使用动画帮助聚焦 PPT 构思 PPT 的构思是整个制作过程最重要的一个环节。在做之前需要想清楚讲什么，怎么讲。 逻辑：根据逻辑使用合适逻辑图 并列 对比 次序 结构：哪些页面快速过，哪些仔细讲 节奏 轻重 设计原则 关于设计原则，推荐阅读《写个大家看的设计书》，全书比较精炼无尿点。 亲密性 将相关的项组织在一起使物理位置相互靠近 是否靠近可体现出元素之间是否存在关系 亲密性的根本目的是实现组织性，让信息更有条理容易被记住。 对齐 任何元素都不能在页面上随意放，每一项都应当与页面上某个内容存在某种视觉联系。 眼睛喜欢看到有序的事物 对齐会给人一种平静、安全的感觉，有助于表达信息。 重复 设计的某些方面需要在整个作品中重复 重复可以增强“一致性”，让零散的东西看起来更像一个整体 重复还可以为作品带来一种专业性和权威性 对比 对比是为页面增加视觉效果的最有效途径 是在不同元素之间建立层次结构最有效方法 如果两个项之间完全不同，就应当使之不同，而且是截然不同 用来组织信息、清晰层级、在页面上指引读者，并且制造焦点 应该怎么样 尽量只使用一种字体 尽量只使用一种对齐方式 尽量只使用一种色系或者一种色系加灰色 保证一个页面上的元素不多于 3 个，多于 3 个就通过亲密性关联 要确保每一项元素都与页面上的其他项存在某种对齐 尽量使用冷色做为背景色 不该怎么样 艺术字永远不要用 PPT 自带设计模板永远不要用 下载的炫酷模板永远不要用 动画和换场永远不要酷炫 复杂的图片永远不要做为背景 尽量不要把红色黄色做为背景 尽量不要使用居中对齐 不要将粗线与一种更粗的线进行对比 不要将棕色与黑色对比 如果要使用两种字体，就不要用非常类似的字体 素材网站和插件 KOPPT http://koppt.cn/index islide https://www.islide.cc/ 几点注意 讲的东西和 PPT 上的东西不要完全一样，不能完全无关 幻灯片比例：根据现场实际情况，避免大黑边 4:3 16:9 现场环境及条件 幕布投影质量很差使用深色背景 人站在屏幕当中深色背景（发布会） 插入视频或者音频一定要小心现场不能播放 越复杂的东西越容易出错 所有的展示都是为讲服务 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-04-11-rescueyouslide/"},{"title":"DNS 的一个新选择","content":"什么是 DNS 网域名称系统（英文：Domain Name System，缩写：DNS）是将域名和 IP 地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。通过这个系统我们可以将一个域名对应到其真实的 IP 地址。 例如 kaopubear.top 的域名是人类可读的，但是机器不能识别，我们必须找到其 IP 才可以。这里的 DNS 就像是一个通讯录，我们把名字输入进去，返回一个固定的手机可识别的电话号码然后拨号。 几乎互联网上的一切活动均由一个 DNS 请求开始。DNS 是互联网的目录。点击每一个链接发每一封邮件时，设备所要做的第一件事都是询问这个目录看能在哪里找到这项内容。 好用的 DNS 有什么标准 很简单：快速安全，无劫持，能解析到。 但是如果你用到了一个坑爹的 DNS，那问题远比你想象的严重。大多数人都是使用运营商自动分配的 DNS，但有时候你会发现自己的网页出现了一些莫名其妙的低俗广告，或者有些网站就是打不开。这就很可能你的 DNS 给你的域名解析了一个假的 IP 地址，或者对你的 DNS 进行了劫持插入了运营商想让你看到的东西，比如广告。 也就是说，如果想，DNS 可以决定哪些域名给你解析，哪些域名不给你解析，哪些给你解析错。 ISP 和一些有需要的人都能看到你访问的每个网站和使用的每个应用，如果他们想，DNS 提供商可以出售你的使用信息给别人。 用什么 DNS 目前国际上最知名的应该是 gu 歌的 8.8.8.8，国内的有 114.114.114.114 。随便搜一下，你其实就可以看到很多关于某些国内 DNS 服务商做的好事。 我在实际使用的时候用了很长一段时间 114.114.114.114 ，因为目前这个是国内比较快的一个了。但是它会某名的屏蔽掉我自己的博客，因为我的 top 域名是在国内买的，但是解析到的是境外服务器 (github) 的未备案 IP。国内其它很多公司，包括百度的域名我是都不敢用的。 现在好了，愚人节知名的顶级 CDN 提供商 Cloudflare 推出了自己的公共 DNS 服务，1.1.1.1 , 主打快速保护隐私和绝对安全，而且好记 : ) 当然，因为国内的环境，我今天做了测试，快速需要打个引号，但是隐私和安全还是信得过的，其承诺“ We committed to never writing the querying IP addresses to disk and wiping all logs within 24 hours.” 。 这个公司可以去查下，能搞定这么霸气的 1.1.1.1 其实不查应该也知道挺牛，这个公司以前为数百万个网站提供过免费的 SSL 加密。 如何修改 DNS windows 点击开始菜单，然后点击控制面板。 点击网络和互联网。 点击更改适配器设置。 右键点击您连接的 Wi-Fi 网络，然后点击属性。 选择 Internet 协议版本 4（如果需要，请选择版本 6）。 点击属性。 单击使用下面的 DNS 服务器地址 将这些地址替换为 1.1.1.1 DNS 地址： 对于 IPv4：1.1.1.1 和 1.0.0.1 对于 IPv6：2606：4700：4700 :: 1111 和 2606：4700：4700 :: 1001 点击确定然后关闭。 重新启动浏览器。 MacOS 打开“系统首选项”。 搜索 “DNS 服务器”，并从下拉列表中将其选中。 点击 + 按钮以添加 DNS 服务器，然后输入 1.1.1.1 再次点击 +，然后输入 1.0.0.1 依次点击 “确定”和“应用”。 相关博客：Announcing 1.1.1.1: the fastest, privacy-first consumer DNS service 国内外测试速度如下图 我在本地电脑用 dig 测试的话比 114 慢些，但是还可以接受。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-04-02-anewsafedns/"},{"title":"高效使用云笔记的 5 个问题和 10 个关键","content":"问题 1：为什么使用云笔记 问题 2：如何选择云笔记产品 问题 3：云笔记中该记录什么 问题 4：如何对信息进行分类 问题 5：如何建立个人知识体系 关键 1：善用搜索功能 关键 2：office 文档图片深度搜索 关键 3：学会添加笔记内部链接 关键 4：一键保存微信聊天记录 关键 5：笔记本自由排序 关键 6：迂回支持 markdown 关键 7：凌乱网页简化格式 关键 8：保证笔记及私密内容安全 关键 9：充分利用专属印象邮箱 关键 10：建立个人电子档案 问题 1：为什么使用云笔记 大脑擅长的事情是思考而非记录。记笔记应该是每一个经历过学生时代的人都会有的习惯。大概四五年前，随着身边各种信息的海量增加，我逐渐感到只用纸笔记录显得吃力了，那时人人网还有微博之类的网站开始盛行，时不时会读到一些他人分享的文章，看到可能有用的我就会收藏但是到了真用的时候还得去网站上翻以前的收藏记录，而且有时找到的仅仅是“原文已删除”的结果。在大三经历了一次重要笔记本丢失事件后意识到只靠纸笔来记录不仅吃力而且有巨大风险，于是正式转向云笔记。 如今，我们的大脑每天都面临着“任务，想法和信息”这三座大山。 任务指所有会花费精力和时间的事，包括需要做和想要做的事情。 触景生情或者触景生感的事情其实一直在发生，但是很多好的想法总是无处安放和相互关联。 每天面对海量的信息即要求我们学会筛选还要求可以进行快速定位。 面对这三座大山，使用且高效地使用云笔记就变得越来越重要。 问题 2：如何选择云笔记产品 我前前后后试过市面上几款主要云笔记的付费版（没有付费版的不敢试用），例如国内相对知名的有道云，为知。最终我的选择是印象笔记。以下是几个原因，也是我挑选多数工具的主要标准，供你参考。 用户基数和范围足够大：印象笔记在 2016 年全球用户已经超过 2 亿，中国用户超过 2000 万。 公司规模足够大且产品尽量单一：做为曾经的独角兽公司，印象笔记在全球云笔记行业的地位无需多言，而印象笔记则是他们的唯一产品（还有极少量衍生产品，而且正在逐步砍掉）。这意味如果印象笔记产品砸了，公司也就完了。 足够重视用户体验和反馈：我曾分别以普通用户或者付费会员身份向几家产品反馈过 BUG 或者进行产品咨询，印象笔记的客服和反馈渠道是最畅通也是解决最完善的。如果你不信，不妨以申请 token 的名义给印象笔记发封邮件试试。 产品迭代足够快且改动不大：印象笔记的预览本和正式版迭代速度很快，且国际版本和国内版保持一致，产品思路清晰，不会突然来一次面目全非或者哗众取宠的迭代升级。 产品本身足够好用和安全：当用户规模足够大且产品相对单一时基本可以说明产品本身没什么问题，这里要特别强调的是印象笔记高级搜索功能，所有图片和 office 文档的内容都支持搜索。至于数据安全，首先突然关门的可能性极低（这也是不敢用没有付费版或者收入来源产品的原因），另外如果用国际版本数据本身存在谷歌云。 题外话：如果只用一条标准筛选，基本可以概括为 能用国外优秀产品就尽量不要用国内同类产品（不含任何歧视实事求是）。国内的厂家绝大多数都是一个调性，宣称免费的一定得想各种办法加广告（去看看 163 邮箱每次通过网页版发邮件是不是都会赠送一条广告）；宣称更符合国人习惯的都是抄完之后瞎改改（抄就好好抄能不能不乱改，国人习惯就是加皮肤和头饰么）。 问题 3：云笔记中该记录什么 针对前文提到的三座大山（杂事，想法，信息），如何建立一个有条理且顺畅的思维模式是首要问题。很多时候我们不是不知道怎么做而是不知道做什么。 除了多关注当前任务，学会区分短期目标和长期目标 ）。可以按照责任和关注点思路建立符合自身实际情况的思维模式。所谓责任是指自己承担的不同角色，关注点则是每个角色的不同关注方向。这样在面对问题和一件事情时，我们就可以先把它放在一个恰当的位置而不至于毫无头绪，如果一件事请不在自己的关注点内就果断放弃。 以作者本人举例，我本身具有工作角色，家庭角色和社群角色以及社会角色等责任，在工作角色中，我首先是一个在读博士，又是一个博客作者，还是生信技能树团队的一位讲师。于是，顺着这个思路可以整理出自己的如下关注点。 在印象笔记中，我们可以根据不同的角色和关注点来建立信息分类体系。 问题 4：如何对信息进行分类 面对每天接触的海量信息，第二个需要解决的问题是如何对信息进行分类，即明确信息类型和来源。 信息类型包括： 纸质：书籍；手写笔记；其他资料（说明书，会议资料，教材） 文字：word 文档，markdown 文档 图片：各种照片和截图 文件和音视频：PDF 等文本和会议录音录像等 HTML 文本：通过浏览器看到的各种网页 信息来源包括： 短信和邮件：隐含信息为一件需要做的事情或者一份需要保存的资料 即时通讯工具：如今大量有价值的信息存在于微信 QQ 等即时通讯工具中 网站：各种论坛和博客文章。 手机 APP：公众号，阅读类应用。 针对不同的信息类型和来源，印象笔记可以进行如下操作： 纸质：纸质书籍关键段落进行标注后直接进拍照，会议资料收写笔记等也可以电子化 文字：放弃使用 word，直接存为笔记即可 邮件：每个印象笔记账号都有专属邮件帐户，可以直接保存到印象笔记 即时通讯工具：微信聊天记录和公众号文章可以一键保存 网站：主流浏览器使用剪藏插件一键保存 手机 APP：大量 APP 都接入了印象笔记 API，支持直接转存。如 Pocket，IFTTT, inoreader, 多看阅读等等。 问题 5：如何建立个人知识体系 知识体系这个词已经被各种所谓的“知识管理专家”说烂玩坏了，通俗地讲就是把碎片化、分散、相对独立的知识概念和信息加以整合，从而形成具有联系的知识系统进而解决实际问题。再通俗就是从输入到输出的过程。你接受了什么（多少）信息并不重要，输出了什么观点（解决了多少问题）才重要。 建立知识体系大体可概括为三步：获取信息、加工信息和串联整合。 目前获取信息的途径主要包括深度阅读（读书或者学习软件 manual 等第一手资料）和浅阅读（碎片化阅读如公众号等），深度阅读的优势是系统且主题固定，但比较费时和耗费精力；浅阅读的优势在于具有社交属性和相对高效，但通常内容随机主题分散，大量阅读伴随大量遗忘。 在印象笔记中，针对深度阅读可以尝试构建个人书库。每读完一本书建立一个笔记，可以包括书摘（拍照或 kindle 导入画线笔记），自己的读书笔记和其他经典书评，最后还可以整理成思维导图。 针对浅阅读，可以： 判断是否感兴趣：浏览题目和首段内容； 感兴趣的内容直接保存印象笔记； 对内容初步加工：对内容进行命名分类并添加标签； 进行主题阅读：对相同标签内容进行主题阅读，并进行编辑和添加感想。 信息源回溯：所有网页保存内容都会自动保存网页地址，感兴趣的进行回溯，查看信息源其它内容。 构建知识体系除了看到有用信息即收集，还需要获得有用信息即加工。在印象笔记中信息加工的三个要素分别是命名、分类和标签。 命名可以包括时间地点和部分关键信息。 印象笔记支持笔记本组，笔记本和笔记三个层级分类。区别于传统的纸质笔记本和电脑文件整理思路，云笔记一定要弱化分类强化标签和搜索，其实只要用到笔记本和笔记这两个层级就够用了。 分类的方法有很多，例如可以按照未完成、已完成和参考资料进行分类。未完成是正在进行的任务和项目；已完成是已经结束的任务和项目；参考资料是其他任务和项目可能会用到的知识体系。 印象笔记支持建立 250 个笔记本的同时还支持 10000 个标签。我们可以把笔记本理解为类别，把标签理解为属性。例如我的未完成和已完成以及参考资料中都有“RNA-seq”或者“时间管理”等内容，我就可以通过标签来同时对它们进行查看。而同一篇笔记可以包含多个标签，进而从多个维度进行管理。 再次强调：用好标签是使用印象笔记最重要的一点。 接下来，我们关注一下高效使用印象笔记的十个关键点。 关键 1：善用搜索功能 印象笔记的高级搜索实在太强大，看似只是一个简单的文字搜索，其实可以对笔记的创建日期、媒体类型、创建地点等信息搜索，而且还（部分）支持通配符与反选。除此之外，常用到的搜索语句可保存，以后可以直接点击以保存语句进行搜索。 这里仅罗列几个高频搜索技巧： 操作符 描述 范例 intitle: 在笔记标题中搜索。 intitle: 咖啡 可以搜索标题中含有“咖啡”的笔记。 notebook: 在指定的笔记本中搜索笔记。 notebook: 财务将只搜索“财务”笔记本中的笔记。 any: 将显示匹配任一 搜索关键词的笔记。若不使用该操作符，印象笔记搜索将只显示匹配全部关键词的笔记。 any: 披萨 啤酒 将搜索所有含有“披萨”或“啤酒”的笔记（去除 any: 将只显示同时包含“披萨”及“啤酒”的笔记）。 tag: 搜索含有指定标签的笔记。 tag: 医疗 将搜索含有标签“医疗”的笔记。 resource: 搜索包含特定媒体类型（音频，图像等）的笔记。 resource:application/pdf 将搜索所有包含 PDF 文件的笔记。resource:image/jpeg 将会搜索所有内含 JPEG 格式图片的笔记。resource:audio/* 将会搜索所有内含音频文件的笔记。 source: 通过应用程序搜索笔记或者通过其他途径来创建它们（比如 Email、SMTP 来添加笔记；通过剪藏来创建剪辑，等等）。 **source:mobile.* **将搜索所有创建于移动版应用某一类型的所有笔记。source:web.clip 搜索结果将显示所有通过剪藏创建的笔记。 关键 2：office 文档图片深度搜索 准确的说，印象笔记中其实不存在文档附件的概念，笔记中所有 PDF、Word、Excel 的内容都可以进行搜索的，图片里的文字也可以搜索。目前手写中文字体识别准确率并不高，英文还是靠谱的。 关键 3：学会添加笔记内部链接 在进行信息收集和加工之后，使用添加内部链接功能可以为同类知识添加目录或者建立关联，在 A 笔记中插入 B 笔记的链接，点击即可跳转到 B 笔记。如下所示： 关键 4：一键保存微信聊天记录 现在大多数公司和实验室多多少少都微信办公了，很多聊天都记录参杂着各种通知和工作安排。 印象笔记支持直接保存聊天记录，操作方式如下。 关键 5：笔记本自由排序 给笔记本名称前添加数字可以让笔记本按照自己希望的顺序排序，方便查找，提高效率。 关键 6：迂回支持 markdown 印象笔记并不支持完整的 markdown 语法，目前只有几个类似于 markdown 语法的快捷操作方式。这个问题可以通过使用开源的第三方编辑器和插件解决。 首先申请印象笔记的 Developer token；安装 vs code 编辑器并安装 EverMonkey 插件，在编辑器编辑好之后就可以进行推送，在印象笔记端呈现的就会是渲染好的文件了。最后再把原始的 markdown 文档做为附件保存在笔记中就大功告成。 当然，有些印象笔记第三方编辑器可以支持 markdown 语法，可以自行搜索。 关键 7：凌乱网页简化格式 有时从网页保存的文章有奇奇怪怪的复杂格式，保存到印象笔记中看的非常心累。可以使用网页剪藏插件的隐藏广告功能。 有些微信公众号文章的排版也花哨过头，这时可以使用简化格式功能。 简化格式前 简化后 关键 8：保证笔记及私密内容安全 有些人喜欢把一些比较私密的信息保存在印象笔记中，为了不让别人直接看到想要保密的内容，可以对笔记中的部分内容进行加密，在手机客户端也可以设置打开应用需要指纹解锁。 在笔记中选中一部分内容，然后右键点击选择加密文本，就可以直接设置密码。 再打开有加密内容的笔记就是如下效果。 另外，为了进一步保证安全，印象笔记支持类似于 iOS 系统的两步验证。如果在新设备登陆，除了输入密码之外，还会要求输入短息验证码或者 Google Authenticator 生成的随机验证码。 关键 9：充分利用专属印象邮箱 每个印象笔记账号都有专属邮件帐户，提前把这个邮箱存到自己常用的邮箱联系人中。一方面在收到重要的邮件后可以直接转发到印象笔记，内容和附件都会自动保存，另一方面在发送某些重要邮件时也可以直接密送印象笔记。订阅某些邮件服务时，比如信用卡账单，还可以直接填写印象笔记邮箱。 另外，只要知道另一个印象笔记用户的注册邮箱，就可以通过邮箱地址将自己的笔记共享给对方，并进行协同操作。 关键 10：建立个人电子档案 除了利用印象笔记构建知识体系之外，另一个应用方向就是建立个人信息档案。 一方面可以把自己各种缴费的重要收据和所买电子产品说明书进行电子化备份，已被不时之需；另一方面可以建立自己的财务档案和旅游档案等内容；同时也可以建立个人简历，保存适用于各种场合的自我介绍，各类证书的扫描件和不同尺寸的照片等。 使用印象笔记手机客户端对文本材料进行拍照时，会识别名片和纸张边缘等信息并自动矫正，拍完直接保存无需二次处理，如下图所示。 参考资料及扩展阅读： 《印象笔记留给你的空间》 李参 印象笔记官方帮助文档 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-03-11-howtouseevernote/"},{"title":"给初学者的 R 语言介绍","content":"几点说明： 文档由 R Markdown[1] 写成。 下文是我暂时能想到的一些内容，水平有限，供大家了解，大牛小神都可以出门右拐不用看哈。 写作初衷：目前在水中科院上海分院这边生物统计学助教，本文及后续一段时间里的 R 相关内容主要是为了供这门课的同学参考，同时也是自我总结的过程。 数据科学重要性 摩尔定律 [2] 告诉我们计算机的计算能力每两年就会翻一倍，这使得数以百万计的计算机生成了大规模数据集。 海量的数据如何处理成了各行各业都需要面对和解决的问题；如何从海量信息中提取有效信息并总结出一般性的规律也值得我们去思考。 数据驱动下产生的这门学科，被我们称为数据科学（Data science），其中涉及到数据的收集、处理、分析和呈现四大方面。 2012 年，哈佛商业评论将** Data Scientist **定义为 21 世纪最性感的职业 ^3。 数据科学和我们每个人都不遥远 如何高效准确地从各种各样的 paper 中找到自己需要的信息。 如何快速地将各种信息进行整理并且提炼出自己的看法，以便和老板 talk 的时候侃侃而谈。 如何让自己的实验数据更具有说服力。 如何处理自己辛苦搬砖产生的大量实验数据。 生物统计学重要性 数据科学家是不是 21 世纪最性感的职业我们在这里先不做评论，但是从小你我就都听过： 21 世纪是生命科学的世纪 很多人也是因为这句话而走上了一条不归路。 学生物的人，在属于你们的世纪里从事这个世纪最性感的职业，走上人生巅峰一定指日而待。当然，就算是在生物领域里多接触学习一些和数据科学相关的知识，看起来也是一件很炫酷的事情。 而生物统计学这门课，就是所有实验狗窥探程序猿或者数据科学家生活最简单的一条途径。 学习生物统计学课程 如果稍微长点心，就算不能入门一门编程语言，最起码也可以看见那扇门。 如果稍微用点心，以后看到文献中复杂的统计学方法或者炫酷的数据展示方式，也能大概知道它是怎么来的。 如果再多用点心，很可能今后进行大量的实验数据处理时也可以独当一面，放弃用了很多年（其实还是不会用）的 Excel 如果你突然发现自己在数据分析方面很有天赋，那就是前途无量了。 怎样入门数据科学 这里的标题用了数据科学没有用生物统计学，是想说在这门课上接触到的东西，绝不仅仅只能用来分析你手上那些生物学数据。另一方面，标题里用了入门而非掌握或者精通，是想说通过短短的一学期课程，你几乎不可能学好或者掌握一门复杂的学科，最多也就是入门。 至于之后的事情，是从入门到精通还是从入门到放弃，并不在我们目前的讨论范围。 如果想入门数据科学或者在实际工作中运用一些数据科学的知识，你最起码需要从以下几个方面入手。其中，生物统计学这门课给你提供的更多是基础的统计学知识和如何正确地处理数据，而我们即将接触的一门编程语言，则完全可以帮助你做好以下很多方面的工作，比如方便快捷地获取数据，正确地处理数据和恰当的展示你的数据。 数学和统计知识 这门课程会从介绍最基本的统计学概念开始，随后会涉及到多种常见的统计学模型和假设检验。 你要做的，就是努力回忆残存的高中和大学数学与统计知识，争取理解各种常见的统计学名词和概念究竟是什么意思。 了解自己的研究领域 没有背景的数据分析是没有意义的，生物学尤其如此。一定不要做了一堆实验得到一堆数据然后分析一通发现不知道自己要说什么。充分了解自己的研究领域是必要的。 合理地获取数据 通过哪些途径和手段可以获取已有的公共数据是你需要考虑的问题。其实，很多时候我们都是在做重复的工作，大量的公共数据很有可能就足够回答你的问题。但是，你并不知道它在哪或者该怎么用。 学会如何合理地设计自己的实验也非常重要。实验盲目做太多，数据重复没意义而且关键是累；实验设计的不合理，数据再怎么分析也没意义。 正确地处理数据 你要的数据需要用什么实验来做，得到的数据又应该用什么方法来处理。你的数据背景是否干净，你的实验数据是否需要进行预处理，你用的统计模型是否合适。有时候万年 t-test 很难有太强的说服力。 恰当地展示数据 如果你有了类似于 DNA 双螺旋的发现，你的实验结果再怎么展示问题都不大。但更多时候，你的实验结果并不能让所有人兴奋或者信服。这时，如何把自己的实验数据更好地展示给别人，从而让别人更容易理解进而愿意接受你的观点就显得非常重要了。 同样的一套数据，有时候用不同的方法展示效果会有巨大的差别。保证数据真实性的情况下，让你的图看起来更加漂亮总没有坏处。毕竟，我们对任何东西的第一印象永远是颜值。 数据科学常用语言 这一部分，我会罗列若干种非自然语言，每一个在数据科学中都有广泛的应用。这里所谓的语言，很多也是开发环境或者软件，你只需要有个印象。我的目的是想在后面说为什么从学 R 开始。更具体的内容可以参考这篇文章 《数据科学家的成长之路 [译]》 Excel 没错，我把 Excel 作为一门语言放在这里了，你发现自己竟然掌握了一门数据科学常用语言，而且用了那么多年。 你可能会按列求和、查找替换、求方差标准差，甚至还会分列。但是，你会用几个 Excel 常用函数呢，比如最基本的 VLOOKUP/SUMIF/COUNTIF；你能熟练的使用透视表么。我们就不提宏和 VBA 了，其实这也是把 Excel 算做一门语言的原因。 MATLAB MATLAB 是一款鼎鼎大名的数据分析软件，如果你偶尔听说过各种类型的建模比赛，那么多数少不了 MATLAB 的身影。如果你日常的工作涉及到图像处理或者各种信号处理，学它是没错的。除此以外，如果你打开过 MATLAB 的软件，你会发现它类似于 Excel 可视化的交互可以让人很容易上手而无需面对看起来吓人的命令行。作为一款商业数据分析软件，它最大的特点就是贵。 Python Python 是一门非常强大且用途极其广泛的编程语言，在数据科学界也受到很多人的喜爱。各种各样的库可以满足数据科学不同方面的各种需求：对于神经网络，有 Theano 和 Tensorflow；面向机器学习有 scikit-learn；面向数据分析有 NumPy 和 Pandas。而且，据绝大多数人反馈，他可能是最容易入门的语言之一，而且它是免费的开源语言。你不需要因为使用它而支付任何费用。 如果你是一个井井有条的强迫症患者，Python 很适合你，它会强制使用者在代码中留出正确的空白和缩进。另外，如果你第一眼就知道 Python 该怎么读，说明你们有缘，不妨去多了解一下。 SQL 谈到数据库的时候，基本上是逃不掉 SQL 的。不过，如果不做数据库或者网站开发，它对你基本也没太大用处。而且学术届或者说生物圈的人，其实很少在日常中使用 SQL 对数据进行增删改查和统计。而其他大多数和大数据相关的领域和行业，学会 SQL 是必须的。 R 记住，R 语言是统计学家为了统计学家进行统计学工作而开发的一种语言。这看起来和程序猿没什么关系，是不是瞬间亲切了很多。 和 Python 一样，R 也是免费开源的。类似于 Python 中的库，R 里各种各样的包则可以满足你对于统计学的一切幻想。和 Python 相比，它还有一个很大的优点，就是你不会读错它的名字。 为什么要学习 R R 的诞生 1992 年，肉丝（Ross Ihaka）和萝卜特（Robert Gentleman）两个人在 S 语言（贝尔实验室开发的一种统计用编程语言）的基础上开始构思一种新的用于统计学分析的开源语言，直到 1995 年第一个版本正式发布（和各位年龄相仿）[3]。因为他们名字的第一个字母都是 R，所以这门语言就被叫做 R。这两个人都是统计学教授出身，再加上 R 语言的生父 S 语言，所以** R 语言在统计学方面有着纯正的血统**！ 如果你平时的工作会涉及到统计学，那么接触 R 语言实在是太正常不过了。 另外，关于 R 语言的开发者，看名字（Ross 和 Robert）部分人以为是伉俪，其实就是两个大老爷们。如图所示 R 的发展 作为开源软件的 R 能够迅速发展，很大程度上取决于其活跃的社区。学习 R，很大程度上也是学习各种 R 包的使用。截止目前（2017 年 2 月 25 日），CRAN(Comprehensive R Archive Network)[4] 上已经有 10162 个可以获取的 R 扩展包，内容涉及各行各业，可以适用于各种复杂的统计。各地的 CRAN 镜像都是 R 网站的备份文件，内容完全一样，你可以选择离自己最近的去访问。 R 的特长 在 R 官网有这样几句介绍 R provides a wide variety of statistical (linear and nonlinear modelling, classical statistical tests, time-series analysis, classification, clustering, …) and graphical techniques, and is highly extensible. One of R’s strengths is the ease with which well-designed publication-quality plots can be produced, including mathematical symbols and formulae where needed. 因为 R 语言本身为统计而生，所以你能想到的所有统计相关的工作，R 都可以非常简洁的用几行命令（甚至 1 行命令）帮你完成。 R 高度的可扩展性正是体现在它那 1 万多个包上，你想做的几乎所有事情都可以用现有的 R 包来辅助完成（当然，有些工作即便能完成但也不适合）。 R 另一个杀手锏就是其强大的绘图功能，正如上面的英文介绍所言，R 可以画图，画各种各样的图，画各种各样高逼格的图，画各种各样高逼格可以直接出版的图。 完善的统计学功能再加上强大的绘图功能，就是你学习的最大理由。 对于生物相关的工作者而言，他们还有一个巨大的福利就是 Bioconductor[5]，这里面的一千多个 R 包都是用来解决生物（信息）问题的。 R 应用示例 在这一部分，仅仅是给展示几个用 R 可以轻松完成的相对有趣的工作。 安装对应包后应该可以直接运行 示例 1 ggplot2 画图 #第一次使用，需要安装相应的包 #以后只需要调用即可 #install.packages(&quot;ggplot2&quot;) library(&quot;ggplot2&quot;) theta &lt;- seq(0,24*pi, len=2000) radius &lt;- exp(cos(theta)) - 2*cos(4*theta) + sin(theta/12)^5 dd &lt;- data.frame(x=radius*sin(theta), y=radius*cos(theta)) ggplot(dd, aes(x, y))+geom_path()+xlab(&quot;&quot;)+ylab(&quot;&quot;) 效果展示 示例 2 词频分析及词云 # install.packages(&quot;wordcloud2&quot;) library(wordcloud2) wordcloud2(demoFreqC, size = 0.7, shape = 'diamond') 效果展示 示例 3 查看我国各地空气质量 [6] #install.packages(&quot;rvest&quot;) #install.packages(&quot;leafletCN&quot;) #install.packages(&quot;rgeos&quot;) Sys.setlocale(&quot;LC_CTYPE&quot;, &quot;eng&quot;) library(rvest) library(leafletCN) library(rgeos) doc = read_html(&quot;http://www.pm25s.com/cn/rank/&quot;) cities = doc %&gt;% html_nodes(&quot;.cityrank a&quot;) %&gt;% html_text() cities = iconv(cities, &quot;UTF-8&quot;, &quot;UTF-8&quot;) AQI = doc %&gt;% html_nodes(&quot;span[class^='lv']&quot;) %&gt;% html_text() %&gt;% .[c(F,F,T)] %&gt;% as.numeric dat = data.frame(city = cities, AQI = AQI) geojsonMap(dat, &quot;city&quot;, popup = paste0(dat$city,&quot;:&quot;,dat$AQI), palette = &quot;Reds&quot;, legendTitle = &quot;AQI&quot;) 效果展示 如何尝试入门 R 语言 一开始这一部分的标题是 如何学好 R 语言，但是写这部分东西需要很强的功底，我知道自己根本谈不上学好。 后来又打算叫 如何入门 R 语言，但是每个人能付出的精力和能力又各不相同，而且因为平时我用 R 的地方不太多，只是最近担任助教才又开始继续学习。为了避免看了文章却没入门的朋友来吐槽，机智如我，干脆就叫如何尝试入门 R 语言。 学习路线 看到这篇文章的一部分人很可能是我担任助教这门课（生物统计学）的同学，而另一部分人很可能与生物信息学相关。 为了通过考试 如果你是前者而且仅仅是为了通过最后的考试，我建议你只需要在每节理论课后认真理解老师上课的内容，在每节讨论课后拿出两三天消化我们作业题中用到的 R 语言知识点就可以了。 大致了解一下 R 语言是什么，能干什么用（看完这篇文章，这部分就可以了）。 学习如何在 R 的官网下载 R，如何在自己的电脑安装 R 并成功运行。 学习如何安装 Rstudio，并且了解其基本的用法（这步可省略）。 学习如何查看 R 帮助文档（这步很重要）。 学习如何将作业中的数据（作业中通常是 txt 或者 csv 格式）正确地导入 R。 了解 R 语言中的常见变量。 学习 R 语言一些最基本的命令，如安装包、调用包、读入写入文件、构造矩阵和基础绘图等。 学习在 R 中如何使用（课上提到的）统计学相关函数，了解其参数的含义。 能够独立完成最后几次作业和上一年的期末考试题。 生物信息学相关 了解 R 语言在生物信息学领域的应用。 理解 R 语言中的各种变量。 学习如何创建数据集、清洗数据和使用常见的统计分析方法。 能够对数据进行高级操作，对数据进行转换。 学习 R 语言的中高级绘图方法，能够使用 ggplot2。 学习 R 中高级统计分析方法，如聚类、主成分分析和线性回归等。 学习并熟练使用自己研究领域相关的 R 包（通过 bioconductor）。 个人感觉，如果能完成上述几条学习路线，那么 R 语言就算入门了。 入门的标准是什么呢？我想就是给你一份数据让你处理，你脑子里的第一反应是可不可用 R 做；如果给你一个任务，你能上手尝试用 R 去解决。 参考资料 这里罗列部分在尝试入门的过程中，可能会有用的资料。 在线资料 R 语言官网 R 语言官方文档 RStudio 官网 Bioconductor 官网 R 语言资料库 R 函数和包的在线帮助文档 统计之都社区 中文书籍 《R 语言编程艺术》 《R 语言实战》 《统计建模与 R 软件》 《ggplot2: 数据分析与图形艺术》 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 R markdown 官网网站 http://rmarkdown.rstudio.com ↩︎ 摩尔定律 https://en.wikipedia.org/wiki/Moore%27s_law ↩︎ R language https://wiki2.org/en/R_(programming_language) ↩︎ CRAN 官网 https://cran.r-project.org/ ↩︎ Bioconductor 官网 https://www.bioconductor.org/ ↩︎ 示例 3 来源：http://langdawei.com/2017/01/07/aqi.html ↩︎ ","link":"https://kaopubear.top/blog/2017-03-06-rintro2sibs/"},{"title":"『终极算法』摘抄笔记-贝叶斯学派","content":"贝叶斯定理 对于贝叶斯学派来说，学习“仅仅是”贝叶斯定理的另外一个运用，将所有模型当作假设，将数据作为论据：随着你看到的数据越来越多，有些模型会变得越来越有可能性，而有些则相反，直到理想的模型渐渐突出，成为最终的胜者。 假设你半夜在一个陌生的星球上醒来。虽然你能看到的只是繁星闪烁的天空，你有理由相信太阳会在某个时间点升起，因为多数星球会自传并绕着自己的太阳转。所以你估计相应的概率应该会大于 1/2（比如说 2/3）。我们将其称为太阳会升起来的“先验概率”，因为这发生在看到任何证据之前。“先验概率”的基础并不是数过去这个星球上太阳升起的次数，因为过去你没有看到；它反映的是对于将要发生的事情，你优先相信的东西，这建立在你掌握的宇宙常识之上。但现在星星开始渐渐暗淡，所以你对于太阳会升起的信心越来越强，这建立于你在地球上生存的经历之上。你的这种信心源自“后验概率”，因为这个概率是在看到一些证据后得出的。天空开始渐渐变亮，后验概率又变得更大了。 贝叶斯通过以下句子概况了这一点：P（原因｜结果）随着 P（结果），即结果的先验概率（也就是在原因不明的情况下结果出现的概率）的下降而下降。最终，其他条件不变，一个原因是前验的可能性越大，它该成为后验的可能性就越大。综上所述，贝叶斯定理认为：P（原因｜结果）=P（原因）×P（结果｜原因）/ P（结果） 贝叶斯定理之所以有用，是因为通常给定原因后，我们就会知道结果，但我们想知道的是已知结果，如何找出原因。例如，我们知道感冒病人发烧的概率，但真正想知道的是，发烧病人患感冒的概率是多少。 贝叶斯定理作为统计学和机器学习的基础，受到计算难题和巨大争论的困扰。你想知道原因也情有可原：这不就是我们之前在感冒的例子中看到的那样，贝叶斯定理是由条件概率概念得出的直接结果吗？的确，公式本身没有什么问题。争议在于相信贝叶斯定理的人怎么知道推导该定理的各个概率，以及那些概率的含义是什么。对于多数统计学家来说，估算概率的唯一有效方法就是计算相应事件发生的频率。例如，感冒的概率是 0.2，因为被观察的 100 名病人中，有 20 名发烧了。这是“频率论”对于概率的解释，统计学中占据主导地位的学派就是由此来命名的。但请注意，在日出的例子以及拉普拉斯的无差别原则中，我们会做点不一样的事：千方百计找到方法算出概率。到底有什么正当的理由，能够假设太阳升起的概率是 1/2、2/3，或者别的呢？ 然而，贝叶斯学派眼中的概率。概率并非频率，而是一种主观程度上的信任。因此，用概率来做什么由你决定，而贝叶斯推理让你做的事就是：通过新证据来修正你之前相信的东西，得到后来相信的东西（也被称为“转动贝叶斯手柄”）。 所有模型都是错的，但是有些却有用 随着变量的增加，如果有 20 种症状和 1 万个病人就会遇到之前提到过的组合爆照问题。因此我们会做简化的假设来减少概率的数量，这些概率的数量由我们估算而来，且我们可以掌控。一个很简单且受人追捧的假设就是，在给定原因的情况下，所有的结果都相互独立。如果我们想直接估算 P（感冒｜发烧、咳嗽等），假如不利用定理先将其转化成 P（发烧、咳嗽等｜感冒），那么我们就还需要指数数量的概率，每个组合的症状以及感冒或非感冒都有一个概率。 如果学习算法利用贝叶斯定理，且给定原因时，假定结果相互独立，那么该学习算法被称为“朴素贝叶斯分类器”。 统计学家乔治·博克斯说的一句很有名的话：“所有的模型都是错的，但有些却有用。”虽然一个模型过于简化，但你有足够的数据用来估算那就比没有数据的完美模型要好。令人诧异的是，有些模型错误百出，同时又很有用。经济学家弥尔顿·弗里德曼甚至在一篇很有影响力的文章中提出，最有说服力的理论往往受到最大程度的简化，只要这些理论所做的预测是准确的，因为它们用最简洁的方法解释最复杂的问题。 马尔科夫链 1913 年第一次世界大战前夕，俄国数学家安德烈·马尔可夫发表了一篇文章，将所有事情的概率运用到诗歌当中。诗中，他模仿俄国文学的经典：普希金的《尤金·奥涅金》，运用了当今我们所说的“马尔可夫链”。他没有假定每个字母都是随机产生的，与剩下的毫无关联，而是最低限度引入了顺序结构：每个字母出现的概率由在它之前、与它紧接的字母来决定。 例如元音和辅音常常会交替出现，所以如果你看到一个辅音，那么下一个字母（忽略发音和空格）很有可能就是元音，但如果字母之间互相独立，出现元音的可能性就不会那么大。这可能看起来微不足道，但在计算机发明出来之前的年代，这需要花费数小时来数文字，而马尔可夫的观点在当时则很新颖。如果元音 i 是一个布尔型变量，《尤金·奥涅金》的第 i 个字母是元音，则该变量为真，如果它是一个辅音则为假。 源于谷歌的页面排名，本身就是一条马尔可夫链。拉里·佩奇认为，含有许多链接的页面，可能会比只含几个的要重要，而且来自重要页面的链接本身也更有价值。这样就形成了一种无限倒退，但我们可以利用马尔可夫链来掌控这种倒退。想象一下，一个页面搜索用户通过随机点击链接来从这个页面跳到另外一个页面：这时马尔可夫链的状态就不是文字而是页面了，这样问题就变得更为复杂，但数学原理是一样的。那么每个页面的得分就是搜索用户花在该页面上的时间，或者等于他徘徊很久后停留在该页面上的概率。 如果我们测量的不仅仅是元音对辅音的概率，还有字母顺序遵循字母表顺序的概率，利用与《尤金·奥涅金》一样的统计数据，我们可以很愉快地生成新的文本：选择第一个字母，然后在第一个字母的基础上选择第二个字母，以此类推。当然结果是一堆没有意义的数据，但如果我们让每个字母都依照之前的几个字母而不止一个字母，这个过程就开始听起来更像一个酒鬼的疯话，虽然从整体上看没有意义，但从局部上看却很连贯。虽然这还不足以通过图灵测试，但像这样的模型是机器翻译系统的关键组成部分，比如谷歌翻译可以让你看到整版的英文页面（或者几乎整版），不管原页面的语言是什么。 如果某些状态组成一条马尔可夫链，但我们看不到它们，得从观察中将它们推导出来。人们称其为隐藏的马尔可夫模型，或者简称为 HMM（有点误导人，因为被隐藏的是状态，而不是模型）。HMM 和 Siri 一样，处于语音识别系统的中心。在语音识别过程中，隐藏的状态是书面形式的单词，而观察值则是对 Siri 说的声音，而目标则是从声音中推断出单词。模型有两个组成部分：给定当前单词的情况下，下一个单词出现的概率和在马尔可夫链中的一样；在单词被说出来的情况下，听到各种声音的概率。 HMM 还是计算生物学家最为喜爱的工具。一个蛋白质分子是一个氨基酸序列，而 DNA 则是一个碱基序列。举个例子，如果我们想预测一个蛋白质分子怎样才能形成三维形状，我们可以把氨基酸当作观察值，把每个点的褶皱类型当作隐藏状态。同样，我们可以用一个 HMM 来确定 DNA 中基因开始转录的地点，还可以确定其他许多属性。 如果状态和观察值都是连续而非离散变量，那么 HMM 就变成人们熟知的卡尔曼滤波器。经济学家利用卡尔曼滤波器来从数量的时间序列中消除冗余，比如 GDP（国内生产总值）、通货膨胀、失业率。“真正的”GDP 值属于隐藏的状态；在每一个时间点上，真值应该与观察值相似，同时也与之前的真值相似，因为经济很少会突然跳跃式增长。卡尔曼滤波器会交替使用这两者，同时会生成流畅的曲线，仍与观察值一致。 贝叶斯网络：推理问题 **马尔可夫链隐含这样的猜想：考虑到现在，未来会有条件地独立于过去。**此外，HMM 假设每个观察值只依赖于对应的状态。贝叶斯网络对贝叶斯学派来说，就像逻辑与符号学者的关系：一种通用语，可以让我们很好地对各式各样的情形进行编码，然后设计出与这些情形相一致的算法。我们可以把贝叶斯网络想成“生成模型”，即从概率的角度，形成世界状态的方法：首先要决定盗窃案或地震是否会发生，然后在此基础上决定报警器是否会响起，再次在此基础上决定鲍勃和克莱尔是否会打电话。贝叶斯网络讲述这样的故事：A 发生了，接着它导致 B 的发生；同时，C 也发生了，而 B 和 C 共同引起 D 的发生。为了计算特定事件的概率，我们只需将与之相关事件的概率相乘即可。 你身后有几个士兵：假设夜深人静时你正带领排成纵队的一个排，穿过敌人的领地，而你想确认所有士兵仍在跟着你。你可以停下，自己数人数，但那样做会浪费太多时间。一个更聪明的办法就是只问排在你后面的第一个兵：“你后面有几个兵？”每个士兵都会问自己后面的士兵同一个问题，知道最后一个士兵回答“一个也没有。”倒数第二个士兵现在可以说“一个”，以此类推，直到回到第一个士兵，每个士兵都会在后面士兵所报数的基础上加一。现在你知道有多少兵还跟着你，你甚至都不用停下来。 语音识别的方法：Siri 用同样的想法来计算你刚才说的概率，通过它从麦克风中听到的声音来进行“报警”。把“Call the police”（报警）想成一排单词，正以纵队形式在页面上行走，“police”想知道它的概率，但要做到这一点，它需要知道“the”的概率；“the”回过头要知道“call”的概率。所以“call”计算它的概率，然后将其传递给“the”，“the”重复步骤并将概率传递给“police”。现在“police”知道它的概率了，这个概率受到句子中每个词语的适当影响，但我们绝不必建立 8 个概率的完整表格（第一个单词是否为“call”，第二个是否为“the”，第三个是否为“police”）。实际上，Siri 考虑在每个位置中出现的所有单词，而不仅仅是第一个单词是否为“call”等，但算法是一样的。也许 Siri 认为，在声音的基础上，第一个单词不是“call”就是“tell”，第二个不是“the”就是“her”，第三个不是“police”就是“please”。个别地，也许最有可能的单词是“call”、“the”和“please”。但那样会变成一句没有意义的话“Call the please”，所以要考虑其他单词，Siri 得出结论，认为句子就是“Call the police”。 然而，最受人青睐的选择就是借酒浇愁，喝得酩酊大醉，然后整夜都在跌跌撞撞。该选择的技术术语为“马尔可夫链蒙特卡洛理论”（Markov chain Monte Carlo，MCMC）：有“蒙特卡洛”这个部分，是因为这个方法涉及机遇，比如到同名的赌场去，有“马尔可夫链”部分，是因为它涉及采取一系列措施，每个措施只能依赖于前一个措施。MCMC 中的思想就是随便走走，就像众所周知的醉汉那样，以这样的方式从网络的这个状态跳到另一个状态。这样长期下来，每个状态受访的次数就与它的概率成正比。人们在谈论 MCMC 时，往往把它当作一种模拟，但它其实不是：马尔可夫链不会模仿任何真实的程序，我们将其创造出来，目的是为了从贝叶斯网络中有效生成样本，因为贝叶斯网络本身就不是序变模式。 对于贝叶斯学派来说，知识越过模型的结构和参数，进入先验分布中。原则上，之前的参数可以是任意我们喜欢的值，但讽刺的是，贝叶斯学派趋向于选择信息量不足的先验假设（比如将相同概率分配给所有假设），因为这样更易于计算。在任何情况下，人类都不是很擅长估算概率。对于结构这方面，贝叶斯网络提供直观的方法来整合知识：如果你认为 A 直接引起 B，那么应把箭头从 A 指向 B。 在生物信息中，贝叶斯学习能对单个数据表起作用，表中的每列表示一个变量（例如，一个基因的表达水平），而每行表示一个实例（例如，一个微阵列实验，包含每个基因被观察到的水平）。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-03-05-TheMasterAlgorithm7/"},{"title":"2018，不妨从“丢”开始","content":"“丢”并不简单 所谓“丢”，high level 的说法就是：断舍离 在《断舍离》这本书的序言中，作者提到过如下一段话： 断舍离和单纯的扫除、收拾不一样，并不是以“很可惜啊”、“还能用吗”、“不能用了吗”为考虑的重点，而是要自问“这个东西适合自己吗”。换句话说，断舍离的主角并不是物品，而是自己。**这是一种以“物品和自己的关系性”为核心，取舍选择物品的技术。**你要做到的思考方式并不是“这东西还能使，所以要留下来”，而是“我要用，所以它很必要”。**主语永远都是自己，而时间轴永远都是现在。现在自己不需要的东西就必须放手，只选择必要的物品。**通过这个过程，你可以从看得见的世界走向看不见的世界，最终实现对自己的深刻、彻底的了解，并接纳最真实的自己。 所谓“断”是断绝想要进入自己家的不需要的东西；所谓“舍”是舍弃家里到处泛滥的破烂。通过不断重复“断”和“舍”，最后到达“离”的状态：脱离对物品的执念，处于游刃有余的自在的空间。 所谓断舍离是透过整理物品了解自己，整理内心，让生活舒适。针对物品而言，我们需要做的事情包括不用性价比做为依据来购买物品而是根据自己是否需要；家里一年也没穿过一次的衣服该扔就要扔掉或者捐掉；逐渐舍弃对物质（品）的 过度依赖，让自己拥有可以自由支配的空间和时间。 学习中的断舍离 脱离了初中高中填鸭式的学习模式，进入大学以后学习方式就或主动或被动地转化为自主式学习。如果更系统地说，借用斯科特·杨 (Scott Young) 在《如何高效学习》的说法，叫做整体性学习，也就是不断的将新知识融入到已有知识结构中，不断的构建和扩展知识信息网络。 **整体性学习包括：获取，理解，扩展，纠错，应用和测试共六个步骤。**如果感兴趣，不妨阅读《如何高效学习》这本书，或者去看看作者在 TEDx 的相关视频，这里不展开讨论。 接下来我们要谈的是为什么在整体性（自主性）学习中需要断舍离。 日常，我们所有的听和读都是获取信息的方式，获取和收集信息是任何学习的第一步，也是学习最基础的阶段，然后不幸的是对于不少人而言学习通常在这一步就已经结束了。开始了么？已经结束了。 信息收集的方式可以分为主动和被动。所谓主动即问题为导向，因为有问题需要解决，所以通过各种途径去收集信息；所谓被动即非刻意浏览，例如每天随手打开的各类文章，在阅读之前我们并没有预期自己将会看到什么。如下图所示，这里得到的内容只能称之为数据 (data) 或者信息，还远不能称之为知识。所谓的数据其实只是信号或事实，在通过清洗和处理表达为有用的形式之前，数据本身没有用途。 因此我们首先要做的就是对已有信息进行预处理，比如同类内容的选择和整合。 一方面，面对自己看到的“可能有用的知识”，不是考虑这个知识本身重不重要，而是自己短期内会不会用到；另一方面，已经收藏的知识点（其实只能称为信息），如果过去三四个月都没再碰，就要学会勇敢的删除。这就是信息收集中涉及的断舍离。 在理解阶段，我们首先要理解各种专有名字的基本解释，理解公式和定理的基本含义并能进行解释；在扩展阶段，我们需要扩展当前知识的边界，也就是将新旧知识联系起来，以旧带新，用新顾旧。这两个阶段是构建知识联系，提取知识骨架和构建知识模型的关键阶段。在这个过程中，我们需要进一步整理已有知识， 例如思考哪些知识点可以合并，哪些工具可以相互替代。这就需要我们进行第二次的断和舍。 所谓纠错阶段是自我反思和提高的过程，在理解阶段和扩展阶段我们往往会过犹不及的，很多扩展和联系其实并不成立甚至根本就是我们在没有学习充分情况下的想当然。通过实践和测试我们不断纠正已有的知识框架和体系，并且有针对性的进行补充和删改，这也就是纠错阶段的断和舍。 2018 年，不妨从“丢”开始。 有了上述这些理论基础再审视我们自身实际情况，2018 年不妨别立太多所谓“得到”或“收获”相关的 flag，而是学会从“丢”开始。 以下是一些小建议，供你参考。 整理自己的办公和学习环境： 桌面上一个小时用不到一次的东西就收进抽屉 笔只要一支，本子只要一个 桌子上的书别摆超过三本 多喝水但是桌子上只留一个水杯 书架上书如果太多就每个月送出去或者二手转出一本 整理自己的信息仓库 每天印象笔记中删除的笔记比新写入的多一篇 每天微信收藏删除的文章比新收藏的多一篇 每天各类稍后读应用中删除的红心比新加的多一个 简而言之，就是尝试所有常用收藏类的工具每天都删除一个收藏 希望 2018 年，我们能学会轻装上阵，走得更远。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-02-26-easylifeeasylearn/"},{"title":"『终极算法』摘抄笔记-联结学派","content":"赫布律 “当 A 细胞的轴突和 B 细胞足够近，并且重复或不断地对其放电时，A、B 中的一个细胞或者两个细胞都会经历生长过程或者代谢改变，这样 A 细胞（作为对 B 细胞放电的细胞之一）的效率就会得到提高。” 1949 年《行为的组织》 这段话经常被转述成“一起放电的神经元也会被串连在一起”。 赫布理论解释了神经元如何组成联接，从而形成记忆印痕（英语：engram(neuropsychology)）。赫布理论阐明了细胞集群（Cell Assemblies）的形态和功能：“两个神经元或者神经元系统，如果总是同时兴奋，就会形成一种‘组合’，其中一个神经元的兴奋会促进另一个的兴奋。如果一个神经元持续激活另一个神经元，前者的轴突将会生长出突触小体（如果已有，则会继续长大）和后者的胞体相连接。” 高尔顿·威拉德·奥尔波特根据自联想 (auto-association) 的思路，进一步提出了关于细胞集群的作用，以及它们在形成记忆痕迹中的角色： 如果系统的输入会导致同样的模式重复出现，那么组成这个模式的元素之间的相互关联性将会大大增强。这意味着，其中任何一个元素都会倾向于触发同组的其他元素，同时（以减少权重的方式）抑制组外其他不相关元素。另一个角度来看，这个模式作为一个整体实现了“自联想”。我们可以把一个学习了（自联想）的模式称为记忆痕迹。 通常认为，从整体的角度来看，赫布学习是神经网络形成记忆痕迹的首要基础。 如今，当突触后神经元在突触前神经元之后会很快放电时，突触会变大（或重新形成突触）。和所有的细胞一样，神经元里外有不同的离子浓度，穿过神经元的细胞膜形成电压。当突触前神经元放电时，微小的囊会向突触间隙释放神经递质分子。这会使突触后神经元的膜中的通道打开，让钾离子和钠离子进入，最终会改变通过膜的电压。如果有足够多的突触前神经元一起放电，电压会突然升高，一个动作电位会顺着突触后神经元的轴突而下。这还会使离子通道变得更加灵敏，并出现新的通道，对突触进行加强。就我们的知识所能达到的水平，这就是神经元进行学习的过程。 感知器 感知机是生物神经细胞的简单抽象。神经细胞结构大致可分为：树突、突触、细胞体及轴突。单个神经细胞可被视为一种只有两种状态的机器——激动时为‘是’，而未激动时为‘否’。神经细胞的状态取决于从其它的神经细胞收到的输入信号量，及突触的强度（抑制或加强）。当信号量总和超过了某个阈值时，细胞体就会激动，产生电脉冲。电脉冲沿着轴突并通过突触传递到其它神经元。为了模拟神经细胞行为，与之对应的感知机基础概念被提出，如权量（突触）、偏置（阈值）及激活函数（细胞体）。 在人工神经网络领域中，感知机也被指为单层的人工神经网络，以区别于较复杂的多层感知机（Multilayer Perceptron）。作为一种线性分类器，（单层）感知机可说是最简单的前向人工神经网络形式。尽管结构简单，感知机能够学习并解决相当复杂的问题。感知机主要的本质缺陷是它不能处理线性不可分问题。 在感知器中，一个正权值代表一个兴奋性连接，一个负权值代表一个抑制性连接。如果其输入量的加权和高于界限值，那么会输出 1；如果加权和小于界限值，那么输入 0。通过改变权值和界限值，我们可以改变感知器计算的函数。 输入量的权值越高，相应的突触也会越强。细胞体把所有加权输入量加起来，轴突使结果变成一个阶跃函数。图中代表轴突的框表明了阶跃函数的图像：0 代表输入量的低值，当输入量到达界限值时，会突然变成 1。假设感知器有两个持续输入量 x 和 y（换句话说，x 和 y 可以是任何数值，不仅仅是 0 和 1），那么每个例子都可以由平面上的一个点来表示，而正面例子（例如，感知器中输出量为 1）和负面例子（输出量为 0）之间的界线就是一条直线。 感知器根据所有输入量的权值进行判断，即少数服从多数，通过调整输入量的权值来改进准确性。感知器的缺陷在于感知机不能解决简单的异或（XOR）等线性不可分问题。 S 形曲线 S 形曲线是世界上最重要的曲线。首先输出量随着输入量缓慢增长，如此缓慢，似乎保持不变。接着它开始变化得很快，然后变得更快，之后越来越慢，直到几乎保持不变为止。 S 形曲线是所有种类相变的形状：电子应用领域自旋反转的概率、铁的磁化、将少量记忆写到硬盘上、细胞中离子通道的打开、冰块融化、水蒸发、早期宇宙的膨胀扩张、进化中的间断平衡、科学中的范式转移、新技术的传播、离开多民族社区的白人大迁徙、谣言、流行病、革命、帝国的没落等。 当你没法调好淋浴的温度时（开始水很冷，然后很快又变得很热），都是 S 形曲线的错。你做爆米花时，看看 S 形曲线的进度：一开始什么也没发生，几粒玉米爆开，又有一把爆开，很多玉米突然像烟花一样爆开，更多的玉米爆开，最后你就可以吃爆米花了。你肌肉的每个动作都遵循 S 形曲线：先是缓慢移动，然后快速移动，最后又缓慢移动。 如果放大 S 曲线的中段部位，会发现它近似一条直线。很多我们认为是线性的现象，其实都是 S 形曲线，因为没有什么能够毫无限制地增长下去。辨别一条 S 形曲线就会得到一条钟形曲线：缓慢、快速、缓慢变低、高、低。在 S 形曲线加入一连串向上和向下交错的曲线，你会得到接近正弦波的曲线。实际上，每个函数都可以近似看作 S 形曲线的总和：函数上升时，你加一条 S 形曲线；函数下降时，你减掉一条 S 形曲线。孩子的学习也不是一直都处于进步状态，这个过程是若干个 S 形曲线的累积。技术变革也是如此。 反向传播和梯度下降 反向传播误差误差，通常缩写为「BackProp」，是几种训练人工神经网络的方法之一。这是一种监督学习方法，即通过标记的训练数据来学习（有监督者来引导学习）。 简单说来，BackProp 就像「从错误中学习」。监督者在人工神经网络犯错误时进行纠正。 一个人工神经网络包含多层的节点；输入层，中间隐藏层和输出层。相邻层节点的连接都有配有「权重」。学习的目的是为这些边缘分配正确的权重。通过输入向量，这些权重可以决定输出向量。 在监督学习中，训练集是已标注的。这意味着对于一些给定的输入，我们知道期望 / 期待的输出（标注）。 反向传播算法：最初，所有的边权重（edge weight）都是随机分配的。对于所有训练数据集中的输入，人工神经网络都被激活，并且观察其输出。这些输出会和我们已知的、期望的输出进行比较，误差会「传播」回上一层。该误差会被标注，权重也会被相应的「调整」。该流程重复，直到输出误差低于制定的标准。 上述算法结束后，我们就得到了一个学习过的人工神经网络，该网络被认为是可以接受「新」输入的。该人工神经网络可以说从几个样本（标注数据）和其错误（误差传播）中得到了学习。 反向传播，比感知器算法要强大很多。单个神经元只能够对直线进行学习。给定足够的隐藏神经，一台多层感知器，正如它的名字一样，可以代表任意的复杂边界。这使得反向传播成为联结学派的主算法。 反向传播是自然及技术领域中非常常见的战略实例：如果你着急爬到山顶，那你就得爬能找到的最陡的坡。这在技术上的术语为“梯度上升”（如果你想爬到山顶）或者梯度下降（如果你想走到山谷）。细菌就是通过游向食物（例如葡萄糖）分子浓度高的地方来觅食的；遇到有毒物质，它们则会游向有毒物质浓度低的地方。所有事物，从机翼到天线阵，都可以通过梯度上升来优化。反向传播就是在多层感知器中有效做到这一点的方法：不断对权值进行微调，以降低误差，然后当所有调整失败时，停止调整。 有了反向传播，你就不必从头开始弄明白怎样对每个神经元的权值进行微调，这样做起来会很慢。你可以一层一层来做，根据调整与其相连神经元的方法，来调整每个神经元。如果在突发事件中，除了一件工具，你得把整个机器学习工具包都扔掉，那么梯度下降可能是你想留下的工具。 梯度下降法背后的直观感受可以用假设情境进行说明。一个被卡在山上的人正在试图下山（即试图找到极小值）。大雾使得能见度非常低。因此，下山的道路是看不见的，所以他必须利用局部信息来找到极小值。他可以使用梯度下降法，该方法涉及到察看在他当前位置山的陡峭程度，然后沿着负陡度（即下坡）最大的方向前进。如果他要找到山顶（即极大值）的话，他需要沿着正陡度（即上坡）最大的方向前进。使用此方法，他会最终找到下山的路。不过，要假设山的陡度不能通过简单地观察得到，而需要复杂的工具测量，而这个工具此人恰好有。需要相当长的一段时间用仪器测量山的陡峭度，因此如果他想在日落之前下山，就需要最小化仪器的使用率。问题就在于怎样选取他测量山的陡峭度的频率才不致偏离路线。 在这个类比中，此人代表反相传播算法，而下山路径表示能使误差最小化的权重集合。山的陡度表示误差曲面在该点的斜率。他要前行的方向对应于误差曲面在该点的梯度。用来测量陡峭度的工具是微分（误差曲面的斜率可以通过对平方误差函数在该点求导数计算出来）。他在两次测量之间前行的距离（与测量频率成正比）是算法的学习速率。 多层感知器：非线性模型 前馈神经网络 前馈神经网络是最先发明也是最简单的人工神经网络。它包含了安排在多个层中的多个神经元（节点）。相邻层的节点有连接或者边（edge）。所有的连接都配有权重。 一个前馈神经网络可以包含三种节点： 输入节点（Input Nodes）：输入节点从外部世界提供信息，总称为「输入层」。在输入节点中，不进行任何的计算——仅向隐藏节点传递信息。 隐藏节点（Hidden Nodes）：隐藏节点和外部世界没有直接联系（由此得名）。这些节点进行计算，并将信息从输入节点传递到输出节点。隐藏节点总称为「隐藏层」。尽管一个前馈神经网络只有一个输入层和一个输出层，但网络里可以没有也可以有多个隐藏层。 输出节点（Output Nodes）：输出节点总称为「输出层」，负责计算，并从网络向外部世界传递信息。 在前馈网络中，信息只单向移动——从输入层开始前向移动，然后通过隐藏层（如果有的话），再到输出层。在网络中没有循环或回路（前馈神经网络的这个属性和递归神经网络不同，后者的节点连接构成循环）。 下面是两个前馈神经网络的例子： 单层感知器——这是最简单的前馈神经网络，不包含任何隐藏层。 多层感知器——多层感知器有至少一个隐藏层。 多层感知器（Multilayer Perceptron, 缩写 MLP）是一种前向结构的人工神经网络，映射一组输入向量到一组输出向量。MLP 可以被看作是一个有向图，由多个的节点层所组成，每一层都全连接到下一层。除了输入节点，每个节点都是一个带有非线性激活函数的神经元（或称处理单元）。一种被称为反向传播算法的监督学习方法常被用来训练 MLP。MLP 是感知器的推广，克服了感知器不能对线性不可分数据进行识别的弱点。多层感知器（Multi Layer Perceptron，即 MLP）包括至少一个隐藏层（除了一个输入层和一个输出层以外）。单层感知器只能学习线性函数，而多层感知器也可以学习非线性函数。 联结学派 连接主义学派并不认为人工智能源于数理逻辑，也不认为智能的关键在于思维方式。这一学派把智能建立在神经生理学和认知科学的基础上，强调智能活动是将大量简单的单元通过复杂方式相互连接后并行运行的结果。 基于以上的思路，连接主义学派通过人工构建神经网络的方式来模拟人类智能。它以工程技术手段模拟人脑神经系统的结构和功能，通过大量的非线性并行处理器模拟人脑中众多的神经元，用处理器复杂的连接关系模拟人脑中众多神经元之间的突触行为。相较符号主义学派，连接主义学派显然更看重是智能赖以实现的“硬件”。 参考资料 https://www.jiqizhixin.com/articles/2016-11-25-3 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-02-25-TheMasterAlgorithm6/"},{"title":"『终极算法』摘抄笔记-贝叶斯学派","content":"贝叶斯定理 对于贝叶斯学派来说，学习“仅仅是”贝叶斯定理的另外一个运用，将所有模型当作假设，将数据作为论据：随着你看到的数据越来越多，有些模型会变得越来越有可能性，而有些则相反，直到理想的模型渐渐突出，成为最终的胜者。 假设你半夜在一个陌生的星球上醒来。虽然你能看到的只是繁星闪烁的天空，你有理由相信太阳会在某个时间点升起，因为多数星球会自传并绕着自己的太阳转。所以你估计相应的概率应该会大于 1/2（比如说 2/3）。我们将其称为太阳会升起来的“先验概率”，因为这发生在看到任何证据之前。“先验概率”的基础并不是数过去这个星球上太阳升起的次数，因为过去你没有看到；它反映的是对于将要发生的事情，你优先相信的东西，这建立在你掌握的宇宙常识之上。但现在星星开始渐渐暗淡，所以你对于太阳会升起的信心越来越强，这建立于你在地球上生存的经历之上。你的这种信心源自“后验概率”，因为这个概率是在看到一些证据后得出的。天空开始渐渐变亮，后验概率又变得更大了。 贝叶斯通过以下句子概况了这一点：P（原因｜结果）随着 P（结果），即结果的先验概率（也就是在原因不明的情况下结果出现的概率）的下降而下降。最终，其他条件不变，一个原因是前验的可能性越大，它该成为后验的可能性就越大。综上所述，贝叶斯定理认为：P（原因｜结果）=P（原因）×P（结果｜原因）/ P（结果） 贝叶斯定理之所以有用，是因为通常给定原因后，我们就会知道结果，但我们想知道的是已知结果，如何找出原因。例如，我们知道感冒病人发烧的概率，但真正想知道的是，发烧病人患感冒的概率是多少。 贝叶斯定理作为统计学和机器学习的基础，受到计算难题和巨大争论的困扰。你想知道原因也情有可原：这不就是我们之前在感冒的例子中看到的那样，贝叶斯定理是由条件概率概念得出的直接结果吗？的确，公式本身没有什么问题。争议在于相信贝叶斯定理的人怎么知道推导该定理的各个概率，以及那些概率的含义是什么。对于多数统计学家来说，估算概率的唯一有效方法就是计算相应事件发生的频率。例如，感冒的概率是 0.2，因为被观察的 100 名病人中，有 20 名发烧了。这是“频率论”对于概率的解释，统计学中占据主导地位的学派就是由此来命名的。但请注意，在日出的例子以及拉普拉斯的无差别原则中，我们会做点不一样的事：千方百计找到方法算出概率。到底有什么正当的理由，能够假设太阳升起的概率是 1/2、2/3，或者别的呢？ 然而，贝叶斯学派眼中的概率。概率并非频率，而是一种主观程度上的信任。因此，用概率来做什么由你决定，而贝叶斯推理让你做的事就是：通过新证据来修正你之前相信的东西，得到后来相信的东西（也被称为“转动贝叶斯手柄”）。 所有模型都是错的，但是有些却有用 随着变量的增加，如果有 20 种症状和 1 万个病人就会遇到之前提到过的组合爆照问题。因此我们会做简化的假设来减少概率的数量，这些概率的数量由我们估算而来，且我们可以掌控。一个很简单且受人追捧的假设就是，在给定原因的情况下，所有的结果都相互独立。如果我们想直接估算 P（感冒｜发烧、咳嗽等），假如不利用定理先将其转化成 P（发烧、咳嗽等｜感冒），那么我们就还需要指数数量的概率，每个组合的症状以及感冒或非感冒都有一个概率。 如果学习算法利用贝叶斯定理，且给定原因时，假定结果相互独立，那么该学习算法被称为“朴素贝叶斯分类器”。 统计学家乔治·博克斯说的一句很有名的话：“所有的模型都是错的，但有些却有用。”虽然一个模型过于简化，但你有足够的数据用来估算那就比没有数据的完美模型要好。令人诧异的是，有些模型错误百出，同时又很有用。经济学家弥尔顿·弗里德曼甚至在一篇很有影响力的文章中提出，最有说服力的理论往往受到最大程度的简化，只要这些理论所做的预测是准确的，因为它们用最简洁的方法解释最复杂的问题。 马尔科夫链 1913 年第一次世界大战前夕，俄国数学家安德烈·马尔可夫发表了一篇文章，将所有事情的概率运用到诗歌当中。诗中，他模仿俄国文学的经典：普希金的《尤金·奥涅金》，运用了当今我们所说的“马尔可夫链”。他没有假定每个字母都是随机产生的，与剩下的毫无关联，而是最低限度引入了顺序结构：每个字母出现的概率由在它之前、与它紧接的字母来决定。 例如元音和辅音常常会交替出现，所以如果你看到一个辅音，那么下一个字母（忽略发音和空格）很有可能就是元音，但如果字母之间互相独立，出现元音的可能性就不会那么大。这可能看起来微不足道，但在计算机发明出来之前的年代，这需要花费数小时来数文字，而马尔可夫的观点在当时则很新颖。如果元音 i 是一个布尔型变量，《尤金·奥涅金》的第 i 个字母是元音，则该变量为真，如果它是一个辅音则为假。 源于谷歌的页面排名，本身就是一条马尔可夫链。拉里·佩奇认为，含有许多链接的页面，可能会比只含几个的要重要，而且来自重要页面的链接本身也更有价值。这样就形成了一种无限倒退，但我们可以利用马尔可夫链来掌控这种倒退。想象一下，一个页面搜索用户通过随机点击链接来从这个页面跳到另外一个页面：这时马尔可夫链的状态就不是文字而是页面了，这样问题就变得更为复杂，但数学原理是一样的。那么每个页面的得分就是搜索用户花在该页面上的时间，或者等于他徘徊很久后停留在该页面上的概率。 如果我们测量的不仅仅是元音对辅音的概率，还有字母顺序遵循字母表顺序的概率，利用与《尤金·奥涅金》一样的统计数据，我们可以很愉快地生成新的文本：选择第一个字母，然后在第一个字母的基础上选择第二个字母，以此类推。当然结果是一堆没有意义的数据，但如果我们让每个字母都依照之前的几个字母而不止一个字母，这个过程就开始听起来更像一个酒鬼的疯话，虽然从整体上看没有意义，但从局部上看却很连贯。虽然这还不足以通过图灵测试，但像这样的模型是机器翻译系统的关键组成部分，比如谷歌翻译可以让你看到整版的英文页面（或者几乎整版），不管原页面的语言是什么。 如果某些状态组成一条马尔可夫链，但我们看不到它们，得从观察中将它们推导出来。人们称其为隐藏的马尔可夫模型，或者简称为 HMM（有点误导人，因为被隐藏的是状态，而不是模型）。HMM 和 Siri 一样，处于语音识别系统的中心。在语音识别过程中，隐藏的状态是书面形式的单词，而观察值则是对 Siri 说的声音，而目标则是从声音中推断出单词。模型有两个组成部分：给定当前单词的情况下，下一个单词出现的概率和在马尔可夫链中的一样；在单词被说出来的情况下，听到各种声音的概率。 HMM 还是计算生物学家最为喜爱的工具。一个蛋白质分子是一个氨基酸序列，而 DNA 则是一个碱基序列。举个例子，如果我们想预测一个蛋白质分子怎样才能形成三维形状，我们可以把氨基酸当作观察值，把每个点的褶皱类型当作隐藏状态。同样，我们可以用一个 HMM 来确定 DNA 中基因开始转录的地点，还可以确定其他许多属性。 如果状态和观察值都是连续而非离散变量，那么 HMM 就变成人们熟知的卡尔曼滤波器。经济学家利用卡尔曼滤波器来从数量的时间序列中消除冗余，比如 GDP（国内生产总值）、通货膨胀、失业率。“真正的”GDP 值属于隐藏的状态；在每一个时间点上，真值应该与观察值相似，同时也与之前的真值相似，因为经济很少会突然跳跃式增长。卡尔曼滤波器会交替使用这两者，同时会生成流畅的曲线，仍与观察值一致。 贝叶斯网络：推理问题 **马尔可夫链隐含这样的猜想：考虑到现在，未来会有条件地独立于过去。**此外，HMM 假设每个观察值只依赖于对应的状态。贝叶斯网络对贝叶斯学派来说，就像逻辑与符号学者的关系：一种通用语，可以让我们很好地对各式各样的情形进行编码，然后设计出与这些情形相一致的算法。我们可以把贝叶斯网络想成“生成模型”，即从概率的角度，形成世界状态的方法：首先要决定盗窃案或地震是否会发生，然后在此基础上决定报警器是否会响起，再次在此基础上决定鲍勃和克莱尔是否会打电话。贝叶斯网络讲述这样的故事：A 发生了，接着它导致 B 的发生；同时，C 也发生了，而 B 和 C 共同引起 D 的发生。为了计算特定事件的概率，我们只需将与之相关事件的概率相乘即可。 你身后有几个士兵：假设夜深人静时你正带领排成纵队的一个排，穿过敌人的领地，而你想确认所有士兵仍在跟着你。你可以停下，自己数人数，但那样做会浪费太多时间。一个更聪明的办法就是只问排在你后面的第一个兵：“你后面有几个兵？”每个士兵都会问自己后面的士兵同一个问题，知道最后一个士兵回答“一个也没有。”倒数第二个士兵现在可以说“一个”，以此类推，直到回到第一个士兵，每个士兵都会在后面士兵所报数的基础上加一。现在你知道有多少兵还跟着你，你甚至都不用停下来。 语音识别的方法：Siri 用同样的想法来计算你刚才说的概率，通过它从麦克风中听到的声音来进行“报警”。把“Call the police”（报警）想成一排单词，正以纵队形式在页面上行走，“police”想知道它的概率，但要做到这一点，它需要知道“the”的概率；“the”回过头要知道“call”的概率。所以“call”计算它的概率，然后将其传递给“the”，“the”重复步骤并将概率传递给“police”。现在“police”知道它的概率了，这个概率受到句子中每个词语的适当影响，但我们绝不必建立 8 个概率的完整表格（第一个单词是否为“call”，第二个是否为“the”，第三个是否为“police”）。实际上，Siri 考虑在每个位置中出现的所有单词，而不仅仅是第一个单词是否为“call”等，但算法是一样的。也许 Siri 认为，在声音的基础上，第一个单词不是“call”就是“tell”，第二个不是“the”就是“her”，第三个不是“police”就是“please”。个别地，也许最有可能的单词是“call”、“the”和“please”。但那样会变成一句没有意义的话“Call the please”，所以要考虑其他单词，Siri 得出结论，认为句子就是“Call the police”。 然而，最受人青睐的选择就是借酒浇愁，喝得酩酊大醉，然后整夜都在跌跌撞撞。该选择的技术术语为“马尔可夫链蒙特卡洛理论”（Markov chain Monte Carlo，MCMC）：有“蒙特卡洛”这个部分，是因为这个方法涉及机遇，比如到同名的赌场去，有“马尔可夫链”部分，是因为它涉及采取一系列措施，每个措施只能依赖于前一个措施。MCMC 中的思想就是随便走走，就像众所周知的醉汉那样，以这样的方式从网络的这个状态跳到另一个状态。这样长期下来，每个状态受访的次数就与它的概率成正比。人们在谈论 MCMC 时，往往把它当作一种模拟，但它其实不是：马尔可夫链不会模仿任何真实的程序，我们将其创造出来，目的是为了从贝叶斯网络中有效生成样本，因为贝叶斯网络本身就不是序变模式。 对于贝叶斯学派来说，知识越过模型的结构和参数，进入先验分布中。原则上，之前的参数可以是任意我们喜欢的值，但讽刺的是，贝叶斯学派趋向于选择信息量不足的先验假设（比如将相同概率分配给所有假设），因为这样更易于计算。在任何情况下，人类都不是很擅长估算概率。对于结构这方面，贝叶斯网络提供直观的方法来整合知识：如果你认为 A 直接引起 B，那么应把箭头从 A 指向 B。 在生物信息中，贝叶斯学习能对单个数据表起作用，表中的每列表示一个变量（例如，一个基因的表达水平），而每行表示一个实例（例如，一个微阵列实验，包含每个基因被观察到的水平）。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-02-25-TheMasterAlgorithm5/"},{"title":"『终极算法』摘抄笔记-符号学派","content":"理性主义和经验主义 理性主义者认为，感官会欺骗人，而逻辑推理是通往知识的唯一可靠的道路。经验主义者认为所有推理都是不可靠的，知识必须来源于观察及实验。理性主义者喜欢在迈出第一步前，就提前规划好一切。经验主义者喜欢尝试新事物，然后看看结果会怎样。 柏拉图是早期的理性主义者，而亚里士多德是早期的经验主义者。关于这个问题的辩论，真正开始于启蒙运动时期，每方有三位伟大的思想家：笛卡儿、斯宾诺莎、莱布尼茨是理性主义的代表，洛克、贝克莱、休谟则是经验主义的代表。 休谟提出过一个非常爆炸性的问题：在概括我们见过的东西以及没见过的东西时，怎样才能做到合理？从某种意义上说，每种学习算法都在尝试回答这个问题。在这个问题提出 250 年之后，大卫沃尔伯特提出了“没有免费的午餐”定理，规定了怎样才是最好的学习算法，最直白的答案就是没有那个学习算法可以比得上随意猜测。 没有免费的午餐理论 (No free lunch theorem, NFL) 没有算法能完美地解决所有问题。当所有问题出现的机会相同，或所有问题同等重要时，不管算法 A 有多好，泛化能力多强，算法 A 有多笨拙，这两个算法的期望值是相同的，换言之，这两个算法的性能可能差不多，甚至，一个最优算法可能和一个胡乱猜想的算法性能相似。 数学家认为机器学习这个问题是一个不适定问题（ill–posed problem）：这个问题没有唯一解。下面是一个简单的不适定问题：哪两个数相加的得数是 1000？假设这两个数都是正数，答案就有 500 种……1 和 999，2 和 998 等等。解决不适定问题的唯一办法就是引入附加假设。如果要求第二个数是第一个数的三倍，那么答案就是 250 和 750。因此，在机器学习的问题中引入预设观念是必不可少的，没有观念就无法进行学习。事实上，预设观念对于人类认识社会也是必要的。 适定问题 (well-posed problem): 适定问题是指定解满足下面三个要求的问题：解是存在的；解是唯一的；解连续依赖于定解条件，即解是稳定的。这三个要求中，只要有一个不满足，则称之为不适定问题。 预设的重要性 Four Rules of Scientific Reasoning from Principia Mathematica We are to admit no more causes of natural things than such as are both true and sufficient to explain their appearances. Therefore to the same natural effects we must, as far as possible, assign the same causes. The qualities of bodies, which admit neither intensification nor remission of degrees, and which are found to belong to all bodies within the reach of our experiments, are to be esteemed the universal qualities of all bodies whatsoever. In experimental philosophy we are to look upon propositions inferred by general induction from phenomena as accurately or very nearly true, not withstanding any contrary hypothesis that may be imagined, till such time as other phenomena occur, by which they may either be made more accurate, or liable to exceptions 牛顿法则 规则 1：没有什么比既真实又足以解释其现象者更能说明自然事物的原因。 规则 2：对于相同的自然现象，我们必须尽可能地找到相同的原因。 规则 3：事物的属性，如果其程度不能增加或减少，且在我们的实验所及范围之内为所有物体所有，则应视其为所有事物的普遍属性。 规则 4：在实验哲学中，我们认为由现象所总体归纳出的命题是准确的或是基本正确的，而不管任何反面假设，直到出现了其他可以使之更精确，或是可以推翻这些命题之时。 牛顿法则的第四条（我们见过的所有东西在宇宙中也是真实的）是机器学习的第一个不成文规则。我们归纳自己能力范围内、应用最广泛的规则，只有在数据的迫使下，才缩小规则的应用范围。 简单总结即首先做有条件的假设，如果这样无法解释数据，再放松假设的条件，这就是典型的机器学习。这个过程通常由算法自行进行，不需要你的帮助。首先，算法会尝试所有单一因素，然后尝试所有两个因素的组合，之后就是所有三个因素的组合等。但是这种方法有一个问题，如何合取的概念太多，我们就没有足够的时间逐个进行尝试。 以在线约会匹配为例，另一种思路是，暂且假设每个配对都合适，然后排除所有不含有某品质的搭配，对每种品质重复同样的做法，然后选择那个排除了最多不当搭配和最少适当搭配的选项。 现在你的定义看起来就像“只有他开朗，这对才合适”。现在反过来试着把其他品质加进去，然后选择那个排除了剩下最多的不当搭配和剩下最少的适当搭配的选项。现在的定义可能是“只有他和她都开朗，这对才合适”。然后试着往那两个特点里加入第三个品质，以此类推。一旦排除了所有不合适的搭配，你就成功了：就有了这个概念的定义，这个概念排除了所有的正面例子和所有的负面例子。例如，“每对中的两个人都开朗，这对才合适，他爱狗，而她不爱猫”。现在你可以丢掉所有数据，然后只把这个定义留下，因为这个定义概括了所有和你的目标相关的东西。这个算法保证能在合理的时间内完成运算，而这也是我们在本书中见过的第一个真实的学习算法。 过拟合的问题 每当算法在数据中找到现实世界中不存在的模型时，我们说它与数据过于拟合。过拟合问题是机器学习中的中心问题。在所有主题中，关于过拟合问题的论文最多。每个强大的学习算法，无论是符号学算法、联结学算法，或者其他别的学习算法，都不得不担忧幻觉模式这个问题。避免幻觉模式唯一安全的方法，就是严格限制算法学习的内容，例如要求学习内容是一个简短的合取概念。但是这种做法又会出现把“孩子和洗澡水一起倒掉的问题”。 其实在现实生活中，过拟合的问题无处不再。例如白人小孩看到拉美裔的小孩会脱口而出女佣。学习算法因为拥有从数据中发现模型近乎无限制的能力，因此非常容易过拟合。 约翰·冯·诺依曼曾说过：“用 4 个参数，我能拟合一头大象；用 5 个参数，我可以让它的鼻子扭动起来。”当今我们通常会学习拥有数百万参数的模型，这些参数足以让世界上的每头大象都扭动鼻子。甚至曾有人说过，数据挖掘意味着“折磨数据，直到数据妥协”。 组合爆炸的组合爆炸 假设的数量会随着属性的增多而呈指数级增长。在机器学习中，一个概念可能实例的数量，是其属性数量的指数函数：如果属性是布尔值，每种新的属性可能会是实例数量的两倍，方法就是引用之前的每个实例，然后为了那个新属性，对该实例以“是”或“非”来进行扩展。反过来，可能概念的数量是可能实例数量的指数函数：既然每个概念都把实例分成正面或者负面，加入一个实例，可能的概念就会翻倍。因此，概念的数量就是属性数量的指数函数的一个指数函数！换句话说，机器学习就是组合爆炸的组合爆炸。 **学习就是你拥有的数据的数量和你所做假设数量之间的较量。**更多的数据会呈指数级地减少能够成立的假设数量，但如果一开始就做很多假设，最后你可能还会留下一些无法成立的假设。 信任的准确度 在机器学习中，我们可以利用自己拥有的数据，将其分成一个训练集和一个测试集，然后前者交给学习算法，把后者隐藏起来不让学习算法发现，用来验证其准确度。留存数据的准确度就是机器学习中的“黄金标准”。对不可见数据的测试是判断学习算法是否过拟合的唯一方法。 避免过拟合的方法就是运用统计显著性检验来确保我们看到的模型真实可靠。例如，拥有 300 个正面例子、100 个反面例子的规则，和拥有 3 个正面例子、1 个负面例子的规则一样，它们训练数据的准确率都达到 75%，但第一个规则几乎可以肯定比抛硬币好用，而第二个则不然，因为抛 4 次硬币，可以很容易得出 3 次正面朝上。在构建规则时，如果某一时刻无法找到能提高该规则准确度的条件，那么我们只能停下，即便它还包括一些负面例子。这样做会降低规则的训练集准确度，也可能让它变成一个更能准确概括的规则。 显著性检验是决定一项研究结果是否值得出版的“黄金标准”，为了降低假阳性的可能，我们一方面可以否定低显著性的假设进而对剩下的假设做进一步的数据检测。另一种方法则是选择更加简单的假设，比如稍微降低规则的准确度，来缩短规则的长度。 对较简单假设的偏好就是众人皆知的奥卡姆剃刀原理（Ocam’s razor），但在机器学习背景下，这有点误导性。“如无必要，勿增实体”，因为剃刀常常会被替换，仅意味着挑选能够拟合数据的最简原理。奥卡姆可能对这样的想法感到迷惑，也就是我们会偏向那些不那么能完整解释论据的理论，因为这个理论的概括性更好。简单的理论更受欢迎，因为它们对于我们来说，花费的认知成本更低；对于我们的算法来说，花费的计算成本更低，这不是因为我们想让这些理论更准确。 当准确度不尽如人意时，我们需要分析原因。在机器学习中，即分析“偏差”和“方差”。某座钟如果总是慢一个小时，那么它的偏差会很高，但方差会很低。但如果这座钟走得时快时慢，最后平均下来准点了，那么它的方差会很高，但偏差会很低。 在掌握训练集的随机变量之后对算法的预测进行对比。如果算法一直出错，那么问题就出在偏差上，则需要一个更为灵活的学习算法（或者只和原来的不一样即可）。如果出现的错误无模式可循，问题就出在方差上，要么尝试一种不那么灵活的学习算法，要么获取更多的数据。大多数学习算法都有一个“把手”，通过旋转“把手”，你可以调节这些算法的灵活度，例如，显著性检验的界限值，或者对于模型规模的惩罚方式。扭动“把手”是你尝试的第一个方法。 归纳是逆向的演绎 对于每个事实，我们构建这样的规则，让我们由第一个事实推出第二个事实，然后通过牛顿定律将其推广。当同一条通用规则一次又一次被归纳出来时，我们有信心说那条规则说的是真的。 逆向演绎的一个局限性就在于，它涉及很密集的计算，因此很难扩展到海量数据集中。因为这些原因，符号学家选择的算法是决策树归纳。决策树可以当作此类问题的答案：如果有多个概念的规则对应一个实例，那怎么办？那么我们怎么知道实例对应哪个概念呢？ 答案是让规则自己选择。决策树通常会保证，每个实例会准确对应一条规则。也就是说，在一次及以上的属性测试中，如果每对规则存在区别，这样的规则集将被组织成一棵决策树。对于决策树而言，你无法选择其中的两种或三种，或者一个都不选。拥有这个属性的概念组被称为类集，而预测类集的算法称为分类器。单个概念隐含两类定义：概念本身及其反面（例如，垃圾邮件和非垃圾邮件）。分类器是机器学习最为普遍的方式。 针对如何选择决策树最佳属性的问题，可以考虑信息论中熵的概念。**一组对象的熵，就是用来衡量混乱度的单位。**如果 150 人的组里面有 50 个共和党人、50 个民主党人、50 个独立人士，那么这个组的政治熵会达到最大。另一方面，如果这个组全部是共和党人，那么熵就变成零（这就是党派联合的目的）。所以为了学习一棵好的决策树的优点，我们在每个节点选择这样的属性：在其所有分支中，产生的熵在平均值上属性最低，取决于每个分支上有多少例子。 符号学派 因为其起源和指导原则，符号学派和其他学派相比和人工智能的其他方面关系更为密切。如果计算机科学是一块大陆，符号主义机器学习和知识工程学会有很长的交界线。知识通过两个方向进行交易——手动输入的知识，供学习算法使用；还有归纳得出的知识，用来加入知识库中，但最终理性主义者和经验主义者的断层线会刚好落在这条界线上，想越过这条界线则不容易。 符号主义是通往终极算法的最短路程。它不要求我们弄明白进化论和大脑的工作原理，而且也避免了贝叶斯主义的数学复杂性。规则集合决策树易于理解，所以我们知道学习算法要做什么。这样它可以轻易算出自己做对或做错什么，找出故障，得出准确结果。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-02-17-TheMasterAlgorithm4/"},{"title":"『终极算法』摘抄笔记-五大算法概述","content":"符号学派 所有的信息都可以简化为操作符号，就像数学家那样，为了解方程，会用其他表达式来代替本来的表达式。符号学者明白你不能从零开始学习：除了数据，你还需要一些原始的知识。他们已经弄明白如何把先前存在的知识并入学习中，如何结合动态的知识来解决新问题。他们的主算法是逆向演绎，逆向演绎致力于弄明白为了使演绎进展顺利哪些知识被省略了，然后弄明白是什么让主算法变得越来越综合。 连结学派 学习就是大脑所做的事情，因此我们要做的就是对大脑进行逆向演绎。大脑通过调整神经元之间连接的强度来进行学习，关键问题是找到哪些连接导致了误差，以及如何纠正这些误差。联结学派的主算法是反向传播学习算法，该算法将系统的输出与想要的结果相比较，然后连续一层一层地改变神经元之间的连接，目的是为了使输出的东西接近想要的东西。 进化主义学派 进化学派认为，所有形式的学习都源于自然选择。如果自然选择造就我们，那么它就可以造就一切，我们要做的，就是在计算机上对它进行模仿。进化主义解决的关键问题是学习结构：不只是像反向传播那样调整参数，它还创造大脑，用来对参数进行微调。进化学派的主算法是基因编程，和自然使有机体交配和进化那样，基因编程也对计算机程序进行配对和提升。 贝叶斯学派 贝叶斯学派最关注的问题是不确定性。所有掌握的知识都有不确定性，而且学习知识的过程也是一种不确定的推理形式。那么问题就变成，在不破坏信息的情况下，如何处理嘈杂、不完整甚至自相矛盾的信息。解决的办法就是运用概率推理，而主算法就是贝叶斯定理及其衍生定理。贝叶斯定理告诉我们，如何将新的证据并入我们的信仰中，而概率推理算法尽可能有效地做到这一点。 类推学派 对于类推学派来说，学习的关键就是要在不同场景中认识到相似性，然后由此推导出其他相似性。如果两个病人有相似的症状，那么也许他们患有相同的疾病。问题的关键是，如何判断两个事物的相似程度。类推学派的主算法是支持向量机，主算法找出要记忆的经历，以及弄明白如何将这些经历结合起来，用来做新的预测。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-02-17-TheMasterAlgorithm3/"},{"title":"『终极算法』摘抄笔记-算法和机器学习概述","content":"什么是算法 算法就是一系列指令，告诉计算机该做什么。计算机是由几十亿个微小开关（称为晶体管）组成的，而算法能在一秒内打开并关闭这些开关几十亿次。 最简单的算法是触动开关。一个晶体管的状态就是一个比特信息：如果开关打开，信息就是 1；如果开关关闭，信息就是 0。 第二简单的算法是：把两个比特结合起来。克劳德·香农以“信息论之父”而为人所知，他第一个意识到晶体管的活动就是在运算，因为晶体管开了又关，是对其他晶体管的回应。 如果 A 晶体管只有在 B 和 C 晶体管都打开时才打开，那么这时它就是在做小型的逻辑运算。如果 A 晶体管在 B 和 C 晶体管其中一个打开时才打开，就是另外一种小型逻辑运算。如果 A 晶体管在 B 晶体管任何关闭的时候打开，或者反过来，这又是第三种运算。所有算法，无论多复杂，都能分解为这三种逻辑运算：且，或，非。 一种算法不仅是简单的一套指令，这些指令必须精确且不能模糊，这样计算机才能够执行。我们平时用到的菜谱就不能称之为算法。 算法是一套严格的标准。人们常说，你没法真正了解某样东西，直到你能用一种算法来将其表达出来（理查德·费曼曾说，“如果我无法创造某样东西，那么也就无法理解它”）。 设计算法这个过程充满陷阱，什么事都不能想当然。如果你的一些构建已经出错，就得找其他方法。设计算法最重要的一点就是用一种计算机能理解的语言来将算法记录下来，接下来对其进行纠错：找出每个误差并修正，直到计算机能够运行程序。 算法复杂性的三个层面 空间复杂性 即为了储存在计算机内存中，一个算法所需信息的比特数量。如果计算机无法提供该算法所需的内存，那么这个算法就没用，必须忽略。 时间复杂性 该算法运行多长时间，也就是说，在产生想要的结果之前，算法利用及重新利用晶体管的步骤有多少。如果算法运行时间太久，我们等不了，那么这个算法也没用。 人类的复杂性 当算法变得很复杂以致人类大脑已无法理解，当算法不同部分的交互过多且过于深入时，误差就会悄然潜入。我们找不到这些误差，也就无法纠正它们，算法也就不会做我们想做的事。即便我们让它运行起来，它也会停下来。对使用它的人来说，它没必要那么复杂，而且它和其他算法也合作得不好，这为日后埋下隐患。 初步理解机器学习 今天为止，人们能编写许多计算机无法学习的程序。可令人更为惊讶的是，计算机却能学习人们无法编写出来的程序。 我们会开车、会辨认字迹，但这些技能都是潜意识发挥出来的，无法向计算机解释这些事情是如何完成的。但是，如果我们把关于这些事情的足够多的例子交给学习算法，该算法会很乐意弄明白怎样独立完成这些事情，这时我们就可以放手让算法去做了。 **学习算法是种子，数据是土壤，被掌握的程序是成熟的作物。**机器学习专家就像农民，播下种子，灌溉，施肥，留意作物的生长状况，事事亲力亲为，而不是退居一旁。 一旦我们这样看待机器学习，随即也会发生两件事。 我们掌握的数据越多，我们能学的也越多。没有数据什么也学不到。有了大数据很多东西可以学习。这也是机器学习无处不在的原因，因为有飞速增长的数据。 机器学习是一把剑，利用这把剑可以解决多种复杂性问题。只要有足够的数据，一段只有几百行代码的程序可以轻易生成拥有上百万行代码的程序，而且它可以为解决不同问题不停产生不同的程序。这可以显著降低程序员工作的复杂度。 学习算法的区别和地位 有些学习算法学习知识，有的则学习技能。例如：“所有人都会死”是知识，骑单车是技能。 在机器学习中，知识往往以统计模型的形式出现，因为多数知识都是可以统计的：所有人都会死，但只有 4%是美国人。技能往往以程序的形式出现：如果马路向左弯曲，那么向左转动车头；如果一只鹿跳到你面前，那么立刻刹车。 通常，这些程序都很简单，复杂的是它们的核心知识。如果你能判断哪些邮件是垃圾邮件，那么你也就能判断该删除哪些邮件。如果你能在象棋游戏中判断这盘棋自己的优势在哪里，那么你也就懂得该怎么走。 在信息处理这个生态系统中，学习算法是顶级掠食者。数据库、网络爬虫、索引器等相当于食草动物，耐心地对无限领域中的数据进行蚕食。统计算法、线上分析处理等则相当于食肉动物。 食草动物有必要存在，因为没有它们，其他动物无法存活，但顶级掠食者有更为刺激的生活。数据爬虫就像一头牛，网页相当于它的草原，每个网页就是一根草。当网络爬虫进行破坏行动时，网站的副本就会保存在其硬盘当中。索引器接着做一个页面的列表，每个词都会出现在页面当中，这很像一本书后的索引。数据库就像大象，又大又重，永远不会被忽略。在这些动物当中，耐心的野兽飞快运转统计和分析算法，压缩并进行选择，将数据变为信息。学习算法将这些信息吞下、消化，然后将其变成知识。 算法在科学研究中的作用 机器学习是“打了类固醇”的科学方法，也遵循同样的过程：产生假设、验证、放弃或完善。 科学家可能会花费毕生精力来提出或验证几百个假设，而机器学习系统却能在一秒钟内做完这些事。机器学习使科学的发现过程自动化。这既是商业领域的革命，也是科学领域的革命。 有了大数据和机器学习，你就能弄明白比之前复杂很多的现象。在多数领域，科学家一般只使用种类很有限的模型，例如线性回归模型，在这个模型当中，你用来适应数据的曲线总是一条直线。遗憾的是，世界上的大多数现象都是非线性的（或者说这也是一件幸事，如果是线性的，生活会变得非常乏味。实际上，那样就不会存在生命了）。 机器学习打开了广阔、全新的非线性模型世界。这就好比在只有几缕月光照射的房间，打开了明亮的灯。在生物学领域，学习算法的研究成果包括：DNA 分子中基因的位置；在蛋白质合成前，多余的核糖核酸在哪里进行绞接；蛋白质如何折叠成各自的特有形状；不同条件如何对基因的表达造成影响。用不着在实验室对新药进行测试，机器学习就可以预测这些药物是否有效，只有最有效的药品才会受到测试。学习算法还会剔除那些可能产生严重副作用（甚至导致癌症）的药物，备选药物无须在经过人体试验被证明无效后才被禁止使用，从而避免了代价昂贵的失败。 算法如何影响选举 奥巴马总统雇用了拉伊德·贾尼（机器学习专家，他是奥巴马竞选中的首席科学家）。贾尼研究的是如何整合最伟大的分析运算，并将其应用到政治史中。他们将所有选民的信息整合成单个数据库，然后将该数据库和他们能在社交网络、市场营销等领域找到的资源结合起来。 之后着手对每个选民做四种预测： 支持奥巴马的可能性有多大 会不会参加民意调查 会不会回应竞选宣传并照做 对特定问题进行对话之后，他们会不会改变选举决定。 基于这些选民的例子，奥巴马团队每个晚上进行 66 000 场选举模拟，并用这些结果指导奥巴马竞选的志愿者大军：该给谁打电话，该拜访谁，该说什么。 机器学习的终极影响 2011 年，“大数据”的概念流行起来，机器学习被明确归入全球经济未来的中心。当今，似乎没有哪个人类钻研的领域不受到机器学习的影响，甚至包括看起来没有多大关系的领域（如音乐、体育、品酒）。尽管机器学习发展很明显，但这也仅仅是未来的预告。虽然它有用，但实际上当今在工业上起作用的学习算法的生成还是受到了很大限制。如果现在实验室的算法能在各领域的前线使用，比尔·盖茨说机器学习的突破产生的价值将相当于 10 家微软，其实这个说法有点保守了。如果这些观点让研究人员真正觉得眼前一片光明，而且收到效果，那么机器学习带来的就不仅仅是新的文明时代，还是地球生命进化的新阶段。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-02-17-TheMasterAlgorithm2/"},{"title":"『终极算法』摘抄笔记-是否存在终极算法","content":"## 同样的算法做不同的事情 朴素贝叶斯算法是一个可以用短方程来表达的学习算法。只要提供患者病历的数据库，包括病人症状、检查结果，或者他们是否有什么特殊情况，朴素贝叶斯算法就可在一秒之内做出诊断，而且往往比那些花几年在医学院学习的医生还要强。该算法还可应用于学习垃圾邮件过滤器，乍一看这和医疗诊断毫无关系。 最近邻算法的用途十分广泛，从笔迹识别到控制机器人手，以及推荐你可能喜欢的书籍或者电影。 决策树学习算法也同样擅长决定你的信用卡申请是否应被通过、寻找 DNA 中的绞接点，以及下棋时指导下一步该怎么走。 在机器学习领域，如果提供适当的数据来让机器学习，那么相同的算法既可以处理信用卡申请，也可以下棋。实际上大量的机器学习应用仅仅由几个算法来负责。 是否存在终极算法 终极算法假设：所有知识，无论是过去的、现在的还是未来的，都有可能通过单个通用学习算法来从数据中获得。 有没有这种算法，可以接收任何数据及假设并输出隐藏其中的知识？当然，我们得限制假设的可能性，否则如果把整个目标知识都以假设形式赋予算法，那就是在作弊。我们可以通过限制输入的规模、要求假设弱于当前学习算法等方法，来实现这个目的。 神经学科的证据 大脑负责我们能感知以及想象的一切。如果某物存在，但大脑无法对其进行学习，那么我们就不知道它的存在。我们可能只是没看见它，或者认为它是随机出现的。 不管怎样，如果将大脑放入计算机中运行，那个算法就能掌握我们能学会的一切。因此发明终极算法的一种途径（可以说是最流行的一种）就是对人脑进行逆向解析。 进化学科的证据 生物多样性源于自然选择机制。而计算机科学家对该机制非常熟悉：我们通过反复研究尝试许多备选方法来解决问题，选择并改进最优方案，并尽可能多地尝试这些步骤。进化论是一种算法。上帝创造的不是物种，而是创造物种的算法。 利用足够多的数据，一种简单的算法能掌握什么？关于这个问题最经典的例子就是进化论。输入进化论这个算法的信息是所有存在过的、活着的生物的经历以及命运（对现在的算法来说是大数据）。这个进化论算法已经在地球上最强大的计算机运行了 300 多万年——这台强大的计算机就是地球自己。 物理学科的证据 在物理学中，适用于不同数量的方程往往可以用来描述发生在不同领域的现象，例如量子力学、电磁学、流体动力学。波动方程、扩散方程、泊松方程表明：一旦我们在某个领域发现它们，也很快能在其他领域发现它们；一旦我们在某个领域懂得解开它们，也能在所有领域将它们解开。 此外，所有这些方程都很简单，涉及几个和空间、时间有关的数量的相同导数。很容易想象，它们都是主方程的几个例子，而终极算法要做的，就是用不同的数据集来将它实例化。 统计学的证据 根据一个统计学流派的观点，所有形式的学习都是基于一个简单的公式——贝叶斯定理。贝叶斯定理会告诉我们每当看到新的证据后，如何更新已有的想法。一种简单的贝叶斯学习算法对世界进行一系列假设，由此开始进行学习。当它看到新的数据时，与该数据匹配的假设更有可能会成立（或者不可能成立）。 贝叶斯定理就是将数据变成知识的机器。据贝叶斯统计学派的观点，贝叶斯定理是将数据变成知识的唯一正确方法。如果该学派的观点正确，贝叶斯定理要么就是终极算法，要么就是推动终极算法发展的动力。 计算机科学的证据 在计算机科学中，P 和 NP 是两类最重要的问题。如果我们能有效解决它，那么这个问题就属于 P；如果我们能有效找到其解决方案，那么这个问题属于 NP。著名的 P=NP 的问题就是，能有效找到的问题是否可以得到有效解决。因为 NP 完全问题，回答这个问题需要的只是证明某个 NP 完全问题可被有效解决（或者无法被有效解决）。 关于什么是 P 问题，NP 问题和 NPC 问题这里做一点补充。 首先，解释一下时间复杂度的概念。时间复杂度并不是表示一个程序解决问题需要花多少时间，而是当问题规模扩大后，程序需要的时间长度增长得有多快。即对于高速处理数据的计算机来说，处理某一个特定数据的效率不能衡量一个程序的好坏，而应该看当这个数据的规模变大到数百倍后，程序运行时间是否还是一样，或者也跟着慢了数百倍，或者变慢了数万倍。 不管数据多大，程序处理花的时间始终不变，即具有 O(1) 的时间复杂度，也称常数级复杂度；数据规模变得有多大，花的时间也跟着变得有多长，这个程序的时间复杂度就是 O(n)，比如找 n 个数中的最大值；而像冒泡排序、插入排序等，数据扩大 2 倍，时间变慢 4 倍的，属于 O(n^ 2) 的复杂度。还有一些穷举类的算法，所需时间长度成几何阶数上涨，这就是 O(a^ n) 的指数级复杂度，甚至 O(n!) 的阶乘级复杂度。 时间复杂度可以分为两个级别。一种是 O(1),O(log(n)),O(n^ a) 等，我们把它叫做多项式级的复杂度，因为它的规模 n 出现在底数的位置；另一种是 O(a^ n) 和 O(n!) 型复杂度，它是非多项式级的，其复杂度计算机往往不能承受。当我们在解决一个问题时，我们选择的算法通常都需要是多项式级的复杂度，非多项式级的复杂度需要的时间太多，往往会超时，除非是数据规模非常小。 P 类问题的概念：如果一个问题可以找到一个能在多项式的时间里解决它的算法，那么这个问题就属于 P 问题。 NP 问题是指可以在多项式的时间里验证一个解的问题。NP 问题的另一个定义是，可以在多项式的时间里猜出一个解的问题。 例如在需要枚举时，我们可以首先进行猜测。求最短路径的问题中问从起点到终点是否有一条小于 100 个单位长度的路线。 我们可以随便画几条线说就是它了，只要我们人品好，计算之后路径长度 98，比 100 小。于是答案出来了，存在比 100 小的路径。 至于这道题是怎么做出来的，就是因为我们找到了一个比 100 小的解。在这个题中找一个解很困难，但验证一个解很容易。验证一个解只需要 O(n) 的时间复杂度，也就是说我可以花 O(n) 的时间把我猜的路径的长度加出来。只要猜的好就一定能在多项式的时间里解决这个问题。猜到的方案总是最优的，不满足题意的方案也不会来骗我去选它。这就是 NP 问题。 接下来是 NPC 问题，即存在这样一个 NP 问题，所有的 NP 问题都可以约化成它。换句话说，只要解决了这个问题，那么所有的 NP 问题都解决了。这种问题的存在难以置信，并且更加不可思议的是，这种问题不只一个，它有很多个，它是一类问题。这一类问题就是传说中的 NPC 问题，也就是 NP-完全问题。NPC 问题的出现使整个 NP 问题的研究得到了飞跃式的发展。 NPC 问题的定义非常简单。同时满足下面两个条件的问题就是 NPC 问题。首先，它得是一个 NP 问题；然后，所有的 NP 问题都可以约化到它。证明一个问题是 NPC 问题也很简单。先证明它至少是一个 NP 问题，再证明其中一个已知的 NPC 问题能约化到它。 弄明白蛋白质如何折叠成特定形状；通过 DNA 来重新构建一系列物种的进化史；在命题逻辑中证明定理；利用交易成本来发现市场中的套利机会；按照给定回报率找出最安全的投资组合、到达几个城市的捷径、微芯片上元件的最佳布局方案、生态系统中传感器的最佳布局、自旋玻璃门最低的能量状态；安排好航班、课程、工厂工作；最优化资源分配、城市交通流、社会福利，以及提高你的俄罗斯方块分数。这些都属于 NP 完全问题。 NP 完全问题，意思是如果你能有效解决其中一个问题，就能有效解决所有 NP 类问题，包括相互间的问题。谁会猜到，这些表面上看起来迥然不同的问题，会是同一个问题？如果它们真的是同一个问题，就可以说一种算法能学会解决所有问题（或更准确地说，所有能有效解决的例子）。 后续 我们寻找终极算法的过程是复杂且活跃的，因为在机器学习领域存在不同思想的学派，主要学派包括符号学派、联结学派、进化学派、贝叶斯学派、类推学派。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-02-17-TheMasterAlgorithm1/"},{"title":"贯穿你我一生的基因之谜","content":"无处不在的基因 选一个心情不错的时间，打开手中叫做「唾液采集器」的小管子吐进一些唾液，再把它寄给一家公司。几天后你就会收到一份复杂而详细的报告，这份报告里将记录你和上百项健康风险、几十项遗传性疾病是否有关，甚至还会帮你寻根溯源，告诉你有多少少数民族或东南亚的祖先。 没错，得到这些结果需要的仅仅是你那 1ml 唾液加上口袋里的两三百块钱，而这项业务就是近两年国内愈发火爆的「消费级基因检测」。目前来看，基因检测似乎是帮你从根源上判断自己是否属于一个「少数派」略显极客的不错选择。 2017 年 12 月 28 日，我国正式启动为期四年的「中国十万人基因组计划」，这是我国在人类基因组研究领域实施的首个国字号项目。在这之前，美国于 2016 年开始自己的精准医疗计划（Precision Medicine Initiative），其中有 1.3 亿美元预算用作 百万基因组计划 。如果再向前追溯，英国早在 2012 年就启动了 10 万人基因组项目 。 如果你是一个非常关注自我健康或者对新技术保持敏感的人，应该对上述基因检测的场景并不陌生或者它已经真切地在你身上发生过；如果你是一个爱看财经和科技新闻的人，国际诸如 23andMe 、国内诸如华大基因、贝瑞合康这类已经进入 A 股的基因产业相关公司也会时不时霸占你的头条。即便你不在上述两类人之列，每天只「关心粮食和蔬菜，希望面朝大海春暖花开」，也一定逃不掉转基因这个话题。 无论是基因检测（包括无创产前检测）、精准医疗还是转基因，其中的根本都是基因以及基因如何改变我们和我们的生活。「21 实际是生命科学的世纪」这句话一方面让无数学子走入生物「坑」，成为这一领域内大家自黑的标配；但是另一方面从目前的发展趋势来看似乎也不无道理，毕竟人们吃饱穿暖之后自然会更加关注疾病健康这些生命科学领域的主要问题。 作为一名生物信息学专业在读博士，我的日常工作都在和基因打交道，从收到的各种基因相关问题来看，也可以感受到很多人对于基因（以及背后生命科学）的兴趣愈发浓厚。的确，对于非本行业的从业者或者对生命科学不甚了解的普通人而言，面对这一波基因产业热潮和身边越来越多的基因相关产品，了解基因的发展历史和相关基础知识十分必要。 此刻，如果有一本优秀的科普通识读物能够带你由浅入深的了解和理解一个学科（行业），那无疑是幸运和幸福的。《基因传：众生之源》就是这样一本书。 不一样的科普读物 《基因传：众生之源》（The Gene: An Intimate History）的作者是印度裔美国肿瘤专家悉达多·穆克吉（Siddhartha Mukherjee），毕业于斯坦福大学并在哈佛取得博士学位。而他更为人所知的身份是一位科普作家，曾凭借《重病之王：癌症传》（The Emperor of All Maladies: A Biography of Cancer）获得 2011 年普利策文学奖。《基因传：众生之源》英文原版于 2016 年出版，一经出版就获得了《华盛顿邮报》十佳书籍，《纽约时报》畅销书等荣誉。 2 年之后，这本书的中文版终于得以和国内读者见面。38 万余字，620 页的厚度让这本书拿在手里就能直观地感受到一种传记的「 厚重」。如果从史书体例来说，《基因传：众生之源》属于编年体，按照时间顺序记载了从 1865 年至成书日期（2015 年）基因的发展过程；从内容来说又可以分为基因的发现、认识和基因技术的应用几大层面。 在阅读之前我一度担心这种厚度科普读物的可读性和易读性，但随着阅读的深入我发现自己这种担心完全多余，甚至每读完一部分再返回去重新阅读总能读出新的感悟。接下来，我就从四个角度和你分享《基因传：众生之源》是一本怎样的书？ 阅读本书的四个角度 遗传学入门的通俗教材 遗传学？教材？希望你不要被吓到。这可能是阅读本书最无聊的一个角度，但也是对一本科普读物的极高评价，意味着准确，严谨以及尊重事实。 无论你是一个有没有相关学科背景的读者，它都可以当做一本基础的入门教材或者复习材料。从达尔文进化论开始，到高中生物里的孟德尔遗传定律、摩尔根遗传定律和肺炎链球菌试验，再到大学里的基因组学知识。这个专业内权威教科书《基因 X 》中提到的重点概念在《基因传：众生之源》中都有涉及且解释通俗易懂。作为一个意外惊喜，整本书最后竟然还配有名词解释作为附录，这更让我不禁想到之前的大学课本，没毛病。 下面是本书中关于「基因连锁交换定律」的解释，来自于教科书又通俗于教科书，相信你一定不难理解。 由于某些基因之间的连接十分紧密，以至于它们从不发生互换。摩尔根的学生认为，这些基因在染色体上的物理位置可能最为接近。而其他位置相距较远的连锁基因则更容易解离…… 简而言之，遗传连锁的紧密程度反映了染色体上基因物理位置的远近：通过观测两种遗传性状（例如，金发与蓝眼）连锁或者解离的时间，就可以判断控制这些性状的基因在染色体上的距离。 基因发展史的优秀传记 稍微转化一下视角把基因人格化（里查德·道金斯笔下《自私的基因》是这种写法的最好示例），那么《基因传：众生之源》绝对是一部优秀的名人传记。这本书按照时间顺序和故事情节，完整地讲述了基因理论的起源、发展和未来，以及这个过程中遇到的种种问题和争议。 在阅读某些章节时，我仿佛有一种在读《史蒂夫·乔布斯传》和《硅谷钢铁侠》的感觉。基因从起初不为人所知，到被极少数人接受，再到彻底改写生命科学的研究方法和历史，这就是一个典型的名人成长过程。他在有所成就之前一定会经历各种意想不到的困难，而成名之后虽然成绩显著但也必然少不了各种问题和争议。如此看来，基因不就是生命科学圈里的乔布斯和埃隆·马斯克么，再一次没毛病。 在介绍基因研究起步阶段所面对的困难时，书中有一段描述如下： 阿瑟·科恩伯格（Arthur Kornberg）曾经这样说过：“细胞生物学家凭借观察，遗传学家仰仗统计，生化学家依靠提纯。” 实际上，在显微镜的帮助下，细胞生物学家们已经习惯于在细胞水平观察可见结构执行的可识别功能。但是迄今为止，基因只是在统计学意义上“可见”。 **新发现初期和新事物诞生向来都会饱受争议或被大部分人无视。**科学家们习惯了显微镜下肉眼可见的细胞结构，用户们习惯了手机应该可以更换电池，所以 20 世纪 30 年代统计学意义上「可见」的基因不被人相信，2007 年发布的初代 iPhone 因为大尺寸触摸屏和内置不可更换电池而引起了广泛争议。而 20 年后 1953 年 DNA 双螺旋结构的发现之于基因研究的影响就类似于 2010 年「再一次，改变一切」的 iPhone 4 对于苹果手机的影响。 或许，伟大的东西总需要一些时间来证明，但如果新的发现和事物足够伟大和重要，它们也无需让我们等太久。正如书中所说： 从孟德尔开始进行豌豆实验，再到卡丽·巴克被法院强制执行绝育手术，这中间只经历了短短的 62 年。就在这稍纵即逝的 60 多年间，基因已经从一种植物学实验中的抽象概念演变为操纵社会发展的强大工具。 60 年时间，基因完成了从抽象概念到足以操纵社会发展的强大工具的完美转身；而 iPhone 也仅仅用了 10 年时间就从坊间争议变成了你我手中的街机。 想要从不为人所知到被众人接受，在这个过程中需要做出很多妥协与和解，甚至「少许的牺牲是必要的」。说到这里你是不是以为我要吐槽 iPhone 的「比大更大」和「特供双卡」了，别误会，我说的是基因与生物学其它领域的和解。 将基因作为解决这些生物学核心问题答案的认识姗姗来迟，而这种滞后导致了一种奇怪的现象：作为事后出现的学科，遗传学将被迫与生物学其他主要领域的观点和解。如果基因是代表生物信息的通用货币，那么它将不仅局限于诠释遗传规律，而且还可以用来解释生物界的主要特征。 反思文化伦理的历时读物 基因理论的发展史就是人类文化与伦理的进化史。作者以基因理论的发展为线索，为我们讲述了基因理论与俄国十月革命，第二次世界大战等众多历史事件背后的隐秘关联，也为我们清晰地描述了极端种族主义如何以基因学说为借口，逐步使科学完全论为政治工具的过程。从这个角度来说，这本书又是一部严肃的文化和伦理历史读物。 时间来到 20 世纪中叶，无论基因学说被接受与否，它都已经成为某种潜在的政治与文化工具，并且跻身历史上最危险的思想之一。希特勒的种族净化政策基础就来自于优生学和社会达尔文主义。优生学这一概念在纳粹德国得到了全面推广，他们将不具生产力的人口以各种方法处理掉，从而阻止他们繁衍后代。 从强制绝育到秘密屠杀再到种族清洗，纳粹希望通过此举实现创造一个「优等民族」的梦想。 纳粹主义盗用了基因与遗传学的名义为延续其罪恶进行宣传与辩解，同时还驾轻就熟地将遗传歧视整合到种族灭绝的行动中。基因就这样史无前例地在悄无声息中与身份混为一谈，然后这些带有缺陷的身份被纳粹主义利用，并且成为他们实施种族灭绝的借口。截至 1941 年，T4 行动已经屠杀了将近 25 万的成人与儿童。此外，在 1933 年到 1943 年间，大约有 40 万人根据绝育法接受了强制绝育手术。 德国纳粹坚信人的基因是不可改变的，因此低等人种必须被清除，而与之遥相呼应的还有苏联「大清洗运动」。 大清洗运动完全不科学的科学依据来自李森科的「新拉马克主义」。与德国纳粹不同，李森科认为一个事物本身的特性是怎样不重要，可以通过人为使其得到获得性遗传。对作物而言，它能够在短期内培育出更抗寒高产的品种；对人而言，社会革命能够有目的地塑造和改变人性（即环境改变遗传）。 其实不只德国和苏联，在历史上很多美国著名的政治人物与经济学家都是优生学的坚定支持者。在某一段历史时期，美国曾以智力作为评价标准为大量所谓低智力人群进行了绝育手术，在这些人眼中，他们可以暂时忍受和低等人生活在同一个世界，但一定是要为自己的后代创造一个更纯净的世界。 然而，从目前的研究结果来看，用基因来对人进行区分和为人划分等级是一件非常愚蠢的事情。你认为黑人的祖先就是黑人，白人的祖先也是白人？往上 1 代，你有父母 2 人；往上 2 代，有爷爷奶奶外公外婆 4 个人；往上数 3 代就是 8 个人。倘若再往上 n 代，当代祖先人数就是 2 的 n 次方个。所以只要时间足够久远，全世界任何种族任何地方的人都有可能是你的祖先。这也就是当下基因检测项目可以为你进行祖源分析最通俗的理解和解释，如果你对这些内容感兴趣，不妨去阅读《人类基因的历史地图》。 简而言之，当科学沦为政治、政治开始干涉科学的时候，很难说谁是最大的受害者。 揭示人性的科研圈纪实小说 永远不要相信哪里还是一片净土，有人的地方就有江湖。科研圈也不例外。 《基因传：众生之源》这本书之所以能让人读起来完全不像读传统科普一样乏味，是因为除了讲述科学问题以外还有大量的人性与道德因素参杂其中。在发现问题和解决问题的道路上，合作是科学家们之间永远绕不开的话题，而只要涉及到利益又躲不掉斗争。在这你来我往之间，有人成功就有人失败，有人被铭记就有人被遗忘。 达尔文与华莱士 达尔文同时期的另一位科学家华莱士几乎是同时和达尔文得出了一致的结论并提前发表。不过两人的家庭背景和个人地位在当时可并不相同，用如今的标准来看达尔文是高富帅本人，华莱士却只能在图书馆长椅上读书。 当达尔文看到华莱士寄给自己的手稿时，内心发现「我文章被抢发了（还好没有我名气大）」，于是赶紧去找另一位圈中大佬求助，对方则建议他背靠背发表文章。不过彼时两篇背靠背文章出来都没有引起太大的波澜。到了第二年，达尔文感觉不能在等下去，于是他放弃了整理好所有结果再出书的计划，匆忙将《物种起源》这本书交给出版社并请求出版社尽快将其出版，他在给出版商的信中如是写道「我衷心希望这本书能够在您的大力支持下旗开得胜」。从此，人们记住了达尔文，至于华莱士…… 1858 年 6 月，华莱士将自己概括的自然选择理论初稿寄给了达尔文。达尔文对华莱士理论与自身观点的相似性感到震惊，而他在惊慌失措之余匆忙带着自己的手稿找到好友赖尔。赖尔巧妙地建议达尔文将两篇论文同时提交给即将于夏季召开的林奈学会会议，这样可以让达尔文与华莱士共同分享此项发现带来的荣誉。 被遗忘的孟德尔 维特根斯坦曾说「一个微不足道的想法，就足以占据某个人的一生」。 确实，一眼看去孟德尔的人生充满了繁杂琐碎的念头。他整天周而复始地沉浸在播种、授粉、开花、采摘、剥壳与计数的工作里。尽管整个过程极度枯燥乏味，但是孟德尔却深信天下大事必作于细。 深信天下大事必作于细的孟德尔，1866 年将自己的论文发表在年度《布尔诺自然科学协会学报》上，平日里少言寡语的孟德尔仅用 44 页纸就总结了自己将近 10 年的研究成果。然而后面发生的事情至今人们都很难理解。 1866 年至 1900 年，孟德尔的文章仅被引用了 4 次，几乎从科学文献领域中消失。1890 年至 1900 年的 100 年里，尽管关于人类遗传及其操纵问题和顾虑已成为所有会议的重点议题，但孟德尔的名字与他的成果依然不为世界所知。这件事也被称为「生物学史上最为怪异的沉默事件」之一。究其原因或许是因为论文发表的协会期刊没有名气，没有人注意到那篇几十页的文章。 总之，现代生物学的立足之本就这样被长期埋没。 更可笑的是，时间来到 1900 年，才有三篇完全独立的文章结果同时指向孟德尔的豌豆杂交实验，而这已经是 40 年前的事情了。 正如书中所写： 研究成果被重新发现一次可以反映科学家的先见之明，而被重新发现三次则着实是对原创者的一种鄙夷不屑。 1900 年，有 3 篇独立发表的论文在 3 个月内相继问世，而所有研究成果均指向孟德尔的豌豆杂交实验，当然这也暴露了某些生物学家目光短浅的事实，正是他们将孟德尔的成果尘封长达 40 年。 DNA 双螺旋背后的故事 DNA 双螺旋结构的解析无疑是近代生命科学发展史最重要的一件事。提到这件事你最先想到的两个人一定是沃森和克里克以及高中生物教材上的那张插图。如果你对这个专业还有多一点了解，可能知道和这两个人共同分享诺贝尔奖的还有一位叫威尔金斯的科学家。 其实，在这三个男人的背后还有一位叫做罗莎琳德·富兰克林的女科学家被人们遗忘了。 罗莎琳德·富兰克林曾使用 X 射线经过长时间努力得到了一张极清晰的 B 型 DNA 照片。作为富兰克林同事的威尔金斯把这一消息告诉了沃森，并亲自从富兰克林的抽屉里取出这张关键的照片展示给他欣赏。而这一切都是在富兰克林则完全不知情的情况下公开的。更匪夷所思的是，后期沃森和克里克因为一个关键问题而一筹莫展时，一份富兰克林提交给政府官员的详细工作报告又一次送到了他们两个人手上。 回忆起这件事，威尔金斯表达过如下想法，看的出来他也很凌乱： 或许我应该先得到罗莎琳德的许可，但是我没有这样做。那时的情形一言难尽……如果在正常情况下，那么我自然会先征得她的允许，可是即使当时大家相处融洽，她也不会允许别人这样做……虽然我先看到了这张照片，但是相信没有人会忽略其中的螺旋结构。” 1962 年，沃森、克里克和威尔金斯凭借他们的发现获得了当年的诺贝尔奖，而富兰克林在 1958 年死于卵巢癌广泛转移，年仅 37 岁。 未来以来 1989 年 1 月，美国国立卫生研究院 31 号楼召开了一次小型会议，宣布正式启动人类基因组计划；2003 年 4 月，国际人类基因组组织正式宣布人类基因组计划完成，当时全基因组测序成本约为 10 亿美元；2007 年，全基因组测序成本是 1000 万美元；2008 年底，全基因组测序成本接近 10 万美元；2014 年，Illumina（测序设备生产商）宣布全基因组测序成本为 1000 美元；今天，国内多家公司「简化版」（只检测部分位置非全基因组）基因检测服务售价低于 500 人民币。 感谢科技和技术的进步，让很多几年前只能躺在研究院实验室里的项目如今可以走进公众视野，让我们有机会一窥贯穿你我一生的基因之谜。 如果你是这方面的技术小白又有一颗好奇心，可以通过提供 1ml 唾液尝试了解困扰自己多年问题的某些潜在深层次原因（比如基因）。例如你感觉自己总受负面情绪干扰，可能只是因为你本身患有抑郁症的可能性就比常人高；如果你总是无法像其他人一样享用牛奶，很可能就是因为你的乳糖代谢相关基因和大多数人不同。对于和我一样从事生物信息专业或者有专业背景的人来说， 完全可以进行一次个人全基因组测序，然后自己分析自己的数据，想想还是一件非常极客的事情。 不过，在这篇书评最后，我还是想给你提个醒。《基因传：众生之源》这本书适合每一个人都拿来读读，但是个人基因检测项目并不是对所有人都有意义。 比如，你很难通过自己当下的表征对基因检测结果准确与否进行判断，因为从专业知识来讲，性状都是由基因和环境共同决定的；再比如，目前根据你个人基因位点突变情况来进行的重大疾病预测， 原理上得出的结果还是一个概率问题，既然是概率就不要用必然的心态去衡量；最后，对一个人的基因进行检测类似于查看他的「出厂设置」，如今给手机跑分人们认为虽然正常但也没太大必要了，如果要给一个人的「天赋」或者「能力」跑分评级，从道德和伦理上你认为所有人都会接受么？ 以上，就是我阅读《基因传：众生之源》这本书的一些感受和对于目前基因检测项目的一些看法与建议。把这本书推荐给你，想必你在阅读的时候一定会有不同的体验和收获。 注：本文所有引用内容均摘录于《基因传：众生之源》，本文配图来自于网络，本文修改稿首发于 少数派 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-02-13-thegene-book/"},{"title":"窥概率","content":"概率论代表一种看待世界的方式，关注的焦点是可能性。**对随机事件发生的可能性进行规范的数学描述是概率论的公理化过程。**概率的公理化结构体现出的是对概率本质的认识。 贝叶斯定理 从科学研究的方法论来看，贝叶斯定理提供了一种全新的逻辑。它根据观测结果寻找合理的假设，或者说根据观测数据寻找最佳的理论解释，其关注的焦点在于后验概率。 在贝叶斯学派眼中，概率描述的是随机事件的可信程度。如果手机里的天气预报应用给出明天下雨的概率是 85%，这就不能从频率的角度来解释，而是意味着明天下雨这个事件的可信度是 85%。 频率学派认为假设是客观存在且不会改变的，即存在固定的先验分布，只是作为观察者的我们无从知晓。因而在计算具体事件的概率时，要先确定概率分布的类型和参数，以此为基础进行概率推演。 相比之下，贝叶斯学派则认为固定的先验分布是不存在的，参数本身也是随机数。换言之，假设本身取决于观察结果，是不确定并且可以修正的。数据的作用就是对假设做出不断的修正，使观察者对概率的主观认识更加接近客观实际。 概率论和机器学习 概率论是线性代数之外，人工智能的另一个理论基础，多数机器学习模型采用的都是基于概率论的方法。但由于实际任务中可供使用的训练数据有限，因而需要对概率分布的参数进行估计，这也是机器学习的核心任务。 估计 概率的估计有两种方法：最大似然估计法和最大后验概率法，两者分别体现出频率学派和贝叶斯学派对概率的理解方式。 最大似然估计法的思想是使训练数据出现的概率最大化，依此确定概率分布中的未知参数，估计出的概率分布也就最符合训练数据的分布。 最大后验概率法的思想则是根据训练数据和已知的其他条件，使未知参数出现的可能性最大化，并选取最可能的未知参数取值作为估计值。在估计参数时，最大似然估计法只需要使用训练数据，最大后验概率法除了数据外还需要额外的信息，就是贝叶斯公式中的先验概率。 从理论的角度来说，频率学派和贝叶斯学派各有千秋，都发挥着不可替代的作用。但具体到人工智能这一应用领域，基于贝叶斯定理的各种方法与人类的认知机制吻合度更高，在机器学习等领域中也扮演着更加重要的角色。 随机变量 概率论的一个重要应用是描述随机变量。根据取值空间的不同，随机变量可以分成两类：离散型随机变量和连续型随机变量。在实际应用中，需要对随机变量的每个可能取值的概率进行描述。 离散变量的每个可能的取值都具有大于 0 的概率，取值和概率之间一一对应的关系就是离散型随机变量的分布律，也叫概率质量函数。概率质量函数在连续型随机变量上的对应就是概率密度函数。 概率密度函数体现的并非连续型随机变量的真实概率，而是不同取值可能性之间的相对关系。对连续型随机变量来说，其可能取值的数目为不可列无限个，当归一化的概率被分配到这无限个点上时，每个点的概率都是个无穷小量，取极限的话就等于零。而概率密度函数的作用就是对这些无穷小量加以区分。 重要分布 定义了概率质量函数与概率密度函数后，就可以给出一些重要分布的特性。重要的离散分布包括两点分布、二项分布和泊松分布，重要的连续分布则包括均匀分布、指数分布和正态分布。 数字特征 除了概率质量函数 / 概率密度函数之外，另一类描述随机变量的参数是其数字特征。数字特征是用于刻画随机变量某些特性的常数，包括数学期望、方差和协方差。 数学期望即均值，体现的是随机变量可能取值的加权平均，即根据每个取值出现的概率描述作为一个整体的随机变量的规律。方差表示的则是随机变量的取值与其数学期望的偏离程度。方差较小意味着随机变量的取值集中在数学期望附近，方差较大则意味着随机变量的取值比较分散。 数学期望和方差描述的都是单个随机变量的数字特征，如果要描述两个随机变量之间的相互关系，就需要用到协方差和相关系数。协方差度量了两个随机变量之间的线性相关性，即变量 Y 能否表示成以另一个变量 X 为自变量的 aX+b 的形式。 根据协方差可以进一步求出相关系数，相关系数是一个绝对值不大于 1 的常数，它等于 1 意味着两个随机变量满足完全正相关，等于 -1 意味着两者满足完全负相关，等于 0 则意味着两者不相关。需要说明的是，无论是协方差还是相关系数，刻画的都是线性相关的关系。如果随机变量之间的关系满足 Y=X2，这样的非线性相关性就超出了协方差的表达能力。 内容主要整理摘录自王天一老师相关文章 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-01-18-justseeProbability/"},{"title":"先验后验和贝叶斯","content":"随机并不随机 设想一个转盘游戏有红黑两种，且颜色各占一半。现在请你写下自己的预测结果。如果你配合可以此刻直接写到评论区，再来看文章后续内容。 首先要说的一点是，转盘是否公平，你心里其实已经预先有了答案。 曾有大量人参与过这一实验，5 次转动转轮产生的红、黑（R/B）颜色序列，一共有 32 种可能。由于每次转动转轮之后小球停在红色或黑色区域的概率相同，因此上述 32 种序列出现的概率也相同。 事实上，人们的选择并不均匀。不信你可以看看自己写下的答案。其实，BBRBR、BRRBR 这类序列出现的次数远远超过预期，RBRBR 这类序列出现的次数则低于预期，而 RRRRR 几乎没有出现过。对于这样的结果，看起来似乎理所当然。与 BBRBR 相比，RRRRR 给人的感觉并不像一个随机序列，尽管转动转盘出现这两种结果的概率是相同的。 如果再让你立刻说一个 1——20 之间的数字，你选择的是 17，或者是 7 么。大量测试显示如果让人们在 1——20 之间选一个数字，17 是最常被选到的数字。如果我们让人们在 0 至 9 之间选一个数字，他们最常选的是 7。在随机选择时，末尾是 0 和 5 的数字出现的次数远低于我们的预期，在人们心目中，这些数字的随机程度似乎比较低。 先验概率 关于转盘的问题，我们通常默认它是一种非常公平的游戏，小球停在红色或黑色区域的概率是相同的。但是，就是有人认为转轮偏向于某个颜色。这其中包括： 红色论：转轮偏向于红色，小球停在红色区域的次数占比为 60%。 公平论：转轮是公平的，小球停在红色区域与黑色区域的次数相同。 黑色论：转轮偏向于黑色，小球停在黑色区域的次数占比为 60%。 如果我再问你这三种理论的置信度是多少？除非证据确凿，通常我们很可能会认为轮盘赌是公平的。例如公平概率为 90%，黑色论与红色论正确的概率分别只有 5%。 注意，此时的 90，5，5 就是所谓的先验概率（priori probability），即认为某个理论正确的概率。 当然，不同的人可能有不同的先验概率：怀疑论者认为三个理论的先验概率都是 1/3，而有些人充分信任庄家的节操，认为红色论与黑色论的先验概率只有 1%。 但是，这些先验概率不是一成不变的。如果我们找到了某理论优于另一理论的证据（例如，小球连续 5 次停在红色区域中），不同理论的置信度就会发生改变。 后验概率 那么，这个规律在转盘中会起到什么作用。我们转动转轮 5 次，得到 RRRRR 的概率是多少呢？这个时候，之前的先验概率就要发挥作用了。 在公平时，每次转动转轮后小球停在红色区域的概率为 1/2，因此，得到 RRRRR 这个结果的概率为：1/2×1/2×1/2×1/2×1/2=1/32=3.125%换言之，得到 RRRRR 与得到其他 31 种颜色序列的概率完全相同。 如果黑色论是正确的，小球停在红色区域的概率为 40%，即 0.4，那么，得到 RRRRR 结果的概率为：0.4×0.4×0.4×0.4×0.4=1.024% 如果红色论是正确的，小球停在红色区域的概率为 60%，那么，得到 RRRRR 结果的概率为：0.6×0.6×0.6×0.6×0.6= 7.76% 公平论的先验概率为 0.9，这个先验概率的 3.125%，即 0.9×0.031 25（0.0281），即“公平论正确且小球 5 次停留的区域为 RRRRR”的方框中，剩下的 0.8719 则是“公平论正确但停留区域不是 RRRRR”。 同理，红色论的先验概率是 0.05，因此，“红色论正确且结果为 RRRRR”的先验概率是 0.05×7.76%=0.0039；而“红色论正确但结果不是 RRRRR”的是 0.0461。黑色论的先验概率也是 0.05。但是，黑色论与 RRRRR 这个结果之间的关系很扭曲，因此，“黑色论正确且结果为 RRRRR”的概率为 0.05×1.024%=0.0005。 我们可以画出下图。 如果我们转动转盘并且真的得到 RRRRR 的结果，对红色论而言就是好消息，对黑色论而言则是坏消息。 小球连续 5 次停在红色区域，这种情况位于方框图的下排，黑色论、公平论与红色论的先验概率分别为 0.0005、0.028 和 0.0039。换句话说，在这种情况下，公平论与红色论的先验概率比率大约是 7∶1，红色论与黑色论的先验概率比率大约是 8∶1。稍加换算，黑色论正确的概率是 1.5%; 公平论正确的概率是 86.5%; 红色论正确的概率是 12%。也就是说，和最初相比，由此可见，红色论的置信度增加一倍多，而黑色论的置信度几乎消失。置信度的这种变化是十分恰当的，小球连续 5 次停在红色区域，我们对转轮受到人为操纵的怀疑当然会增加。 到这里，上述计算展示了在连续 5 次看到小球停在红色区域之后，公平论、红色论、黑色论的置信度的变化情况，也就是所谓的后验概率（posterior probability）。 贝叶斯推断 **先验概率描述的是看到相关证据之前的置信度，而后验概率描述的是看到相关证据之后的置信度。**我们所做的工作叫作“贝叶斯推理”（Bayesian inference），由先验概率到后验概率的需要用到“贝叶斯定理”（Bayes’s Theorem）的概率公式。 在贝叶斯推理的过程中，人们在看到证据后，某种理论的置信度不仅取决于证据的内容，还取决于一开始时的置信度。 单纯地依靠零假设显著性检验的做法，其实违背了贝叶斯推理的本质。例如吃一个西瓜病情延缓和吃药病情延缓得到的统计概率都可能是 0.05。也就会让人认为西瓜与药有相同的疗效。 费舍尔曾说过：“科研人员不会设一个固定的显著性临界值，然后年复一年，无论情况如何变化，都依据这条红线去推翻各种假设。相反，他们会在证据的启示下，结合自己的想法，认真考虑每一个具体案例。” 贝叶斯定理对推理方法产生了广泛的影响，例如教会机器根据人们输入的大量数据来学习，但这些方法并不适用于回答是或否的问题。对于是或否的问题，人们常常借助费舍尔的方法做出判断。具体的说，信奉贝叶斯定理的统计学家通常对显著性检验不感冒，他们对“该新药是否有疗效”之类的问题不感兴趣，而是更关注如何建立一个预测模型，以便更准确地判断该药物的不同剂量在针对不同人群时可以取得什么样的疗效。 回到最开始的问题。出现 RBRRB 与 RRRRR 这两个结果的可能性都非常小，而且概率相同，但是在人们看来，前者是随机结果，后者则不是，这是为什么？贝叶斯的统计学观点足以解释其原因。当看到 RRRRR 这个结果时，我们就会更加相信一个转轮盘做过手脚，小球会停在红色区域，对于这个理论，我们已经赋予了某个先验概率。但是，如果出现的结果是 RBRRB，我们确不会认为转轮中藏有可以产生 RBRRB 这个结果的特殊装置。先验概率不是一视同仁，而是有所取舍的。在心理上，有的想法会得到明显的重视，而对于 RBRRB 这一类结果，我们赋予它们的先验概率几乎接近于零。 相较于复杂想法以及以完全陌生的现象为基础的想法，我们往往更喜欢简单的想法和那些通过类比我们所熟知的事物而产生的想法。这种喜好似乎是一种不公平的偏见，但是，如果没有任何偏见，我们就有可能整天都处于震惊的状态。比如，就在刚刚，我竟然听到外面有汽车嗯了三下喇叭。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-01-06-bayesian/"},{"title":"关于 P 值的几点问题","content":" 关于假设检验中的 P 值相关的文章和批评实在太多了。最近看大一本书中有提到了 P 值的部分，简单做个整理。 可能性极小和基本不可能有天壤之别 P 值的诞生伴随着假设检验，人们经常会把“可能性极小”理解成“基本不可能”，而且，“基本”一词的影响力越来越小，最终淡出人们的考虑范围。 但是，“不可能”与“可能性极小”是不同的概念，两者的意思相去甚远。不可能的事情绝不会发生，而可能性极小的事件并不少见。这就意味着我们在根据可能性极小的观察结果进行推理时，由于受到归为不可能法的影响，会产生一种不可靠的逻辑立场。 统计功效是个大问题 关于 P 值其实总有说不完的话和吐不完的槽。国外更是有一众大牛执着于吐槽 P 值。其中一位是希腊人约翰·约安尼迪斯（John Ioannidis），2005 年他发表了一篇题为“公开发表的研究成果大多不真实的原因何在”的论文，在临床医学领域引发了一场罕见自我批评的狂风暴雨，不过随之而来的是一波自我辩解的风潮。 约安尼迪斯认为我们在医学上尝试使用的介入治疗法大多不起作用，我们所检测的各种关系大多是子虚乌有。以基因与疾病之间的关系为例。基因序列中有大量基因，其中绝大多数都不会引发癌症、抑郁症或肥胖症等，至少人们没有直接观察到基因会导致人们患此类病症。例如基因对精神分裂症的影响，由于这种疾病有遗传的可能，人们几乎可以肯定是基因在起作用。对 10 万“遗传性多态现象”进行检验，以期找出与精神分裂症有关的基因。在这些基因中，大约有 10 种真的会对精神分裂症产生影响。那么，其余的 99 990 个与精神分裂症没有任何关系。但是，其中的 1/20 或者说 5 000 种会顺利通过统计学显著性检验。 如果研究方法的功效不足，真实结果就完全有可能被认定为不具有统计学显著性而被排除在外。也就是在仅有的 10 个真实结果中还有几个被你扔掉了，多惨。 赢家诅咒与不可重复 统计功效低下的研究只能找出非常显著的效果，但是效果有时就是非常小。在检验基因的作用时，研究人员有可能认为检验结果不具有统计学显著性，因此将其排除在外；而那些顺利通过检验的结果，要么是假阳性，要么是过度夸大基因作用的真阳性结果。在样本量小、影响程度通常有限的研究中，统计功效低下的风险尤为突出。 如果研究规模比较小，那么人们在用 p 值过滤时，往往会排除影响程度较为接近 p 值的结果，因此，上述检验得到的较大显著性差异是有悖常理的。 这种现象称作“赢家诅咒”。有的实验取得了令人信服、广受赞誉的结果，但是人们在重复这些实验时，却常常得到乱七八糟、令人失望的结果。之所以出现这样的情况，赢家诅咒就是一个原因。2012 年，加利福尼亚一家名叫安进的生物技术公司开展了一项计划，科研人员通过重复实验去验证癌症生物特征方面的一些著名的实验结果，总计 53 种。结果，他们只成功验证了其中的 6 种。 文件柜效应 另一个问题被称为“文件柜效应”，假定我们在了解基因与我们研究的某种疾病之间是否存在相关性时，测试了 20 个遗传标记，并发现只有一个测试结果的 p 值小于 0.05，其实在所有的遗传标记都不起作用时，我们的成功率正好是 1/20。 如果 20 组研究人员分别在 20 个实验室里针对绿色软糖行了共计 20 次测试，结果会怎么样呢？有 19 个实验室不会得出具有统计学显著性的测试结果，他们也不会据此发表论文。这是毫无疑问的，谁会把“吃绿色软糖与得痤疮之间没有相关性”作为重大发现公开发表呢？第 20 个实验室里的研究人员比较幸运，得出了一个具有统计学显著性的测试结果，还发表了。这其实还是有幸存者偏误的成分。我们没看到应该锁到柜子里的 19 次失败结果。 P 值操控 如果你做过一些数据分析，就会发现如果我们找出各种理由，修改与研究结果直接相关的统计数据，我们常常可以把 p 值由 0.06 降至 0.04。乌里·西蒙逊（Uri Simonsohn）是宾夕法尼亚大学的一位教授，他是重复实验研究的开创者，他把这些做法称作“p 值操控”。 问题在于，通常 p 值操控并不像我们理解的那样粗暴，而且一般都不是恶意行为。在操控 p 值时，人们坚信自己的假设是正确的。此时，人们很容易找到理由，认为自己得出可以发表的研究结果是正确的，甚至还会后悔一开始的时候没有朝这个方向努力。 我们可以把众多研究发表结果的 P 值做一个统计。按道理应该从 0 到 0.05 逐渐减少。 但是统计调查人员发现，在政治科学、经济学、心理学及社会学等多个领域里，p 值曲线在接近 0.05 这个临界值时会明显向上倾斜。大量本来位于 p=0.05 这个临界值之上而无法发表的实验结果，经过对数据的坑蒙拐骗、威逼利诱甚至严刑逼供之后，变成了令人满意的结果。 用 0.05 设置一个生死界线，是在基本范畴的问题上犯错误，把连续变量（我们有多少证据可以证明这种药物有疗效，这种基因可以决定智商分数，排卵期的女性倾向于支持民主党总统候选人）当作二进制变量（对或者错）来处理。也就是说，我们应该允许科研人员报告不具有统计学显著性的研究结果。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2018-01-05-pvalue/"},{"title":"统计世界的那些八卦 1","content":" 《女士品茶》读书笔记 最近整理前一段时间看过的书，想了想先从《女士品茶》开始，正如这本书的自序所言，全书没有关于概率统计的抽象概念，但是却介绍了一些概率统计在各个领域的应用。这几篇系列文章将依托于《女士品茶》这本书，对概率统计世界的那些八卦做一些梳理。 随机性 概率和统计 随机性，概率和统计这三个名词经常会同时出现，以至于很多人都会把它们混为一谈，其实这三个数学概念有着巨大的区别。 所谓随机性通常都是不可预测的同义词，但是在数学中随机性并非不可预测出乎意料，随机事件都拥有一个可以进行数学描述的结构。 而概率表达的是人们对于可能发生的时间的感受。概率的数学理论中具有复杂的方法用于计算事件发生的概率。并且这其中伴随着很多重要定律的产生。 统计分布概念的提出很大程度上是概率理论的功劳。但是概率理论本身又不足以描述统计方法，有时科学上的统计方法还会违反某些概率定律。 一切要从那位喝茶的姑娘开始 虽然这本书的名字叫做《女士品茶》，但是这本书和女士以及茶都没有什么关系。但是整个概率统计的历史又必须从一个喝茶的姑娘开始。 题外话，如果你就在电脑边不妨立刻打开 R，然后输入?fisher.test() 查看 fisher.test 在 R 中的帮助文档，其中对该检验使用的示例就是一个女士喝茶的故事。 20 实际 20 年代末，一群剑桥的老师及她们的家人在一起喝下午茶，这个时候一个女士坚定的认为这个奶茶你是先放奶还是先放查会有极大的差别。然后一个叫做罗纳德埃尔默费希尔的老哥就陷入了沉思，他在思考如何才能判断这个不知道谁家的败家玩意儿的话到底是对的还是错的。于是乎他们一帮人就用各种方式泡了好多杯奶茶让这为女士一次品尝。 整个实验过程在他的《实验设计》这本书中有详细的论述。主要问题就在于给她多少杯茶合适，她猜对多少才算她真的能喝出差别，同时需要给这位女士透露多少信息等。但是书中并没有写真的存在这么一件品茶的故事。 故事暂且告一段落，但是《实验设计》这本书对 20 世纪的前 50 年产生了暴风般的影响。你要知道，在此之前，所有的科学实验都是说不清为什么要那样做，做完实验也不会把所有结果全部公布。其中最著名的一个例子就是孟德尔这位小哥的豌豆实验，那个神奇的 3：1 分离比，你知道他这个结论是怎么写的么。他用的描述方法是：“两组实验的前 10 个结果可以说明……”。 费希尔的贡献则是完全改变了这一局面，比如人们曾经争论了 20 年那种肥料更有效，最后他说其实之前那些数据和天气的关系更大。意不意外，惊不惊喜。 至于那个品茶的女士，据当时在场的其他人会议，她的所有判断全部正确。意不意外，惊不惊喜。 自己的坑自己来填 这一趴首先出场的配角是英国科学家弗朗西斯高尔顿，作为一名正宗的爵士，他最大的贡献是发现了指纹独一无二的特性，而且还做了分类和识别的方法，类似于指纹这种不规则的凹凸，被称为“高尔顿标识”。也就是说，你每次在使用指纹给手机解锁的时候，都应该默念一句“感谢老高”。 对于统计，他的贡献则在于因为他非常希望把数学的严谨性带到生物学中，为此统计了大量的父子身高数据。然后发现了一个重要的现象“均值回归”。一句话解释就是“高爸爸的儿子比高爸爸矮，矮爸爸的儿子比挨爸爸高”！你可别看这句话和绕口令一样，但是均值回归延申出来的统计模型主导了经济学和工程学。 如果说均值回归的意义，就是人类的身高基本稳定，不会因为“高爸爸的儿子比高爸爸高，矮爸爸儿子比矮爸爸矮”而造成人类身高的迅速两极分化，从而确保物种的平衡和相似。进而高尔顿又给出了相关系数的概念。 故事到这里，配角就该告一段落了，真正把相关系数用公式完整表达出来的则是他的学生卡尔皮尔逊。而他也是这一趴的主人公。皮尔逊的革命性思想在于阐明了实验结果并非是仔细测量的精确值，而只是一些数字的分布，进而这些分布可以写成公式来描述观测值等于给定值的概率。一句话就是在实验里，我们只谈数值的概率而不谈确定的值。 既然我们测到的不是真的，就需要来解决随机属性的问题，于是就有了所谓的钟形曲线或者正太分布。 说到正太分布，当我在读这一章节的时候，最吸引我的其实不是正文的内容，而是脚注对于正态分布的注解。 正态分布有时又叫高斯分布，这是因为人们曾经认为高斯是第一个写出正态分布公式的人。实际上，首个写下正态分布公式的不是卡尔·弗里德里希·高斯，而是一位更早的数学家，名叫亚伯拉罕·棣莫弗。另外。我们有理由相信。在此之前，丹尼尔·伯努利曾在无意中发现了这个公式。这些事实可以证明当代科学史学家斯蒂芬·施蒂格勒所说的误称定律，即数学上一切以入命名的概念都不是以发现者的名字命名的。 皮尔逊在正太分布的基础上提出了所谓的“偏斜分布”，同时定义了这个体系中的四个重要的参数：均值，标准差，对称度和峰度。这个事情在我们今天看来，其实就是我们所有观测的东西都需要这四个参数来描述，但是我们永远无法真的知道这四个参数，只能用已有的数据去估计。即参数估计。 这一部分的结尾也是这一章节的高潮，当然也是我觉得最喜感的地方。 为了应用自己的研究成果，皮尔逊和他的几个老铁创办了《生物统计》杂志，本意是要用他们的数学思想证明达尔文关于进化论的观点。简单说就是算出某一个物种某种特点的全部四个参数，进而观察这四个参数的变化。不过虽然他们收到了世界各地超级多的数据，但最后就变成了为了数据而数据的堆砌。 在这个过程中，1908 年，一个作者使用**“学生”** 的笔名提出了一种叫做**“t 检验”** 的思想，也就是所谓的“student t test”。这是该“学生”的首次登场，后面还有他的故事。 在皮尔逊的整个为了证明达尔文进化论而努力的生涯中，他曾经在《生物统计》杂志发表了一篇文章，论述澳大利亚土著人和欧洲人身体测量结果具有相同分布，同时提出了一种叫做“拟合优度检验”的统计工具，“拟合优度检验”这个家伙可是非常厉害了，能判断一组观测值是否符合某个预期分布。 它厉害到什么程度呢？老皮尔逊的儿子埃贡皮尔逊后来就是用老爷子的“拟合优度检验”推翻了大部分他爸爸的工作。对于卡尔皮尔逊来说，正所谓“自己挖的坑，终究要由自己来填” 未完待续 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-12-27-ladytasttea1/"},{"title":"四步实现内网穿透","content":" 想要做数据分析，一个配置说的过去的服务器必不可少，在自己的笔记本跑数据总有一些说不出的痛。如果能把实验室配备的高性能服务器搬回宿舍，就可以在宿舍里愉快地工作了。 达成这一愿望一共只需要四步： 下班后趁机潜入机房 拔掉服务器电源，对服务器进行简单拆解 低调地将服务器各零件搬回宿舍 在宿舍对服务器进行组装并调试 以上步骤实施过程中，如果出现意外概不负责！ 如果对于上述方法不满意，那按照下面四步进行操作是完全可以成功且几乎没有风险的。 本文将讲解如何通过四步实现内网穿透，解决实验室等内网服务器在宿舍等外网无法连接使用的难题。 假设你已经有一个具有公网 IP 的服务器（比如谷歌云、亚马逊或者阿里云等云服务器），并且实验室配有高性能内网 IP 服务器。 第一步 通过链接：https://github.com/fatedier/frp/releases/download/v0.14.1/frp_0.14.1_linux_amd64.tar.gz 下载 frp 安装包。 将下载好的安装包frp_0.14.1_linux_amd64.tar.gz 分别保存到你的公网 IP 服务器和内网服务器，并分别解压缩。 tar zxvf ./frp_0.14.1_linux_amd64.tar.gz cd frp_0.14.1_linux_amd64/ # 目录内容如下 # frpc frpc_full.ini frpc.ini frps frps_full.ini frps.ini LICENSE 第二步 在公网 IP 服务器 中修改目录中的frps.ini配置文件，将bind_port改为自己喜欢的可用端口 [common] bind_port = 7000 在内网 IP 服务器 中修改frpc.ini配置文件，server_port 改为和上一步bind_port 相同的端口，remote_port设置为内网可用的一个端口，server_addr 改为你的公网可用服务器 IP 地址。 [common] server_addr = 123.123.123.123 server_port = 7000 [ssh] type = tcp local_ip = 127.0.0.1 local_port = 22 remote_port = 6000 第三步 分别启动公网服务器和内网服务器对应服务。 首先在公网服务器中启动** frps**。 cd frp_0.14.1_linux_amd64/ ./frps -c ./frps.ini # 链接成功会出现如下内容 #2017/12/21 20:23:25 [I] [service.go:88] frps tcp listen on 0.0.0.0:7000 #2017/12/21 20:23:25 [I] [main.go:112] Start frps success #2017/12/21 20:23:25 [I] [main.go:114] PrivilegeMode is enabled, you should pay more attention to security issues # 以上命令用于测试，在实际使用中可使用如下命令在后台运行 nohup ./frps -c ./frps.ini &gt; /dev/null 2&gt;&amp;1 &amp; 公网服务器启动成功后，在内网服务器中启动** frpc**。 cd frp_0.14.1_linux_amd64/ ./frpc -c ./frpc.ini # 链接成功会出现如下内容 # 2017/12/21 20:18:13 [I] [control.go:277] [fabbf33cfb85d5bd] login to server success, get run id [fabbf33cfb85d5bd], server udp port [0] # 2017/12/21 20:18:13 [I] [control.go:412] [fabbf33cfb85d5bd] [ssh] start proxy success # 以上命令用于测试，在实际使用中请使用如下命令在后台运行 nohup ./frpc -c ./frpc.ini &gt; /dev/null 2&gt;&amp;1 &amp; 第四步 在 Linux 中或者 Windows 内置 linux 子系统中直接通过 SSH 访问内网服务器。其中 username 是内网服务器用户名，后面的 IP 地址则是公网服务器的 IP 地址。 ssh -oPort=6000 username@123.123.123.123 更加方便的是配置自己电脑中的 Xshell 或类似软件，以 Xshell 为例 首先点击新建会话，主机 为自己的公网 IP 地址，端口号 为第二步中的内网 remote_port 端口号。 然后点击登陆，此时的登陆名为内网服务器用户名，登陆密码为内网服务器登陆密码，然后保存该会话，以后就可以在宿舍等外网环境下 一键登录 实验室的高性能内网服务器。 在配置的过程中，如果出现无法连接等问题，可以查看 log 文件，更加详细的介绍和其它丰富功能可以参考 frp 官网 https://github.com/fatedier/frp 从此以后再也没有理由不在宿舍工作了！ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-12-21-frpbasic-md/"},{"title":"variant分析阶段小结3-对变异进行注释","content":"variant annotation 通过上面几步内容，我们找到了一些可信度相对高的突变位置，接下来一个很重要的内容就是对这些突变位点进行注释和功能预测。注释目前常用的工具有两种，一个是 snpEFF，另一个是 annovar。注释的思路也可以分为两类，一类是按照基因注释，另一类是按照位置注释。 SnpEFF 首先来说说SnpEFF，这个软件的用法说难不难，但是需要注意的地方不少。输入文件是前面生成的 filter 过的 vcf 文件（也可以是跑 ChIP-seq 等出来的 peak 文件），正式使用前首先需要下载好所研究物种的数据库，比对后的新 vcf 文件会在 INFO 这一列生成一个名字是 ANN 的 tag 。软件下载安装好之后，注释过程主要有三步： 查看官方已经准备好的数据库 据说目前已经有了超过 2500 个物种的注释信息，植物研究常用的拟南芥和水稻自然是有的。 java -jar snpEff.jar databases | less 下载自己需要的数据库 这里我们下载水稻的数据库信息为例 java -jar /home/zf/software/snpEff/snpEff.jar Oryza_sativa 下载好之后，会在软件安装目录中的 data 目录下出现名字是 Oryza_sativa，里面会有一个后缀是 bin 的文件，这个文件就是后面注释时要使用的文件。 画外音：开始我使用的是官方已经准备好的数据库，但是因为这个植物相关的数据库来自 Ensembl，里面的信息很多物种并不是最新的，而且会有很多我们不想要的注释内容存在。又因为水稻目前主要有来自 MSU 和 RAPDB 的两版注释信息，所有我们选择重新构建自己的水稻注释数据库。 构建自己的数据库 # 修改 snpEff.config 文件 vi snpEff.config # 添加如下两行信息，含义是构建两个版本的Rice数据库 # 分别是msu和rapdb ----- rapdb_rice.genome: Rice msu_rice.genome: Rice ----- mkdir ./data/msu_rice mv ./data/msu_rice # 下载相应genome,cds,protein文件和gtf文件到该文件夹 # 利用gffread 把gff转换为gtf # 重命名如下 data/msu_rice/ ├── cds.fa ├── genes.gtf ├── protein.fa ├── sequences.fa # build database java -Xmx20g -jar snpEff.jar build -v msu_rice 2&gt;&amp;1 | tee msu_rice.build # 构建完成后结构如下 data/msu_rice/ ├── cds.fa ├── genes.gtf ├── protein.fa ├── sequences.fa ├── snpEffectPredictor.bin # 后续注释需要的文件 对 vcf 结果文件进行注释 java -Xmx32g -jar /home/zf/software/snpEff/snpEff.jar msu_rice filtered_freeabyes.vcf -v &gt; filtered_freeabyes_anno.vcf 说明 在注释的过程中，会输出所用数据库统计信息和运行中产生的警告。如下所示，可以看到我注释使用的 Rice Genome 的 msu 版本。一共有 55986 个基因。 00:00:12 Genome stats : #----------------------------------------------- # Genome name : 'Rice' # Genome version : 'msu_rice' # Genome ID : 'msu_rice[0]' # Has protein coding info : true # Has Tr. Support Level info : true # Genes : 55986 # Protein coding genes : 55986 #----------------------------------------------- # Transcripts : 66338 # Avg. transcripts per gene : 1.18 # TSL transcripts : 0 #----------------------------------------------- # Checked transcripts : # AA sequences : 66112 ( 99.66% ) # DNA sequences : 66135 ( 99.69% ) #----------------------------------------------- # Protein coding transcripts : 66338 # Length errors : 25 ( 0.04% ) # STOP codons in CDS errors : 5 ( 0.01% ) # START codon errors : 0 ( 0.00% ) # STOP codon warnings : 0 ( 0.00% ) # UTR sequences : 35273 ( 53.17% ) # Total Errors : 25 ( 0.04% ) #----------------------------------------------- # Cds : 292025 # Exons : 312496 # Exons with sequence : 312496 # Exons without sequence : 0 # Avg. exons per transcript : 4.71 # WARNING : No mitochondrion chromosome found #----------------------------------------------- # Number of chromosomes : 14 # Chromosomes : Format 'chromo_name size codon_table' # '1' 43270923 Standard # '3' 36413819 Standard # '2' 35937250 Standard # '4' 35502694 Standard # '6' 31248787 Standard # '5' 29958434 Standard # '7' 29697621 Standard # '11' 29021106 Standard # '8' 28443022 Standard # '12' 27531856 Standard # '10' 23207287 Standard # '9' 23012720 Standard # 'Un' 633585 Standard # 'Sy' 592136 Standard ... ... WARNINGS: Some warning were detected Warning type Number of warnings INFO_REALIGN_3_PRIME 171 WARNING_TRANSCRIPT_INCOMPLETE 126 WARNING_TRANSCRIPT_MULTIPLE_STOP_CODONS 14 rapdb 版本的基因组信息如下 00:00:07 Genome stats : #----------------------------------------------- # Genome name : 'Rice' # Genome version : 'rapdb_rice' # Genome ID : 'rapdb_rice[0]' # Has protein coding info : true # Has Tr. Support Level info : true # Genes : 37851 # Protein coding genes : 35667 #----------------------------------------------- # Transcripts : 44618 # Avg. transcripts per gene : 1.18 # TSL transcripts : 0 #----------------------------------------------- # Checked transcripts : # AA sequences : 42215 ( 99.99% ) # DNA sequences : 42219 ( 94.62% ) #----------------------------------------------- # Protein coding transcripts : 42219 # Length errors : 1254 ( 2.97% ) # STOP codons in CDS errors : 0 ( 0.00% ) # START codon errors : 9239 ( 21.88% ) # STOP codon warnings : 677 ( 1.60% ) # UTR sequences : 38131 ( 85.46% ) # Total Errors : 10099 ( 23.92% ) #----------------------------------------------- # Cds : 164901 # Exons : 196575 # Exons with sequence : 196575 # Exons without sequence : 0 # Avg. exons per transcript : 4.41 # WARNING : No mitochondrion chromosome found #----------------------------------------------- # Number of chromosomes : 12 # Chromosomes : Format 'chromo_name size codon_table' # '1' 43270923 Standard # '3' 36413819 Standard # '2' 35937250 Standard # '4' 35502694 Standard # '6' 31248787 Standard # '5' 29958434 Standard # '7' 29697621 Standard # '11' 29021106 Standard # '8' 28443022 Standard # '12' 27531856 Standard # '10' 23207287 Standard # '9' 23012720 Standard 结果文件 snpEff_genes.txt snpEff_summary.html filtered_indels_gatk_anno.vcf 其中 html 文件会给出主要（详细）的注释统计信息，所有关心的统计信息这个 html 里面都有而且还进行了简单的可视化，除了丑没啥大毛病。我这里仅用了之前 freebayes 产生的结果作为测试文件。例如： 整体情况 突变的影响和功能 突变分布的区域 再比如 SNP 的类型 snpEFF_gene.txt 这个文件里面统计了每一个基因的相关突变情况，其基因信息主要来自 Ensembl 数据库。 filtered_indels_gatk_anno.vcf 是主要的注释 vcf 文件，这里面和源文件相比变化的是 INFO 列 ANN tag , 形式如下所示，每两个竖线之间具体表示一类信息。总的来说一条注释一共有 16 列,有些不一定每个位点都有，如果一个位点有多条注释则使用逗号分隔。可以参考官网的详细解释。 我从生成的文件中提取了一个 ANN 注释信息，为了方便说明，整理成如下表格。 内容 解释 T Allele (or ALT) missense_variant Annotated using Sequence Ontology terms. MODERATE Putative_impact A simple estimation of putative impact / deleteriousness : {HIGH, MODERATE, LOW, MODIFIER} LOC_Os01g01380 Common gene name (HGNC). Optional: use closest gene when the variant is “intergenic” LOC_Os01g01380 Gene ID transcript Feature type preferred to use Sequence Ontology (SO) terms LOC_Os01g01380.1 Feature ID protein_coding Transcript biotype 6/6 Rank / total Exon or Intron rank / total number of exons or introns. c.341C&gt;T HGVS.c Variant using HGVS notation (DNA level) p.Ser114Phe HGVS.p: If variant is coding, this field describes the variant using HGVS notation (Protein level) 1399/3482 cDNA_position / cDNA_len: Position in cDNA and trancript's cDNA length (one based). 341/1566 CDS_position / CDS_len: Position and number of coding bases (one based includes START and STOP codons). 114/521 Protein_position / Protein_len: Position and number of AA (one based, including START, but not STOP). Distance to feature All items in this field are options, so the field could be empty. Up/Downstream: Distance to first / last codon Intergenic: Distance to closest gene Distance to closest Intron boundary in exon (+/- up/downstream). If same, use positive number. Distance to closest exon boundary in Intron (+/- up/downstream) Distance to first base in MOTIF Distance to first base in miRNA Distance to exon-intron boundary in splice_site or splice _region ChipSeq peak: Distance to summit (or peak center) Histone mark / Histone state: Distance to summit (or peak center) Errors, Warnings or Information messages 多注释问题 通常情况下，一个位点会出现多个注释信息，比如可能是一个基因的上游，也可能是一个基因的下游，或者一个基因有过个转录本，再或者位点本身就是 MNPs。既然是多个就有一个谁在前谁在后的问题，SnpEff 的规则是影响大的在前，突变有害的在前，实在没得挑了，按照基因位置排序。如果一个位点有很多条注释信息并不利于我们进行后续统计，这是可以使用软件本身提供的一些脚本进行处理。 如果想保留所有的注释信息，可以让每一个注释信息独立一行 cat filtered_freeabyes_anno.vcf |/home/zf/software/snpEff/scripts/vcfEffOnePerLine.pl |less 也可以每个变异只保留第一条注释 cat filtered_freeabyes_anno.vcf |/home/zf/software/snpEff/scripts/vcfAnnFirst.py |less 进行 regulatory 或者 non-coding 注释 annovar 这个软件也还行，不过用起来没有 SnpEff 那么顺手，一是需要转换一下 vcf 文件变成软件支持的格式，二是生成的结果文件比较简单（是缺点但是有时候也是优点），三是生成数据库的时候需要对注释文件进行一些转换，格式但凡有些问题就会很心累。当然，如果做的是人的研究不存在这个问题，而且关于人各种注释信息 annovar 都支持的非常好。 研究植物的话，无论基于基因还是位置的注释都需要自己生成 gff3 或者 bed 文件。 使用过程主要有一下几个步骤。 生成注释数据库 和使用 SnpEff 类似的，首先准备好水稻两个版本注释的 gtf 文件和基因组文件。 首先要把 gtf 文件（如果是 gff 文件需要先用 gffread 转换成 gtf 文件）转换为 genepred 文件，话说这个 genepred 文件的有点还是非常之多的，介绍可以看我之前写的一篇博客。转换的工具是 gtfToGenePred，要想用这个软件，得先安装 kentUtils。多少有点麻烦。 # 转换rapdb文件 gffread transcripts.gff -T -o transcripts.gtf gtfToGenePred -genePredExt transcripts.gtf rap_refGene.txt # 报错 # transcripts.gtf doesn't appear to be a GTF file (GFF not supported by this program) # 转换 msu文件 gffread genes.gff3 -T -o msu.gtf gtfToGenePred -genePredExt msu.gtf msu_refGene.txt #正常 神奇不神奇，惊喜不惊喜！一样的命令，msu 的文件转换成功但是 rapbd 的就不行。于是查找原因。 head -n1 msu.gtf Chr1 MSU_osa1r7 exon 2903 3268 . + . transcript_id &quot;LOC_Os01g01010.1&quot;; gene_id &quot;LOC_Os01g01010&quot;; gene_name &quot;LOC_Os01g01010&quot;; head -n1 transcripts.gtf Chr01 irgsp1_rep exon 2983 3268 . + . transcript_id &quot;Os01t0100100-01&quot; 问题出来了，rapdb 转换的 gtf 文件少了两个 gene_id 和 gene_name，这是为什么呢？ 再看原始 gff 文件 msu Chr1 MSU_osa1r7 gene 2903 10817 . + . ID=LOC_Os01g01010;Name=LOC_Os01g01010 Chr1 MSU_osa1r7 mRNA 2903 10817 . + . ID=LOC_Os01g01010.1;Name=LOC_Os01g01010.1;Parent=LOC_Os01g01010 Chr1 MSU_osa1r7 exon 2903 3268 . + . ID=LOC_Os01g01010.1:exon_1;Parent=LOC_Os01g01010.1 rapdb chr01 irgsp1_rep mRNA 2983 10815 . + . ID=Os01t0100100-01;Name=Os01t0100100-01;Locus_id=Os01g0100100 chr01 irgsp1_rep five_prime_UTR 2983 3268 . + . Parent=Os01t0100100-01 chr01 irgsp1_rep five_prime_UTR 3354 3448 . + . Parent=Os01t0100100-01 chr01 irgsp1_rep CDS 3449 3616 . + 0 Parent=Os01t0100100-01 问题出来了，rapdb 的 gff 文件没有 gene 信息，也没有 gene_id，很尴尬。 sed 's/Locus_id/gene_id/;s/Name/gene_name/' transcripts.gff &gt; new.gff gffread new.gff -T -o new.gtf awk -F';' '{printf $1&quot;;&quot;$2&quot;;&quot;$2&quot;\\n&quot;}' new.gtf |sed 's/gene_id/gene_name/' &gt; rapdb.gtf gtfToGenePred -genePredExt rapdb.gtf rap_refGene.txt 到这里终于有了需要的基因注释文件 LOC_Os01g01010.1 Chr1 + 2902 10817 3448 10297 12 2902,3353,4356,5456,7135,8027,8231,8407,9209,10103,10273,10503, 3268,3616,4455,5560,7944,8150,8320,8608,9617,10187,10430,10817, 0 LOC_Os01g01010 incmpl incmpl -1,0,0,0,2,1,1,0,0,0,0,-1, Os01t0100100-01 Chr1 + 2982 10815 3448 10297 12 2982,3353,4356,5456,7135,8027,8231,8407,9209,10101,10273,10503, 3268,3616,4455,5560,7944,8150,8320,8608,9615,10187,10430,10815, 0 Os01g0100100 incmpl incmpl -1,0,0,0,2,1,1,0,0,1,0,-1, 接下来是生成 m 的 fRNAasta 文件 retrieve_seq_from_fasta.pl --format refGene --seqfile ../msu_rice/sequences.fa msu_refGene.txt --out msu_refGeneMrna.fa retrieve_seq_from_fasta.pl --format refGene --seqfile ../rap_rice/sequences.fa rap_refGene.txt --out rap_refGeneMrna.fa 然后把这两个文件分别放在 annovar 下的 msu 和 rap 文件夹即可。 生成输入文件 convert2annovar.pl -format vcf4 filtered_samtools.vcf &gt; filtered_samtools.annovar.txt 根据基因信息进行注释 annotate_variation.pl -buildver msu filtered_samtools.annovar.txt /home/zf/software/annovar/msu/ --geneanno --outfil filtered_samtools.annovar 结果文件 filtered_samtools.annovar.variant_function intergenic LOC_Os01g01100(dist=1986),LOC_Os01g01110(dist=1684) Chr1 55398 55398 A G hom 38.415 2 exonic LOC_Os01g01380 Chr1 194123 194123 C T hom 39.4149 2 exonic LOC_Os01g01380 Chr1 194204 194204 C T hom 102 4 exonic LOC_Os01g01380 Chr1 194698 194698 C T hom 39.4149 2 filtered_samtools.annovar.exonic_variant_function line2 nonsynonymous SNV LOC_Os01g01380:LOC_Os01g01380.1:exon6:c.C260T:p.A87V, Chr1 194123 194123 C T hom 39.4149 2 line3 nonsynonymous SNV LOC_Os01g01380:LOC_Os01g01380.1:exon6:c.C341T:p.S114F, Chr1 194204 194204 C T hom 102 4 line4 nonsynonymous SNV LOC_Os01g01380:LOC_Os01g01380.1:exon6:c.C835T:p.L279F, Chr1 194698 194698 C T hom 39.4149 2 line5 synonymous SNV LOC_Os01g01380:LOC_Os01g01380.1:exon6:c.T894C:p.D298D, Chr1 194757 194757 T C hom 74 3 关于结果的解读可以参考官网，和 SnpEff 相比，variant_function 文件第一列是突变的位置，第二列是相关基因，后面就是输入文件。而 exonic_variant_function 则是专门针对外显子区域的突变进行注释。第一列的信息是在原始注释文件的行数，第二列是突变的种类，和 SnpEff 不同的是，如果有多个突变注释信息，annovar 只会根据突变的权重列出最重要的一个。 关于突变区域的解释 Value Default precedence Explanation Sequence Ontology exonic 1 variant overlaps a coding exon_variant (SO:0001791) splicing 1 variant is within 2-bp of a splicing junction (use -splicing_threshold to change this) splicing_variant (SO:0001568) ncRNA 2 variant overlaps a transcript without coding annotation in the gene definition (see Notes below for more explanation) non_coding_transcript_variant (SO:0001619) UTR5 3 variant overlaps a 5' untranslated region 5_prime_UTR_variant (SO:0001623) UTR3 3 variant overlaps a 3' untranslated region 3_prime_UTR_variant (SO:0001624) intronic 4 variant overlaps an intron intron_variant (SO:0001627) upstream 5 variant overlaps 1-kb region upstream of transcription start site upstream_gene_variant (SO:0001631) downstream 5 variant overlaps 1-kb region downtream of transcription end site (use -neargene to change this) downstream_gene_variant (SO:0001632) intergenic 6 variant is in intergenic region intergenic_variant (SO:0001628) 关于突变类型的解释 Annotation Precedence Explanation Sequence Ontology frameshift insertion 1 an insertion of one or more nucleotides that cause frameshift changes in protein coding sequence frameshift_elongation (SO:0001909) frameshift deletion 2 a deletion of one or more nucleotides that cause frameshift changes in protein coding sequence frameshift_truncation (SO:0001910) frameshift block substitution 3 a block substitution of one or more nucleotides that cause frameshift changes in protein coding sequence frameshift_variant (SO:0001589) stopgain 4 a nonsynonymous SNV, frameshift insertion/deletion, nonframeshift insertion/deletion or block substitution that lead to the immediate creation of stop codon at the variant site. For frameshift mutations, the creation of stop codon downstream of the variant will not be counted as &quot;stopgain&quot;! stop_gained (SO:0001587) stoploss 5 a nonsynonymous SNV, frameshift insertion/deletion, nonframeshift insertion/deletion or block substitution that lead to the immediate elimination of stop codon at the variant site stop_lost (SO:0001578) nonframeshift insertion 6 an insertion of 3 or multiples of 3 nucleotides that do not cause frameshift changes in protein coding sequence inframe_insertion (SO:0001821) nonframeshift deletion 7 a deletion of 3 or mutliples of 3 nucleotides that do not cause frameshift changes in protein coding sequence inframe_deletion (SO:0001822) nonframeshift block substitution 8 a block substitution of one or more nucleotides that do not cause frameshift changes in protein coding sequence inframe_variant (SO:0001650) nonsynonymous SNV 9 a single nucleotide change that cause an amino acid change missense_variant (SO:0001583) synonymous SNV 10 a single nucleotide change that does not cause an amino acid change synonymous_variant (SO:0001819) unknown 11 unknown function (due to various errors in the gene structure definition in the database file) sequence_variant (SO:0001060) 基于位置注释 基于位置注释有多种具体的思路，比如可以是组蛋白修饰区域，转录因子集合区域，或者是 miRAN 区域，也可以是基因组上的重复片段，还可以是基因组上一些特征区域比如启动子。 其中重复区域的注释比较重要，可以参考下面这段解释 Genetic variants that are mapped to segmental duplications are most likely sequence alignment errors and should be treated with extreme caution. Sometimes they manifest as SNPs with high fold coverage and probably high confidence score, but they may actually represent two non-polymorphic sites in the genomes that happen to have the same flanking sequence. 针对植物研究而言没有现成的数据下载，所以通常使用我们自己分析生成的 gff3 文件或者 bed 文件来进行注释。 比如我们利用 repeatmasker 软件找到了水稻中的简单重复区域，可以利用其生成的注释文件对我们的 vcf 结果进行基于位置信息的进一步注释。 说到 RepeatMasker 这个软件就再说两句，软件安装完成后利用以下命令，可以完成 repeat 的寻找 RepeatMasker -parallel 10 -species rice -gff -dir repeat rice.fa 会得到四个结果文件，其中 gff 和.out 文件是需要的，但是这个 gff 文件是 gff2 格式，并不是 annovar 要求的 gff3 格式（每一列必须有 ID=），虽然这个软件有一个脚本可以 out 文件改为 gff3，但还是不符合要求，需要讲结果文件的 Target=改为 ID= cat /home/zf/software/annovar/msu/rice_repeat.gff3|sed 's/Target=/ID=/' |cut -d' ' -f1 &gt;rice_repeat.gff annotate_variation.pl -regionanno -buildver msu -dbtype gff3 -gff3dbfile rice_repeat.gff filtered_samtools.annovar.txt /home/zf/software/annovar/msu/ --outfile filtered_samtools.annovar 注释结果: 在测试文件的 9 万个变异位点中，有 1088 个注释到了重复区域。 gff3 Score=14;Name=(AAT)n Chr1 444478 444478 - GTA hom 121 3 gff3 Score=14;Name=(AGGAA)n Chr1 528020 528020 - AAAGGGAAGAG hom 30.4183 1 gff3 Score=60;Name=(AT)n Chr1 563936 563936 A T hom 36.4154 2 gff3 Score=26;Name=(CAATAC)n Chr1 574725 574725 A G hom 36.4154 2 可以看出富集最多的重复区域是 A-rich cut -f2 filtered_samtools.annovar.msu_gff3|cut -d';' -f2|sort \\ |uniq -c |sed 's/ *//'|tr ' ' '\\t' |sort -k1,1nr|head 118 Name=A-rich 57 Name=(AT)n 40 Name=(TA)n 28 Name=GA-rich 16 Name=(TC)n 14 Name=(ATAT)n 14 Name=(ATT)n 12 Name=(AG)n 下一篇讲一些常用的下游分析 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-12-12-variant3annotation/"},{"title":"链特异性测序那点事","content":" 2021 年 12 月更新，距离写这篇文章已经过去 5 年了，但是今天发现这篇文章还会有人看。感慨一下。以及如果你只是想通过比对后的 bam 文件判断一下链特异性建库与否，这个文章太长了，直接去用RSeQC这个软件的 infer_experiment.py命令跑一下就好。祝好～ 本文最早写于 2017 年，时间略显久远，各位选择性吸收 关于链特异性测序的若干问题，很久以前就以为自己想清楚了，但是每次提起它的时候又容易重新产生各种各样的小困惑。于是整理一下，以免以后再时不时犯迷糊。很多东西就是这样，你以为的明白并不是真的明白，一年前的明白和一年后的明白也不是同一个明白。我这么说，不知道你能明白还是不明白。 RNA-seq 基本流程 下图是一个大概的 RNA-seq 基本流程 把 RNA 破碎成小片段，然后将 RNA 转变成一条 cDNA，这一步需要用到反转录酶 reverse transcriptase (RT) 才能用 RNA 作为模板合成 DNA。 不论是转录还是反转录都需要引物。通常如果我们要 mRNA，那就可以用 oligo-dT 作为 RT 的引物，但是用它有两个问题，第一个是只能反转录那些有 A 尾巴的 RNA，第二个问题是 RT 不是一个高度持续性的聚合酶，可能让转录提前发生终止，造成的结果就是 3'端要比 5'端 reads 富集，这样就会使得后续定量分析带来 bias。 另一种常用的引物称为随机引物，随机引物的好处是没有 A 尾巴的诸如 ncRNA 也被留下了，而且不会存在明显的 3'端偏差。但是很多研究也发现，所谓的随机引物根本就不随机，这也是测序结果中，通常前 6 个碱基的 GC 含量分布特别不均匀的原因。这几个碱基 GC 含量均匀很可能不是接头或者 barcode 那些东西，其实是 Illumina 测序 RT 这一步的 random hexamer priming 造成的 bias，很多人在处理数据的时候会把这几个碱基去掉，其实很多时候真多 RNA-seq 数据去不去掉基本什么影响，不过开头如果有低质量的碱基倒是应该去掉。 随后是第二条链合成，这一步用是 DNA 聚合酶，以刚才和成的第一条链作为模板。 接下来就是在序列两端加上接头，加接头一方面是为了让机器可以识别这些序列，把这些序列固定；二是为了让多个样品可以同时上机，平摊每个样品的测序价格。双端测序为了让 read 从两边开始延伸，也需要在两端有所需的引物。 Adapter element Requirement Location Function Amplification element Required 5′ and 3′ terminus Clonal amplification of the construct Primary sequencing priming site Required Adjacent to the insert Initiating the primary sequencing reaction Barcode/Index Optional 5′-end of the insert/Between the sequencing priming site and its respective amplification element Provides a unique label to sequences from different samples. Allows pooling of multiple experiments in a single sequencing reaction. Paired-end sequencing priming site Optional Adjacent to the insert on the side opposite of the primary sequencing priming site Sequencing into the insert on the end opposite of the primary read Index sequencing priming site Optional Complementary to the 5′-end of the sequencing priming site Sequencing of the index 所谓双端测序，因为很多时候 read 的长度要短于 insert，为了增加覆盖度于是就想出了从 insert 两端同时测序的办法。使得测序深度增加的同时也能够用来判断 isoform 方向。 对于 illumina 数据，有一条 5-3 的 universal adaptor；还有一条是 3-5 的 indexed adatpor，这条引物含有特意的 barcode。需要说明的是，在双端测序中，如果 insert 不是足够长，那么 R1 可能就会测到 R2 的引物，同时 R2 可能会测到 R1 引物的反向互补序列。 大概的意思就是下面两张图。 加了接头以后进行 PCR 的扩增。扩增后就开始测序，测序的过程如下图所示。 测序的基本思想是机器识别四种碱基发出的不同颜色的荧光，可以理解为一个 flow cell 立着非常多序列，机器一层一层扫过去，通过识别荧光而判断这一层每个序列的碱基是什么。 因为一个 cell 密密麻麻的全是荧光信号，机器并不是总能把每一个判断的非常准确，如果某一个荧光信号没有那么清晰，这个碱基的测序质量就比较低，如下图。 有的时候，如果一大片点都是同一种荧光，机器也可能犯晕，不知道到底哪一个荧光属于哪一个序列。这种情况尤其是在序列的前几个碱基容易发生。 The sequencing machine uses the first few bases to establish where the cDNA fragments are on the flow cell. If all of the bases in one part of the flow cell are all the same, like 'C', and all show up green in the picture, then the colors will bleed together and it will not be clear where exactly all of the reads are. In contrast, if you have a lot of different colors in a region, it's easier to determine where each one is, even with a little color bleed. 链特异性测序 和普通的 RNAseq 不同，链特异性测序可以保留最初产生 RNA 的方向，普通建库方式为什么不行呢？因为传统建库方式通过两个接头的 ligation 把 RNA 已经变成了双链 DNA，最后的文库中一部被测序的链对应正义链（sense strand），一部分被测序的链测是反义链。 链特异性建库方式有不止一种，对应到不同的软件又有不同的叫法，下面是几种称呼。要记住的是 dUTP 测序方式的名字是 fr-firstrand，也是 RF。 至于具体的 read 方向接下来通过更详细的 IGV 截图说明问题。 链特异性建库方式（以目前最常用的 dUTP 为例，如下图所示）首先利用随机引物合成 RNA 的一条 cDNA 链，在合成第二条链的时候用 dUTP 代替 dTTP，加 adaptor 后用 UDGase 处理，将有 U 的第二条 cDNA 降解掉。 这样最后的 insert DNA fragment 都是来自于第一条 cDNA，也就是 dUTP 叫 fr-firststrand 的原因。对于 dUTP 数据，tophat的参数应该为–library-type fr-firststrand。这里的 first-strand cDNA 可不是 RNA strand，在使用htseq-count 时，真正的正义链应该是使用参数-s reverse 得到的结果。 正正反反不清楚 说到链特异性测序，实在让人困惑的是各种链的概念，尤其是翻译成中文就更说不清了。 DNA 的正链和负链，就是那两条反向互补的链。参考基因组给出的那个链就是所谓的正链（forword），另一条链是反链（reverse）。但是这正反一定不能和正义链（sense strand）反义链（antisense strand）混淆，两条互补的 DNA 链其中一条携带编码蛋白质信息的链称为正义链，另一条与之互补的称为反义链。但是携带编码信息的正义链不是模板，只是因为它的序列和 RNA 相同，正义链也是编码链。而反义链虽然和 RNA 反向互补，但它可是真正给 RNA 当模板的链，因此反义链也是模板链。 总结两点 正义链（sense strand）= 编码链（coding strand）= 非模板链 forword strand 上可以同时有 sense strand 和 antisense strand。因为这完全是两个不同的概念。 写这篇文章的原因，就是因为有人问我，链特异性测序数据 htseq-count 的结果是不是应该把正负链的基因分别在-s yes 和-s reverse 两个参数结果中统计出来再做下游分析。这里犯的错误就是我们混淆了基因组正反链和基因正义反义链的概念。 dUTP 到底是怎么回事 从前文的一个图我们可以总结出dUTP 方式测序 R1 文件中 read1 的方向和基因的方向（正义链）是相反的，而 R2 文件中的 read2 方向和基因的方向是相同的。 可以参考下面的两个 igv 文件 bam 截图。 首先解释一下 igv 两个颜色参数的意义 Read strand in pastels, red for positive rightward (5' to 3') DNA strand, blue for negative leftward (reverse-complement) DNA strand, and grey for unpaired mate, mate not mapped, or otherwise unknown status. First-of-pair strand assignment is dependent on RNA transcript directionality and is useful for directional libraries. Displays reads or read pairs in which the forward read is first (F1 or F1R2) in red and reads or read pairs in which the reverse read is first (R1 or R1F2) in blue. Unknown status is in gray. For a given transcript, non-directional libraries will show a mix of red and blue reads aligning to the locus. Directional libraries will show reads of one color in the direction matching the transcript orientation. 下面这个图示按照 igv 颜色选项中的 read strand 方向进行区分，可以看到所有红色 read 都是在正链方向（注意正链不是正义链），而所有蓝色的 read 都是负链方向。下面基因的方向是正链方向，也就是和粉色的 read 同向的，如果你把鼠标放到随意一个粉色的 read 上，就能看到显示的信息是second of pair，也就是pair 中的 read2（R2）；反之如果你在蓝色的 read 上面，就会显示信息是 first of pair，也就是 R1 。 总结，dUTP 测序中 pair read 中的 read1（R1）和基因方向相反，read2（R2）和基因方向相同 再看下面这张图 这张图展示了两个基因 1 和 2，我们可以发现gene1 的正义链就在正链上，而gene2 的正义链其实是在反链上。看 read 情况，a，c 两个 read 虽然针对正链负链而言方向一致，都是负链方向，但是如果把a 是 pair 中的 read1（first of pair ），而c 是 pair 中的 read2（second of pair）。也就是说，read 方向一致，但一个是 read1 一个是 read2，说明这两个 read 对应的基因一定是反向的。同样的道理，虽然b，d 都是两个方向为负链的 read，但是 b 其实是所在 pair 的 read2（second of pair），而 d 是所在 pair 的 read1（first of pair）。 再次强调，dUTP 测序中 pair read 中的 read1（R1）和基因方向相反，read2 和基因方向相同 当使用 read strand 来进行颜色区分的时候，每一个基因上两种颜色的分布应该相对均匀（也就是所谓的 pair end）。 如果这个时候把颜色选项改为按照first of pair of strand来区分，会出现下图的变化。 geng1 的 read 全部变成了紫色，而 gene2 的 read 全部变成了粉色。 如果是非链特异性测序，在first of pair of strand模式下，同一个 gene 相关的 read 颜色也是明显混杂的。如下图\\ 再一次总结： dUTP 链特异性测序中，RNA 方向（gff 文件中基因的方向）与 read1 相反，与 read2 相同。如果 read1 比对到基因组正链上，则对应的 gene 在基因组负链；如果 read2 比对到基因组正链则对应的 gene 在基因组正链。 dTUP 测序方式叫做 fr-firstrand（留下的是 cDNA 第一条链），也是 RF。 如果 dUTP 链特异性测序，看基因表达量应该 counts for the 2nd read strand aligned with RNA(htseq-count option -s reverse, STAR ReadsPerGene.out.tab column 3 ) 如果想看反义链是否有转录本（比如 NAT）应该用 the 1st read strand aligned with RNA ( htseq-count option -s yes，STAR ReadsPerGene.out.tab column 4) 几个常用软件的设置 STAR mpping 时无需特别设置，但如果不是链特异性数据且下游分析要用到 cufflinks 则需要增加参数 --outSAMstrandField intronMotif。为的是增加一个 XS 标签。 If you have stranded RNA-seq data, you do not need to use any specific STAR options. Instead, you need to run Cufflinks with the library option --library-type options. For example, cufflinks... --library-type fr-firststrand should be used for the standard dUTP protocol, including Illumina’s stranded Tru-Seq. hisat2 --rna-strandness RF 目的也是给比对序列添加一个 XS 标签以区分方向，方面 cufflinks 使用。 For single-end reads, use F or R. 'F' means a read corresponds to a transcript. 'R' means a read corresponds to the reverse complemented counterpart of a transcript. For paired-end reads, use either FR or RF. With this option being used, every read alignment will have an XS attribute tag: '+' means a read belongs to a transcript on '+' strand of genome. '-' means a read belongs to a transcript on '-' strand of genome. tophat --library-type option fr-firststrand 具体解释参见下表 Library Type Examples Description fr-unstranded Standard Illumina Reads from the left-most end of the fragment (in transcript coordinates) map to the transcript strand, and the right-most end maps to the opposite strand. fr-firststrand dUTP, NSR, NNSR Same as above except we enforce the rule that the right-most end of the fragment (in transcript coordinates) is the first sequenced (or only sequenced for single-end reads). Equivalently, it is assumed that only the strand generated during first strand synthesis is sequenced. fr-secondstrand Ligation, Standard SOLiD Same as above except we enforce the rule that the left-most end of the fragment (in transcript coordinates) is the first sequenced (or only sequenced for single-end reads). Equivalently, it is assumed that only the strand generated during second strand synthesis is sequenced. htseq-count -s reverse/yes(看反义链) For stranded=no, a read is considered overlapping with a feature regardless of whether it is mapped to the same or the opposite strand as the feature. For stranded=yes and single-end reads, the read has to be mapped to the same strand as the feature. For paired-end reads, the first read has to be on the same strand and the second read on the opposite strand. For stranded=reverse, these rules are reversed. RSEM --forward-prob 0（正义链）1（看反义链） The RNA-Seq protocol used to generate the reads is strand specific, i.e., all (upstream) reads are derived from the forward strand. This option is equivalent to --forward-prob=1.0. With this option set, if RSEM runs the Bowtie/Bowtie 2 aligner, the '--norc' Bowtie/Bowtie 2 option will be used, which disables alignment to the reverse strand of transcripts. (Default: off) Probability of generating a read from the forward strand of a transcript. Set to 1 for a strand-specific protocol where all (upstream) reads are derived from the forward strand, 0 for a strand-specific protocol where all (upstream) read are derived from the reverse strand, or 0.5 for a non-strand-specific protocol. (Default: 0.5) sXpress --rf-stranded / --fr-stranded(看反义链) --fr eXpress only accepts alignments (single-end or paired) where the first (or only) read is aligned to the forward target sequence and the second read is aligned to the reverse-complemented target sequence. In directional sequencing, this is equivalent to second-strand only. --rf eXpress only accepts alignments (single-end or paired) where the first (or only) read is aligned to the reverse-completemented target sequence and the second read is aligned to the forward target sequence. In directional sequencing, this is equivalent to first-strand only. trinity --SS_lib_type RF Trinity performs best with strand-specific data, in which case sense and antisense transcripts can be resolved. RF: first read (/1) of fragment pair is sequenced as anti-sense (reverse(R)), and second read (/2) is in the sense strand (forward(F)); typical of the dUTP/UDG sequencing method. 参数错了又怎样？ 到这里，会想问两个问题。有时候我们不知道数据的建库方式是不是链特异性的，如果弄错了结果会怎么样呢？ 如果你用 STAR mapping 完可以用 igv 像上文提到的那样，看看是不是链特异性测序。 下面是两个真是数据的 count 统计情况。 对于仅仅进行基因表达定量来说，把链特异性数据当作普通建库数据来处理，可以观察第 2 列数据和第 4 列数据。具体某一个基因而言，影响不会太大，因为绝大多数反义链本身表达量就非常低。 不过可以注意 noFeature 和 ambiguous 这两个值，因为基因组中存在两个基因分别在正链和负链且又重叠的情况，不区分方向会比区分方向的 ambiguous 数目多一些。因为如果不能通过方向来区分到底属于哪个基因，这样的 read 就会被认为是 ambiguous。 但是因为区分了方向，又会使得 noFeature 的数目更多一些。不过两者总体影响不会差别非常大。如果不能判断建库方式，在 htseq 中使用-s no 参数是一个比较保险（虽然不是非常精确）的做法。 -s no -s yes -s reverse N_noFeature 1290001 16837194 1480658 N_ambiguous 633021 16413 74710 AT1G01010 58 2 56 AT1G01020 65 0 65 AT1G03987 5 5 0 AT1G01030 296 5 291 AT1G01040 901 5 1078 AT1G03993 0 182 0 AT1G01050 428 0 434 AT1G03997 1 7 0 AT1G01060 85 0 85 AT1G01070 73 0 73 AT1G04003 0 0 0 AT1G01080 1166 15 1151 AT1G01090 2901 0 2901 AT1G01100 1560 0 1560 AT1G01110 82 0 82 AT1G01120 484 0 484 AT1G01130 72 9 63 AT1G01140 518 3 515 AT1G01150 0 1 0 AT1G01160 356 192 551 AT1G04007 4 189 0 AT1G01170 55 11 423 相反，如果把普通建库方式的数据当作链特异性数据来处理。 比如在 htseq-count 中使用了-s reverse 参数，这个时候只有 R2 方向和基因方向相同的 pair 才用来算作一个 count，所有 R2 和基因方向不同的 pair 就被当作 no feature 了。这样的结果影响可以通过下面的表格观察。 用正常方法数出的 noFeature 是 6 万左右，而用-s yes 或者 reverse 数出来的 noFeature 就接近 46 万了。将近 40 万的 read 被丢掉。 所以，如果把普通建库的数据误当作链特异性数据来处理极有可能会损失大量的数据，如果弄错了链特异性建库的方式，那可能你就没几个 read 剩下了。另外，计算出来的结果自然也会有非常大的差异，是不准确的。 -s no -s yes -s reverse N_unmapped 729831 729831 729831 N_multimapping 443861 443861 443861 N_noFeature 63787 4591673 4599916 N_ambiguous 594720 27992 27789 AT1G01010 101 54 47 AT1G01020 84 41 43 AT1G03987 1 0 1 AT1G01030 80 37 43 AT1G01040 499 279 293 AT1G03993 0 33 25 AT1G01050 634 312 337 AT1G03997 0 0 0 AT1G01060 3274 1644 1630 AT1G01070 97 43 54 AT1G04003 0 0 0 AT1G01080 585 303 282 AT1G01090 1768 907 861 AT1G01100 1132 549 583 AT1G01110 60 21 39 AT1G01120 1099 573 526 参考资料 1 参考资料 2 参考资料 3 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-11-11-ssrna/"},{"title":"shell 脚本应知应会","content":"基本介绍 shell 脚本通常是一个以 shebang 起始的文本文件 #!/bin/bash 其中#!位于解释器路径之前。/bin/bash是 Bash 的解释器命令路径。 还有一种常见的写法是#!/bin/bash -ex这里的-e 类似于在第二行写set -e其意义是Exit immediately if a command exits with a non-zero status. ；而-x 的意思是Print commands and their arguments as they are executed. 终端打印 echo echo 加或者不加单双引号都可以打印 echo 后面的内容，默认情况下 echo 在每次调用后会添加一个换行符。 不加双引号的问题是不能显示 echo 后的; ，单引号中变量替换无效。 echo 同样接受双引号字符串内的转义序列作为参数。如果需要使用转义序列，则采用 echo –e &quot;包含转义序列的字符串&quot;这种形式。 $ name=dou; echo -e &quot;my name is\\t$name&quot; my name is dou 有的时候编写脚本需要在不同的命令之间输出一些信息给用户进行提示，这个时候如果能输出不一样的颜色或者背景会比较醒目。打印彩色输出可以使用如下方式。 下面是一些常用颜色的对应码 字体 重置=0，黑色=30，红色=31，绿色=32，黄色=33，蓝色=34，洋红=35，青色=36，白色=37 背景 重置=0，黑色=40，红色=41，绿色=42，黄色=43，蓝色=44，洋红=45，青色=46，白色=47 打印彩色字体 echo -e &quot;\\e[1;32m This is green text \\e[0m&quot; 打印彩色背景 echo -e &quot;\\e[1;42m This is green text \\e[0m&quot; printf 我们可以在 printf 中使用格式化字符串，还可以指定字符串的宽度、左右对齐方式等。在默认情况下，printf 并不像 echo 命令一样会自动添加换行符，我们必须在需要的时候手动添加。 举例如下 $ printf &quot;%-5s %-10s %-4.2f\\n&quot; 1 Sarath 80.3456 1 Sarath 80.35 %s、%c、%d 和%f 都是格式替换符，%-5s的含义是左对齐且宽度为 5，%-4.2f\\n 的含义是浮点数且宽度为 5 保留两位小数。 变量 var=value var 是变量名，value 是赋给变量的值。如果 value 不包含任何空白字符（例如空格），那么它就不需要使用引号进行引用，否则必须使用单引号或双引号。在变量名之前加上$前缀就可以打印出变量的内容。以在 printf 或 echo 命令的双引号中引用变量值。 export命令用来设置环境变量。至此之后，从当前 shell 脚本执行的任何应用程序都会继承这个变量。我们可以按照自己的需要，在执行的应用程序或者 shell 脚本中导出特定的变量。 添加环境变量 日常，安装各种软件是最常见的事情。当你必须使用源代码编译生成程序并将其安装到某个特定路径中时，有项极其常见的任务就是将该程序的 bin 目录加入 PATH 环境变量。 我们可以在自己 home 目录下的.bashrc文件添加一些路径，以指定二进制文件或者库文件，让每次 shell 启动时执行，例如： PATH=&quot;$PATH:/home/user/bin&quot; export PATH #### 或者 export PATH=/opt/myapp/bin:$PATH export LD_LIBRARY_PATH=/opt/myapp/lib;$LD_LIBRARY_PATH 如果只是在当前 shell 执行，可以写一个函数放在bashrc 中 addpath() { [ -d &quot;$2&quot; ] &amp;&amp; eval $1=\\&quot;$2\\$\\{$1:+':'\\$$1\\}\\&quot; &amp;&amp; export $1 ; } 使用addpath PATH /add/path 可以快速把一个路径添加到当前 shell 中 数学运算 shell 不像 R 可以天然支持各种数学计算，但是可以利用 let、(( )) 和 [] 执行基本的算术操作。而在进行高级操作时， expr 和 bc 这两个工具也会非常有用。 let 命令可以直接执行基本的算术操作。当使用 let 时，变量名之前不需要再添加$。 #!/bin/bash no1=4; no2=5; let result=no1+no2 echo $result #自加 let no1++ let no+=6 # [] result=$[ no1 + no2 ] bc 可以进行浮点数运算的高级函数，通过scale 设定小数精度 no=54; result=`echo &quot;$no * 1.5&quot; | bc` echo $result $ echo &quot;scale=4;3/8&quot; | bc .3750 echo &quot;sqrt(100)&quot; | bc #Square root echo &quot;10^10&quot; | bc #Square 文件描述符及重定向 在编写脚本的时候会频繁使用标准输入（stdin）、标准输出（stdout）和标准错误（stderr）。通过内容过滤将输出重定向到文件是我们平日里的基本任务之一。当命令输出文本时，这些输出文本有可能是错误信息，也可能是正常的（非错误的）输出信息。单靠查看输出的文本本身，我们没法区分哪些是正常，哪些是错误。 这个时候可以通过文件描述符来解决问题。 0 标准输入 1 标准输出 2 标准错误 当一个命令发生错误并退回时，它会返回一个非 0 的退出状态；而当命令成功完成后，它会返回数字 0。退出状态可以从特殊变量$? 中获得（在命令执行之后立刻运行echo $?，就可以打印出退出状态） 分别重定向输出和错误可以使用cmd 2&gt;stderr.txt 1&gt;stdout.txt ；重定向到一个文件可以使用cmd 2&gt;&amp;1 output.txt 不查看输出内容或者错误，可以重定向到“垃圾桶”/dev/null 中。 tee 可以在显示输出的时候，将输出内容重定向到一个文件，但是需要注意的是，错误信息是不会保存到重定向的文件中的，tee 只能接受 stdout。如果像追加操作而非覆盖的话，需要使用 tee -a 参数。 将脚本内部的文本块进行重定向 有时候需要在脚本中输出大量内容，可以使用cat&lt;&lt;EOF&gt;&gt; #!/bin/bash cat&lt;&lt;EOF&gt;log.txt LOG FILE HEADER This is a test log file Function: System statistics EOF # 两个 EOF 之间的内容会写进 log.txt # 如果不指定文件，会直接打印到屏幕 数组 数组是 shell 脚本非常重要的组成部分，它借助索引将多个独立的数据存储为一个集合。普通数组只能使用整数作为数组索引，关联数组可以使用字符串作为索引。 定义数组array_var=(1 2 3 4 5 6) 调用某个数组元素echo ${array_var[0]} 调用所有元素 echo ${array_var[*]} 调用数组长度 echo ${ #array_var[*]} 调用数组索引 echo ${!sample_names[*]} 获取、设置日期和延时 用格式串结合 + 作为 date 命令的参数，可以按照你的选择打印出对应格式的日期。 $ date &quot;+%d %B %Y&quot; 21 October 2017 检查命令花费的时间，可以把开始和结束时间嵌入写好的脚本头和尾 #!/bin/bash start=$(date +%s) commands; statements; end=$(date +%s) difference=$(echo &quot;scale=2;($end-$start)/60&quot; | bc) echo Time taken to execute scripts is $difference mins 脚本中生成延时 使用 sleep 函数，sleep 1m 延迟 1 分钟 shell 脚本调试 shell 的调试相对简单和单调。可以使用 set -x 和 set +x 对脚本进行部分调试。 对于想要输出的命令的区域，可以限定在 set -x 和 set +x 之前 函数与参数 定义函数： # 定义函数 function fname() { statements; } # 使用函数 fname arg1 arg2 例如 fname() { echo $1, $2; #访问参数 1 和参数 2 echo &quot;$@&quot;;#以列表的方式一次性打印所有参数 echo &quot;$*&quot;; #类似于$@，但是参数被作为单个实体 return 0; #返回值 } 退出状态 查看命令是否成功执行，如果成功退出则推出状态为 0。 #!/bin/bash fastqc input.bam if [ $? -eq 0 ]; then echo &quot;fastqc executed successfully&quot; else echo &quot;fastqc terminated unsuccessfully&quot; fi 输出变输入 使用管道（pipe）连接每个过滤器 cmd1|cmd2|cmd3 字 shell 和反引用 # 子 shell ouptup=$(commands) # 反引用 output=`commands` 读取键盘输入 如果用户不知道你写的脚本怎么用，那么我们可以提示用户在直接运行脚本后进行参数的输入。 在 shell 中，我们可以使用 read 直接读取键盘输入。 # 让用户输入内容 read -p &quot;input fastq file name: &quot; inputfile fastqc $inputfile read -p &quot;are you sure to continue(y/n): &quot; judge if [ &quot;$judge&quot; == &quot;y&quot; ] then echo ok coutine else exit 0 fi 重复命令直到成功 有些命令比如（下载），可能需要重复执行指导成功，可以使用 whil 来构造函数进行判断 repeat() { while :; do $@ &amp;&amp; return; sleep 30; done } # : 是 shll 内建命令每次会返回退出码 0 # $@ 表示输入的所有命令和参数 ### 增加延时尝试 waitrepeat() { while :; do $@ &amp;&amp; return; sleep 30s; done } 字段分隔符和迭代器 IFS shell 中内置的字段分隔符，IFS 的默认值为：空白（包括：空格，tab, 和新行），当文件中的分隔符是逗号或者其他是就需要使用到 IFS oldIFS=$IFS IFS=, for item in $data; do echo Item: $item done IFS=$oldIFS 使用循环进行迭代 # for for var in list do commands #使用变量$var done for((i=0;i&lt;10;i++)) { commands; #使用变量$i } # while while condition do commands; done # until 直到条件为真时执行 x=0; until [ $x -eq 9 ]; do let x++; echo $x; done 比较测试 我们可以用 if、if else 以及逻辑运算符进行测试，用比较运算符来比较数据项。除此之外，还有一个 test 命令也可以用于测试。 if 判断 # if 条件 if condition; then commands; fi # else if 和 else if condition; then commands; else if condition; then commands; else commands; fi 算数比较 条件通常被放置在封闭的中括号内，且一定要注意在 [或] 与操作数之间有一个空格。 [ $var -eq 0 ] #当 $var 等于 0 时，返回真 [ $var -ne 0 ] #当 $var 为非 0 时，返回真 # 其他 -gt：大于 -lt：小于 -ge：大于等于 -le：小于等于 文件系统 [ -f $file_var ]：如果给定的变量包含正常的文件路径或文件名，则返回真。 [ -x $var ]：如果给定的变量包含的文件可执行，则返回真。 [ -d $var ]：如果给定的变量包含的是目录，则返回真。 [ -e $var ]：如果给定的变量包含的文件存在，则返回真。 [ -c $var ]：如果给定的变量包含的是一个字符设备文件的路径，则返回真。 [ -b $var ]：如果给定的变量包含的是一个块设备文件的路径，则返回真。 [ -w $var ]：如果给定的变量包含的文件可写，则返回真。 [ -r $var ]：如果给定的变量包含的文件可读，则返回真。 [ -L $var ]：如果给定的变量包含的是一个符号链接，则返回真。 字符串 使用字符串比较时，最好使用双中括号。 [[ $str1 == $str2 ]]：当 str1 等于 str2 时，返回真。 [[ $str1 != $str2 ]]：如果 str1 和 str2 不相同，则返回真 [[ -z $str1 ]]：如果 str1 包含的是空字符串，则返回真。 [[ -n $str1 ]]：如果 str1 包含的是非空字符串，则返回真。 逻辑运算符 &amp;&amp; 逻辑与 || 逻辑或 if [[ -n $str1 ]] &amp;&amp; [[ -z $str2 ]] ; then commands; fi test 如果不想写括号，可以使用 test if test $var -eq 0 ; then commands; fi 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-22-shellscript1/"},{"title":"经济学周记 15-权利的保护","content":"产权的兴起 人类社会需要产权安排 外部性；人口的集聚 权利的安排带来的好处足够大，才会关心怎样界定产权，行使产权 产权兴起动力之一：外部性 地理位置：打猎区域，三文鱼产权界定 牛仔与铁丝网，美国西南部 产权兴起动力之二：人口集聚 铁路公司申请建立黄石公园 人与人之间越来越紧密联系 陌生人之间需要进行协调 人与人之间为了争夺猎物，产生了产权安排的需求 人与人的集聚，陌生人之间的合作，产生了对产权和制度安排的需要 产权：使用权，收益权和转让权 产权的三个要素 使用权：决定如何去使用 使用权和所有权：一份资产，两种说法，各自表述，互不影响 国有土地的使用权可以转让 使用权和所有权可能是分工，可能是不同条件下的使用权。是一份资源不同侧面和环节的使用和沟通 收益权 转让权 只有完全拥有资产，才能一次性的转让使用权和收益权 从产权的角度看，是不是真正拥有某钱物品最好的测试方法是能不能卖出去 产权保护原则之一：财产原则 《财产原则，责任原则与不可让渡性：大教堂的一个视角》 财产原则 一个人想要剥夺别人的所有权只有一个办法，就是向原来的所有权持有者付费，付到原来的所有权持有者愿意放弃为止。 如果只有这种办法才能把所有权从别人手里拿过来的话，就说这种产权是根据“财产原则”进行保护的。 政府只对财产权进行了一次干预：确权。对转让的价格和条款没有任何影响 责任原则 当一个人侵害了别人的产权以后，侵害者就要向原来的产权所有者进行赔偿，但是赔偿的金额不由原来的所有者定，而由第三方定 财产原则是产权交换的时候由财产权人自己定价，而这个“责任原则”是由第三方定的。 在实施“责任原则”的时候，政府干预了两次：第一是确权；第二是对产权的定价作出裁决。产权的价格不由财产权的原来所有者决定，而是由第三方决定，这叫责任原则 责任原则下，政府对财产权的保护做了两重的干预。第一是确权；第二是当发生侵权行为的时候政府来决定赔偿的金额。 不可转让原则 政府禁止所有权人把他所拥有的资产卖给别人 在不可转让原则下面，政府对财产权的保护进行了三重干预 第一，确权 第二，如果产生侵权的行为，那么由政府决定这个侵权的赔偿金额 第三，政府还禁止原来的产权所有者出让他的产权，不准卖，这也是一种保护 哪种更好 在交易费用非常高的情况，没办法进行事前议价，进而使用责任原则 由于交易费用，大量产权不能通过财产原则保护，只能通过责任原则保护 为什么要惩罚刑事犯罪 伤害了别人 改变了规则：使原本可以根据财产原则保护的资产变得只能通过责任保护 使用共诉的方法 产权保护原则之二：责任原则 码头紧急避险案 保护财产权用哪一种原则，主要是看交易费用。 申请禁制令是用财产原则对所有权进行保护 现代产权案件中的责任原则 软件多用第三方定价，责任原则进行赔偿 炉具公司诉美国铁路运输公司 法律可以把人送回以前的世界 赔偿所有的运输费用和食宿费用，仿佛一切没有发生过。（责任赔偿） 产权保护之三：不可转让原则 政府进行三重干预 确权 侵权时，第三方决定侵权行为赔偿方式 产权所有者本身也无权转让自己的产权 原因 买卖引起社会很大的麻烦，禁止买卖土地给外国人 威胁现存的道德观 父爱主义：政府感觉自己比个人更了解他们的利益所在 认为农民会卖土地 自我执行的父爱主义：自己对自己信不过。 一个人上好几个闹钟 知道自己在某个时刻和情形下就会失去理智 摩尔诉加州大学董事会案（1990 年） 背景 有白血病，切除胰脏 医生有权处理切除的胰脏 医院用这个器官开发了新药 病人上诉 中级法院认为人对器官有所有权 有权分占部分收益 但是宪法没写人有还是没有对自己器官的所有权 如果判病人赢等于承认个人具有兜售个人器官的权利 法官不该主动立法 加州最高法院 原告不具有买卖器官的权利 如果没有所有权挣不了钱 对研发没贡献但是因为独特的细胞本身包含一定的租值会引发抢购 如果器官有卖买 成本：放弃了的最大代价 器官移植变成可能再租值销售的成本就增加 如果合法化，死人的沉默成本不是成本，可以成为供应最大群体 减少医药费开支 移植器官所产生的需求 毒贩反对毒品合法化 如果合法化吸毒的人可能增加也可能减少 非自愿吸毒的人数会下降 毒贩的犯罪天赋派不上用处 加州大麻合法化：经济力量的考量 一周总结 产权界定的两种方法：存量法与流量法 存量法 谁发现了金矿，整个金矿归谁 合理分配开发时间，安排节奏 流量法：谁挖到了金子，金子归谁 专利池降低竞争成本 国有资产不是明确的资产 经济学角度看惩罚：惩罚的力度=违法造成的伤害/违法被逮住的机会 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-21-econote15/"},{"title":"经济学周记 14-价格辨析","content":"权利有别于能力 权利有别于权力：权利是文明的产物 权利的定义：权利是要由社会来保障实行的，是别人对你的认可，不是你自己认为有就有，是别人认为你有、别人愿意出来保护你行使的，那才叫权利。这是权利的特征，这是人类社会跟动物社会区别的地方。 能力有别于权利 能力，Might 权利，Right。 在动物世界里面，你看到的只有能力，没有权利 能力取决于自己能够占有多少，而权利取决于别人、社会的其他人愿意给你多少。 权利是人赋 “人赋权利”是一种实证观点 实证：是什么，是怎么样，目前是怎么样，客观的描述 规范：应该怎么样 独生子女政策：没有生二胎的权利（实证的角度），应不应该有另当别论 权力从哪里来 《Rights from Wrongs》德肖维茨：辛普森杀妻案律师 权利不来自于神 权利不来自于自然：自然本来就是中性的，没有客观价值的，不带有主观价值倾向的。 权利不来自于逻辑：永真的逻辑不带来任何知识，公理来自于法律；逻辑不会告诉我们任何关于世界应该怎么去管制、怎么去运行的知识。 权利不来自于法律：法律是有了权利以后对权利的一种体现。 权利来自于人类的经验教训 权利来自于人类的经验，尤其是那些惨痛的经验、巨大的错误。 权利来自于错误，正确来自于错误。 我们过去惨痛的教训，让我们一点一点地前行，一点一点地改变我们的社会制度安排。 理所当然的权利本身之间就存在冲突 言论自由和不受冒犯的权利 界定权利：当我们要使用的资源，产生的效应和别人冲突的时候才会界定权利 权利需要他人的认可和执行 自杀权的问题 阿尔钦对“产权”的解释：产权是一种通过社会强制而实现的，对某种经济物品的多种用途进行选择的权利。 自由不等于免费（free） 财产权利与政治权利同样重要：《果脯园购物中心诉罗宾斯案》 行使权利所动用的资源并不免费 言论自由：政治的权利 形式政治权利，要动用经济资源，经济资源本身有主。他们也有权利和产权 政治上的权利要和经济的产权保护有所区分 经济权利是人的基本权利 阿尔钦观点 私有产权与人权并不冲突，都是人权。 私有产权是人们使用和交换特定物品的人权。如果产权的行使受到抑制，那权力会朝着其他方向倾斜。 如果在产权上的保护不平等，那人们在别的权利上也就不平等。 产权重要的原因：产权保护个人自由。 弗里德曼观点 批评公共政策只是一份兼职，只是一份业余爱好，你必须有一份正职，你要找一份工作，你要有稳定的收入来源。 以批评公共政策为生，如果没有稳定的收入，最后你的观点也靠不住，也不够客观。 真正能够不偏不倚表达自己观念的人，是一个功成名就、在私立大学任教、行将退休的老教授 人只有做到这样的地步，你说起话来才有底气，才不会受其他的因素干扰。 要行使政治的自由，经济基础也非常重要。 产权保护是物理属性 世界上不存在绝对的产权 世界上不存在绝对的产权：菜刀不能杀人 权利是减下去的 权利是加起来的 法无禁止则可为；法无准许不可为 权利不等于福利 第一波基本权利：自由迁徙，生育，职业选择 第二波基本权利：就业权，免费享受教育权，免费享受医疗 天然享受需要有人来提供 如果天然有权享受福利，那谁有义务来提供这些福利 中国经济成就来源于人权大幅改进：就读和就业的自由 产权保护的是物理价值：只保护资产物理属性，不保护经济价值 物联网约车不需要牌照 波斯纳：法律经继学家《法律经济学分析》 新技术和商业模式诞生，老一代会式微甚至消失 一周总结 天赋人权动听但不能相信 权利很明显不是天赋的 随着时间的变化 随着约束条件的变化 随着相关利益者博弈的力量的变化而衍生、 权利是在变化当中争取来的 看清楚这个世界的真实一面：人生而平等是人们追求的目标 财富状态不同，积累不同，做坏事所付出的代价就不同 浏览器广告拦截：权利博弈，浏览器弹窗是不是物理属性？ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-21-econote14/"},{"title":"经济学周记 13-价格教益","content":"房价上涨好不好 无论房价涨跌都不应该人为管制 北京的限购政策 价格是现实的一个反映。反映的现实是多方面的 仅仅按住价格，并不能改变价格所反映背后的现实 好比你管不住温度，却非要去管温度计一样荒唐 房价上涨的正面因素 大城市房价上涨的原因是聚集：房子以外是更好的服务 对大城市抱怨最多的就是生活在里面的人 对美国人而言穷人和富人的区别在于位置：好的位置带来不同的人，经历和机会；重要的不是你是谁，而是你跟谁在一起。 不要以为你非得有天大的本事，才能够在大城市里面立足 人与人之间讲究的，不是你个人的本事有多大，而是你的本事跟别人的本事能不能相匹配，你们之间能不能够互相服务 人口集聚提高大城市的经济效率 城市化的进程还没有结束 住房的需求就还会增加 日本的 GDP 基本都来自三个大城市 房价上涨的负面因素 交易不灵活不频繁 房屋容积率的限制太大 廉价保障房其实更贵 通过各种限制来解决房价上涨的问题是不现实的：人总有想用的对策，比如假离婚 房屋限购只能让实际房价更高 盖房子的人不赚钱了自然就不盖了 新楼盘数量减少，总量下降 供需矛盾加剧房价上涨 住房市场化让人们买房更容易：有房才能结婚其实是因为买房更容易 提供廉价住房将减少社会流动 住房并不是一个标准品 绑在廉租房限制了流动 廉价保障法不是免费午餐 政府用的越多，私人用的更少，谁能把这个地方用的更好 没有使用需求就没有投资需求 不让富人买房，穷人就能买房，可能房子早就少了。 空置率不可能客观衡量和计算 有两个小房子比有一个大房子的人可能做的贡献更大 下有对策用来减少空置率 房屋是一个综合的服务 任何价格管制都不能成功 凡是政府要进行价格管制的地方，人们就总有不同的对策，绕过他们的管制 学费不超过一个数值可以分出其他各种费用 使用需求是投资需求的基础 所有的投资需求都是以实际的使用需求为基础的 没有实际使用的需求就不会有投资需求 出高价做投资，是人们表达不同意见的一个和平有效的方法（投资的真谛） 价格是高度分权的结果 大城市平均房价还有上升余地 供给和需求决定论：集聚程度远远没有完成 房价决定了地价而不是地价决定了房价 房价上涨有正面原因 问题：容积率不够高，交易不够频繁 不应该把投资需求和使用需求对立起来 中美房价租售比的差异 房子买还是不买？中国的房屋租售比要比美国低得多 如果要的仅是居住服务，那你租房要比买房合算多了。 如果你买房还看中这套房子可能附带的户口等功能则另当别论。 如果要投资的回报，就是需要去买房。 价格协调人与人的关系 价格有三个基本的作用 以最直接、最节俭、最有效的方式向有需要的人、向相关的人传递关于稀缺性的信号。 指导人们根据稀缺性的信号来安排生产的方式。 指导产品的分配 如何分饼能决定饼做多大 价高者得是最有效的竞争方式 出价的方式会是的资源消耗最低，不会带来无谓损失 努力赚钱换取服务会带来正面的负效应 过剩与短缺均源于价格的管制 不论是短缺还是过剩都不是因为供给或者需求发生变化，而是因为价格受到人为干预。 短缺是当价格被人为压低以后，人们不得不采取其他非价格的方式，才能获得他们的需求的一种现象。 过剩是那些卖东西的人，供给者不得不采取其他非价格的方式，才能把他们手头上的东西成功地卖出去的一种社会现象。 没有任何人可以控制市场价格：你的房子卖了一百万，这个钱不是你定的，是市场定的。 一周总结 什么样的城市房价上涨 房价持续上涨的地方是那些人口和资金净流入的城市，北上广深、杭州、成都、南京等等。 在这些城市里面，地段位置，包括距离市中心的距离、周边的学校、商圈等等，都能够决定房价的高低。 房价持续下降的地方，也就是人口和资金净流出的地方。人口净流出意味着需求减少，资金净流出意味着发展减缓。 原来我们今天过得那么好 享受服务，占有就不重要了 流量逻辑和存量逻辑 重要的市场指标有哪些：利率，汇率，价格 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-21-econote13/"},{"title":"经济学周记 12-价格管制","content":"春运火车票价还不够高 不承认火车票是商品属于鸵鸟心态：不管是否承认，火车票就是品，经济规律就会起作用。 春节回家不是刚需：看似刚需的原因是交通成本近年来下降。 黄牛党可以为社会节省无谓的损失 黄牛为什么不把价格抬得再高一点 之所以有黄牛就是因为价格不够高，进而展开价格意外的竞争——排队 人追求利润最大化——减少无谓损失（排队的时间） 实名制让火车票价格更贵 春节运力不可能做到毫不吃力 垄断商品不是反对市场定价的理由，一件商品不论是由垄断的企业提供的还是由竞争的企业提供的，它的价格都应该由市场来决定，它的定价都应该是市场价。只要它的定价不是市场价，就会出现短缺现象或者过剩现象，从而会引发“无谓的损失”。火车票定价应该参照航空公司的做法，只要用价格竞争的方式受到抑制，人们就不得不采用其他的非价竞争方式，对价格的管制越严格，人们所不得不采用的迂回方式就越浪费。本质问题还是能不能把自身的利益和客观的规律分开。 美国的房租管制 三位诺奖得主，1974 年获奖的哈耶克（Friedrich Hayek）、1976 年获奖的弗里德曼（Milton Friedman ）和 1982 年获奖斯蒂格勒 (George Stigler )，他们合写了一本书，名字叫做《房管制：神话与现实（Rent Control: Myths and Realities,1981 ）》 书中提到了以下内容： 地震能摧毁房屋，但不能制造短缺 旧金山的地震和大火并没有造成房屋短缺 价格可以波动：只要出价，就能够找到自己愿意找到的房子 价格管制可以制造房屋短缺 有房的不愿意租了，穷人更租不上房子 价格管制带来的负担让刚好成为房东的人来承担是有问题的 一个社会如果把个人的权利置于公平之上的话，那么这个社会运的结果，当然不会是公平的，但是它却离公平很近。 另一种社会，如果要把追求公平，放在追求保护个人的权利之上话，这个社会就既不能保证个人的权利，也不能达到所谓的公平。 每当要追求公平的时候，肯定会出现的结果是甲和乙两个人商量怎么逼着丙去替丁做一些事情，而甲和乙自己还从中分一杯羹。 解除价格管制 二战后的德国：物质匮乏，恶性通胀，价格管制。但是解除价格管制让商品一夜之间重回橱窗，采取了两种方法： 抓紧货币：废除不值钱的就马克，新的不乱发 放开价格：全国范围内接触价格管制 扩展资料：《制高点：世界经济之战》，对这个故事做了很生动的介绍，很值得去看一下（这是本片的视频链接：http://www.guokr.com/post/327264/ ）；周其仁：《改革的逻辑》 但是为什么我们的改革不可能一夜之间完成？德国有盟军来维护平稳；中国是自己革自己；大胆和沉着要平衡好。 食物补贴和货币补贴的权衡 左派经济学家詹姆士托宾，右派经济学家弗里德曼。 帮助穷人的最好方法：用金钱的方式进行补贴，同时让市场发挥己本身应该发挥的功能，而不是直接干预商品的价格。 政府给东西的原因 政府本身没钱可给，只好下命令。 政府有父爱主义：不愿意相信穷人，怕乱花钱 给相关商人优惠 公交补贴：钱给公交公司还是市民？补贴穷人的两种思路：补贴商品的供应商；直接补贴受益人。对大学教育的补贴也是这样的情况，导致学校只需要讨好政府而不用提高教学质量；大学的食堂也是这样的情况，钱直接给了餐厅。把钱给学生是更好的选择。 一周总结 为什么还有要价格管制 不患寡而患不均不是真实人性 傅里叶综合症：绝对平均主义的心态 人最重要的是看重自己的改进而不是跟别人的距离 人和别人的距离取决于自己的视野 政府维持管制的三大原因 维稳问题防止社会动荡 既得利益在起作用 人的无知引发了很多无谓的损失 为何取消火车票价折扣 火车票春节涨价不行，那就平时应该降价，最重要的是该有差价 高铁也有这样的策略 讨好老板和讨好客户的区别 讨好客户：积累自己的人力资本，对社会有正贡献 讨好领导：耗费自己的人力资本 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-20-econote12/"},{"title":"经济学周记 10-价格进阶","content":"世界上有哪些竞争规则 暴力是非常重要和常见地竞争规则 失败的时候人们会谴责 成功的时候会膜拜 今天大量的经济资源和壁垒都是由国家机器在背后支撑 靠智力高低竞争资源：考试是一个重要的竞争方式 以论资排辈界定产权 按照社会身份分配财产：职业；官位 按照劳动时间：先到先得与随机分配 按需分配与价高者得 规则不同禀赋不同的人机会不一样 各种竞争规则的优劣 没有所谓的哪一个更公平，不同的人有不同的公平观。竞争必须有规则，没有最公平，每当决定一个竞争的规则，本身都会带来成本。 竞争带来的成本，其他人难以得益。你排队花时间值得，但是其他人不可能从你排队浪费的时间得到好处。无谓的损失指社会其他人不能从中获得任何好处 按出价高低竞争可让社会财富高速增加，出价高低不是最公平的但是最有效率的。 人们会去努力赚钱 会从事积极有收益的服务 带来其他人也愿意付钱购买的商品或者服务 造成的无谓损失最小 为了得到自己想要的东西，必须生产别人也想要的东西 增加了社会的福利 何为短缺和过剩 稀缺和短缺的关系 稀缺是基本事实，好的东西不够，别人也要。如果一种商品用且只用价格高低来竞争，就永远不会短缺而是稀缺。只要出价就能买到，比如奔驰，蒂芙尼钻石。短缺是因为价格受到了抑制仅用出价的方法买不到，比如出租车短缺，出钱打不上车，春节火车票。 短缺需要使用价格以外的手段去竞争才能得到。短缺经济时代的现象：只要有人排队就去排，买什么不用管，因为时间是不值钱的。而过剩是价格被人为拔高的结果，过剩不是供给过多，而是价格受到人为哄抬。只有竞争，加上其他手段才能卖出去，现象是过剩，例如资本主义倒牛奶事件。 减少过剩方法 减少补贴 限制农民产量 自找门路去处理 最省事的违反价格管制 短缺时采用哪种非价格的竞争，《一种价格管制理论》（张五常），提出价格管制：管制不是收税，政府不要你的钱。但是价格管制必然导致价值耗散：资源用不到刀刃上。 人是追求损失最小化的动物：有了限制人自然会想办法。如何应对价格管制：只要政府要求房价下跌，房东会纵容自己的偏好选择租户；捆绑销售；房屋改造别的用途，不出租了。 一周总结 商家为什么舍弃价高者得 不同教育阶段的消费标准 不仅仅考虑价格并不意味着不考虑价格 选择伴侣不看收入，但是圈子已经筛选过了 美国石油短缺为何一夜消失：里根总统：解除一切针对石油产品的价格管制 执行困难的政策不是好政策：违反了价格规律 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-20-econote11/"},{"title":"为什么要写作","content":" 本文为生信技能树约稿，关于为什么要写作，为什么要坚持写。 我写作的经历 最早和健明认识的契机就是因为写作，那个时候给他看了两样东西： 8 篇 Circos 作图学习笔记 自己写的书《靠谱学长说》(https://book.kaopubear.top/) 称为书其实就是 2014 年底到 2015 年底大概一年时间我个人所写和考研相关的文章合集。 一年时间写了 200,000 字，那本合集里有 20 篇致考研人系列文章，11 篇答研友问性质的随笔，50 篇英语新闻学习笔记。仅仅是我自己的百度云加密分享链接已经显示浏览下载超过了 10,000 次，还不算其它的转发借 (chao) 鉴 (xi) 以及在 GitBook 开源之后的访问。如果你恰好是 14 年之后的考研人，真还不排除听说过“一只思考问题的熊”或者“靠谱学长说”的可能。 读研之后开始接触生物信息，写作重心也慢慢从自己的公众号转移到了技术型博客 (http://kaopubear.top)。目前博客已有（在更）的内容有统计学基础与 R 系列文章，Linux 学习系列文章，生物信息基础知识系列文章以及日常的各种实践心得和笔记。 总之，写作这个事从大学开始就没再停下。 为什么要写作 如果在 Google 或者任何一个写作平台（比如简书）搜索“为什么写作”都能搜到大量相关主题文章。全部翻下来，肯定逃不出整理思路，输出倒逼输入，分享结交朋友或者增加收入这么几个原因，当然我也不例外。 如果我不写文章，很多想法就无法整理成方法论进而帮助别人；如果我没写过《靠谱学长说》，就不可能认识健明或者加入生信技能树，如果没有加入生信技能树就没办法认识更多优秀的人；如果我没写过那么多文章就很难让别人知道我，然后在曾经一段时间内通过合理的方式合理地割韭菜。 不过，在这里想聊些更深层次或者更实际的原因。 如果你想整理思路，记笔记存到本子上是一样的；如果想结交朋友方法也多的是，比如给那些作者持续小额打赏然后加个小密圈；如果想增加收入……呃，对于大多数人来说别想了，不存在的。如果你能想出 100 个类似的写作理由，也就能想出 100 个对应的不写作理由。 那为什么还要写？ 成年人做事情总要讲一些回报，或者是给别人些什么，或者是从别人身上拿走些什么。前者包括自己的想法、经历或者三观；后者包括别人的物质、精力或者时间。你可以想想，是否做任何一件事情都逃不出这两个目的。 而我要说的是：写作是同时实现这两个目的最简单的方法。 你可能会有疑问，写作能给别人些什么，又能从别人身上拿走什么。 写作的过程重塑了你思考的过程，写作的内容自然也就展示了你的思考和想法，还有什么是比输出思想更厉害的输出么？ 别人阅读你的文字看似是在“不劳而获”拿走本属于你的东西，但是你拿走的可是每个人最宝贵的东西——时间。只要有人打开你的文章，无论读了一分钟、十分钟还是又实践了三十分钟，这个时间用掉就再也回不来了，还有什么是比拿走时间更厉害的拿走么？ 如果你学了一项技能，看了一篇文章，就已经付出了自己的时间和精力，从经济学角度讲这些付出都是你的沉没成本。所谓沉没成本是那些用了就再也回不来的东西，沉没成本在产生的一刻就已经不是成本了。你后面唯一能做的是增加收益，自己学了自己做是最基本的层次，别人问然后你再讲是最不划算的收益。 想要追求边际收益最大化那就写下来记下来然后发出来吧。因为前期你的学习已经是沉没成本，写作投入成本又固定，多一个人看就多完成了一次输出，多拿走了一份对方的时间和精力，也就多了一份收益。 想清楚这个问题，其实就能明白没有什么是比写作更轻松更划算也更严肃的事情了。 是什么让我们不同 看到这里可能又会产生新疑问：按照上面的说法，写出来的东西有人看是赚了，但是如果根本没人看还写么？ 写，当然要写。 先不说写了没有人看是一件概率非常小的事情，如果你感觉自己弱，其实肯定有比你更弱的，如果你感觉自己强，肯定还有更强的，所以无论水平如何，只要写出来就有受众。即便真的恰好没有人看，也还是要写。 用我自己举例，那么多准备过考研或者考过研的人我们之间有什么不同么？两三年前我觉得没什么不同，那段时间大家状态和经历大同小异，你那时做过的别人也在做，你想的可能别人也都有想。可两三年后再看，我发现自己比他们多了 20 万字。 如果问起别人对那段经历的感受和建议，他们能说的是：“哎，别提了……（此处省略若干字）”。 如果问起我，都懒得说话，先报以微笑 😃 再给一个链接 https://book.kaopubear.top/。 **虽然写作是一件如此轻松和划算的事情，但写作最初（也是最终）的目的一定是为了自己而写。**通过自己的文字你可以审视过去的自己并和未来的自己交流，如果这个过程中恰好（或者碰巧）又完成了自身输出和其它一些事情当然再好不过，如果没有也一定不亏。 这个世界上的人大致分为三类：一类好为人师，一类好为人徒，还有一类无欲无求。 判断自己是哪一类人其实不难。 如果你时不时会忍不住给身边朋友推荐喜欢的耳机、书或者 APP 之类用过的东西就是第一类人；如果总是喜欢收集相关信息，询问别人意见，自己用了之后闷声发大财，那就是第二类人；如果你从来没心思推荐也从来不主动寻找，本着该来的总会来这种思想，那就是第三类人。 实际上第三类人很少，绝大多数人都属于前两类或者在前两类之中转换身份。既然都好为人师或者好为人徒，是什么让我们慢慢变得不同。 上面的问题我也说不好，但是有人曾经问过我另外两个问题，我有自己的答案。 大家同样都是搜东西学习，为什么人就越来越不一样呢 因为有些人是在 Wikipedia、Google、专业搜索引擎和源文档里搜索学习，而另外一些人是在群聊天记录和公众号历史消息里搜索学习。 大家同样都是写东西，为什么人就越来越不一样呢 因为有些人是写给过去的自己，有些人是写给未来的自己。有些人的文字一定有自己实战体会和思考，有些人就是复制粘贴，还好意思说写。 最后 为什么要写，为什么还要坚持写。 因为，来都来了，总要留下些什么，不然怎么祸害其他人。 文中提到的 GitBook 开源书籍：https://book.kaopubear.top 博客地址：http://kaopubear.top 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-15-whykeepwriting/"},{"title":"经济学周记 10-价格初探","content":"经济是否可预测 正方：可以对经济进行预测分析 来源于物理 拉普拉斯假说 测不准原理，原子预测随机 反方：人类社会，经济发展不可预测 人际之间的效用不可比较 每个人对不同商品有不同的偏好和个人估值 个人的偏好无法横向比较 每个人对物品的效用可以比较，但是两个人之间不可以比较 个人和企业有高度计划，但是社会无计划 对于整个社会各自的目标都不同 计划经济不知道社会的总目标 数据不可得 个人不知道兴趣的真正排序 凭什么告诉你 别人可能误导你（测不准原理）：人口普查，统计的结果随着人们的预期而变化 人会对自身的预测本身作出新的反应 预测什么会流行就会倒过来影响什么会流行 数据无法集中 奖惩很难恰如其分 知识在社会中的应用 经济体系要解决的是变化问题：不是要解决边际平衡问题，而是每天的生活有了变化应该如何去应付。如果只为了解决边际平衡问题实施什么制度无所谓，可以试错。 关于变化的知识永远无法集中：变化发生时总是在某个局部被感受到。知识指的是谁在什么地方需要什么东西什么品质愿意付出什么，商人掌握了上述信息，如何利用局部的信息很关键。 价格能够提供解决方案：人际效用用价格来比较，价格可观察统计和加总而且价格传递了关于稀缺的信息。这种传递方式节俭，什么不够价格上涨，而且价格所传递的关于稀缺的信息只会传到相关者那里。同时价格可以指导生产。价格本身是最好的奖励和惩罚，做错事价格已经惩罚，做对事价格已经奖励。 价格有效节俭明确的传递稀缺信息，指导生产选择不同生产方式，也可以解决奖惩问题：有钱多拿，没钱少拿。 如何分饼决定饼多大 人的感情对于理解社会运行客观规律是很大的障碍。 价格只能在具体的交易中形成。价格是每一个人发自他们内心，根据他们实际情况，最后达成的一个经济行为。价格只是反映事实的信号。 富人不能优先享受，人们就不会对价格作反应。如果有钱人不享受优先待遇，为什么要奋斗变成有钱人。 如何分饼决定了饼能做多大：要把饼做大，也要把饼分匀是错的，不可能先做饼再分饼。例如土地法案和美国知识产权《拜杜法案 》。价格众多作用种指导分配（奖惩）的作用最重要。 换个角度看国难财的行为 乘人之危有别于拦路抢劫：国难并不是发国难财的人制造出来的，就像医生利用了病人的生病，老师利用了学生的无知。阻止别人发国难财，只会让遭受灾害的人处境更糟。 人们在学习价格，风平浪静的时候一切都可以接受。一旦有了具体的事例，价格的作用就会忽略。价格不是请客吃饭，价格永远起调节作用。 愿望和结果分开来看，愿望是一回事，愿望造成的结果是另一回事。发国难财的人本身的行为就会增加供给使得商品的价格下降缓解供需矛盾。例如，滴滴打车涨价，如果不涨价凭什么你来坐车，别人凭什么给你提供服务。 一周总结 人工智能不能代替人力 需求不可预测，需要不断满足 满足需求的方式多种多样不断变化（不同年龄需求不同） 攀比永远存在，但不知道比什么 数据是根据观察和理论而来的 需要有观察的纬度 不存在没有立场和理论的数据收集 先有想法和角度才会有数据 理论和观点立场和人的想象有关 如何做饼决定饼的大小：价格的三个作用中分配功能是最重要的 活具有不确定性，要在当时环境下判断行为的准确性，不能事后的信息判断 供给不自由，价格依然有意义 很多事情本来供给就不自由，比如出租车，石油，看病价格。 供给是否自由和价格有没有意义没关系。 传递稀缺性，指导生产和产品的分配是价格的作用。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-10-econote10/"},{"title":"经济学周记 9-需求定律（2）","content":"需求第二定律 定义：需求对价格的弹性，和价格变化之后流逝的时间长度成正比。随着时间的增强，需求对价格的弹性增加 需求的价格弹性 需求对价格的弹性就是需求量的变化百分比除以价格变化的百分比。（每当价格变化百分之一，需求量会变化百分之几） 例如 价格变 2，需求量变 5，弹性是 2.5 弹性大于 1：奢侈品 弹性小于 1：必需品 弹性永远为负，谈绝对值 需求曲线上的弹性处处不等，价格越高弹性越大。 需求曲线斜率相等，弹性不等 斜率 弹性的变化：价格高时&gt;1, 价格低时&lt;1 同一种商品，价格的高低决定了是奢侈品还是必需品。生活中不存在刚需，有经济学和心理学的因素在内。 垂直需求曲线 刚性需求：无论价格多高，需求量都不变。代表的是一个人没有办法寻找任何替代方案。 但是，人会寻找替代方案，药太贵不治了。 寻找替代方案是不变的人性规律（图来自 1956 年） 水多就多用，少就少用，要看综合成本最小化。 时间推移需求弹性会越来越高 每当出现新的情况，出现新的冲击的时候，人们寻找替代方案的范围一开始的时候可能没那么大，但是随着时间的推移，他们选择替代方案的空间会越来越大，他们能够找的对策就越来越多。随着时间的推移，需求弹性变高，替代品越来越多，对策越来越多。 第二定律应用（税负分摊） 房地产交易税由谁承担：如果商家有本事把税推给买家，为什么不多推一点 税负由买卖双方共同承担 图解： 一条倾斜向下的需求曲线 D，有一条倾斜向上的供给曲线 S，相交的点是一个平衡点叫 N。 没有征税，买卖双方的均衡点就在 N 这一点上，在这一点上的均衡价格是 P0，其均衡销售量或者需求量是 Q0。 征税，需求者付的价格 P0 成了 Pd；供应者赚到的钱从 P0 到了 Ps，整个交易量从 Q0 收缩到 Q1。 需求者买方多付了钱，卖方少收了钱。买方多付的钱，再加上卖方少收的钱，这两笔钱加起来恰好等于政府增加的税收。 A 矩形是买家所承担的税收部分。B 矩形是卖家所承受的政府的税收的部分，A 加 B 的总面积，恰好等于政府的税收收入。 供应者和需求者谁承担更大税务 上下两个矩形的大小有需求曲线和供应曲线的相对斜率（比较陡的缺乏弹性） 情况 1：需求曲线相对弹性高 情况 2：供应曲线相对弹性高 要看供应者和需求者谁的弹性低，谁对交易更迫切，谁付得就多一些。 弹性大小决定承担税负的分担比例。例如养老保险，要看雇主雇员谁更需要这份工作 法律无效定律 政府收税规定谁付跟实际上是谁支付的没有关系，取决于交易双方的相对弹性。例如谈恋爱谁迁就谁，谁更迫切想结婚。 需求第三定律 需求第三定律要回答的问题是附加费用的问题。 精选品和普通品之间的价格本来是有差距的，但是加上一笔附加费以后，它们的差距就缩小了，精选品显得便宜了。而附加费越大，这种效果就越显著，精选品就会显得越便宜。 例如： 不远万里从美国跑到中国来演出的乐团，他们要支付高昂的交通费用、住宿费用，这时候只有高质量的乐团，才值得花这笔钱； 跑到拉斯维加斯去的中国游客，他们下的赌注比美国当地人下的要大，也是这个道理； 中国的留学生要跑到美国去读书，他们也要付出更大的成本，所以一般来说，是好的同学更容易跑到外面去读书； 从澳大利亚进口到中国的肉，运输成本不低，事先要把骨头去掉； 如果你有机会从美国坐飞机到中国，你能够带一瓶液体，那么你更可能带的是红酒或者香水不可能带的是一瓶矿泉水或者一瓶啤酒。 附加成本上升并不是好事，质量上去了，但是选择少了，买卖双方都减少了选择的机会。 需求第三定律：每当消费者必须支付一笔附加费的时候，高品质的产品就相对低品质的产品变得便宜了，这笔附加费越高，高品质产品就变得越便宜。“好东西运到远方去定律”。但是也和运输技术等相关。 一周总结 需求第一定律 倾斜向下 需求量和价格呈反比 需求量和需求差别 只有价格变化：需求量 其他条件：需求（曲线） 需求供给没有必然区分 交易剩余：买卖双方赚的便宜 需求第二定律 弹性 价格决定了奢侈品还是替代品 没有所谓的刚需，人可以找替代方案 税负分担原则 共同承担 相对弹性越低承担比例越大 每一个人即是需求者也是供给者 人会提前应对意外：好处和坏处都会一层层分担出去 上有对策下有政策 增加挂钩的土地政策 边远地方开垦新的农田，城市周边可以盖房 税负分摊 第二门外语学什么 谁的经济好 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-10-econote9/"},{"title":"Excel 初级公式","content":" 懒是人类进步的绊脚石，偷懒是人类进步的阶梯。如果完成任何一项工作时觉得复杂，那一定就有还不知道的更简单的方法。 基本知识 Excel 可以处理的数值有效位数最多为 15 位，公式中文本类型的常量必须写在半角双引号内 运算符包括算数运算符和比较运算符，其中比较运算符返回逻辑值 &lt;&gt; 表示不等于 excel 所有数据类型中，数值最小，文本大于数值，最大的是逻辑值 true 文本运算符 &amp; 可以将两个数据合并为一个文本类型数据 引用运算符 冒号 单个空格 逗号 其中单个空格返回空格左右两边的单元格引用的交叉区域，而逗号返回左右两边单元格引用的合并区域 相对引用和绝对引用往往混合使用效果更佳，注意，F4 可以快速切换 如果想确定使用提示列表里的某个函数可以按 tab 键补全，另外 ctrl+shift+A 可以显示出所有需要的参数 SUMIF 函数 =SUMIF（条件区域，求和条件，求和区域） 如果条件区域和求和区域相同，只需要写出求和区域即可 条件区域的写法 &quot;&gt;100&quot; &quot;&lt;&gt;100&quot; 求和条件可以是数字 文本 单元格引用格式 也可以是公式，文本必须在双引号之间 SUMIFS 可以用来多条件求和 注意：AVERAGEIF 按照条件求平均值，用法和 SUMIF 相同 按照模糊条件求和时可以结合通配符使用 SUMIF（范围，“Chr*”，求和范围） 关于通配符，excel 中只有两种通配符，分别是？和* ，其中*代表任意字符，? 代表单一字符 写法可以如下 SUMIF（范围，“”“&amp;A2&amp;”, 求和范围） 表示匹配中间内容是 A2 单元格的 COUNTIF =COUNTIF（单元格区域，计数条件） 参数可以是数字，表达式和单元格引用以及文本字符串，且可以使用比较运算符和通配符 例如=COUNTIF(A2:A10,&quot;??&quot;) 或者 (A2:A10,&quot;&quot;&amp;B2&amp;&quot;&quot;) 如果想用 COUNTIF 统计所有非真空单元格个数，可以使用筛选条件&quot;&lt;&gt;&quot; COUNTBLANK 专门用来统计所有空单元格个数 COUNTA 统计所有非真空单元格个数 COUNT 统计所有数值单元格个数 另外，在我们日常数据的过程中，很可能会用到多条件统计 COUNTIFS(A1:A10,&quot;&gt;=60&quot;,B1:B10,&quot;&gt;=80&quot;) 如何对数据进行取舍，方法很多且都很常用 ROUND（取舍的数值，保留的位数） 需要注意的是，其中保留的位数可正可负可 0，差别自己试一下就知道了 如果你想强行向上取舍，使用 ROUNDUP 反之如果你想强行向下取舍，使用 ROUNDDOWN 取整还可以用 INT 和 TRUNC 对字符串进行操作 首先是对字符串进行合并 excel 可以非常方便的对数据进行分类，点一下鼠标就可以了。但是有的时候我们想把几列的内容合并起来，可是并没有一个合列的选项。如果想用合并单元格，这会犯非常低级的错误。 可以使用 CONCATENATE 函数 CONCATENATE(A2,A3,&quot;任意其它字符串&quot;,A4) 想怎么合就怎么合，如果觉得函数太长，好吧，可以用&amp; 有的时候我们还想统计一下文本的长度 长度可以用字符和字节来表示，其中一个中文占一个字符，占两个字节 统计字符长度用 LEN() 统计字节长度用 LENB() 注意，如果一个函数针对的是字符，那么再后面加上 B 往往就可以处理字符了 excel 本身是不区分大小写的，可以使用函数 EXACT 来完成 如果你想查找一个字符所在的位置，咋整 可以使用 FIND 或者 SEARCH（查找的字符，查找的位置，从第几个字符开始查找） 注意，只有 FIND 可以区分大小写，只用 SEARCH 可以使用通配符，如果想把通配符当作普通字符来处理，需要再*前面加~ 截取字符 可左可右可中间 左边 LEFT（要处理的字符串，6 要提取的字符个数） 右边 RIGHT 同理 中间多了一个参数。 MID（要处理的字符串，从第几个字符开始提取，提取几个字符） 替换字符，似乎可以查找替换啊。但是，类似与 linux 中的 sed，excel 中有两个函数可以使用，一个是 SUBSTITUTE，另一个是 REPLACE SUBSTITUTE（需要替换字符的文本或者单元格引用，需要替换的文本，需要替换成什么，替换第几次出现的字符） 注意，这个函数是用来替换指定文本的，如果不知道具体文本，只是想在指定位置进行替换要使用下面的函数 REPLACE（需要替换字符的文本或者指定的单元格，要替换的起始位置，替换字符的个数，要替换成什么） 比如给电话号码中间四位加星号，就可以用这个函数 =REPLACE(A1,4,4,&quot;&quot;) 1850697 常用的查找函数 VLOOKUP 最常用的函数，具体的用法就是（你找啥，在哪找，要找对应的那一列，精确查找还是模糊查找） 有几点需要注意 第一个参数可以使用通配符进行模糊匹配 查找区域中匹配的内容必须位于第一列 有多个对应值只会返回第一个值 0/FALSE 表示精确匹配，excel 里的说明有问题 在平时的实际应用中，有一个问题曾经困扰了我很久。就是怎么同时返回多列对应 的数值。 这个问题可以通过对第一第二个参数使用绝对引用，对第三个参数使用相对应用，利用 COLUMN 函数。 =VLOOKUP(E2,E2,E2,A2:2:2:D$100,COLUMN(B:B),0) MATCH 可以在某一个范围内搜索特定的项 MATCH（要查找的内容，搜索的区域，匹配类型） 查找的内容可以是值，数字，单元格引用 查找的范围只能是一行或者一列 匹配类型有三种 -1 MATCH 查找大于或等于查找值的最小值，查找范围内的值必须按降序排列 1 小于或者等于查找值的最大值，查找范围内的值必须按照升序排列 0 完全等于 MATCH 返回的是位置而非值本身，匹配文本时不区分大小写 同样可以配合通配符使用 INDEX 返回所在区域交叉处的位置 INDEX（范围，行序号，列序号） 如果将 INDEX 和 MATCH 连用可以解决 VLOOKUP 的一些问题 比如 =INDEX($A2:2:2:C33,MATCH(&quot;ARR1&quot;,33,MATCH(&quot;ARR1&quot;,33,MATCH(&quot;ARR1&quot;,A2:2:2:A$33,0),3) 即可以进行逆向搜索。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-09-excelfunctionbasic/"},{"title":"经济学周记 8-需求定律（1）","content":"个人主义的主观价值论 需求的特点：你想要的东西别人也想要，有一个层层递进的规律。 个人估值的多层含义（personal worth） 一个人对一件商品的个人估值，是他为了得到这件商品所愿意支付的其他商品的最高数量。 只有个人才有行动能力，集体不能决定，集体不会感受，不会思考，不会评估。所有价值与估值都起源于个人，完全主观，价值是人赋予的。个人行动都是可观察可记录的，不是单纯的愿望。人对于美和舒适的判断在特定的社会和时期可以评判和记录。 主观价值论与客观价值论 客观价值论：所有物品都有客观本质不以人的意志为转移的价值，价格只是围绕价值上下波动。 主观价值论：本身没有价值，只有人对它的判断。 区别 凡是客观价值论能解释的主观价值论都可以解释 客观不能解释的主观也可以解释（明星拍广告；珍贵的老照片） 主观价值论可以更好地指导生产（结果导向，需求导向，市场经济） 边际革命 奥地利学派引入了边际概念，边际是指**“新增”带来的“新增”**。 边际成本就是每新增一个单位产品，所要新增的成本 边际收入是多卖一个产品，你能够新增的收入 边际产量是你多增加一份投入，所能够多获得的产量 边际效用是你多消耗一个单位的商品，所能带来的新增的享受 边际效用递减原理通俗的讲就是吃馒头的第一口最解饿。 边际收益与边际成本趋同：人会朝着边际平衡的方向迈进，边际收益尽量等于边际成本。 水和钻石谁带来的幸福高：前 1000 块钱都用来买水，是因为水带来的幸福感更大，当第 1001 块钱买了一点点钻石，此刻水和钻石带来的边际收益是相等的。 钱要确保花在边际效用最大的产品上面。 每个人都是边际平衡的高手，我们所进行的所有活动，所花的时间，每一个活动每一个商品，它带给我们的边际效用都是一样的。60 分到 80 分就可以了，不用从 99 到 100，因为边际成本在增加，但边际效用在递减。你提高的只不过是几分，但付出的努力成本却很高。最后从 90 分到 100 分，那你要花的努力就是巨大的，而这些努力带给你的边际效益却非常低了。因为除了经济学课，你还有其他的很多科目需要学习。 努力做到边际平衡：我们带来的新增的享受，总是有一个递减的规律。由于资源是有限的，每个人怎样才能够最有效地利用他们有限的资源得到最高的效用，办法就是边际的平衡，在每多花一个单位的成本，不管这个成本指的是多一个单位的时间、多一个单位的金钱、多一个单位的注力、多一个单位的努力，他们都要把这多一个单位的成本，花在那些带给他们收益最大的那种活动或商品上去。从而使得所有这些商品和活动给他们带来的边际收益是相等的，这就叫边际平衡的概念。如果一个人这么做了，那么他得到的总收益就会达到最大。 需求第一定律 定义：无论何时何地，价格提高，商品的需求量就减少，价格降到一定的程度，需求量就会增加。 如上图，当价格上升到一定程度的时候，横坐标需求量就减少；当价格下降，横坐标需求量就会增加 这里纵坐标是自变量；横坐标需求量是因变量，当价格发生变化，需求量会发生变化。需求（曲线）刻画的是当所有其他条件不变的情况下，价格和需求量之间的对应关系。当其他的条件发生变化，价格和需求量以外的任何其他的条件发生变化，需求就会发生变动，就要用另一条位置不一样的需求曲线来刻画新的关系。 需求与需求量存在重要区别 需求曲线（任意一点）刻画价格和需求量的关系 整条曲线构成需求曲线，整条曲线是一个需求函数，是一种需求 需求曲线上的点对应的是需求量 整条曲线对应的是一种需求 需求曲线本身不动，当沿着这条不动的曲线滑动，每个点代表：只有价格变化时需求量相对变化。当价格以外的其他条件变化时，整条曲线发生移动。例如秃子收入增加，帽子价格上升，护理头发成本增加，假发需求变化；假发价格下降，需求量变化。 需求曲线永远向下：有人认为钻石项链需要的人多，玻璃项链需求人少，越贵越买，不符合需求曲线永远向下。其实，玻璃是一条曲线，钻石是另一条位置更高但依旧倾斜向下。 需求和供应曲线 当价格上升到一定程度，需求量为负，需求就变成了供给。需求和供给没有黑白之分，取决于市场价格。价格低会买入，是需求者，价格进一步提升，就不买了，价格还在上升，变成供给者。价格上升，需求者可以变成供给者，例如买了房不住反而租出去。 消费者剩余：需求曲线上任何一点代表对该商品在这个单位的个人估值，是愿意为了获得这个单位的服务所愿意付出的最大代价。对商品的个人估值和为了得到这件商品所付出的代价之间的差距叫剩余，由消费者和生产者共同产生。 一周总结 经济学不讨论人性的善恶 如果条件变化，人的行为会怎么变化 如果时间成本高，人情是否会淡薄 边际平衡：边际收益等于边际成本。手上的有限资源，在每一种不同的资源或者每一种不同的活动上面，带给我们的边际收入要均衡。自助餐效用为负的那一点就停止了，本质是资源的浪费。 强者越强的趋势不会永远下去。强者不会无止境地发展，因为使强者变强的那些因素，带来的效益是会边际递减的，是会回归的。世界上没有任何一种禀赋，它边际收益是永远上升的。 假如你是个菜农，如果市场上的菜价上升了，那么你对蔬菜的需求量是上升了还是下降了？ 这里涉及两条曲线，一条是市场上一般人对蔬菜的需求曲线，当蔬菜的价格上升，其他的因素不变，蔬菜的需求量就会下降。但这时菜农是个例外，因为他的财富状况明显受到他卖蔬菜的收入的影响。蔬菜贵了他卖的更好了，收入增加了，财富状况发生了变化。他自己的需求曲线发生了移动。这是另外一条需求曲线，他变得有钱了。所以不论在哪个价位上面，它的需求量都上升了。 供应者不和需求者竞争 价格不是商人定的，而是需求者定的 供应者和需求者不存在竞争 供应者之间；需求者之间存在竞争 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-08-econote8/"},{"title":"经济学周记 7-交易费用","content":"有人群就有交易费用 交易费用：凡是在一个人的社会里不存在，而在多个人的社会里存在的成本（张五常）。 一个人的社会也有成本，成本是放弃了的最大代价。 科斯的经济学忠告 当交易费用为 0 的时候，不管产权属于谁，资源都会落到最有价值的用途之上 现实生活中的交易费用不可能是 0 要关注真实世界的经济学 现实中交易费用高不可攀 工厂烟囱过滤器的费用是 50，不装造成的损失是 500。如果没有交易费用，不管法院判给谁都会按上，如果判工厂输，工厂会装，不判，用户自己花钱会装。但是，如果有交易费用，用户之间很难谈妥，每个人出多少钱。类似于小区装电梯。 风俗习惯与道德规范为何重要 人之间原本不信任，交易费用存在，权力和责任地分配没有最优。第三方在确认资源最佳分配的前提下，非常有把握时应该使用强制力进行重新分配。但是，现实生活中有多种阻力，交易费用高，因此初始分配、制度和道德规范就就重要。同时，风俗习惯和道德规范节省交易费用，习惯节省了讨价还价和协商的成本。 为什么禁止醉驾：要避免交通意外各方付出的成本不同，行人成本大，司机成本低，所以禁止醉驾。 征地的权衡 在美国，假如没有公正的补偿，那么私人财产也不得被取用于公共用途。征地权的界限有待摸索。中国存在的问题是政府是唯一的卖家和买家，大家没有回旋的余地。 寻求合作解 有问题不要讲理要讲数，找平衡点和合作解。比如大学宿舍办 party，有人复习，有人要玩。出去办 party 要花 300，想复习的人觉得价值是 100。300 和 100 之间寻找一个交易值。请同学去星巴克复习。 蜜蜂的预言（张五常）：橘子花蜜多，蜜蜂贡献小，养蜂人向果农补贴；苹果树花蜜不足，蜜蜂贡献大，果农向养蜂人补贴。 大学生产的纪念品，学校和买的人谁占便宜看价格即可判断：有标志的价格高就是买的人占便宜，反之是帮学校宣传。 瑞格利球场的门票 楼房的顶上都是座位，周围的居民楼顶私自卖票，最后的和解方案是收入的 17%归球场。 成本概念的递进 成本的复杂性：从具体到抽象，个人到社会，静态到动态。从根本上讲，成本是放弃了的最大代价。一个人社会的有形的物资具有成本，木材取暖就不能盖房子；也可以是无形资产（不是只有货币成本），如便利店的商品贵。但是，如果没有什么可放弃也就不存在成本，沉没成本不是成本。 产品价格与成本无关：最终商品的价供求关系决定了最终商品的价格，价格倒过来决定了商品生产原材料的成本。 所有盈亏都是一次性的：所有的盈利都是横财，意外的收入；所有的亏损都是横祸，意外的损失；只要有盈亏，资源未来的使用价值就会有调整，成本也因此调整。 没有旱涝保收的生意（租与寻租的概念）：租是对资产的付费，资产的供给在一定程度不以付费的变化而变化，是白赚的收入。寻租则是企业寻求垄断性优惠政策的过程要付出的成本。 交易费用永远为正，资源资产和责任的初始界定非常重要，交易费用巨大；交易费用越低越好，交易费用低可以方便的交易更好配置资源。社会发达成本变高的原因：落后地区交易费用不是 0 而是接近无限大，这些没有被纳入计算。比如通信费用，网费，电话费。但是没有的话无法通信。 制度费用与制度迁移的费用：所有交易费用的总和是制度的成本，在制度下为学校企业政府的付出费用叫做制度费用，制度的迁移本身需要付出成本。 一周总结 中国式过马路符合科斯定律：防止时间的浪费，人多时人群应该获得路权。 彩礼的制度功能： 支付功能 克服信息不对称问题，生产能力，筹措资金能力 表决心重视程度，越穷越重视 机场扰民不一定赔钱 采用三个人的思路 租房进去以后有人在周围盖房发出噪音，此时如果支付噪音赔偿费，应该租户得到赔偿，因为租房的时候是没有噪音的费用。 如果租房前已经开工了，要补偿应该给房东，因为租户支付的费用其实已经是便宜的，是房东在工地开工时受到了损失。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-08-econote7/"},{"title":"经济学周记 6-科斯定律","content":"社会成本：伤害与被伤害 实例分析 牛与小麦：牛吃小麦要不要阻拦 泳池阳光和酒店副楼：一个酒店盖楼挡住了另一个酒店泳池的阳光，楼能不能盖。 烟囱与邻居：左边房子的烟囱在右边人家的房顶，右边打算把房子盖高挡住了烟囱，右边要不要拆。 火车和亚麻：火车烧煤有火星，路边有很多亚麻属于农夫，火车的火星把亚麻给烧了，铁路要不要赔。 糖果商和医生：糖果商和医院共用一堵墙，医生自己临时盖的房觉得糖果商吵，糖果商要不要停工。 养鸡场与新君民：养鸡场本身很偏远，城市开发后在养鸡场旁建了小区，养鸡场要不要搬。 水泥厂和老居民：水泥厂有污染，水泥厂周围的老居民去告，水泥厂要不要赔。 以上例子共同点：一方伤害了另外一方，需不需要赔偿，需要赔偿并且加以限制。 社会成本：值得不值得 有人说，行使你的权利，但应该以不伤害别人的权利为界。这句话不能解决上面的例子，两方都可以用它来进行辩护。所有的伤害其实都是相互的，上述例子实际是双方在争夺稀缺的资源，争夺地，争夺阳光，安静，新鲜空气，科斯发表《社会成本问题》提出这一观点。 爱泼斯坦的 123 归纳法（Richard epstein） 假设两个资产的所有者 同一个人会发生什么 如果两个人发生什么 如果三个人是什么 一个人：要看谁的价格高 牛和小麦谁贵 楼和泳池那个收入高 火星和亚麻中肯定会选择一个最便宜的解决方法：铁路改道，建筑高墙，和农夫达成协议 谁避免意外成本最低谁的责任越大 铁路烧了亚麻，责任可能在农夫。农夫避免意外的成本更低，应该承担更大的责任。可以使整个社会避免意外付出的总成本越少。 养鸡场拥有污染权，居民能够剥夺养鸡场的污染权但是居民应该承担养鸡场搬迁的成本。 科斯观点：不是一方伤害一方，双方都在争夺稀缺的资源，伤害是相互的。 谁用得好就归谁 淘宝店的数据归谁：用户；店家；平台 不管谁产生存在哪里，最后谁能用好就会不断地折腾争取，使数据落在他们手上。因此，设计制度时，方便更好运用数据的那些人得到这些数据，尽量减少其中的阻碍。 同样，kindle 中的数据归谁，笔记是我做的，kindle 是我买的，下划线是我画的，但数据归亚马逊。在使用合约里面就是这么写的，你选择了同意，即便使用协议根本没看。隐私权偷走了？但是做法是合理的，因为亚马逊用的价值更大。就算不同意，亚马逊肯定会想办法得到，其他方式交易成本更高。 隐私权与公共安全的权衡：隐私权并非一点都不能出让，有些数据对大众也很重要。公安机关有没有权利征用个人隐私权，二者相对而言，谁用的好就归谁。 钻石归矿工还是白富美：钻石是矿工挖出来的，但是最后都到白富美身上，谁用得好就归谁。 女朋友和科斯定律：只要交易费用足够低，不管这个女孩现在跟谁谈朋友，最后还是会和最合适的人在一起。 科斯定律的概念：一项有价值的资源，不管一开始它的产权属于谁，最后这项资源都会流动到最善于利用它，能最大化利用其价值的人手里。制度设计要尽量让资源的流动和分配更容易，提高经济资源的使用效率。 越富足越健康（环保） 汽车与马车谁更环保：汽车，有尾气；马车，有马粪，马粪变干压成粉末弥散在空中，蹄铁的噪声，马还会失控。 我们必须用持平的眼观看待污染：不是一方污染一方，而是多方在争用一种稀缺资源，要在其中取得平衡。 “科斯对价”化解狼群之争：黄石生态公园需要多少狼群，有人认为狼越多越好，比如打猎打狼的人，管理员能有补贴，环保分子认为原始；有人越少越好，比如养牲口的人。那么应该怎么办？如果让养牲口的人证明自己的牲口被狼咬死，让养狼人来提供赔偿。这个赔偿的价格叫做科斯对价。养狼人自然也就控制了狼群数量。 布餐巾和纸餐巾哪个环保：布重新使用更环保，但是洗得浪费水和清洁剂；用布破坏更大，因为布贵，消耗的资源肯定多。所以，用布要看值不值得，比如伤害了环境但是增进了感情，生命也是有限的。 一周总结 应不应该不重要，重要的是世界运行规律 每个人都有各自的想法，先关注这个世界是怎么样的，它本来是怎么样的。 例如历史上管女人成本比较低，所以限制女人，现代社会男女在一起不像火星和亚麻那么危险，女人用武之地增加，把女人关在屋子里的成本增加，所以检点守规矩的责任更多落到男人身上。 准确理解科斯定律的五个要点 科斯定理：只要交易费用足够低，不论资源归谁所有，资源的用途是一样的。 资源归谁所有，用在什么用途：和产权所有者无关；与当事人数目无关；和补偿不补偿没有直接关系；随着默认责任改变，需要补偿的后来可能就不需要；谁避免意外所要付出的代价小，谁的责任越大，跟赚多少钱无关。 垃圾分类：好处微小，成本高昂。个人分类，需要确定类别，部件拆开，分开运输，花费精力，到了垃圾处理厂往往还有进行分类。不如处理厂最后统一分类。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-08-econote6/"},{"title":"经济学周记 5-成本进阶","content":"理解盈利和亏损 凡是盈利都是意外 成本是放弃了的最大代价，放弃的东西越多，代价越高；放弃东西越少，代价越少。 没有放弃就没有成本。汉堡吃第一口的成本几乎等于整个汉堡的成本，吃一口就换不回钱了；一辆新车使用半年的成本是新车减去二手车的价格，用的旧了多用半年就无所谓了；1 个碗是 10 块买的，知道是古董后可以卖 10 万，再用这个晚吃饭的成本是 10 万。 当我们得知碗是古董开始就获得了盈利，凡是盈利都是意外，称为 windfall profit 横财。价值是在和预期不一样的一刻开始，赚取盈利只是一刹那的事情，一旦盈利碗就变成了不同的资源，是另一种资源则未来带来的服务就变了。 盈利会提高资源未来使用的成本，亏损会降低资源未来使用的成本 买了 1 个碗 5 万，发现是假的，只能卖 10 块，再用这个碗吃饭的成本是 10 块，亏损一刹那后会调整对碗的预期，亏损也是意外的，windfall loss 横祸。每当发生意外就重新调整资源的未来估值，重新调整后使用资源的成本就要按照新的估值计算。一旦盈利，资源使用成本升高；一旦亏损，资源使用成本下降。 重新估值不难，难得是找出盈利和亏损的原因 终产品的供需决定原材料成本 认为政府高价拍卖土地推高了房价是不正确的，资源有价是因为最终产品有需求。 成本决定论站不住脚 所谓成本决定论：一块地本来就有价值，价值是客观存在的。产品售价=所有成本*利润率。如果正确，提高价格的方法就是不停的提高成本，例如在自行车上加宝石。产品原材料决定了产品最终售价是错的。 供需关系决定商品价格，商品价格决定资源成本。最终产品的供需决定了最终产品的价格，价格反过来决定原材料的成本。所以要学会逆向思考。 牛肉面贵不是因为房租贵：该地生产率高，人们愿意过来，所有原材料贵。人们过来需要吃饭，餐饮贵导致了房租贵。 演唱会酬劳高不会导致票价贵：喜欢的人多，愿意出价高才使得明星酬劳高。 政府拍卖土地不会推高房价：能卖出高价是因为最终需求者对土地有需求，人们对产品的需求导致房价贵和土地价格贵，政府免费还是拍卖土地不会对房价有影响，唯一的区别在于收入是明钱还是暗钱。 “租”是对资产的付费 能够带来收入的就是资产：土地，矿山，才能，发明创造。对资产的付费就是租，租是旱涝保收的收入。最优选择和次优选择存在较大落差，少给 1000 还是会做，多的 1000 就是白赚的，即所谓的租。公司上班时给你 1 万块让你全心全意工作，但你用半个小时干别的，没扣钱，叫租。但是旱涝保收具有相对性，有没有认真工作，会有长远影响。 租包括经济组，准组，寻租。 有一种资产不以收费的变化而变化，这种资产带来的收入就是租，是相对旱涝保收的收入。每个人都在享受租，但是时间不同竞争条件变化。真正旱涝保收的收入不存在。 寻租，乞丐没有白拿施舍 乞丐没有白拿施舍：乞丐要蹲着比惨，给的钱多了其他乞丐都来了，乞丐拿施舍本身存在竞争，竞争本身就会消耗资源。 政府规制下的消耗资源：为了拿到政府优惠政策，本身就要消耗社会资源。 寻租概念的起源：贼并没有减少资源的总量，但是贼增加了做锁的成本。 所谓寻租是指向政府争取优惠，自己得到好处，社会总资源耗散的行为。如果国家制度设计不当，寻租行为活跃，在这些国家的人每天很忙但是国家很穷。 一周总结 当皇帝不一定是好职业 好生意如果旱涝保收，人们逐渐了解了以后就不再是好生意。因为企业内部：盈利后要寻找盈利要素，要素的要价和付费会上涨；企业外部：其它竞争者进入提供替代品，抢夺用户。铁饭碗进入门槛会提高，再进来就没什么好处了。 凝聚人类劳动越多的产品价值不一定越高，有时候没有凝聚多少劳动的产品但是价值可能很高，iPhone6 的成本低要价高，赚的钱要归到每一种生产要素上。最终的定价不以它的生产成本为标准，以最后的供需为定价依据。赚了钱再向前归功或者归咎。 一个事情有租的一面也有成本一面，一份资源，如果它提供的东西跟它的收费没有关系的时候，体现的就是租。 如果人懒一点，多点空余时间休息，没有什么后果，这就是在享受租。我提供的服务跟收费没关系。但是精益求精会带来好处，这个时候懒是有成本的。竞争会逼着旱涝保收的资本逐渐变成成本，本来可以懈怠的做法长远看要付出代价。 减少寻租的方法：政府能给出去的好处越少，寻租活动越少。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-08-econote5/"},{"title":"经济学周记 4-成本初探","content":"成本 成本是放弃了的最大代价 资源有若干选项 选项的成本是所有落选选项当中价值最高的那个 理解成本的困难之处 放弃的选项本身没有实现 需要用想象才能知道其价值 成本的关系 选项是选项的成本 选项与选项互为成本 通常说的成本是指机会成本 成本由别人决定 负面感受不是成本 完成一项工作的过程有很多负面感受，其中的辛苦和汗水不是成本，这个过程中并没有放弃任何东西。 具体例子 做 A 事情：正面感受 100 分，负面感受 70 分，净幸福 30 分 做 B 事情：正面感受 50 分，负面感受 10 分，净幸福 40 分 做 A 事情放弃 B 事情的成本 40 分（净幸福） A 和 B 二者互为成本 成本由别人决定 自家铺位卖茶叶蛋没有租金是否没有成本？ 卖茶叶蛋放弃了其他可能性，如果出租那么租金由社会共同决定，他人的看法决定了铺位价值（租金），铺位价值决定了卖茶叶蛋的成本。卖茶叶蛋成本和铺位属于谁没有关系，只和放弃了的最大收入机会有关。 职业范围由社会决定 不忘初心的难处：第一次做选择时机会成本不多；境遇的变化使自身机会增加；坚持原来的看法成本随之增加；放弃的东西越来越多 职业选择：受别人对职业看法的影响，如果可以成为优秀的程序员却去学生物，放弃的代价是程序员的收入 择业需要考虑 职业受益最大 满足兴趣 花费成本最低 自己的生命，如何度过，职业如何选择，很大程度由社会其他人决定。 别只盯着钱 ​ 全部成本和货币成本 货币成本有别于全部成本。成本有很多，货币，时间，风险…… 比如，给士兵发薪比免费征兵更便宜。 ​ 义务当兵就不能从事原职业 多了廉价士兵可能少了企业家 放弃的代价不可估量 发薪就愿意当兵的人在别处机会最少 当兵会给他们带来最大的满足感 再比如，中间商赚差价商品价格更便宜 如果没有中间商，便宜但是花费大量时间等成本 中间商之间也在竞争，会使成本降到最低 再比如，减少中间环节，药品价格反升 中间渠道存在成本 仍然是目前所有可能性当中最低的 沉没成本不是成本 有选择就有成本，没有选择才没有成本。做事情最难的是当机立断，电影不好看时最好的选择就是立刻离开，因为票已经买了钱已经付了，电影票钱沉没了就不再是成本。大学选专业发现不合适就应该尽快换。 边际成本决定行为选项 还要投入多少才能获得预期回报？A 方案：投入 100 回报 150；B 方案：投入 100 回报 200 AB 都投入了 50，选择 B AB 都没开始，选择 B A 投入 90，B 还没投入，选择 A，A 的边际回报要比 B 更高 总之，要看当前时点下未来的投资回报率。 将错就错可能更有效率 3000 元空调只能制冷，4000 元空调能制热制冷，夏天买了 3000 的制冷空调，想要制热的成本是 1000；到了冬天要重买能制热的，卖了旧空调得 1000，再买新的 4000，制热的边际成本从 1000 变成了 3000。或许买 300 的暖风机更经济。 边际概念在产业的应用 3G 设备已经投入了，4G 进来时 3G 企业应该怎么做。设备已经在那里，沉没成本不是成本了，可以降低服务费，让 4G 进不来。 一周总结 中国工人制造飞机和袜子哪个成本更大 成本是放弃了的最大代价，不是你的东西就不算是放弃。我可以当老师可以当舞蹈家，我当老师的成本不是没当舞蹈家，因为我本来当不了舞蹈家，不当舞蹈家的代价是很低的。（曾经）中国造不了大飞机但做的袜子要的人很多，所以做飞机不做袜子的成本更高，这是比较优势原理。 为了兴趣爱好，职业选择付出了多大的代价 市场上有些工作工资高但是没人去是因为人们为了兴趣在金钱上做了很大牺牲，一旦做了选择不能倒过来怪收入不均。收入不仅代表了货币，还代表了心理满足。 另外，人在工作中可以培养兴趣。人的偏好不是天生固有的 会随着选择而改变。关键时刻有什么选择，后面的选择就取决于这个关键时刻，这种时刻被称为“宪法时刻”，是决定你操作系统的那一刻。 至于到底该不该辞职，无论什么工作，看比自己年长的事业有成的同事，扪心自问，再工作 20 年变成他们，甘不甘心愿不愿意高不高兴。满意则继续，不满意就换工作，因为沉没成本不是成本。 医保系统使得药价越来越高的原因 药品贵的原因 研制新药不确定成本高 药物有专利期和审核期 制度管制，进入门槛高 医保系统：用药和买药的不是一个人，用药的人无需控制支出 近视眼激光手术却越来越便宜 因为不在医保的范围里 存在竞争 范进中举不可取 如果一件事情成功的概率是 1%，反复尝试成功的机会不会提高 每次都考 1 分，连续考 100 次也不会是 100 分 每做一次尝试都有成本 只要有一点点机会就不要放弃是错误的 沉没成本不是成本 有时候学要会果断放弃 有时候又要学会将就 重点是看边际成本和边际收益 不看过去花了多少，而是再花一点钱是不是真的得到想要的 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-07-econote4/"},{"title":"经济学周记 3-选择与稀缺","content":"稀缺 背景：理性人和人性自私不能称为经济学的基础 稀缺是一个基本事实 你想要的别人也想哟（资源有限）：看上的东西总是最贵的，说明被人也想要 人的需求不断变化不断升级（欲望无穷）：人欲望无穷，馒头换酒，艺术登山，需要更多资源。最高层次是荣誉的稀缺。 稀缺的含义 无形资源 有形物质 时空稀缺：机票不同时间价格不同 地理位置稀缺：土地不缺缺位置 信任稀缺：同学之间的关系，社交的圈子 人的需求无限 同样药效有不同的副作用 病变多了是因为人的需求多了 吃饭三两但是自助餐能吃一斤 选择和歧视 ​ 稀缺必须做选择，选择有标准，标准就是区别对待，区别对待就是歧视 稀缺、选择、区别对待和歧视是一体的，只要有一个就意味着同时有其他三个。 歧视无法避免，因为稀缺和选择不可避免 资源有限：取了老婆歧视了世界上的所有男人和其他女人 时间有限 金钱有限：买逼哥的演唱会，其他明星被我歧视了 歧视和逆向歧视 实例：保护黑人作为弱势群体，有些情况白人不在保护之列 逆向歧视：为了消除歧视而产生的新歧视 歧视不可避免，不准明晃晃亏待白人，只能静悄悄的照顾黑人。为了平等待人，必须待人有别。 如何歧视是关键 资源稀缺，必须选择必须歧视 谁有权进行歧视：学校招生主体可以制定歧视性标准 谁承担歧视后果 学校承担歧视响应的歧视后果 歧视结果的承担人应该有知情权：比如用人单位 歧视必有代价 加里贝克尔 歧视别人必有代价 歧视起源 偏好：黑人跳不了四小天鹅 信息不对称：人习惯以偏概全做判断；得到信息的成本太高，以偏概全 歧视越多代价越大 以偏概全要付出代价 歧视成本越高，错误的歧视代价越大 不需要付出代价，会纵容歧视的习惯。越大的城市，歧视越少，是因为代价太高 不同行业环境，歧视的程度也不同 市场竞争越激烈，越能做到包容和豁达开放：私企比国企更不在意你的穿着 歧视的作用和限制歧视的恶果 为什么有时候歧视是合理 歧视别人的人不一定是强势的人：中国人本身在美国是弱势群体。外国排华是因为中国人做生意排华 同祖中介理论：法律不保障，利用其他形式保障，同村同祖同国的道德来保障。 政府禁止合理歧视的后果：2008 年美国次贷危机 ​ 这不是市场的失败，是政府的失败 美国人购房率低（银行不轻易放贷） 进行平权运动，支持弱势群体 拿到贷款的人是白人，人们认为是歧视：银行区别对待一定有道理，黑人还不起 不得不对弱势群体发放贷款 政府威逼利诱必须放贷：政府承担贷款风险 银行知道债务有毒，把债务卖来卖去 银行知道大而不能倒的道理 一周总结 选总统和选伴侣哪个歧视更严重 歧视是中性词，不是贬义词：稀缺，选择，标准，歧视 歧视标准得当的标准 表里如一：个人品味和偏好 我就是喜欢白人的四小天鹅 表里不如一：滴滴专车必须有北京户口，护士和厨师需要么 竞争的压力迫使人们减少那些不恰当的歧视 考虑哪一个选择你更在意表里如一，选错的代价更高，哪个越慎重。 所以，选总统的歧视更多 结果平等和机会平等 人生不是从某个时刻开始，起点平等机会平等，但哪里是起点？ 每个人特点不同，同样的机会不同人也会有不同表现 歧视看似不合理但是合理的例子 DNA 基因解读来确定你是不是适合某个工作，是不是太残忍。 调查你毕业的学校，评语，成绩，证书和履历，目的就是知道你是谁，就是为了表里如一的评价。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-07-econote3/"},{"title":"经济学周记 2-人的本性","content":"不确定性，进化和经济理论 阿尔钦 和科斯并列的产权经济学创始人，张五常之师。 论文《不确定性、进化与经济理论》1950 年发表后，据说这是被引用次数最多的十篇经济学论文之一 阿尔钦认为，尽管由于无知或非理性使得某些企业并没有真正实现利润最大化，但市场经济本身就提供了一种选择“适者”和淘汰“适者”的机制。 经济学关心什么 经济学不关心人是否理性 经济学关心的是存活的条件 在什么样的情况下，人们能够存活下来 如果条件发生了改变，人们存活的情况又会发生怎么样的改变 实例 很多傻子到处开加油站，结果还是只有公路旁边有加油站。很多傻子随机在地图上随便放一个图钉，在图钉标的地方开加油站，最后只有公路旁的加油站活下来。开在公路旁的傻子是傻子，随机的行为，但傻子行为的结果和理性行为的结果一致，所以存活。 随大流还是特立独行 事实客观存在不以人的意志转移，随大流往往是明智的选择，比如在火车站 事实随人的预期和行动而变化，准确判断并特立独行，比如股市 亚当斯密的人性观 亚当斯密 市场经济之父 1759 道德情操论 理论框架的总和和体现 1776 国富论 具体的一部分 名言 每一个人，不需要自己关心社会福利，他也不知道自己怎么去推动社会的福利。他只需要关心自己，追求他自己的福利就可以了。但是他在追求自己福利的过程中，会有一只看不见的手，让他的努力转变为对公共事业的推动。这只看不见的手，会让他的自私自利推动社会福利的改进。 人性自私同时具有同情心和爱心 人性自私（爱自己）：完全不自私的人，在社会不被尊重 人具有同情心（设身处地的能力）：天生的能力；强弱不同 爱心有限：同情心随人的距离拉远急速下降 实例：伦敦爆炸，确定对我们自己没影响，哀悼，感叹人脆弱，该干嘛干嘛 陌生人互助需要市场协调 友情爱情有限 日常有成千上万人的帮助 市场是陌生人交往服务的地方 人际互动二分法 小圈子：靠爱心，不用市场的规则，不斤斤计较 大世界：靠市场，讲规则，不用家庭的要求，不要幻想 吃饭不是农夫爱我们 市场经济的基础 自私-爱心-有限-陌生人互助-市场 铅笔的神奇 神奇的原因 世界上没有任何一个人掌握了制造一支铅笔所需要的全部知识，但是这支铅笔却做出来了。 每一个参与生产铅笔的人不知道自己的努力会导致一支铅笔的产生，却使得铅笔能够自动自觉地生产出来了。 生产铅笔的这些人生活在世界各个不同的角落，他们能够共同合作，把一支铅笔造出来。 一支铅笔凝聚着成千上万人的努力和知识，但是我们购买一支铅笔所要支付代价是微乎其微。 市场的力量 市场机制在协调人的分工与合作 商业是最大的慈善 ​ 实例背景 世界银行扶贫失败：2.3 兆美元，每个孩子分不到 12 美分 哈利波特商业奇迹：2005 年 7 月 16 日，900 万册《哈利波特》销售一空 扶贫无效的原因 缺乏反馈机制 市场有很好的反馈机制，影响价格和质量，有明确的效率标准。 慈善没有反馈机制，不知道什么是有效 委托代理问题 花的不是自己的钱不上心 所托非人问题 钱给了造成贫困的政府而非人民 养懒汉效应 产生依赖，力争下游 慈善缺乏反馈机制、所托非人、养懒汉效应等问题，行善扶贫效果往往大打折扣，完全无法到达预期目标；商业行为由于有市场机制发挥作用，协调和鼓励人们分工合作，所以能大幅、持续而高效地改进人们的福利 一周总结 经济学规律不因人的理性与否而转移 不理性的成本和代价可以承受时选择不理性：地球的历史 30 亿还是 50 亿年无所谓 代价足够高时理性：两个食堂鸡腿差五毛钱 理性和非理性相对而言：发脾气不理性，但是会有选择性发脾气（理性胡闹） 随大流还是特立独行 具体问题具体分析 选专业问题：理工，金融，生物，IT 市场经济不会使人情淡薄 过去维系大家庭 有经济因素的考量 结婚彩礼 缺乏商业保险机制 礼尚往来和人情就是保险 现在和志同道合的人交往 商业保险完善 交友的方法方式和对象发生了变化 帮助弱者才叫慈善，帮助强者叫投资 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-07-econote2/"},{"title":"经济学周记 1-经济学视角","content":"战俘营里的经济组织 一句话概括经济学 物质的总量哪怕不发生变化，只要人与人之间能够进行交易，幸福就能够无中生有地产生。 价格与价格波动 有市场就会有价格，有价格就会有价格波动 有了交易就会产生对货币的需求 战俘营的香烟就是货币 有了货币，就会有所谓的劣币驱逐良币 通货膨胀和紧缩 香烟都少了就会紧缩 如果传言有人要送来香烟，就会通货膨胀 如果香烟不被送来了，就会发生泡沫 户籍制度 不同国家的人不能来回走动，有的国家的人不被看好 舆论压力 仇富情绪 对中间商存在敌意 总结 我们看到的社会，只要有人在，就会有需求在 只要有两个以上的人在，他们的需求就不一样，需求不一样就会有交易 有交易就会产生对货币的需求，有货币就有劣币驱逐良币的现象，有货币就有宏观经济的波动，有通货紧缩，有通货膨胀 有交易就有信息不对称，有信息不对称，就会有中间商 有人在的地方就有情绪、就有舆论、就有外部性。 整个战俘营里面的现象，跟战俘营外面所发生的现象就是一致的。 马粪争夺案（公平和效率的关系） 背景：一个人打扫马粪堆好，回去找车来推，一个人来了把堆好的马粪给拿走了。 问题：这个马粪应该属于谁 马 土地 堆马粪的人 看见马粪的人 分析 如果给堆马粪的人会如何 如果给看见马粪的人结果会如何 交通肇事者为什么要负责任？ 如果不负责任，马路会非常混乱 马路的价值消失，效率消失 所以我们认为肇事者负责任是公正的 公正的背后是效率的考量 让社会里每个人都有积极性去积累财富的规则才是公正的规则，让社会能够存活下来的规则才是公正的规则。效率决定了公平，是单个人效率的考量更是是整体社会长远发展的效率考量。 实例：在司法实践里面，各国都有这么一条惯例，就是犯人如果配合司法部门自首认罪，那么他们的量刑就会比较轻。 看得见的和看不见的 经济学最核心的问题是选择和比较 需要考虑看得见的东西 更需要考虑暂时看不见或者永远看不见的东西 法国经济学家马斯夏 《看得见的和看不见的》指出经济学家好坏的标准 坏的经济学家仅仅能看到那些可以看见的后果 好的经济学家却能同时考虑那些可以看得见的后果，以及那些只能通过推测看得到的后果。 破窗理论 背景：窗户打破，主人去买窗户，制造窗户的工人有钱去买面包，面包工人有钱去买衣服。因此，打破窗户是好事情。有破坏才有进步，破坏本身是好事。 变种一：德国二战，日本原子弹之后发展更好了 变种二：老人不退休，年轻人没机会；机器太先进，工人没机会 认识破窗谬误的难点 自然灾害，人的衰老，工具落后会造就就业机会，这些是看得见的已经存在的工作 如果避免了灾害，省下时间和劳动力，可以生产其它更有效的东西，这些是只能想象的东西 后者通过推理我们可以知道其存在，但是不知道它在哪（看不见的东西） 总结 看见看不见的东西需要想象力 做决策时要充分考虑看不见的东西 经济学不关心阴谋论 经济学研究事与愿违的规律，美好愿望不一定带来美好结果。 好人和坏人理论 让好人多干事，把坏人消灭掉 劳动人民收入低，资本家发工资（换人），让资本家多发工资 通货膨胀，地产商提价，抑制地产商提价 房价越来越高，有人在炒房，让炒房的人不得逞 坏人干坏事的影响很有限 知道是坏事我们往往会有提防会避免 最危险的是好人干坏事 好人好心不一定干好事 最低工资制度本来是要保护穷人的，它真的保护他们的利益了吗？ 同工同酬制度本来是要保护那些弱势群体的收益的，但它最后保护他们的收益了吗？ 福利制度本来是让那些没有依靠的人能够找到依靠，最后这些群体的生活，是变得更好了，还是变得更糟了？ 为保护濒临灭绝的动物颁布各种法律最后这些动物的命运是更惨了，还是更好了？ 鼓励循环利用本来是要保护地球的资源但是循环利用的政策最后是破坏了环境还是保护了环境？ 立法不是解决问题终点 不公正不如意的现象仅仅立法还不够 人有能动性，新的政策下会有新的对策，有时候会和我们的初衷有很大的出入 经济学关心 出于良好愿望而产生的有害经济政策 事与愿违的因果关系 实例 眼镜蛇效应：英国在印度殖民期间控制当地眼镜蛇数量出台了捕蛇的鼓励政策，结果很多人开始养蛇 一周总结 学习最好的反馈是什么 如果你觉得你在我这里能够学到一点东西，那么对我的最好的奖赏就是你倒过来教我一点你觉得我应该知道的知识 济学总体的方法论内容 经济规律普遍存在 我们人世间各种制度的安排，更重要的不是看过去，而是看未来，看它怎么样指导未来社会和经济的发展 经济学训练人怎么去看见那些看不见的东西，怎么样才能通过想象力来进行正确合理的比较和选择 经济学的一个关注重点，是事与愿违的现象和规律 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-07-econote1/"},{"title":"统计学基础与 R-8","content":"写在前面 入门生物信息，所有人都绕不开统计基础知识和相关实现方式。本章我们将简要介绍统计学相关基础知识以及如何使用 R 语言进行简单地计算和分析 第八节 常用高阶分析方法 回归分析 所谓回归分析 (regression analysis)，在统计学中有着非常重要的作用，从大的层面来讲指用自变量（解释变量或者预测变量）来预测因变量（相应变量或者结果变量）的方法。比如在几个自变量中找到和因变量更相关的一个，利用自变量和因变量的关系生成等式对因变量进行预测。从小的层面来说，回归的模型非常之多，也非常复杂，例如最小二乘回归，logistic 回归和泊松回归等等。 最小二乘回归是最常用到的回归模型，包括简单线性回归（一元一阶），多项式回归（一元多阶）和多元线性回归（多元）。所谓最小二乘法是用一条直线y=ax+by=ax+by=ax+b（回归线）拟合一组两变量数据的方法，使得误差平方和（点到直线的距离平方和）最小。对数据进行最小二乘回归分析时，要求数据符合正态分布，独立和同方差性。 简单线性回归可以使用 F 检验，拟合优度 (R2R^2R2) 为回归平方和/总平方和，代表因变量可以被自变量解释的比例。 相关系数 (r) 描述个数据点与直线的偏离程度，度量回归线和数据的拟合程度。 在 R 中，lm()是拟合回归模型最简单的函数。针对两个变量，我们一般会先通过简单线性回归进行拟合，通过结果图，根据具体的需要再增加二次项提高预测精度。类似之前提到的 ANOVA 分析，可以使用summary()函数获取回归模型的详细参数和统计量。 有的时候，我们希望能够让回归模型尽量的简单，既减少自变量的数量还不影响对因变量预测的准确对。这是就可以使用anova()函数，查看是否可以删掉一些回归系数不显著的变量。 如果因变量不符合正态分布或者非连续变量，我们就需要考虑使用广义线性模型来进行拟合。当因变量为类别性变量（二项分布）时可以使用 logistic 回归，当因变量为计数型（泊松分布）可以使用泊松回归。在 R 中，这两种方法都可以使用 glm() 来进行计算。 聚类分析 聚类分析是统计中另一个非常重要的方法，可以帮助我们在多维度的数据中把相似的数据归为子集，每个子集中的数据都具有某种程度的相似性。在具体的生物研究中，聚类可以帮助我们通过表达类似的基因找到功能相关的基因，或者帮助推测未知基因的功能。通常聚类分析也被称作非监督机器学习。 进行聚类分析首先需要计算不同观测值之间的距离，进而生成聚类使用的距离矩阵。 计算距离的方法有很多，选择不同的距离计算方法也会对最终的聚类结果产生很大的影响。常用的距离计算方法有欧氏距离 (Euclidean distance)、曼哈顿距离 (Manhattan distance) 和基于相关性距离 (correlation-based distances) 的 Pearson correlation distances、Spearman's rank correlation、Kendall correlation distance 等等。 另外，在构建距离矩阵之前，往往会对原始的观测数据进行标准化，如计算 z score。 总的来说，聚类方法从整体上主要使用的有 Partitioning method 和 Hierarchical Clustering 两类，其中 Partitioning 包括 K-means clustering，K-medoids clustering(PAM) 等具体方法。 k-means 在 k-means 算法中，首先我们需要确定数据最终分为几类 (k)，然后会根据分类数量随机选取 k 个点最为每个类的初始质心（这也是同一组数据每次聚类的结果都不尽相同的原因），随后其他的点都会通过欧式距离找到分到和自己最近的初始中心。通过一次这样的过程之后，再根据每个集合中的点计算均值得到新的质心，重复之前的过程进行迭代。每次迭代，每个集合中的质心都会重新产生，所有的非质心点再重新分配给新的质心形成集合。如果在一次迭代中，只有非常少的点会发生集合的转移则迭代停止。 需要注意的是，k-means 聚类的方法对异常值非常敏感，与之相比 PAM 要好一些。 在 R 中，kmeans 聚类可以使用 stats 包中的kmeans()函数，如果想使用 K-medoids clustering 可以借助 cluster 包中的pam()函数。另外，在进行 cluster 和 pca 相关的分析中，factoextra 也是一个不错的选择，包括了各种常用的功能。 一个比较完整的 k-means 聚类分析过程主要包括数据标准化，评估合适 cluster 数数目，进行计算以及可视化展示等步骤。 Hierarchical Clustering 层次聚类和 k-means 相比不需要预先设定聚类的数目，最终的聚类结果会以颠倒树状结构显示，不同类别观测值在树的最底层（树叶），越向上节点越少。层次聚类可以细分为 Agglomerative Clustering 和 Divisive Hierarchical，前者的思路是从“树叶”向“树干”聚集，后者的思路是从“树干”向“树叶”分裂。一般而言，Agglomerative Clustering 适合在 clusters 比较少时使用；而 Divisive Hierarchical 适合在有大量 clusters 时使用，可以选择到那一步停下不再细分。 以 Agglomerative Clustering 为例，大致流程是首先将每个对象归为一类，每类仅包含一个对象，计算类与类之间的距离。找到最近的两个类然后合并，接着计算新类与所有旧类之间的距离。重复之前的过程，直到最后合并成一个类为止。 根据类间距离计算方法的不同，又可以分为五种：single-linkage（类和类两组对象间的最小距离）、 complete-linkage（类和类两组对象间的最大距离）、 average-linkage（两组对象间的平均距离）、centroid linkage 和 Ward′s method（在每一步使组内离差平方和增量最小）。 一个比较完整的层次聚类分析过程主要包括数据标准化，计算距离，构建聚类树，确定分组以及可视化展示等步骤。 在 R 中，计算距离时可以使用dist()函数，构建聚类树可以使用hclust()函数，将树分组可以使用cutree()。当然也可以使用 cluster 包同时完成上面几个步骤。 以 R 中数据集 USArrests 为例，进行聚类分析。 # 标准化 usa_norm &lt;- dist(scale(USArrests), method = &quot;euclidean&quot;) # 构建树 hc &lt;- hclust(usa_norm, method = &quot;complete&quot;) # install.packages(c(&quot;factoextra&quot;, &quot;dendextend&quot;)) # 可视化展示 library(factoextra) #基础 plot(hc, hang = -1, cex = 0.7) #美化 fviz_dend(hc, k = 4, # 分为 4 类 cex = 0.4, # label 大小，防止字不显示完全 k_colors = c(&quot;#2E9FDF&quot;, &quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), color_labels_by_k = TRUE, # color labels by groups rect = TRUE, # Add rectangle around groups rect_fill = TRUE, rect_border = c(&quot;#2E9FDF&quot;, &quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), ggtheme = theme_void() # ggplot2 主题 ) # 环形 fviz_dend(hc, cex = 0.4, k = 4, k_colors = &quot;jco&quot;, type = &quot;circular&quot;) 主成分分析 当数据集中变量过多时，会为我们的分析带来很大的不便，在这些变量中很可能存在冗余成分。为了减少冗余变量，降低数据维度，只留下少数能够依旧很好预测因变量的不相关变量，我们可以使用主成分分析 (PCA) 方法。 在 R 中，内置函数procomp()可以用来进行 PCA 分析，以 R 中数据集 iris 为例 # 只支持数值型变量，所以提取原数据集前 4 列 ir_num &lt;- iris[, 1:4] # 进行 pca 分析 ir_pca &lt;- prcomp(ir_num, scale. = TRUE) # 查看主成分信息 summary(ir_pca) # Importance of components%s: # PC1 PC2 PC3 PC4 # Standard deviation 1.7084 0.9560 0.38309 0.14393 # Proportion of Variance 0.7296 0.2285 0.03669 0.00518 # Cumulative Proportion 0.7296 0.9581 0.99482 1.00000 通过上述结果可以发现，主成分 1 和 2 可以解释 0.95 的变化。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-03-RandStatistics8/"},{"title":"统计学基础与 R-7","content":"写在前面 入门生物信息，所有人都绕不开统计基础知识和相关实现方式。本章我们将简要介绍统计学相关基础知识以及如何使用 R 语言进行简单地计算和分析。 比例分析 在之前几节内容中提到了均值分析和比较，但有时候我们关心的并不是均值而是比例 (proportion)。 单比例检验 对于 n 比较大（通常为np≥5np \\geq5np≥5 同时 nq≥5nq \\geq5nq≥5 ）的样本来说，根据中心极限定理，样本近似于正态分布，可以使用 z 检验，其检验统计量计算公式为： z=po−pepoq/nz = \\frac{p_o-p_e}{\\sqrt{p_oq/n}} z=po​q/n​po​−pe​​ 其中，pop_opo​表示观测到的比例，pep_epe​为预期比例，n 表示样本量，q=1−pq=1-pq=1−p。 如果样本比较小，则使用二项分布进行统计。 在 R 中，对于小样本，采用binom.test()，对于大样本使用正态分布近似二项分布，利用prop.test()进行分析。 在单样本比例检验中，我们关心的是具有同种特性的两个群体，在该特性总体中所占有的比例情况。例如，小鼠中公鼠母鼠各有一半，有 100 只患有某种疾病，其中有公鼠 60 只，母鼠 40 只。想知道是否公鼠患病率比母鼠高。在该问题中成功次数为公鼠患病数 55，总次数为 100，预期比例为 50%（公母鼠数量相等）。 prop.test(60, 100, p = 0.5, alternative = &quot;greater&quot;) # 1-sample proportions test with continuity # correction # # data: 60 out of 100, null probability 0.5 # X-squared = 3.61, df = 1, p-value = 0.02872 # alternative hypothesis: true p is greater than 0.5 # 95 percent confidence interval: # 0.5127842 1.0000000 # sample estimates: # p # 0.6 其中，x 为成功的次数，n 为总测试，p 为要测试的概率大小。在结果中，显示了卡方检验的统计量值，自由度和 p 值和置信区间，最后给出了样本概率估计值。 双比例检验 如果我们已知两组具有不同特性（A 和 B）样本的样本量和这两组样本中具有某种共同特性（C）的个体数量（也就是知道了 C 特性各自群体比例和总体比例），想要计算具有 C 特性的个体在 A 特性群体和 B 特性群体中的比例是否一样，就需要用到双比例检验。 当样本数量较小时（所有 np 和 nq 都小于 5），通常采用非参数检验** Fisher Exact probability test** 进行分析。当样本力量较大时，我们还是近似使用正态分布 z 检验来进行预测。 例如，男生 500 人，女生 500 人，其中喜欢阅读的男生有 400 人，喜欢阅读的女生有 460 人。男生喜欢阅读的比例是否比女生高。我们假设男生喜欢阅读的比例比女生高，则备择假设是男生喜欢阅读的比例比女生低。 prop.test(x = c(400, 460), n = c(500, 500), alternative = &quot;less&quot;) # 2-sample test for equality of proportions with # continuity correction # # data: c(400, 460) out of c(500, 500) # X-squared = 28.912, df = 1, p-value = 3.787e-08 # alternative hypothesis: less # 95 percent confidence interval: # -1.0000000 -0.0824468 # sample estimates: # prop 1 prop 2 # 0.80 0.92 由结果可知，p&lt;0.05，拒绝原假设，即男生喜欢阅读的比例比女生低。 卡方分布 χ2\\chi^2χ2分布可以通过原假设，得到一个统计量来表示期望结果和实际结果之间的偏离程度，进而根据分布，自由度和假设成立的情况，得出观察频率极值的发生概率（比当前统计结果更加极端的概率）。计算方法是对概率分布中的每一个频率，用期望频数和实际频数差的平方除以期望频数，最后把所有结果相加。得到的统计量结果越大，说明差别越显著，数值越小说明观察和期望的差别越小，当观察频数和期望频数一致是卡方为 0。其实就是在比较观测到的比例和期望的比例的关系。 χ2=∑(O−E)2E\\chi^2=\\sum \\frac{(O-E)^2}{E} χ2=∑E(O−E)2​ 卡方分布就可以用来检验某个分类变量各类的出现概率是否等于指定概率，可以检验数据的拟合优度（指定的一组数据与指定分布的吻合度），也可以用来检验两个变量的独立性（两个变量之间是否存在某种关联）。 在使用卡方检验时，需要的一个参数被称为自由度，指的是独立变量的个数（组数减去限制数）。通常，二项分布已知 p，泊松分布已知λ\\lambdaλ，正态分布已知μ\\muμ和σ2\\sigma^2σ2时的自由度是 n-1。进行独立性检验时，h 行 kl 列联列表的自由度是(h−1)×(k−1)(h-1)\\times(k-1)(h−1)×(k−1)。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-02-RandStatistics7/"},{"title":"统计学基础与 R-6","content":"写在前面 入门生物信息，所有人都绕不开统计基础知识和相关实现方式。本章我们将简要介绍统计学相关基础知识以及如何使用 R 语言进行简单地计算和分析。 第六节 多样本均值分析 在上一节讨论了单样本和双样本均值比较的几种情况，但是很多实验不仅仅有两组样本。进行多组样本之间的均值比较就需要进行单因素方差分析 (one-way analysis of variancd) 和双因素方差分析 (two-way analysis of variancd) one-way ANOVA 在单因素方差分析模型中样本的组数是任意的但是要求样本之间相互独立，每一组的观测值符合正态分布的同时方差相等，目的是比较每个组的均值。原假设是各组间均值相等（观察的差异有随机误差构成），备择假设是至少有一组和其他组均值不同。数据的变异通常来自于组内部的变异和组间真是变异，其中组内变异一方面由个体差异导致，一方面由实验误差导致，而组间变异则是由不同的处理（因子）导致。如果通过计算，非系统性的变异（组内误差）远大于由不同处理造成的变异（组间变异）如下图 b 所示，则接受原假设，反之则拒绝原假设，如下图 a 所示。 其中组间平均平方和=组间 MS=BetweenSS/(k-1)，k-1 为组间自由度，组内平局平方和=组内 MS=WithinSS/(n-k)，n-k 为组内自由度，显著性检验建立在组间平均平方和与组内平均平方和的比值上，且该比值为 F 分布，自由度为 k-1, n-k。 具体到 R 中，使用 R 中的 PlantGrowth 数据集举例。该数据有两个实验组和一个对照组，数据的整体情况上文已经统计过，下面通过 box plot 进行形象化展示（使用前文提到过的 ggpubr 包）。 library(ggpubr) ggboxplot(PlantGrowth, x = &quot;group&quot;, y = &quot;weight&quot;, color = &quot;group&quot;, palette = c(&quot;#2072b8&quot;, &quot;#ff6a38&quot;, &quot;#1e993b&quot;), order = c(&quot;ctrl&quot;, &quot;trt1&quot;, &quot;trt2&quot;), xlab = &quot;Treatment&quot;, ylab = &quot;Weight&quot; ) ggline(PlantGrowth, x = &quot;group&quot;, y = &quot;weight&quot;, add = c(&quot;mean_se&quot;, &quot;jitter&quot;), order = c(&quot;ctrl&quot;, &quot;trt1&quot;, &quot;trt2&quot;), ylab = &quot;Weight&quot;, xlab = &quot;Treatment&quot;) 检测正态分布和方差齐性 #检验方差齐性方法一 bartlett.test(weight ~ group, data=PlantGrowth) #检验方差齐性方法二 library(car) leveneTest(PlantGrowth$weight~PlantGrowth$group) # Bartlett test of homogeneity of variances # # data: weight by group # Bartlett's K-squared = 2.8786, df = 2, p-value = 0.2371 # # Levene's Test for Homogeneity of Variance (center = median) # Df F value Pr(&gt;F) # group 2 1.1192 0.3412 # 27 不符合前提条件时 如果此步骤检测方差不齐性，可以使用** Welch’s ANOVA**，oneway.test()； 如果不符合正态分布模型，可以使用非参数检验** Kruskal-Wallis test**，kruskal.test()和pairwise.wilcox.test()。 进行 one-way ANOVA 分析 pg.aov &lt;- aov(weight ~ group, data = PlantGrowth) summary(pg.aov) # Df Sum Sq Mean Sq F value Pr(&gt;F) # group 2 3.766 1.8832 4.846 0.0159 * # Residuals 27 10.492 0.3886 # --- # Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 通过 aov()，我们只能判断这三组数据之间均值不相等，但是不知道具体哪组存在差别。为了知道具体的差异情况，可以采用如下三种方法。 当进行任意两组间比较时，需要考虑由 family-wise error rate 造成的 p 值误差，需要对 p 值进行校正以保证任何两组之间显著性差异的总体概率可以维持在一个固定的显著性水平。常用的校正方法&quot;bonferroni&quot;、&quot;BH&quot;和&quot;fdr&quot;等。 Pairewise t-test pairwise.t.test(PlantGrowth$weight, PlantGrowth$group, p.adjust.method = &quot;fdr&quot;) # Pairwise comparisons using t tests with pooled SD # # data: PlantGrowth$weight and PlantGrowth$group # # ctrl trt1 # trt1 0.194 - # trt2 0.132 0.013 # # P value adjustment method: fdr Tukey multiple pairwise-comparisons TukeyHSD(pg.aov) # Tukey multiple comparisons of means # 95% family-wise confidence level # # Fit: aov(formula = weight ~ group, data = PlantGrowth) # # $group # diff lwr upr p adj # trt1-ctrl -0.371 -1.0622161 0.3202161 0.3908711 # trt2-ctrl 0.494 -0.1972161 1.1852161 0.1979960 # trt2-trt1 0.865 0.1737839 1.5562161 0.0120064 plot(TukeyHSD(pg.aov)) multcomp 包 glht() library(multcomp) summary(glht(pg.aov, linfct=mcp(group=&quot;Dunnett&quot;))) summary(glht(pg.aov, linfct=mcp(group=&quot;Tukey&quot;))) # Simultaneous Tests for General Linear Hypotheses # # Multiple Comparisons of Means: Dunnett Contrasts # # Fit: aov(formula = weight ~ group, data = PlantGrowth) # # Linear Hypotheses: # Estimate Std. Error t value Pr(&gt;|t|) # trt1 - ctrl == 0 -0.3710 0.2788 -1.331 0.323 # trt2 - ctrl == 0 0.4940 0.2788 1.772 0.153 # (Adjusted p values reported -- single-step method) # # Simultaneous Tests for General Linear Hypotheses # # Multiple Comparisons of Means: Tukey Contrasts # # Fit: aov(formula = weight ~ group, data = PlantGrowth) # # Linear Hypotheses: # Estimate Std. Error t value Pr(&gt;|t|) # trt1 - ctrl == 0 -0.3710 0.2788 -1.331 0.391 # trt2 - ctrl == 0 0.4940 0.2788 1.772 0.198 # trt2 - trt1 == 0 0.8650 0.2788 3.103 0.012 * # --- # Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 # (Adjusted p values reported -- single-step method) # two-way ANOVA 在某些试验中，一个组有两个不同的因子控制，这时需要控制其中一个因子效应后比较另一个因子的效应。此时需要使用双因素 ANOVA。如果一个变量对结果的影响依赖于另一个变量的水平，那么这两个变量之间存在交互效应。 下面我们使用 R 自带数据集 ToothGrowth 进行说明，该数据集包括药物剂量和喂药方法两个变量。 # 检测不同条件样本量是否相等 table(ToothGrowth$supp,ToothGrowth$dose) # 0.5 1 2 # OJ 10 10 10 # VC 10 10 10 summary(ToothGrowth) # 发现 dose 并没有当做因子来处理，需要进行转换 # len supp dose # Min. : 4.20 OJ:30 Min. :0.500 # 1st Qu.:13.07 VC:30 1st Qu.:0.500 # Median :19.25 Median :1.000 # Mean :18.81 Mean :1.167 # 3rd Qu.:25.27 3rd Qu.:2.000 # Max. :33.90 Max. :2.000 tg &lt;- ToothGrowth tg$dose &lt;- factor(tg$dose, levels = c(0.5,1,2), labels =c(&quot;low&quot;,&quot;mid&quot;,&quot;high&quot;) ) # 重新检查 summary(tg) # len supp dose # Min. : 4.20 OJ:30 low :20 # 1st Qu.:13.07 VC:30 mid :20 # Median :19.25 high:20 # Mean :18.81 # 3rd Qu.:25.27 # Max. :33.90 进行双因素方差分析 summary(tg.aov &lt;- aov(tg$len~tg$supp*tg$dose)) ## 正确做法 # Df Sum Sq Mean Sq F value Pr(&gt;F) # tg$supp 1 205.4 205.4 15.572 0.000231 *** # tg$dose 2 2426.4 1213.2 92.000 &lt; 2e-16 *** # tg$supp:tg$dose 2 108.3 54.2 4.107 0.021860 * # Residuals 54 712.1 13.2 # --- # Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 summary(tmp.aov &lt;- aov(ToothGrowth$len~ToothGrowth$supp*ToothGrowth$dose)) ## 错误做法，不将 dose 转换为 factor，《R 语言实战》第一版用到这个例子的时候书上是错误的，第二版已经改正。 # Df Sum Sq Mean Sq F value Pr(&gt;F) # ToothGrowth$supp 1 205.4 205.4 12.317 0.000894 *** # ToothGrowth$dose 1 2224.3 2224.3 133.415 &lt; 2e-16 *** # ToothGrowth$supp:ToothGrowth$dose 1 88.9 88.9 5.333 0.024631 * # Residuals 56 933.6 16.7 # --- # Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 由上述统计结果可以看出两个变量都对结果有显著的影响，下面将数据可视化展示。 library(ggplot2) ggplot(tg, aes(x=dose,y=len))+geom_boxplot(aes(fill = dose))+facet_grid(.~supp) ggplot(tg, aes(x=supp,y=len))+geom_boxplot(aes(fill = supp))+facet_grid(.~dose) library(ggpubr) ggboxplot(tg, x = &quot;dose&quot;, y = &quot;len&quot;, color = &quot;supp&quot;, palette = c(&quot;#2072b8&quot;, &quot;#ff6a38&quot;)) ggboxplot(tg, x = &quot;supp&quot;, y = &quot;len&quot;, color = &quot;dose&quot;, palette = c(&quot;#2072b8&quot;, &quot;#ff6a38&quot;, &quot;#1e993b&quot;)) 如果想要进行任意两组之间的比较还可以使用下面几种方法： TukeyHSD(tg.aov) # Tukey multiple comparisons of means # 95% family-wise confidence level # # Fit: aov(formula = tg$len ~ tg$supp * tg$dose) # # $`tg$supp` # diff lwr upr p adj # VC-OJ -3.7 -5.579828 -1.820172 0.0002312 # # $`tg$dose` # diff lwr upr p adj # mid-low 9.130 6.362488 11.897512 0.0e+00 # high-low 15.495 12.727488 18.262512 0.0e+00 # high-mid 6.365 3.597488 9.132512 2.7e-06 # # $`tg$supp:tg$dose` # diff lwr upr p adj # VC:low-OJ:low -5.25 -10.048124 -0.4518762 0.0242521 # OJ:mid-OJ:low 9.47 4.671876 14.2681238 0.0000046 # VC:mid-OJ:low 3.54 -1.258124 8.3381238 0.2640208 # OJ:high-OJ:low 12.83 8.031876 17.6281238 0.0000000 # VC:high-OJ:low 12.91 8.111876 17.7081238 0.0000000 # OJ:mid-VC:low 14.72 9.921876 19.5181238 0.0000000 # VC:mid-VC:low 8.79 3.991876 13.5881238 0.0000210 # OJ:high-VC:low 18.08 13.281876 22.8781238 0.0000000 # VC:high-VC:low 18.16 13.361876 22.9581238 0.0000000 # VC:mid-OJ:mid -5.93 -10.728124 -1.1318762 0.0073930 # OJ:high-OJ:mid 3.36 -1.438124 8.1581238 0.3187361 # VC:high-OJ:mid 3.44 -1.358124 8.2381238 0.2936430 # OJ:high-VC:mid 9.29 4.491876 14.0881238 0.0000069 # VC:high-VC:mid 9.37 4.571876 14.1681238 0.0000058 # VC:high-OJ:high 0.08 -4.718124 4.8781238 1.0000000 #上述结果如果感觉过于复杂，可以使用下面下面的形式 TukeyHSD(tg.aov,which = &quot;tg$dose&quot;) # Tukey multiple comparisons of means # 95% family-wise confidence level # # Fit: aov(formula = tg$len ~ tg$supp * tg$dose) # # $`tg$dose` # diff lwr upr p adj # mid-low 9.130 6.362488 11.897512 0.0e+00 # high-low 15.495 12.727488 18.262512 0.0e+00 # high-mid 6.365 3.597488 9.132512 2.7e-06 # 或者 pairwise.t.test(tg$len,tg$dose) # Pairwise comparisons using t tests with pooled SD # # data: tg$len and tg$dose # # low mid # mid 1.3e-08 - # high 4.4e-16 1.4e-05 # # P value adjustment method: holm 如果不满足正态分布，则需要使用非参数检验** Kruskal-Wallis test**，kruskal.test()和pairwise.wilcox.test()。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-01-RandStatistics6/"},{"title":"统计学基础与 R-5","content":"写在前面 入门生物信息，所有人都绕不开统计基础知识和相关实现方式。本章我们将简要介绍统计学相关基础知识以及如何使用 R 语言进行简单地计算和分析。 单双样本均值分析 根据数据组数的不同，均值比较可以分为单样本、双样本和多样本。本节首先介绍单样本和双样本。 假设检验一般步骤 谈具体的假设检验之前首先介绍假设检验的一般步骤。 确定假设 原假设 (null hypothesis, H0H_0H0​) 指需要检验的假设，只要当我们有足够的证据时才能否定。在某种意义上与原假设相反的的假设被称为备择假设（alternative hypothesis，H1H_1H1​）。 假设检验是无法给出绝对证明的，我们只能在假定原假设为真的情况下通过假设检验来判断结果是否可信。如果结果极不可能发生，则拒绝原假设，进而接受备择假设。 根据接受假设和真实情况之间的关系，会有四种可能发生。 真实情况H0H_0H0​ 真实情况H1H_1H1​ 接受H0H_0H0​ H0H_0H0​为真且被接受 H1H_1H1​是真，H0H_0H0​被接受 拒绝H0H_0H0​ H0H_0H0​为真但是被拒绝 H1H_1H1​是真，H0H_0H0​被拒绝 其中H0H_0H0​为真但是被拒绝的错误概率称为** I 型错误**，通常用α\\alphaα表示，也称为显著性水平，H1H_1H1​为真但是接受H0H_0H0​的错误概率称为** II 型错误**，常用β\\betaβ表示。 检验的功效（power）=1-β\\betaβ。虽然我们希望α\\alphaα和β\\betaβ都可以尽可能小，但这两者往往是矛盾的，通常我们会先固定α\\alphaα在某个水平，再找合适的检验使β\\betaβ尽可能小。 选择检验统计量 检验统计量（test statistic）是用于对假设进行检验的统计量，进行检验的过程建立在这个统计量之上。 决定拒绝域 拒绝域是可以不接受原假设的一组数值，其分界点被称为临界点。为了求出拒绝域首先要确定假设检验的显著性水平，也就是当样本结果的不可能发生程度多大时就可以拒绝原假设。 单尾检验指检验的拒绝域落在可能数据集的一侧（左侧或者右侧），双尾检验的拒绝域则分布在数据集的两侧，对于检验水平是α\\alphaα的双尾检测而言，两侧分别是α/2\\alpha/2α/2。如果备择假设的表示是“不等于”，则应该使用双尾检验。 求出 p 值 p 值取决于检验统计量和拒绝域。表示得到更加极端结果的概率。 判断样本结果是否在拒绝域内 做出决策 单样本 t-test 说完假设检验的基本流程之后，下面介绍和均值比较相关的假设检验，首先是单样本 t-test。 在数据符合正态分布的前提下使用单样本 t-test 来比较一组样本的均值和已知（理论/总体）均值，所谓的已知均值可能来自于之前的实验数据或者理论值。根据研究问题（原假设）的不同又分为双尾（不等）和单尾检验（大于或者小于）。 统计量计算公式为 t=X‾−μ0s/nt=\\frac{\\overline{X}-\\mu_0}{s/\\sqrt{n}} t=s/n​X−μ0​​ 其中X‾\\overline XX表示样本均值，n 表示样本量，s 是样本标准差（总体方差未知），μ0\\mu_0μ0​表示理论值。通过统计量 t 和自由度，我们可以计算出对应的 p 值。 使用 R 进行单样本 t-test，这里借用 R 自带数据集 PlantGrowth 的 10 个对照组数据。 weight &lt;- PlantGrowth$weight[PlantGrowth$group==&quot;ctrl&quot;] shapiro.test(weight) summary(weight) # Shapiro-Wilk normality test # #data: weight #W = 0.95668, p-value = 0.7475 # # Min. 1st Qu. Median Mean 3rd Qu. Max. # 4.170 4.550 5.155 5.032 5.293 6.110 可以发现均值大概是 5 左右，且数据符合正态分布。下面检验和理论值 7 相比的情况，原假设是等于 7，备择假设是不等于 7，所以采用双尾检验。 t.test(weight,mu = 7) # One Sample t-test # #data: weight #t = -10.673, df = 9, p-value = 2.075e-06 #alternative hypothesis: true mean is not equal to 7 #95 percent confidence interval: # 4.614882 5.449118 #sample estimates: #mean of x # 5.032 通过上述结果看出统计量 t 为-10.673，自由度是 9，p 值是 2.075e-06&lt;0.05，所以拒绝原假设。 单样本 Wilcoxon 符号秩检验 如果样本数据没有通过正态分布检验就要采用单样本 wilcoxon 符号秩检验进行计算。使用该检验需要满足的条件是样本值均匀地分布在均值两侧。 其 R 中的函数为 wilcox.test() wilcox.test(weight,mu=7) 通过结果可知拒绝原假设。 独立双样本 t-test 两个独立样本是指两个比较的样本之间没有关联，不互相影响。使用双样本独立 t-test 的前提是两个样本符合正态分布且方差相等。 独立双样本 t-test 其统计量计算公式为 t=X‾1−X‾2S2n1+S2n2t = \\frac{\\overline{X}_1 - \\overline{X}_2}{\\sqrt{ \\frac{S^2}{n_1} + \\frac{S^2}{n_2} }} t=n1​S2​+n2​S2​​X1​−X2​​ X‾\\overline{X}X分别表示两个样本的均值，n 表示样本量。s2s^2s2表示两个独立样本的方差合并估计，计算公式为 s2=(n1−1)s12+(n2−1)s22n1+n2−2s^2 = \\frac{(n_1-1)s^2_1+(n_2-1)s^2_2}{n_1+n_2-2} s2=n1​+n2​−2(n1​−1)s12​+(n2​−1)s22​​ 依旧以 PlantGrowth 数据进行举例，PlantGrowth 共有三组数据，在这里取两组进行分析。 # 查看各组基本信息 library(dplyr) tmp1&lt;-group_by(PlantGrowth,group) %&gt;% summarise(count=n(),mean=mean(weight),sd=sd(weight)) tmp1 # A tibble: 3 x 4 # group count mean sd # &lt;fctr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #1 ctrl 10 5.032 0.5830914 #2 trt1 10 4.661 0.7936757 #3 trt2 10 5.526 0.4425733 进行独立双样本 t-test 前，首先验证数据是否符合正态分布 (Shapiro-Wilk normality test) 以及两个样本方差是否相等 (F-test)。 关于方差比较 两个方差比较通常使用 F-test，在 R 中的函数为 var.test()，进行 F-test 检验前一定要首先进行正态分布检验，该统计量对于正态分布这个前提条件非常敏感； 多个方差进行比较还可以使用 Bartlett’s test，该方法同样要求满足正态分布前提条件； 如果不能确定数据是否符合正态分布，可以使用 Levene’s test 进行检验，其对数据正态分布的要求并非十分严格； Fligner-Killeen test 则是一种非参数检验方法，数据可以不满足正态分布； 关于方差比较部分内容，在本章不再展开。 shapiro.test(PlantGrowth$weight[PlantGrowth$group==&quot;ctrl&quot;]) shapiro.test(PlantGrowth$weight[PlantGrowth$group==&quot;trt1&quot;]) var.test(PlantGrowth$weight[PlantGrowth$group==&quot;ctrl&quot;], PlantGrowth$weight[PlantGrowth$group==&quot;trt1&quot;]) # Shapiro-Wilk normality test # #data: PlantGrowth$weight[PlantGrowth$group == &quot;ctrl&quot;] #W = 0.95668, p-value = 0.7475 # # Shapiro-Wilk normality test # #data: PlantGrowth$weight[PlantGrowth$group == &quot;trt1&quot;] #W = 0.93041, p-value = 0.4519 # # F test to compare two variances # #data: PlantGrowth$weight[PlantGrowth$group == &quot;ctrl&quot;] and PlantGrowth$weight[PlantGrowth$group == &quot;trt1&quot;] #F = 0.53974, num df = 9, denom df = 9, p-value = 0.3719 #alternative hypothesis: true ratio of variances is not equal to 1 #95 percent confidence interval: # 0.1340645 2.1730025 #sample estimates: #ratio of variances # 0.5397431 满足前提条件，继续方差相等的独立双样本 t-test t.test(PlantGrowth$weight[PlantGrowth$group==&quot;ctrl&quot;], PlantGrowth$weight[PlantGrowth$group==&quot;trt1&quot;], var.equal = T ) # Two Sample t-test # #data: PlantGrowth$weight[PlantGrowth$group == &quot;ctrl&quot;] and PlantGrowth$weight[PlantGrowth$group == &quot;trt1&quot;] #t = 1.1913, df = 18, p-value = 0.249 #alternative hypothesis: true difference in means is not equal to 0 #95 percent confidence interval: # -0.2833003 1.0253003 #sample estimates: #mean of x mean of y # 5.032 4.661 独立双样本 Wilcoxon test 当两个样本不满足正态分布时，使用 Wilcoxon 秩和检验进行非参数检验。 wilcox.test(PlantGrowth$weight[PlantGrowth$group==&quot;ctrl&quot;], PlantGrowth$weight[PlantGrowth$group==&quot;trt1&quot;], exact = F ) # Wilcoxon rank sum test with continuity correction # # data: PlantGrowth$weight[PlantGrowth$group == &quot;ctrl&quot;] and PlantGrowth$weight[PlantGrowth$group == &quot;trt1&quot;] # W = 67.5, p-value = 0.1986 # alternative hypothesis: true location shift is not equal to 0 非独立双样本 t-test 在很多试验中需要比较的两组样本往往有关系的，比如一组病人服药前后的变化，每个人以自己为对照。所谓非独立双样本，就是在第一组样本中的每个数据点都和第二组样本中唯一的数据点对应。 非独立样本和独立样本相比，可以显著降低样本量，提高统计的 power。其统计量计算公式和单样本 t 检验一致。 t.test(PlantGrowth$weight[PlantGrowth$group==&quot;ctrl&quot;], PlantGrowth$weight[PlantGrowth$group==&quot;trt1&quot;], paired = T ) # Paired t-test # # data: PlantGrowth$weight[PlantGrowth$group == &quot;ctrl&quot;] and PlantGrowth$weight[PlantGrowth$group == &quot;trt1&quot;] # t = 0.99384, df = 9, p-value = 0.3463 # alternative hypothesis: true difference in means is not equal to 0 # 95 percent confidence interval: # -0.4734609 1.2154609 # sample estimates: # mean of the differences # 0.371 非独立双样本 Wilcoxon test 和单样本类似，如果不符合正态分布则使用非参数检验。 wilcox.test(PlantGrowth$weight[PlantGrowth$group==&quot;ctrl&quot;], PlantGrowth$weight[PlantGrowth$group==&quot;trt1&quot;], exact = F , paired = T) # Wilcoxon signed rank test with continuity correction # # data: PlantGrowth$weight[PlantGrowth$group == &quot;ctrl&quot;] and PlantGrowth$weight[PlantGrowth$group == &quot;trt1&quot;] # V = 37, p-value = 0.359 # alternative hypothesis: true location shift is not equal to 0 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-10-01-RandStatistics5/"},{"title":"统计学基础与 R-4","content":"写在前面 入门生物信息，所有人都绕不开统计基础知识和相关实现方式。本章我们将简要介绍统计学相关基础知识以及如何使用 R 语言进行简单地计算和分析。 第四节 相关性分析 本节提到的相关性分析和后面会提到的 t-test, ANOVA 以及回归分析等被称为参数检验，这些检验在进行时我们常默认数据符合一定前提条件，如符合正态分布和方差相等等。当样本数量大于 30 时，根据中心极限定理，我们通常认为数据符合正态分布；在进行 t-test 和 ANOVA 分析时，还需要满足样本方差相等。 在进行各种检验之前需要初步检验数据是否符合某种检验的前提条件，如果不符合则应该考虑使用非参数检验或其他方法。 正态分布评估 在评估数据集是否符合正态分布时通常会采用** Shapiro-Wilk’s test 和图示 (Q-Q plot) **结合的方法。使用 Q-Q plot(quantile-quantile plot) 的结果较直观，使用 Shapiro-Wilk’s test 显著性检验的方法更准确（相对而言）。 Shapiro-Wilk’s test 结果受样本量的影响非常大，当样本量很大时即便数据符合正态分布也容易出现 p 值很小进而拒绝原假设的情况（该检验原假设是样本来自于正态分布）。样本量很小时即便真实数据不 s 是来自正态分布，也可能接受原假设。 这里试举一例 # 分别随机生成两组二项分布和指数分布随机数 set.seed(90) x &lt;- rbinom(15,8,0.7) y &lt;- rexp(15,0.5) shapiro.test(x) shapiro.test(y) # Shapiro-Wilk normality test # # data: x # W = 0.95996, p-value = 0.6917 # # Shapiro-Wilk normality test # # data: y # W = 0.96168, p-value = 0.7216 可以发现，即便我们生成的两个样本都不是正态分布，但是检验的结果仍然没有拒绝原假设（没有拒绝不等于接受原假设）。好在 R 中该函数限制检测的样本个数是 3 到 5000。因此，同时结合图像来分析还是很必要的。 一般使用 Q-Q plot 来检验是否符合正态分布，R 中默认的函数是qqnorm()；ggplot2 中可以使用函数qplot()；qqpubr 包是基于 ggplot2 二次开发的简易升级版，操作更加友好，可以使用函数ggqqplot()。 下面利用生成的数据绘图。 # 生成符合正态分布的一组数据并绘图 z &lt;- rnorm(50) qqnorm(z) library(ggplot2) qplot(sample=z) library(ggpubr) ggqqplot(z) 相关性分析 **Pearson **相关系数、**Spearman **相关系数、**Kendall **相关系数都可以用来表示变量之间的相关性，一般情况使用 pearson 相关系数更多，如果明确样本不符合正态分布可以使用 kendall 或者 spearman 相关系数。这三种相关系数都可以通过cor()函数来进行计算，下面通过 R 已有数据集 cars，查看汽车车速和刹车距离之间的相关性。 pearson 相关系数计算公式 r=∑(x−mx)(y−my)∑(x−mx)2∑(y−my)2r = \\frac{\\sum{(x-m_x)(y-m_y)}}{\\sqrt{\\sum{(x-m_x)^2}\\sum{(y-m_y)^2}}} r=∑(x−mx​)2∑(y−my​)2​∑(x−mx​)(y−my​)​ 其中 m 表示均值。 cor(cars, method = &quot;pearson&quot;) 相关性可视化展示 可以使用散点图进行两个变量之间的相关性展示。 plot(cars) ggplot(cars, aes(x=speed, y=dist))+ geom_point() ggscatter(cars,x=&quot;speed&quot;, y=&quot;dist&quot;,\\ add = &quot;reg.line&quot;, conf.int = T,cor.coef = T) Pearson 相关性检验 前面我们只是计算了两个变量之间的相关性，还应该对相关进行显著性检验。原假设为变量之间没有相关性，使用函数为cor.test() cor.test(cars$speed,cars$dist,\\ alternative = &quot;two.side&quot;, method = &quot;pearson&quot;) 统计结果中，t 表示 t 检验统计量，df 表示自由度，pvalue 是 t 检验的显著性水平，conf.int 表示 95%的置信区间，sample estimates 是相关系数。相关系数越接近-1 表示负相关，接近 1 表示正相关。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-09-28-RandStatistics4/"},{"title":"统计学基础与 R-3","content":"写在前面 入门生物信息，所有人都绕不开统计基础知识和相关实现方式。本章我们将简要介绍统计学相关基础知识以及如何使用 R 语言进行简单地计算和分析。 第三节 估计 在通常的试验中我们获得的信息总是来自样本，想要知道总体的参数，只能通过已有样本参数进行估计。 样本均值是总体均值的点估计，通常样本均值用x‾\\overline xx表示，总体均值用μ\\muμ表示。 在估计总体方差σ2\\sigma^2σ2时，计算公式为$$\\sigma^2=\\frac{\\Sigma(x-\\overline x)^2}{n-1}$$ 用样本方差估计总体方差会使得估计结果偏低，样本越小两个方差的差别可能就越大。在这里，估计总体方差的公式中除的是n−1n-1n−1，能够更接近总体方差。另外，总体方差点估计公式通常记做s2s^2s2, 写作：$$s^2=\\frac{\\Sigma(x-\\overline x)^2}{n-1}$$ 用样本均值估计总体均值时也会产生误差，均值的标准误差是σ/n\\sigma/\\sqrt{n}σ/n​，估计量是s/ns/\\sqrt{n}s/n​。标准误差表示了样本均值的分散情况，从公式中我们可以看出，n 越大，用样本均值估计总体均值越准确。当样本足够大（大于 30），即便总体不符合正态分布，但从中取出的样本均值分布仍然近似于正态分布（中心极限定理）。X‾∼N(μ,σ2/n)\\overline X \\sim N(\\mu, \\sigma^2/n)X∼N(μ,σ2/n) 除了对总体进行点估计以外，我们往往还会对总体进行区间估计，即对通过点估计得到的结果加减一定范围的误差。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-09-27-RandStatistics3/"},{"title":"KaTeX常用公式整理","content":"前几天写了一篇博客记录了在博客中插入数学公式的心路历程，折腾半天最后用的插件支持的 JavaScript 库是KaTeX\\KaTeXKATE​X。 关于这个库的信息，可以查看其GitHub 主页，开发者是khan academy，就是大家熟知的可汗学院。在主页上他们直接对标 MathJax，复杂公式的渲染速度直接把对方秒成渣渣，另外，KaTeX 的排版布局完全基于标准的Donald Knuth’s TeX。 这里简要记录一些平时使用比较多的语法和公式，KaTeX 支持的全部公式，可以在其官网查看。 插入方式 行内插入$数学公式$ 行间插入$$数学公式$$ 简单排版 正常显示ababab$ab$ 生成一个空格aba\\quad{b}ab$a\\quad{b}$ 生成一个大空格aba\\qquad{b}ab$a\\qquad{b}$ 1/2 个空格aba\\enspace bab$a\\enspace b$ 分隔符 ()()(),[][][],&lt;&gt;&lt;&gt;&lt;&gt;$()$,$[]$,$&lt;&gt;$可以正常显示，如果要显示{}\\{\\}{}，需要使用\\转义,即$\\{\\}$ 输入多行公式时可以使用\\left和\\right调整分隔符大小 $$\\{\\frac{x+1}{y^2}\\}$$ $$\\left\\{\\frac{x+1}{y^2}\\right\\}$$ 效果如下 {x+1y2}\\{\\frac{x+1}{y^2}\\} {y2x+1​} {x+1y2}\\left\\{\\frac{x+1}{y^2}\\right\\} {y2x+1​} 希腊字母 字母 表示方法 大写 表示方法 α\\alphaα \\alpha β\\betaβ \\beta γ\\gammaγ \\gamma Γ\\GammaΓ \\Gamma δ\\deltaδ \\delta Δ\\DeltaΔ \\Delta ϵ\\epsilonϵ \\epsilon ζ\\zetaζ \\zeta η\\etaη \\eta θ\\thetaθ \\theta Θ\\ThetaΘ \\Theta ι\\iotaι \\iota κ\\kappaκ \\kappa λ\\lambdaλ \\lambda Λ\\LambdaΛ \\Lambda μ\\muμ \\mu ν\\nuν \\nu ξ\\xiξ \\xi Ξ\\XiΞ \\Xi ο\\omicronο \\omicron π\\piπ \\pi Π\\PiΠ \\Pi ϖ\\varpiϖ \\varpi ρ\\rhoρ \\rho ϱ\\varrhoϱ \\varrho σ\\sigmaσ \\sigma Σ\\SigmaΣ \\Sigma τ\\tauτ \\tau υ\\upsilonυ \\upsilon Υ\\UpsilonΥ \\Upsilon ϕ\\phiϕ \\phi Φ\\PhiΦ \\Phi χ\\chiχ \\chi ψ\\psiψ \\psi Ψ\\PsiΨ \\Psi ω\\omegaω \\omega Ω\\OmegaΩ \\Omega ε\\varepsilonε \\varepsilon φ\\varphiφ \\varphi 关系符号 符号 表示方法 ≥\\ge≥ \\ge or \\geq ≤\\le≤ \\le or \\leq ≠\\ne​= \\ne or \\neq ≡\\equiv≡ \\equiv ≪\\ll≪ \\ll ≫\\gg≫ \\gg ⩾\\geqslant⩾ \\geqslant ⩽\\leqslant⩽ \\leqslant ≧\\geqq≧ \\geqq ≦\\leqq≦ \\leqq ≈\\approx≈ \\approx ≅\\cong≅ \\cong ⊂\\subset⊂ \\subset ⊃\\supset⊃ \\supset ⊆\\subseteq⊆ \\subseteq ∝\\propto∝ \\propto ∈\\in∈ \\in 运算符号 符号 表示方法 +++ + −-− - ±\\pm± \\pm ÷\\div÷ \\div ×\\times× \\times ∖\\setminus∖ \\setminus ⋆\\star⋆ \\star ∪\\cup∪ \\cup ∩\\cap∩ \\cap ∑\\sum∑ \\sum ∏\\prod∏ \\prod ∫\\int∫ \\int ∬\\iint∬ \\iint %\\%% % 箭头 符号 表示方法 ←\\gets← \\gets →\\to→ \\to ↑\\uparrow↑ \\uparrow ↓\\downarrow↓ \\downarrow ↔\\leftrightarrow↔ \\leftrightarrow ⇑\\Uparrow⇑ \\Uparrow ⇓\\Downarrow⇓ \\Downarrow 公式 符号 表示方法 xnx_nxn​ x_n exe^xex e^x xuox_u^oxuo​ x_u^o x\\sqrt{x}x​ \\sqrt{x} x3\\sqrt[3]{x}3x​ \\sqrt[3]{x} ab\\frac{a}{b}ba​ \\frac{a}{b} ab\\dfrac{a}{b}ba​ \\dfrac{a}{b} a/b{a}/{b}a/b {a}/{b} (nk)\\binom{n}{k}(kn​) \\binom{n}{k} (nk){n}\\choose{k}(kn​) {n}\\choose{k} exp⁡\\expexp \\exp lg⁡\\lglg \\lg ln⁡\\lnln \\ln log⁡\\loglog \\log max⁡\\maxmax \\max min⁡\\minmin \\min AB‾\\overline{AB}AB \\overline{AB} AB‾\\underline{AB}AB​ \\underline{AB} a⃗\\vec aa \\vec a ∑i=1n\\textstyle\\sum_{i=1}^{n}∑i=1n​ \\textstyle\\sum_{i=1}^{n} ∑i=1n\\displaystyle\\sum_{i=1}^ni=1∑n​ \\textstyle\\sum_{i=1}^{n} 矩阵、多行公式 \\begin{matrix} a &amp; b \\\\ c &amp; d \\end{matrix} abcd\\begin{matrix} a &amp; b \\\\ c &amp; d \\end{matrix} ac​bd​ \\begin{array}{c|c} a &amp; b \\\\ c &amp; d \\end{array} abcd\\begin{array}{c|c} a &amp; b \\\\ c &amp; d \\end{array} ac​bd​ \\begin{pmatrix} a &amp; b \\\\ c &amp; d \\end{pmatrix} (abcd)\\begin{pmatrix} a &amp; b \\\\ c &amp; d \\end{pmatrix} (ac​bd​) #等号对齐 \\begin{aligned} a&amp;=b+c \\\\ d+e&amp;=f \\end{aligned} a=b+cd+e=f\\begin{aligned} a&amp;=b+c \\\\ d+e&amp;=f \\end{aligned} ad+e​=b+c=f​ #居中对齐 \\begin{gathered} a=b \\\\ e=b+c \\end{gathered} a=be=b+c\\begin{gathered} a=b \\\\ e=b+c \\end{gathered} a=be=b+c​ #分类讨论 x = \\begin{cases} a &amp;\\text{if } b \\\\ c &amp;\\text{if } d \\end{cases} x={aif bcif dx = \\begin{cases} a &amp;\\text{if } b \\\\ c &amp;\\text{if } d \\end{cases} x={ac​if bif d​ 混合使用示例 f(n) = \\begin{cases} \\frac{n}{2}, &amp; \\text{if } n\\text{ is even} \\\\ 3n+1, &amp; \\text{if } n\\text{ is odd} \\end{cases} f(n)={n2,if n is even3n+1,if n is oddf(n) = \\begin{cases} \\frac{n}{2}, &amp; \\text{if } n\\text{ is even} \\\\ 3n+1, &amp; \\text{if } n\\text{ is odd} \\end{cases} f(n)={2n​,3n+1,​if n is evenif n is odd​ \\frac{n!}{k!(n-k)!} = {^n}C_k n!k!(n−k)!=nCk\\frac{n!}{k!(n-k)!} = {^n}C_k k!(n−k)!n!​=nCk​ f(x) = \\sqrt{1+x} \\quad (x \\ge -1) f(x)=1+x(x≥−1)f(x) = \\sqrt{1+x} \\quad (x \\ge -1) f(x)=1+x​(x≥−1) \\left( \\sum_{k=1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k=1}^n a_k^2 \\right) \\left( \\sum_{k=1}^n b_k^2 \\right) (∑k=1nakbk)2≤(∑k=1nak2)(∑k=1nbk2)\\left( \\sum_{k=1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k=1}^n a_k^2 \\right) \\left( \\sum_{k=1}^n b_k^2 \\right) (k=1∑n​ak​bk​)2≤(k=1∑n​ak2​)(k=1∑n​bk2​) \\int u \\frac{dv}{dx}\\,dx=uv-\\int \\frac{du}{dx}v\\,dx ∫udvdx dx=uv−∫dudxv dx\\int u \\frac{dv}{dx}\\,dx=uv-\\int \\frac{du}{dx}v\\,dx ∫udxdv​dx=uv−∫dxdu​vdx 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-09-22-katex/"},{"title":"Linux Command Line 学习笔记 5","content":" 说明；写 Linux Command Line 学习笔记 系列文章本意只是记录自己学习 《Linux Command Line 》 这本书的过程中看到的一些自己没有留意到的地方，因此绝大多数内容只是记录了相关知识点而没有实际扩展内容，纯粹是为了自己后期回顾时有迹可循。另外，因为直接看的原版书，所以有些地方中英混杂。更详细地学习建议去阅读原书即可。 Searching For Files 文件查找 linux 倡导所谓的一切皆文件，那我们怎么在系统中查找到自己想要的文件呢。 locate 查找文件的简单方法 搜索路径名数据库，并且输出每个与给定字符串相匹配的文件名 locate bin/zip 搜索 bin 路径下所有包含zip的路径名 可以结合grep一起使用提高效率 locate 的搜索数据库由updatedb程序创建，并不是实时更新。因此找到的文件不是最新的 updatedb可以使用root进行手动更新 find查找文件的复杂方法 需要明确的一点：find是一个非常神奇的命令 find 最简单的用法是给定一个或者多个目录名去搜索 如 find ~ （搜索自己的家目录） find 下有三层操作方式，分别是** options,tests 和 actions**（详细的信息可以查看 help 帮助文档） test find ~ -type d -type属于测试操作，用来限定查找类型 b 块设备文件 c 字符设备文件 d 目录 f 普通文件 l 符号链接 根据文件名和文件大小进行搜索 find ~ -type f -name &quot;\\*.JPG&quot; -size +1M 这里需要加入双引号防止 shell 展开路径名 +1M 表示大于 1M，不加任何符号表示精确匹配 其他可能会用到的几个 test 条件 -name pattern 用指定的通配符模式匹配的文件和目录 -iname pattern 类似-name 测试条件，不区分大小写 -nouser 匹配的文件和目录不属于一个有效用户 -nogroup 匹配的文件和目录不属于一个有效的组 -size n 匹配的文件大小为 n -type c 匹配的文件类型是 c -user name 匹配的文件或目录属于某个用户，通过用户名或用户 ID 来表示 -group name 匹配的文件和目录属于一个组，用组名或组 ID 来表示 -cmin n 匹配的文件和目录的内容或属性最后修改时间正好在 n 分钟之前 -ctime n 匹配的文件和目录的内容和属性最后修改时间在 n\\*24 小时之前 -newer file 匹配的文件和目录的内容早于指定的文件。当编写 shell 脚本，做文件备份时非常有帮助 -empty 匹配空文件和目录 -inum n 匹配的文件的 inode 号是 n，找到某个特殊 inode 的所有硬链接 -perm mode 匹配的文件和目录的权限是指定的 mode。mode 用八进制或符号表示。 options 使用逻辑操作符建立逻辑关系 查找权限不是 0600 的文件和权限不是 0700 的目录方法 find ~ \\( -type f -not -perm 0600 \\) -or \\( -type d -not -perm 0700 \\) -and 符两边的测试条件都是真则匹配（默认操作） -or 若两边的任一测试条件为真则匹配 -not 若后面的测试条件是真则匹配 () 把测试条件和操作符组合起来控制逻辑优先级，使用时用反斜杠进行转义 Predefined Actions 预定义操作 -delete 删除匹配文件 -ls 对匹配的文件执行等同的 ls -dils 命令。并将结果发送到标准输出。 -print 把匹配文件的全路径名输送到标准输出。如果没有指定其它操作，这是默认操作。 -quit 一旦找到一个匹配，退出。 xargs 从标准输入接受输入，并把输入转换为一个命令的参数 如果文件名中有空格，需要使用-print0 find ~ -iname ‘*.jpg’ -print0 | xargs –null ls -l find 其他参数 -depth 指导 find 程序先处理目录中的文件，再处理目录自身 -maxdepth levels 当执行测试条件和行为的时候，设置目录深度 -mindepth levels 在应用测试条件和行为之前，设置目录深度 -mount 指导 find 程序不要搜索挂载到其它文件系统上的目录 Archiving And Backup 存档备份 压缩 不要压缩已经压缩过的文件 gzip/gunzip 压缩后会取代原始文件 权限和时间戳不变 -c 把输出写入到标准输出，并且保留原始文件。等价于 zcat -d 解压缩，等价于 gunzip -f 强制压缩 -l 显示文件的压缩比例和大小 -r 递归压缩目录 -t 测试压缩文件的完整性 -v 显示压缩过程中的信息 -number 设置压缩指数。1 最快，9 最小，默认值 6 bizp2 速度慢压缩程度更高 相应命令有 bunzip2; bzcat 存档 多个文件整合为一个文件的过程 tar 参数分为 mode 和 options，必须首先包含一个操作模式 -A, 将一存档与已有的存档合并 -c, 建立新存档 -d, 比较存档与当前文件的不同之处 --delete 从存档中删除 -r, 附加具体路径到存档结尾 -t, 列出存档内容 -u, 将较新的文件附加到存档中 -x, 从存档展开文件 归档 tar cvf FileName.tar DirName （f 要紧跟内容） 展开 tar xvf FileName.tar 配合gzip压缩解压 解压：tar zxvf FileName.tar.gz 压缩：tar zcvf FileName.tar.gz DirName 配合bzip2 压缩 tar cjf FileName .tar.bzDirName 解压 tar jxvf FileName .tar.bz 同步 rsync rsync options source destination source 和 destination 指代 一个本地文件或目录 一个远端文件或目录，以[user@]host:path 形式存在 一个远端 rsync 服务器，由rsync://[user@]host[:port]/path 指定 必须有一个本地文件 具体用法待补充 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-09-22-LinuxCommandLine5/"},{"title":"vs code 常用快捷键","content":" 挺早之前写过一个 常用快捷键的集合备忘录，里面包括 win10，印象笔记，Google 浏览器，XShell 以及 sublime text3。如今主力编辑器已经从 sublime text3 换到了 vs code。那就再整理一份 vs code 常用快捷键，希望尽快用熟练提高效率。 首先摆出原件。 VsCode 快捷键组合方式 Ctrl + Shift + ? : 常规组合按钮 Ctrl + K Ctrl + ? : 首先进入 Ctrl K 环境，再组合按键 Shift + K ? : 首先进入 Ctrl K 环境，再单按键 Ctrl + Click: 键盘 + 鼠标点击 Ctrl + DragMouse : 键盘 + 鼠标拖动 通用快捷键 快捷键 功能 Ctrl+Shift+P,F1 调出命令面板（常用） Ctrl+P 快速打开文件 Ctrl+Shift+N 打开新编辑器 Ctrl+Shift+W 关闭编辑器 在 Ctrl+P 窗口下： 直接输入文件名，跳转到文件 ? 列出当前可执行的动作 ! 显示 Errors 或 Warnings，也可以`Ctrl+Shift+M : 跳转到行数，也可以 Ctrl+G 直接进入 @ 跳转到 symbol（搜索变量或者函数），也可以 Ctrl+Shift+O 直接进入 @: 根据分类跳转 symbol，查找属性或函数，也可以 Ctrl+Shift+O 后输入：进入 # 根据名字查找 symbol，也可以 Ctrl+T 基础操作 快捷键 功能 Ctrl + X 剪切 Ctrl + C 复制 Alt + up/down 上下移动行 Shift + Alt up/down 当前行上下复制该行内容 Ctrl + Shift + K 删除行 Ctrl + Enter 光标所在行下插入新行 Ctrl + Shift + Enter 在光标所在行上插入新行 Ctrl + Shift + \\ 匹配花括号的闭合处，跳转 Ctrl + ] / [ 缩进 Home 光标跳转到行头 End 光标跳转到行尾 Ctrl + Home 跳转到文件开头 Ctrl + End 跳转到文件结尾 Ctrl + up/down 行滚动（光标位置不变） Alt + PgUp/PgDown 屏滚动 Ctrl + Shift + [ 折叠代码 Ctrl + Shift + ] 展开代码 Ctrl + K Ctrl + [ 折叠所有子区代码 Ctrl + k Ctrl + ] 展开所有折叠子区代码 Ctrl + K Ctrl + 0 折叠所有区域代码 Ctrl + K Ctrl + J 展开所有折叠区域代码 Ctrl + K Ctrl + C 添加行注释 Ctrl + K Ctrl + U 删除行注释 Ctrl + / 行注释 Shift + Alt +A 块注释 导航 快捷键 功能 Ctrl + T 列出所有符号 Ctrl + G 跳转行 Ctrl + P 跳转文件 Ctrl + Shift + O 跳转到符号处 F8 跳转到下一个错误或者警告 Shift + F8 跳转到上一个错误或者警告 Ctrl + Shift + Tab 切换到最近打开的文件 Alt + left / right 回到上个位置和下个位置 Ctrl + M 用 Tab 来移动焦点 查询与替换 快捷键 功能 Ctrl + F 查询 Ctrl + H 替换 F3 / Shift + F3 查询下一个/上一个 Alt + Enter 选中所有查询到的内容 Ctrl + D 匹配当前选中的词汇或者行，重复操作 Ctrl + K Ctrl + D 移动当前选择到下个匹配位置 Alt + C/R/W 不分大小写/使用正则/全字匹配 多行操作和选择 快捷键 功能 Alt + Click 插入光标 Ctrl + U 撤销最后一次操作 Shift + Alt + I 插入光标到选中范围内所有行尾 Ctrl + I 选中当前行 Ctrl + Shift + L 选中所有同样内容 Ctrl + F2 选中所有同样内容 Shift + Alt + right 块选择 Shift + Alt + left 块选择 Shift + Alt + (drag mouse) 鼠标拖动区域，同时在多个行结束符插入光标 Ctrl + Shift + Alt + (Arrow Key) 插入多行光标的 [方向键控制] Ctrl + Shift + Alt + PgUp/PgDown 插入多行光标的 [整屏生效] 语言操作 快捷键 功能 Ctrl + Space 输入建议 Ctrl + Shift + Space 参数提示 Tab Emmet 指令触发/缩进 Shift + Alt + F 格式化代码 Ctrl + K Ctrl + F 格式化选中部分的代码 F12 跳转到定义处 Alt + F12 代码片段显示定义 Ctrl + K F12 在其他窗口打开定义处 Ctrl + . 快速修复部分可以修复的语法错误 Shift + F12 显示所有引用 F2 重命名符号 Ctrl + Shift + . / , 替换下个值 Ctrl + K Ctrl + X 移除空白字符 Ctrl + K M 更改页面文档格式 编辑器管理 快捷键 功能 Ctrl + F4, Ctrl + W 关闭编辑器 Ctrl + k F 关闭当前打开的文件夹 Ctrl + |切割编辑窗口 Ctrl + 1/2/3 切换焦点在不同的切割窗口 Ctrl + K Ctrl 左右箭头 不同窗口切换焦点 Ctrl + Shift + PgUp/PgDown 切换标签页的位置 Ctrl + K 左右箭头 窗口位置调换 文件管理 快捷键 功能 Ctrl + N 新建文件 Ctrl + O 打开文件 Ctrl + S 保存文件 Ctrl + Shift + S 另存为 Ctrl + K S 保存所有当前已经打开的文件 Ctrl + F4 关闭当前编辑窗口 Ctrl + K Ctrl + W 关闭所有编辑窗口 Ctrl + Shift + T 撤销最近关闭的一个文件编辑窗口 Ctrl + K Enter 保持开启 Ctrl + Tab 调出最近打开的文件列表 Ctrl + K P 复制当前打开文件的存放路径 Ctrl + K R 打开当前文件位置 Ctrl + K O 在新的编辑器中打开当前文件 显示 快捷键 功能 F11 切换全屏模式 Ctrl + =/- 放大 / 缩小 Ctrl + B 侧边栏显示隐藏 Ctrl + Shift + E 资源视图和编辑视图的焦点切换 Ctrl + Shift + F 打开全局搜索 Ctrl + Shift + G 打开 Git 可视管理 Ctrl + Shift + D 打开 DeBug 面板 Ctrl + Shift + X 打开插件市场面板 Ctrl + Shift + H 在当前文件替换查询替换 Ctrl + Shift + J 开启详细查询 Ctrl + Shift + V 预览 Markdown 文件 Ctrl + K v 在边栏打开渲染后的视图 调试 快捷键 功能 F9 添加解除断点 F5 启动调试、继续 F11 / Shift + F11 单步进入 / 单步跳出 F10 单步跳过 Ctrl + K Ctrl + I 显示悬浮 集成终端 快捷键 功能 Ctrl + ` 打开集成终端 Ctrl + Shift + ` 创建一个新的终端 Ctrl + Shift + C 复制所选 Ctrl + Shift + V 复制到当前激活的终端 Shift + PgUp / PgDown 页面上下翻屏 Ctrl + Home / End 滚动到页面头部或尾部 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-09-20-vscode2/"},{"title":"在博客中展示数学公式","content":" 最近写的一系列文章中需要时不时插入一些数学公式，也就不得不接触一些 LaTeX 相关内容，另外由于要发到博客上，还需要让博客能够正确解析 LaTeX 语法。 Hexo 插入数学公式起步 Hexo 博客框架默然使用的 Markdown 解析插件是 hexo-renderer-marked, 我同时使用了 Next 主题。 首先要说明的是，Hexo 默认 Markdown 是不支持 LaTeX 语法的，但是，Next 的主题默认已经支持 MathJax，也就是说不需要再在网页的 header 中引入如下代码： &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt; &lt;/script&gt; 只需要在主题下的配置文件_config.yml中启用相关设置即可 # MathJax Support mathjax: enable: true per_page: true cdn: //cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML 在需要启用 MathJax 的 post 中进行设置 --- title: 统计学基础与 R-2 mathjax: true --- 这么几步下来，网页上其实已经可以显示一部分公式了。但是在 MathJax 中，包含_（下划线）的下标表示语法还是不能正确识别。 尝试不同的 Markdown 插件 为了解决部分 MathJax 语法不能正确编译的问题，我在 Google 上大致搜了搜，主要意见都是一劳永逸的更换 Hexo 的 Markdown 插件。 第一种可供更换的插件是hexo-renderer-pandoc，pandoc 可以说是最牛最全的 Markdown 渲染引擎，R Markdown 用的就是它。 首先在电脑上安装 pandoc 然后在 hexo 中进行如下操作 npm un hexo-renderer-marked --save #卸载旧的 npm install hexo-renderer-pandoc --save 安装新的 然后在后期渲染的过程中，报错了。 INFO Start processing FATAL Something’s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.html Error: [pandoc warning] YAML header is not an object “source” (line 67, column 1) at ChildProcess. (/Users/sean10/Code/sean10.github.io/node_modules/hexo-renderer-pandoc/index.js:73:20) at emitTwo (events.js:106:13) at ChildProcess.emit (events.js:191:7) at maybeClose (internal/child_process.js:877:16) at Process.ChildProcess._handle.onexit (internal/child_process.js:226:5) 在 pandoc 解析的过程中，渲染出现了问题，很可能是我有些文章写得 Markdown 语言并不完全符合 pandoc, 排查这么多篇文章中的错误太浪费时间，于是放弃。 随后，又找到了另一个插件，hexo-renderer-markdown-it-plus 这个插件支持各种各样的 Markdown 扩展语法，尤其是支持 katex。于是我使用后发现确实解决了部分语法不识别的问题，但是所有数学公式除了渲染输出外还会在输出一遍原始格式。迫于无奈，这个方法也放弃了。 修改默认插件语法规则 更换插件的尝试失败后，回顾问题所在其实是默认搜索引擎的下划线语法和 mathjax 的下标语法冲突。也就是说当我在一个公式中出现了两次下标，输入两次_后，默认会把两个下划线之间的部分解析为斜体。 如果不想修改默认语法规则，需要在数学公式中使用\\_对_进行转义，这么做实在是有点麻烦。干脆修改原始的默认语法规则，不让_斜体_转义为斜体字，而是只采用*斜体*的方式。 找到配置文件node_modules\\marked\\lib\\marked.js，对escape,strong 和 em进行如下修改 var inline = { //escape: /^\\\\([\\\\`*{}\\[\\]()#+\\-.!_&gt;])/, escape: /^\\\\([`*{}\\[\\]()# +\\-.!_&gt;])/, autolink: /^&lt;([^ &gt;]+(@|:\\/)[^ &gt;]+)&gt;/, url: noop, tag: /^&lt;!--[\\s\\S]*?--&gt;|^&lt;\\/?\\w+(?:&quot;[^&quot;]*&quot;|'[^']*'|[^'&quot;&gt;])*?&gt;/, link: /^!?\\[(inside)\\]\\(href\\)/, reflink: /^!?\\[(inside)\\]\\s*\\[([^\\]]*)\\]/, nolink: /^!?\\[((?:\\[[^\\]]*\\]|[^\\[\\]])*)\\]/, //strong: /^__([\\s\\S]+?)__(?!_)|^\\*\\*([\\s\\S]+?)\\*\\*(?!\\*)/, strong: /^\\*\\*([\\s\\S]+?)\\*\\*(?!\\*)/, //em: /^\\b_((?:[^_]|__)+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, em: /^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, code: /^(`+)\\s*([\\s\\S]*?[^`])\\s*\\1(?!`)/, br: /^ {2,}\\n(?!\\s*$)/, del: noop, text: /^[\\s\\S]+?(?=[\\\\&lt;!\\[_*`]| {2,}\\n|$)/ }; 保存之后，清空 hexo 缓存，重新部署一次就可以了。最后的效果，可以参考文章 统计学基础与 R-2 后续 配合默认 Markdown 渲染引擎和 MathJax 使用，其实还有一个问题，支持行内公式，但是即便修改了源代码也没有实现多行书写（\\\\换行），比如 $$ H=-\\sum_{i=1}^N (\\sigma_{i}^x \\sigma_{i+1}^x+g \\sigma_{i}^z) $$ ## 用 \\\\ 没有正常换行 $$ f(n) = \\begin{cases} \\frac{n}{2}, &amp; \\text{if } n\\text{ is even} \\\\ 3n+1, &amp; \\text{if } n\\text{ is odd} \\end{cases} $$ ## 用、\\\\ 代替正常的、\\ 实现换行 $$ f(n) = \\begin{cases} \\frac{n}{2}, &amp; \\text{if } n\\text{ is even} \\\\\\ 3n+1, &amp; \\text{if } n\\text{ is odd} \\end{cases} $$ $$f(x): \\begin{cases} x, x&gt;0 \\\\\\ -x,x&lt;0 \\end{cases}$$ 目前下面的所有公式都能正常显示，是因为我已经解决了上文提到的问题。可以看最下面的解决方法。 H=−∑i=1N(σixσi+1x+gσiz)H=-\\sum_{i=1}^N (\\sigma_{i}^x \\sigma_{i+1}^x+g \\sigma_{i}^z) H=−i=1∑N​(σix​σi+1x​+gσiz​) f(n)={n2,if n is even3n+1,if n is oddf(n) = \\begin{cases} \\frac{n}{2}, &amp; \\text{if } n\\text{ is even} \\\\ 3n+1, &amp; \\text{if } n\\text{ is odd} \\end{cases} f(n)={2n​,3n+1,​if n is evenif n is odd​ f(n)={n2,if n is even 3n+1,if n is oddf(n) = \\begin{cases} \\frac{n}{2}, &amp; \\text{if } n\\text{ is even} \\\\\\ 3n+1, &amp; \\text{if } n\\text{ is odd} \\end{cases} f(n)={2n​, 3n+1,​if n is evenif n is odd​ f(x):{x,x&gt;0 −x,x&lt;0f(x): \\begin{cases} x, x&gt;0 \\\\\\ -x,x&lt;0 \\end{cases} f(x):{x,x&gt;0 −x,x&lt;0​ 但是hexo-renderer-markdown-it-plus是可以解决这个问题，在一篇博客中有比较详细的介绍 hexo-renderer-markdown-it-plus plugin demo，可能未来还是需要弄清楚我安装这个插件时出现重复显示的原因。 最终更新 上面提到在使用hexo-renderer-markdown-it-plus时，遇到了公式重复渲染的问题，目前这个方式已经解决，解决方法如下。 npm un hexo-renderer-marked --save #卸载旧的默认 Markdown 插件 npm install hexo-renderer--markdown-it-plus --save 安装新的增强型插件 卸载就插件之后，之前修改的marked.js文件已经被随之删除。现在，我们最需要的是hexo-renderer-markdown-it-plus中的 Katex 插件，为了使用 katex 需要在主题中的网页中引入相关 CSS 文件。 Next 主题中，专门为用户准备了一个自定义文件，即themes\\next\\layout\\_custom\\header.swig文件。在这个自定义 header 文件中写入如下内容 &lt;link href=&quot;https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css&quot; rel=&quot;stylesheet&quot;&gt; # 不要引入最新的 katex 文件，显示效果和插件并不兼容 紧接着在 Hexo 的配置文件中进行配置（可选项） #markdown 设置 markdown_it_plus: highlight: true html: true xhtmlOut: true breaks: true langPrefix: linkify: true typographer: quotes: “”‘’ plugins: - plugin: name: markdown-it-katex enable: true - plugin: name: markdown-it-mark enable: false 因为该插件调用的是KaTeX\\KaTeXKATE​X, 因为可以将主题配置文件修改为 # MathJax Support mathjax: enable: false per_page: false cdn: //cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML 同时新的文章头部也不再需要添加mathjax=true 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-09-19-UseMathJaxinHexo/"},{"title":"统计学基础与 R-2","content":"写在前面 入门生物信息，所有人都绕不开统计基础知识和相关实现方式。本章我们将简要介绍统计学相关基础知识以及如何使用 R 语言进行简单地计算和分析。 概率相关内容 统计学中大量内容源于概率，学习统计学也就必须要了解一些概率中的基本概念，其中尤为重要的是条件概率，以及延伸出的贝叶斯定理（也许是最牛也是最难充分掌握的内容）。 几个概念 **样本空间 (sample space) **是所有可能结果的一个集合，**事件 (event) 则是样本空间中所有感兴趣结果的一个子集。某事件的概率 (probability) **是该事件在无限次试验次数中的相对频率。 事件的交集并集和补集，概率的加法法则和乘法法则在本章中不再做介绍。 **条件概率 (Conditional Probability) **用来描述与其他事件的发生相关的某事件的概率，通常被描述成“在 A 事件下发生事件 B 的概率”。在书写时用|表示，例如P(A|B)是在 B 发生的情况下 A 发生的概率。计算方式为 AB 同时发生的次数除以所有 B 发生的次数。 条件概率计算方法：P(A∣B)=P(A∩B)/P(B)P(A|B)=P(A\\cap B)/P(B)P(A∣B)=P(A∩B)/P(B) 可推出：P(B∣A)=P(A∩B)/P(A)P(B|A)=P(A\\cap B)/P(A)P(B∣A)=P(A∩B)/P(A) =&gt; P(A∩B)=P(A)×P(B∣A)P(A\\cap B)=P(A)\\times P(B|A)P(A∩B)=P(A)×P(B∣A) 全概率公式：P(B)=P(A)×P(B∣A)+P(A′)×P(B∣A′)P(B)=P(A)\\times P(B|A)+P(A&#x27;)\\times P(B|A&#x27;)P(B)=P(A)×P(B∣A)+P(A′)×P(B∣A′) （贝叶斯定理分母部分） 贝叶斯定理：P(A∣B)=P(A)×P(B/A)P(A)×P(B∣A)+P(A′)×P(B∣A′)P(A|B)=\\frac{P(A)\\times P(B/A)}{P(A)\\times P(B|A)+P(A&#x27;)\\times P(B|A&#x27;)}P(A∣B)=P(A)×P(B∣A)+P(A′)×P(B∣A′)P(A)×P(B/A)​ 得到的贝叶斯定理可以帮助我们计算逆条件概率。 在实际的生物学数据处理的过程中，我们还会接触到灵敏度 (sensitivity)、特异度 (specificity)、假阳性 (false negative) 和假阴性 (false positive) 几个概念。在疾病相关研究中，对于某一个症状，灵敏度指发病后出现症状的概率，特异度是不发病时不出现症状的概率。假阳性是指实验结果阳性但是实际为阴性，假阴性是指实验结果为阴性但是实际为阳性。基于灵敏度和特异度可以使用 ROC 曲线，通常来说在两个检验中，曲线下面积大的较好。 概率能够告诉我们事件发生的可能性，但如果想要利用概率预测未来的结果并且评估预测的确定性就需要引入概率分布。 离散概率分布 随机变量： 样本空间中，对不同事件指定有相应概率的数值函数。 随机变量是可以等于一系列数值的变量，这些值都和一个特定概率关联。它的写法是P(X=x)P(X=x)P(X=x)，表示随机变量 X 取特定值为 x 时的概率。随机变量包括离散和连续两种形式，所谓离散指变量只能取一些确定值。连续指的是有无限多种可能取值。 概率分布也叫概率质量分布，P(X=x)P(X=x)P(X=x)。在描述统计量中，样本的频数分布描述每个取值及对应发生次数，如果样本总数除以对应发生次数，得到的频率分布就类似于这里的概率分布。后面会提到的“拟合优度检验”就是比较有限样本频率分布和概率分布的差异。 如果将随机变量和样本对应起来理解，样本中均值的概念在总体（随机变量）中称为期望，也叫作总体均值，表示为μ\\muμ（和均值一致）或者E(X)E(X)E(X)。计算方式是将每个可能值和概率相乘再把所有乘积相加。和均值类似，这里的期望也无法描述相关数值分散程度。 同样，在随机变量中也有类似于样本方差的概念，称为总体方差（随机变量方差），用来表示分散程度。其计算公式为 Var(X)=E(X−μ)2Var(X) = E(X-\\mu)^{2}Var(X)=E(X−μ)2。而概率分布的标准差σ\\sigmaσ同样是方差的平方根。 计算E(X−μ)2E(X-\\mu)^{2}E(X−μ)2时，首先计算每个数值 x 的(x−μ)2(x-\\mu)^{2}(x−μ)2, 然后再将结果乘以概率，最后把所有结果相加。 在数据集中，方差和标准差表示的是数据和均值的距离，在概率分布中表示特定数值概率的分散情况。方差越小，结果越接近期望。 累加分布函数 (cumulative-distribution function, cdf): 随机变量 X，对于 X 的任一指定值 x，概率值P(X≤x)P(X\\leq x)P(X≤x)。即随机变量取值不大于指定值的概率。记作F(x)F(x)F(x) 常见的离散概率分布 几何分布：进行一组相互独立实验，每次实验有成功失败两种可能且每次试验概率相等，想知道第一次成功需要进行的试验次数。 P(X=r)=pqr−1P(X=r)=pq^{r-1} P(X=r)=pqr−1 P(X&gt;r)=qrP(X&gt;r)=q^{r} P(X&gt;r)=qr P(X≤r)=1−qrP(X \\leq r)=1-q^{r} P(X≤r)=1−qr 期望E(X)=1xE(X)=\\frac{1}{x}E(X)=x1​；方差 Var(X)=qp2Var(X)=\\frac{q}{p^{2}}Var(X)=p2q​ 二项分布：进行一组相互独立试验，每次实验有成功失败两种可能，每次试验概率相等且试验次数有限，想知道在有限次试验中成功的次数。 P(X=r)=Cnrprqn−rP(X=r)=C^{r}_{n}p^{r}q^{n-r} P(X=r)=Cnr​prqn−r 期望E(X)=npE(X)=npE(X)=np；方差Var(X)=npqVar(X)=npqVar(X)=npq 二项分布和几何分布差别在于，前者试验次数固定求成功概率，后者求第一次成功前试验次数。 泊松分布：常与稀有事件相关，单独事件在给定区间（区间可以是时间或者空间）内随机独立发生，该区间内的事件平均发生次数已知且为有限值。这个值用λ\\lambdaλ表示。给定区间内发生 r 次事件的概率计算公式：$$P(X=r)=\\frac{e{-\\lambda}\\lambda{r}}{r!}$$ 期望是给定区间内能够期望的事件发生次数 λ，方差也是 λ。如果一个离散随机变量的一批数据计算后方差和均值近似相等，则可以推测样本符合泊松分布。 当二项分布的 p 很小且 n 非常大时，npq≈npnpq\\approx npnpq≈np, 方差和期望近似相等，可以用泊松分布来近似二项分布，从而使计算简化。通常，n 大于 50 且 p&lt;0.1 时为典型的近似情况。 连续概率分布 当数据连续分布，人们关心的是取得某一个特定范围的概率。 概率密度函数 (probability density function, pdf): 本质是一个函数，用这个函数可以求出在一个范围内某连续变量的概率，同时该函数可以指出该概率分布的形状。换句话讲，任意 a,b 两点之间及函数对应曲线下组成的面积等于随机变量 X 落在 ab 间的概率。曲线下面积总和是 1。 概率密度可以指出各种范围内的概率大小，用面积来表示。概率密度只是表示概率的一种方法而非概率本身。 累加分布函数 a 点上的值等于随机变量 X 取值≤a\\leq a≤a的概率，也是概率密度函数 a 左边曲线下的面积。 正态分布是连续数据的一种理想状态。正态分布的概率密度函数是一条对称的钟形曲线，均值具有最大的概率密度，偏离均值概率密度逐渐变小。参数μ\\muμ是均值，也是曲线的中央位置，σ\\sigmaσ表述曲线的“胖瘦”。 连续随机变量 X 符合均值为μ\\muμ，标准差为σ\\sigmaσ的正态分布时写作X∼N(μ,σ2)X\\sim N(\\mu,\\sigma^{2})X∼N(μ,σ2). 线性变换：$$aX+b \\sim N(a\\mu +b,a{2}\\sigma{2})$$ 当 X 和 Y 相互独立（彼此之间没有影响）时： X+Y∼N(μx+μy,σx2+σy2)X+Y \\sim N(\\mu_{x}+\\mu_{y},\\sigma_{x}^{2}+\\sigma_{y}^{2}) X+Y∼N(μx​+μy​,σx2​+σy2​) X−Y∼N(μx−μy,σx2+σy2)X-Y \\sim N(\\mu_{x}-\\mu_{y},\\sigma_{x}^{2}+\\sigma_{y}^{2}) X−Y∼N(μx​−μy​,σx2​+σy2​) 期望E(X1+X2+...+Xn)=nE(X)E(X_{1}+X_{2}+...+X_{n})=nE(X)E(X1​+X2​+...+Xn​)=nE(X)；方差Var(X1+X2+...+Xn)=nVar(X)Var(X_{1}+X_{2}+...+X_{n})=nVar(X)Var(X1​+X2​+...+Xn​)=nVar(X) 当 X 和 Y 并不彼此独立时，使用**协方差 (Covariance) **来描述两个随机变量间的关系，记做 Cov(X,Y) Cov(X,Y)=E[(X−μx)(Y−μy)]Cov(X,Y)=E[(X-\\mu_{x})(Y-\\mu_{y})] Cov(X,Y)=E[(X−μx​)(Y−μy​)] 二项分布正态近似：通常情况，当二项分布满足np≥5np\\geq 5np≥5 （也有建议npq≥5npq\\geq 5npq≥5) 时，可以用正态分布代替二项分布。其中μ=np\\mu = npμ=np,σ2=npq\\sigma^{2}=npqσ2=npq。另外，当泊松分布的 λ&gt;15 时，也可以用正态分布进行近似。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-09-18-RandStatistics2/"},{"title":"统计学基础与 R-1","content":"写在前面 入门生物信息，所有人都绕不开统计基础知识和相关实现方式。本章我们将简要介绍统计学相关基础知识以及如何使用 R 语言进行简单地计算和分析。 描述性统计量 为了解决某个问题，我们通常会观察一组和该问题相关的样本，利用总体中的部分样本来推断总体的情况进而得到相关结论。在通过样本推断总体前，首先需用对已有样本数据进行简单的评估和描述，针对这一需求也就引出了描述统计量这一概念。进行描述性统计时，我们最关注数据两个层面的问题：数据的集中趋势和变异分散性。 数据的集中趋势 面对少则几十多则上千个数字，第一步通常是观察平均水平。下面介绍三个计算数据平均水平的概念：分别是均值 (mean)、中位数 (median) 和众数 (mode)。 均值：所有观察值的和除以观察的个数。算数平均是最自然和常用的测度，其问题在于对异常值 (outliers) 非常敏感。有极端值存在时，均值不能代表样本的绝大多数情况。 中位数：所谓中位数，是指所有样本观测值由小到大排序，位于中间的一个（样本数为奇数）或者两个数据的平均值（样本数为偶数）。 当数据分布对称时，中位数近似等于算数平均数；当数据正倾斜时（图像向右倾斜），中位数小于算数平均数；当数据负倾斜时（图像向左倾斜），中位数大于算数平均数。因此，我们可以通过比较样本的均值和中位数对数据的分布对称性进行初判断。 众数：在样本所有观测值中，出现频率最大（出现次数最多）的数值称为众数。这里需要说明，当数据量很大而且数值不会多次重复出现时众数并不能带来太多信息。比如当计算上万个基因的表达量后，得到的众数最可能是 0，因为每个基因的表达值或多或少都有一些不同，这时候出现最多的就是那些没有检测到表达基因的 0 了。但是在遇到类别数据而非数值型数据时众数有很大用处，或者说众数是唯一可以用于类别数据的平均数。 在 R 中，均值和中位数可以通过mean()和median()进行计算，而众数可以通过modeest包mfv()函数得到。 数据的变异性（离散性） 平均数显然不能说明一切问题，在说明样本数据时我们还必须考虑数据是不是过于分散。例如在篮球队员投篮平均得分相同的情况下，更重要的是知道他们谁发挥更加稳定。 极差 (range) 指一个样本中最大值和最小值之间的差值。在统计学中也称为全距，它能够指出数据的“宽度”（范围）。但它和均值一样易受极端值影响，而且也会受样本量明显影响。 针对极差的缺点，统计学又引入分位数 (quantiles) 概念，通俗讲是把数据的“宽度”细分后再去进行比较从而更好地描述数据的分布形态。分位数用三个点将从小到大排列好的数据分为四个相等部分，而这三个点也就是我们常说的四分位数，分别叫做下四分位数，中位数和上四分位数。当然，除了四分位也可以计算十分位或者百分位。 分位数的引进能够说明数值的位置，但无法说明某数值在该位置出现的概率。为了说明数据的稳定程度，我们可以考虑计算每个数据值到平均数的距离（此处可以脑补一个高瘦形的数据曲线和矮胖形的数据曲线），但样本中所有观测值与均值偏差的和永远是 0。为了解决这种正负距离相互抵消的问题，统计学又引入**方差 (variance) 和标准差 (standard deviation) **概念。 所谓方差指数值与均值距离平方数的平均数，而标准差则是方差的平方根。标准差体现了数据的变异度，标准差越小，数值和均值越近。通常均值用μ\\muμ表示，而标准差用σ\\sigmaσ表示。 在 R 中，可以通过quantile()计算分位数，通过var()来计算方差，通过sd()来计算标准差。 有了标准差的概念，随之而来的问题是当两个样本标准差相同但是均值相差很大时该如何做出区分。于是，统计学引入了变异系数 (coefficient of variation, CV) 概念，变异系数是指样本标准差除以均值再乘 100%。变异系数不会受数据尺度的影响，因此常用来进行不同样本之间变异性的比较。 在实际的数据分析中，如果要比较不同数据集（均值和标准差都不同）之间的数值，通常会引入** z score **的概念，z score 的计算方法是用某一数值减去均值在除以标准差。通过对原始数据进行 z 变换，我们将不同数据集转化为一个新的均值为 0，标准差为 1 的分布。 计算描述性统计量 在 R 中，使用summary()函数会得到一个 data frame 的很多 描述性统计量。当数据某一列是数值型变量时，可以得到该列数据的均值、极值、方差和分位数。 下面我们使用 R 中内置的数据** Edgar Anderson's Iris Data **进行一些简单展示。 summary(iris) #查看常用的描述统计量 Sepal.Length Sepal.Width Petal.Length Petal.Width Species Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 setosa :50 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 versicolor:50 Median :5.800 Median :3.000 Median :4.350 Median :1.300 virginica :50 Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ### 形象化展示 所谓形象化展示就是用图来展示数据结果，比较常见的方法有条形图，箱线图，直方图等 ```r boxplot(iris$Sepal.Length) # 使用箱线图展示某一列数据的分布情况 hist(iris$Sepal.Length) # 使用直方图展示某一列数据的分布情况 plot(ecdf(iris$Sepal.Length)) # 绘制简单的累积分布函数图展示某一列数据分布情况 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-09-16-RandStatistics1/"},{"title":"VScode 使用初体验","content":"什么是 vs code 巨硬主导的开源文本编辑器项目，如果你不知道它，一定也听说过 sublime 或者 atom , 最起码也听说过 Notepad++。 为什么要用 vs 上 code 用了两年的 sublime text 3, 忘了是谁在我一开始用的时候给我提供了一个注册码，以至于我都忘了这货不是一个开源软件。直到几天前突然提示我更新，要知道 sublime text 3 的 beta 版已经持续了好几年。我一激动就点了更新然后……就一直提醒我要不要买。问了问身边的其他人也早已经慢慢从 sublime 转向了其他的阵营，再加上 sublime 用的却是不太顺心，我也就有了换一个编辑器的想法。 目前大家用的最多的三款编辑器分别是 sublime、atom 和 vs code。于是我用两天时间重点体验了 atom 和 vscode, 进行了几项比较之后决定投入 vs code 的怀抱。 比较内容如下： 启动速度尽量快，打开稍大的文件尽量快； 尽量少吃内存； 插件要丰富，可以方便的测试和 debug 使用逻辑要符合自己的口味 比较结果 占用内存和启动速度方面，vs code 给我的感觉和 sublime 基本不分上下，而 atom 则表现出了比较明显的缺点。 插件的丰富程度和管理容易度上 atom 和 vs code 确实都甩 sublime 几条街，而且 atom 绝大多数插件都支持二次定制，非常强大。 使用逻辑上，vs code 给我的感觉最为清晰，而且很好的支持源代码托管以及各种调试。另外，国际化的支持使得 vs code 支持简体中文，初次使用更容易上手。 所以，就选定了 vs code 。而这篇文章就是我在 vs code 上用 Markdown 写成的，多窗口布局支持再配合上牛人的插件支持实时预览。 vs code 使用体验 整体界面 如上图所示，初次打开 vs code 会发现界面主次分明，非常简洁。左边栏从上到下依次是文件资源管理器，跨文件（文件夹）搜索，源代码管理，启动测试和扩展管理。直观醒目，想干什么点什么就可以，完全不用去管顶部的各种选项。左下角会显示你当前脚本中的各种错误和警告信息。使用F1或者ctrl+shift+P可以调出快速导航栏，和 sublime 类似。 资源管理器 打开资源管理器，展示的内容也是足够清晰（这里我安装了 project manager 扩展），首先是编辑器已经打开的文件，然后是正在使用的项目，最后可以提前存入若干常用的项目放在 favorites 列表中做到一件切换。 需要说明，我安装的 insider 版本已经支持在工作区同时打开多个文件夹了。但是由于我不同文件夹在服务器的备份位置不同，所以还是把每个文件夹看做一个独立的项目更加合适，在后期利用 sftp 插件备份会更加灵活。 启动调试 vs code 支持多种语言的调试，当然主打还是 web 开发。我们其实可以把 vs code 和 atom 这类编辑器大致理解为一个浏览器。在 vs code 的调试界面中，可以显示变量和监事信息，也可设置断点，另外，还有插件 (Debugger fro chrome) 助阵。 扩展管理 点击扩展管理图标后，你可以轻松的查看管理已经安装的扩展插件，也可以在搜索框里搜索自己想要的插件进行安装。这里多说一句，插件真的是太多了，我目前已经安装了 46 个，打算再使用半个多月的时间将插件总数控制在 30 个以内，以后想安装一个新的就必须删掉一个旧的。很多时候，less is more。 这次就先写到这里，更多的使用技巧下次再说。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-09-15-vscode1/"},{"title":"Linux Command Line 学习笔记4","content":" 说明；写 Linux Command Line 学习笔记系列文章本意只是记录自己学习 《Linux Command Line 》 这本书的过程中看到的一些自己没有留意到的地方，因此绝大多数内容只是记录了相关知识点而没有实际扩展内容，纯粹是为了自己后期回顾时有迹可循。另外，因为直接看的原版书，所以有些地方中英混杂。更详细地学习建议去阅读原书即可。 The Environment shell 会话中维护着大量的信息称为环境 查看环境变量 printenv 或者 printenv USER set |less 按照字母顺序显示 echo $HOME 别名不能用上述方法查看 alias 建立 shell 环境 shell 会话类型 登陆 非登陆 登录 shell 后会读取的启动文件 /etc/profile 应用于所有用户的全局配置脚本。 ~/.bash profile用户私人的启动文件。可以用来扩展或重写全局配置脚本中的设置。 ~/.bash login 如果文件~/.bash profile 没有找到，bash 会尝试读取这个脚本。 ~/.profile 如果文件~/.bash profile 或文件~/.bash login 都没有找到，bash 会试图读取这个文件。 非登陆 shell 读取文件 /etc/bash.bashrc 应用于所有用户的全局配置文件。 ~/.bashrc 用户私有的启动文件。可以用来扩展或重写全局配置脚本中的设置。对普通用户来说十分重要。 修改 shell 环境 通常，添加目录到 PATH 变量或定义额外环境变量放置到.bash profile 文件中 对于其它的更改，要放到.bashrc 文件 文本编辑器 不管什么时候你修改配置文件时，给你所做的更改加上注释都是一个好主意 Shell 脚本和 bash 启动文件都使用#符号来开始注释。 激活修改 source .bashrc 无需重新登陆窗口 A Gentle Introduction To vi 这里所指的 vi 其实全部是 vim 最重要的一点是知道如何退出 vi vi 是一个模式编辑器，在命令模式中几乎每个按键都是命令 进入插入模式后可以写入文本 保存工作 :wq Moving The Cursor Around l 向右移动一个字符 h 向左移动一个字符 j 向下移动一行 k 向上移动一行 0 (零) 移动到当前行行首 ˆ 移动到当前行第一个非空字符 $ 移动到当前行末尾 w 移动到下一个单词或标点符号的开头 W 移动到下一个单词开头，忽略标点 b 移动到上一个单词或标点符号开头 B 移动到上一个单词的开头，忽略标点符号 Ctrl-f or Page Down 向下翻页 Ctrl-b or Page Up 向上翻页 numberG 移动到第number行。例如，1G 移动到文件的第一行。 G 移动到文件末尾。 Basic Editing i命令进入编辑模式，但是光标无法进入行尾 追加文本 a命令，当光标在行尾时越过行尾进入插入模式 A命令，移动到当前行末尾进入插入模式追加文本 打开一行 在两行之间插入一个空白行并进入插入模式 o 当前行下方打开一行 O 当前行上方打开一行 删除文本 x 当前字符 3x 当前字符及其后的两个字符 dd 当前行 5dd 当前行及随后的四行文本 dW 从光标位置开始到下一个单词开头 d$ 从光标位置开始到当前行尾 d0 从光标位置开始到当前行首 dˆ 从光标位置开始到文本行第一个非空字符 dG 从当前行到文件末尾 d20G 从当前行到文件第20行 剪切复制和粘贴 剪切：d命令，删除的部分被复制到一个粘贴缓冲区 粘贴：p命令，把剪切板中文本粘贴到光标位置之后，大P 命令把文本粘贴到光标之前 复制：y yy 当前行 5yy 当前行及随后的四行文本 yW 从当前光标位置到下一个单词的开头 y$ 从当前光标位置到当前行的末尾 y0 从当前光标位置到行首 yˆ 从当前光标位置到文本行的第一个非空字符 yG 从当前行到文件末尾 y20G 从当前行到文件的第20行 连接行 J命令（大写），两行变为一行 查找替换 查找一行：f 命令；fa 查找 a 字符，;重复查找 查找文件：/命令；/a ,n 进行重复查找 全局查找替换 :%s/Line/line/g；1,4s/a/A/ : 冒号运行 ex 命令。 % 指定要操作的行数。%表示从第一行到最后一行。 操作范围也可以用1,5 来代替，或者用1,$ 来代替，从第一行到文件的最后一行。如果省略了文本行的范围，那么操作只对当前行生效。 s 指定操作。在这种情况下是，替换（查找与替代）。 /Line/line 查找类型与替代文本。 g 全局，对文本行中所有匹配的字符串执行查找和替换操作。省略g，则只替换每个文本行中第一个匹配的字符串。 确认模式%s/Line/line/gc (末尾加 c)replace with Line (y/n/a/q/l/^E/^Y)? y 执行替换操作 n 跳过这个匹配的实例 a 对这个及随后所有匹配的字符串执行替换操作 q or esc 退出替换操作 l 执行这次替换并退出。l 是“last”的简写 Ctrl-e, Ctrl-y 分别是向下滚动和向上滚动。用于查看建议替换的上下文 多文件编辑 vi a b 同时打开 a 和 b 首先进入 a 中，输入 :n 进入 b 输入 :N 进入 a :buffer查看正在编辑哪些文件 两文件之间复制 :buffer 1 进入 a 文件，yy 复制一行 :buffer 2 进入 b 文件，p 粘贴 在一个文件中插入另一个文件 打开a文件 输入 :r b(r 表示 read) 保存文件 :wq 保存并退出 :w a1 将正在编辑的 a 文件保存为副本 a1(但此后编辑的还是 a 文件) 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-09-14-LinuxCommandLine4/"},{"title":"Linux Command Line 学习笔记3","content":" 说明；写Linux Command Line 学习笔记系列文章本意只是记录自己学习 《Linux Command Line 》 这本书的过程中看到的一些自己没有留意到的地方，因此绝大多数内容只是记录了相关知识点而没有实际扩展内容，纯粹是为了自己后期回顾时有迹可循。另外，因为直接看的是原版书，所以很多地方中英混杂。更详细地学习建议去阅读原书即可。 Advanced Keyboard Tricks 建议调换大写键和 ctrl 的映射关系 光标瞬间移动 Ctrl-a 移动光标到行首 Ctrl-e 移动光标到行尾 Ctrl-f 光标前移一个字符；和右箭头作用一样 Ctrl-b 光标后移一个字符；和左箭头作用一样 Alt-f 光标前移一个字 Alt-b 光标后移一个字 Ctrl-l 清空屏幕 文本修改 Ctrl-d 删除光标位置的字符 Ctrl-t 光标位置的字符和光标前面的字符互换位置 Alt-t 光标位置的字和其前面的字互换位置 Alt-l 把从光标位置到字尾的字符转换成小写字母 Alt-u 把从光标位置到字尾的字符转换成大写字母 复制剪切 Ctrl-k 剪切从光标位置到行尾的文本 Ctrl-u 剪切从光标位置到行首的文本 Alt-d 剪切从光标位置到词尾的文本 Alt-Backspace 剪切从光标位置到词头的文本 如果光标在一个单词的开 头，剪切前一个单词 Ctrl-y 把剪切环中的文本粘贴到光标位置 补全 tab; tab两次显示可能的自动补全内容 历史命令 .bash_history 默认保存 500 条历史命令 浏览历史命令history |less 执行时可以使用 !1120 搜索历史命令 Ctrl-r启动递增搜索，输入想要查找的内容 回车即可执行 Ctrl-j复制命令到当前行 展开历史命令 !88第 88 行历史命令 !string重复最近历史列表中，以这个字符串开头的命令 linux 中的录屏功能 scirpt命令 script &lt;file&gt;屏幕显示的一切都会记录在文件中 在原有文件继续追加使用-a选项，-q安静模式 结束记录输入 exit或者ctrl-d Permissions 权限 三类人：拥有者，组员，其他人 命令id 查看用户相关的信息 uid 用户 id gid 组 id ubuntu 中，普通用户账号从 1000 开始 用户信息存储位置 用户账户: /etc/passwd包含用户（登录）名，uid，gid，帐号的真实姓名，家目录，和登录 shell 组定义：/etc/group 密码信息：/etc/shadow 三种操作方式：读取，写入，执行 文件模式-rw-rw-r-- 第一个字符表示文件类型 rwx 读写执行 chmod 更改文件模式 八进制更改 chmod 755 符号更改 符号表示法分为三部分：影响谁，执行哪个操作，要设置哪种权限 影响谁 u 所有者 g 用户组 o 其他人 a 所有 哪个操作 \\+ 加权限 \\- 删除权限 = 指定可用权限 举例 u+x 为所有者添加执行权限。 u-x 删除所有者可执行权限。 +x 为文件所有者，用户组，和其他所有人添加可执行权限。等 价于a+x。 o-rw 除了所有者和用户组，删除其他人的读权限和写权限。 go=rw 给群组的主人和任意文件拥有者的人读写权限。如果群组的主人或全局之前已经有了执行的权限，他们将被移除。 u+x,go=rw 给文件拥有者执行权限并给组和其他人读和执行的权限。多种设定可以用逗号分开。 更改身份 su 以其他用户身份和组 ID 运行一个 shell sudo sudo 命令不要求 root 密码 允许一个普通用户以不同的身份（通常是超级用户），通过一种非常可控的方式来执行命令 sudo 不会重新启动一个 shell，也不会加载另一个用户的 shell 运行环境 chown 更改文件所有者和用户组 chown [owner][:[group]] file... chgrp 更改用户组所有权 passwd 更改用户密码 创建和维护用户和用户组 adduser useradd groupadd 进程 Linux 内核通过使用进程，来管理多任务。 系统启动的时候，内核先把一些它自己的程序初始化为进程，然后运行一个叫做 init 的程序。 init 再运行一系列的称为 init 脚本的 shell 脚本（位于/etc），它们可以启动所有的系统服务。 许多系统服务以守护（daemon）程序的形式实现，守护程序仅在后台运行，没有任何用户接口。 一个程序可以发动另一个程序，这个事实在进程方案中，表述为一个父进程创建了一个子进程。 系统分配给每个进程一个数字，这个数字叫做进程 ID 或 PID 查看进程 ps x R 运行。这意味着，进程正在运行或准备运行。 S 正在睡眠。进程没有运行，而是，正在等待一个事件，比如说，一个按键或者网络数据包。 D 不可中断睡眠。进程正在等待I/O，比方说，一个磁盘驱动器的I/O。 T 已停止. 已经指示进程停止运行。稍后介绍更多。 Z 一个死进程或“僵尸”进程。这是一个已经终止的子进程，但是它的父进程还没有清空它。（父进程没有把子进程从进程表中删除） &lt; 一个高优先级进程。这可能会授予一个进程更多重要的资源，给它更多的CPU 时间。进程的这种属性叫做niceness。具有高优先级的进程据说是不好的（less nice），因为它占用了比较多的CPU 时间，这样就给其它进程留下很少时间。 N 低优先级进程。一个低优先级进程（一个“好”进程）只有当其它高优先级进程执行之后，才会得到处理器时间。 ps aux USER 用户ID. 进程的所有者。 %CPU 以百分比表示的CPU 使用率 %MEM 以百分比表示的内存使用率 VSZ 虚拟内存大小 RSS 进程占用的物理内存的大小，以千字节为单位。 START 进程运行的起始时间。若超过24 小时，则用天表示。 top 动态显示 显示内容 最上面是系统概要，下面是进程列表，以 CPU 的使用率排序 系统概要解读 中断进程 ctrl-c 注意并非所有程序都可以如此中断 程序后台运行 command &amp; 返回工作号和 PID jobs 查看后台运行程序 后台运行的进程对一切来自键盘的输入都免疫，也不能用Ctrl-c 来中断它 使用 fg %1，让工作号是 1 的进程返回前台执 停止进程（不终止） ctrl-z , 使用fg 命令，可以恢复程序到前台运行，或者用bg 命令把程序移到后台。\\ 向进程发送信号 kill [-signal] PID 常用信号 向多个进程发送信号 killall 树型结构的进程列表 pstree 输出一个树型结构的进程列表，这个列表展示了进程间父/子关系。 ps auxf ps uf 系统资源使用快照 vmstat 输出一个系统资源使用快照，包括内存，交换分区和磁盘 I/O。 为了看到连续的显示结果，则在命令名后加上延时的时间（以秒为单位）。例如vmstat 5。 终止输出，按下Ctrl-c 组合键。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-09-10-LinuxCommandLine3/"},{"title":"Linux Command Line 学习笔记 2","content":" 说明；写Linux Command Line 学习笔记系列文章本意只是记录自己学习 《Linux Command Line 》 这本书的过程中看到的一些自己没有留意到的地方，因此绝大多数内容只是记录了相关知识点而没有实际扩展内容，纯粹是为了自己后期回顾时有迹可循。另外，因为直接看的是原版书，所以很多地方中英混杂。更详细地学习建议去阅读原书即可。 Working With Commands 查看命令类型 type 命令有四种可能的形式： 可执行程序，可以编译成二进制文件，诸如用 C 和 C++ 语言写成的程序，也可以是由脚本语言写成的程序，比如说 shell，perl，python 等等 内建于 shell 自身的命令，如 ls shell 函数 命令别名 查看绝对路径 which 只对可执行程序有效果，这里不包括内部的命令（cd）和别名。 帮助 man help 显示相似命令 apropos 简要介绍 whatis 创造命令 alias Redirection I/O redirection allows us to change where output goes and where input comes from. Normally, output goes to the screen and input comes from the keyboard, but with I/O redirection, we can change that. Redirecting Standard Output ls &gt; tmp.txt （只会对输出重定向而不会对错误信息重定向）, 每写一次都会覆盖。 追加使用 ls &gt;&gt; tmp.txt Redirecting Standard Error 文件描述符 文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。 While we have referred to the first three of these file streams as standard input, output and error, the shell references them internally as file descriptors 0, 1 and 2, respectively. The file descriptor “2” is placed immediately before the redirection operator to perform the redirection of standard error to the file. commond 2&gt; tmp.txt Redirecting Standard Output And Standard Error commond &gt; tmp.txt 2&gt;&amp;1 新版 bash commode &amp;&gt; tmp.txt ; &amp;&gt;&gt;tmp.txt Disposing Of Unwanted Output 扔掉错误信息和状态信息 redirecting output to a special file called “/dev/null” 垃圾桶 commond 2&gt; /dev/null Redirecting Standard Input cat - Concatenate files 使用 cat 来写一小段话并存到一个文件中cat &gt; lazy_dog.txt（此时 shell 进入输入状态） 输入内容会存到文件中，使用 ctrl-d 结束输入即可 Pipelines The ability of commands to read data from standard input and send to standard output is utilized by a shell feature called pipelines Using the pipe operator “|” (vertical bar), the standard output of one command can be piped into the standard input of another Filters sort - Sort lines of text uniq - Report or omit repeated lines grep - Print lines matching a pattern wc - Print newline, word, and byte counts for each file head - Output the first part of a file tail - Output the last part of a file tail has an option which allows you to view files in real-time. 使用-f选项 Using the “-f” option, tail continues to monitor the file and when new lines are appended, they immediately appear on the display. This continues until you type Ctrl-c. tee - Read from standard input and write to standard output and files Seeing The World As The Shell Sees It expansions 扩展 Pathname Expansion 路径名扩展 每当我们在 shell 下键入一条命令，并按下 Enter，shell 扩展 (Expansions) 会对我们键入的命令字符串进行一系列处理，然后才执行此命令。shell 扩展是 shell 内建的处理程序，它发生在命令执行之前，因此与我们键入的命令无关 shell 把整条命令按功能分割为多个独立单元，每个独立单元作为整体对待，叫做一个 word，也称为 token With expansion, you enter something and it is expanded into something else before the shell acts upon it 使用echo进行理解，依次输入ls和echo Tilde Expansion &quot;~&quot; 如 cd ~foo Arithmetic Expansion 算术扩展 使用格式 $((expression)) echo $((2 + 2))结果是4，但是无法计算小数 支持的运算方法 + Addition - Subtraction * Multiplication / Division (but remember, since expansion only supports integer arithmetic, results are integers.) % Modulo, which simply means, “ remainder.” ** Exponentiation 注意$((5/2)) 会报错，$((5%2))返回1 brace expansion 花括号 ({}) 扩展 can create multiple text strings from a pattern containing braces 最强大的扩展 花括号扩展是首先被执行的扩展，格式有两种，字符串输出，或序列输出 举例 1 echo Front-{A,B,C}-Back Front-A-Back Front-B-Back Front-C-Back contain a leading portion called a preamble and atrailing portion called a postscript. The brace expression itself may contain either acomma-separated list of strings, or a range of integers or single characters. 举例 2 echo Number_{1..5} Number_1 Number_2 Number_3 Number_4 Number_5 举例 3 echo {001..15} 001 002 003 004 005 006 007 008 009 010 011 012 013 014 015 举例 4 echo a{A{1,2},B{3,4}} baA1b aA2b aB3b aB4b shell 仅仅是把花括号中的字符串以逗号，分隔，然后从左至右输出各个字符串，并不会对字符串做任何语法解释处理 花括号扩展中的一对花括号不能被引号引住，否则字符串会被原样输出，并且花括号中需要至少有一个不带引号的逗号或者一个正确的序列表达式 在花括号扩展中使用反斜杠\\转义特殊字符 parameter and variable expansion 参数和变量扩展 It's a feature that is more useful in shell scripts than directlyon the command line. Many of its capabilities have to do with the system's ability to storesmall chunks of data and to give each chunk a name. Many such chunks, more properlycalled variables, are available for your examination. 参数扩展的基本格式是${parameter}，扩展的结果是${parameter}被替换为相应的值。$是前导符，parameter 是一个可以存储值的参数 参数扩展 在 shell 中，符号$用作参数扩展、命令替换、算数扩展的前导符，就是说$符号告诉 shell 接下来要匹配的可能是这三种扩展中的一种。当然前提是这里的符号$没被转义，也没被引号引用。 字符对{、}定义了扩展范围，虽然它不是必须的，但坚持一直使用是个好习惯，它可以保护变量名 parameter 为值大于 9 的数字，比如${10}表示命令行传入的第 10 个参数 parameter 是一个变量名，其后面紧跟一个可能会被解释成变量名一部分的字符 参数的形式 变量名 变量我们很熟悉，此时 parameter 是一个变量，扩展的结果是${parameter}被替换为 parameter 的值。 可以对 parameter 进行赋值，或修改其值，parameter 根据 shell 中变量名命名规则命名，可能需要使用花括号{}明确变量名范围。同时，如果你真的是想在屏幕输出${LANG}这几个字符，可以使用转义符，像这样echo \\${LANG} 可能你还见过${LANG:-strings}或${parameter/pattern/string}这种用法，它可以让你在显示变量值之前对变量进行替换或修改。 数字 此时 parameter 为数字，称作位置参数，扩展的结果是$n被替换为命令行传入的第 n 个参数 在脚本中，可以使用$n引用从命令行传入的第 n 个参数，不能使用赋值语句对其赋值，内建命令 set、shift 用于对位置参数进行控制。当脚本中有函数 (functions) 时，在函数内部，$n表示传递给此函数的第 n 个参数 特殊字符 command substitution 命令替换 use the output of a command as an expansion ls -l `which cp` 等价于 ls -l ${which cp} Quoting 引号 引号可以控制不想要的扩展 双引号 If you place text inside double quotes, all the special characters used by the shell lose their special meaning and are treated as ordinary characters. 无效扩展 word-splitting, pathname expansion, tilde expansion, and brace expansion 依旧有效的扩展 $; \\ ;``. parameter expansion, arithmetic expansion, and command substitution 为了体会双引号的功能，可以尝试命令echo $(cal)和 echo &quot;$(cal)&quot; The fact that newlines are considered delimiters by the word-splitting mechanism causes an interesting, albeit subtle, effect on command substitution 单引号 If we need to suppress all expansions, we use single quotes 使所有扩展都无效 体会命令 echo &quot;text ~/*.txt {a,b} $(echo foo) $((2+2)) $USER&quot; echo 'text ~/*.txt {a,b} $(echo foo) $((2+2)) $USER' Escaping Characters 转义字符 想要正常使用“$”, “!”, “&amp;”, “ “, 可以使用 \\ 除了转义字符外，\\ 可以有如下功能 ( backslash escape sequences)\\a 蜂鸣 \\b Backspace \\n Newline. On Unix-like systems, this produces a linefeed. \\r Carriage return 回车 \\t Tab 在 shell 如果需要echo识别\\t，需要使用-e参数 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-09-09-LinuxCommandLine2/"},{"title":"Linux Command Line 学习笔记 1","content":" 说明；写 Linux Command Line 学习笔记系列文章本意只是记录自己学习 《Linux Command Line 》 这本书的过程中看到的一些自己没有留意到的地方，因此绝大多数内容只是记录了相关知识点而没有实际扩展内容，纯粹是为了自己后期回顾时有迹可循。另外，因为直接看的是原版书，所以很多地方中英混杂。更详细地学习建议去阅读原书即可。 关于为什么应该学习 linux 或者说 ubuntn，因为 ubuntn 的中文名字叫做“有盼头”，学了它，你才真正有可能成为计算机的主人，才可能自由地使用你的电脑。 所谓自由，解释如下： Freedom is the power to decide what your computer does, and the only way to have this freedom is to know what your computer is doing. Freedom is a computer that is without secrets, one where everything can be known if you care enough to find out. 关于为什么要学习命令行操作而非使用图形界面，解释如下： graphical user interfaces make easy tasks easy, while command line interfaces make difficult tasks possible 图形用户界面让简单的任务更容易完成，而命令行界面使完成复杂的任务成为可能。 What Is The Shell 一个程序，它接受从键盘输入的命令，然后把命令传递给操作系统去执行。 Navigation 一个可以让我们访问 shell 的东西，也叫做终端 The File System Tree Current Working Directory pwd Listing The Contents Of A Directory ls -a 列出所有文件 -d 查看目录信息 -F 添加指示符 -h 人类可读 -r 相反顺序显示 -l 详细信息 -t 按照修改时间排序 -S 按照文件大小排序 通常当我要查看哪些文件占用了大量空间时会使用ls -alhS |less；当我要看看最近修改过哪些文件时会使用ls -alht |less。 关于详细格式，需要注意第二行显示的文件硬连接数目，显示的时间如果太久远会有年份信息，如果很近就只有月份信息了。而这个时间日期是上次修改的时间，不是文件创建时间。 Changing The Current Working Directory Absolute Pathnames 绝对路径开始于根目录，紧跟着目录树的一个个分支，一直到达所期望的目录或文件。 Relative Pathnames 相对路径开始于工作目录。符号“.” 指的是工作目录，“..” 指的是工作目录的父目录。 Shortcuts cd 进入 home cd -先前目录 cd ~foo 进入 foo 的 home Exploring The System uname -a 内核 cat /proc/version linux 版本 lsb_release -a 系统位数 file /bin/ls the amount of free memory free current amount of free space on your disk drives df 查看文件类型 file Linux 没有文件后缀的概念，后缀往往只是让用户易于理解 Linux 的宗旨是一切皆文件 查看文本内容 less remember: less is more! 一个小小的复制粘贴技巧，鼠标左键双击文件名会自动复制，在需要的地方单击鼠标中间就可以直接黏贴刚才复制过的文件名了。 linux 文件系统 链接 Symbolic Links the same way as a Windows shortcut though of course, they predate the Windows feature by many years when we create a symbolic link, we are creating a text description of where the target file is relative to the symbolic link. hard links every file has a single hard link that gives the file its name When we create a hard link, we create an additional directory entry for a file a link cannot reference a file that is not on the same disk partition as the link itself may not reference a directory -rw-r--r-- 4 me me 1650 2008-01-10 16:33 fun a “4” which is the number of hard links that now exist for the file Manipulating Files And Directories 通配符 * Matches any characters ? Matches any single character [characters] Matches any character that is a member of the set characters [!characters] Matches any character that is not a member of the set characters [[:class:]] Matches any character that is a member of the specified class [:alnum:] Matches any alphanumeric character [:alpha:] Matches any alphabetic character [:digit:] Matches any numeral [:lower:] Matches any lowercase letter [:upper:] Matches any uppercase letter [abc]* Any file beginning with either an “a”, a“b”, or a“c” BACKUP.[0-9][0-9][0-9] Any file beginning with “BACKUP.”followed by exactly three numerals [[:upper:]]* Any file beginning with an uppercase letter [![:digit:]]* Any file not beginning with a numeral *[[:lower:]123] Any file ending with a lowercase letter or the numerals “1”, “2”, or “3” cp – Copy files and directories -a 全部拷贝包括权限此参数的效果和同时指定&quot;-dpR&quot;参数相同 -d：当复制符号连接时，把目标文件或目录也建立为符号连接，并指向与源文件或目录连接的原始文件或目录 -f：强行复制文件或目录，不论目标文件或目录是否已存在 -i：覆盖既有文件之前先询问用户 -l：对源文件建立硬连接，而非复制文件 -p：保留源文件或目录的属性 -R/r：递归处理，将指定目录下的所有文件与子目录一并处理 -s：对源文件建立符号连接，而非复制文件 -u：使用这项参数后只会在源文件的更改时间较目标文件更新时或是名称相互对应的目标文件并不存在时，才复制文件 -S：在备份文件时，用指定的后缀“SUFFIX”代替文件的默认后缀 -b：覆盖已存在的文件目标前将目标文件备份 -v：详细显示命令执行的操作 mv – Move/rename files and directories mkdir – Create directories rm – Remove files and directories 务必小心 Be Careful With rm Be particularly careful with wildcards. Consider this classic example. Let's say you want to delete just the HTML files in a directory. To do this, you type: rm *.html which is correct, but if you accidentally place a space between the “_” and the“.html” like so: rm _ .html the rm command will delete all the files in the directory and then complain that there is no file called “.html”. Here is a useful tip. Whenever you use wildcards with rm (besides carefully checking your typing!), test the wildcard first with ls. This will let you see the files that will be deleted. Then press the up arrow key to recall the command and replace the ls with rm. ln – Create hard and symbolic links 《The Linux Command Line》 原版书籍下载地址 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-09-09-LinuxCommandLine1/"},{"title":"Docker 学习笔记 I","content":" 越来越无法忍受目前用的几台服务器各种软件配置都不一致，无法做到随时无障碍切换，于是决定学点 Docker。 什么是 docker Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护 传统虚拟化 虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程 docker 容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟 Docker 的优势 解决一致性问题 开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。 而 Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题啊」 这类问题。 维护和扩展 迁移方便 快速启动 理解 Docker 镜像 操作系统分为内核和用户空间 对于 Linux 而言，内核启动后，会挂载 root 文件系统为其提供用户空间支持 Docker 镜像（Image），就相当于是一个 root 文件系统 除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等） 镜像不包含任何动态数据，其内容在构建之后也不会被改变 分层存储 因为镜像包含操作系统完整的 root 文件系统，其体积往往是庞大的，因此在 Docker 设计时，就充分利用 Union FS 的技术，将其设计为分层存储的架构 镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成 镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层 删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除 Docker 容器 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。 每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为容器存储层。 容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。 容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。 数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器可以随意删除、重新 run，数据却不会丢失。 仓库 Docker Registry 一个 Docker Registry 中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。 仓库名经常以 两段式路径 形式出现，比如 jwilder/nginx-proxy，前者往往意味着 Docker Registry 多用户环境下的用户名，后者则往往是对应的软件名。 在虚拟机上安装 Docker 虚拟机版本 uname -r : 4.10.0-30-generic sudo lsb_release -a : Description:Ubuntu 17.04 安装 Docker sudo apt install docker. io service docker start sudo docker run hello-world 出现如下内容 查看 docker 版本号 docker -v：Docker version 1.12.6, build 78d1802 镜像加速器（被坑以后才发现的问题） 在国内下载很多镜像往往会有龟速现象发生，这里使用官方提供的加速器 registry mirror。 The URL of the registry mirror for China is registry.docker-cn.com 将此镜像设置为默认 新建文件/etc/docker/daemon.json 输入内容{ &quot;registry-mirrors&quot;: [&quot;[https://registry.docker-cn.com](https://registry.docker-cn.com/)&quot;] } 使用 Docker 安装第一个软件 从 Docker Registry 获取镜像的命令是 docker pull 命令格式 docker pull [选项] [Docker Registry 地址]&lt;仓库名&gt;:&lt;标签&gt; 地址格式：&lt;域名/IP&gt;[: 端口号] 默认地址是 Docker Hub 仓库名：两段式名称，既&lt;用户名&gt;/&lt;软件名&gt; 具体事例：sudo docker pull biocontainers/blast 用户名是 biocontainers 。如果这里没有用户名，会从官方 library 中进行下载 出现如下的界面 从下载过程中可以看到我们之前提及的分层存储的概念，镜像是由多层存储所构成。下载也是一层层的去下载，并非单一文件。 下载过程中给出了每一层的 ID 的前 12 位。并且下载结束后，给出该镜像完整的 sha256 的摘要，以确保下载一致性。 下载完成时显示的内容 运行第一个 docker 程序 镜像安装成功后，以这个镜像为基础启动一个容器来运行 docker run 是运行容器的命令 默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 docker rm。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 --rm 可以避免浪费空间。 sudo docker run biocontainers/blast blastp -help 删除容器 docker rm 列出镜像 命令 docker images 列表包含了仓库名、标签、镜像 ID、创建时间以及所占用的空间 之前安装的 biocontainers/blast 占用了接近 2 个 G 的空间 删除本地镜像 docker rmi [选项] &lt;镜像 1&gt; [&lt;镜像 2&gt; ...] &lt;镜像&gt; 可以是 镜像短 ID、镜像长 ID、镜像名 或者 镜像摘要 docker images 默认列出的就已经是短 ID 实例 sudo docker rmi b2b 报错：Error response from daemon: conflict: unable to delete b2b81d1fe174 (must be forced) - image is being used by stopped container 9bf4b361545d 原因是没有删除容器，所以无法删除镜像 首先查看运行的容器有哪些： sudo docker ps -a -q 然后删除相关的容器： sudo docker rm 最后再删除镜像 sudo dokcker rmi 删除流程如下图所示 镜像的唯一标识是其 ID 和摘要，而一个镜像可以有多个标签 删除镜像的时候，实际上是在要求删除某个标签的镜像。所以首先需要做的是将满足我们要求的所有镜像标签都取消（untagged） 并非所有的 docker rmi都会产生删除镜像的行为，有可能仅仅是取消了某个标签而已。 当该镜像所有的标签都被取消了，该镜像很可能会失去了存在的意义，因此会触发删除行为。 镜像是多层存储结构，因此在删除的时候也是从上层向基础层方向依次进行判断删除。镜像的多层结构让镜像复用变动非常容易，因此很有可能某个其它镜像正依赖于当前镜像的某一层。这种情况，依旧不会触发删除该层的行为。 用户权限设置 默认情况下，Docker 命令的运行需要根用户权限。一个解决办法是把用户加入 docker 用户组 Docker 能够将/run/docker.sock的文件权限设为 660、用户组设为 docker。当把用户加入到 docker 用户组后，就无需使用 sudo 命令切换获取根用户权限。 sudo groupadd docker sudo gpasswd -a ${USER} docker sudo service docker restart newgrp - docker # 切换用户组 newgrp - `groups ${USER} | cut -d' ' -f1` 参考资料 https://yeasy.gitbooks.io/docker_practice/ http://www.runoob.com/docker/docker-hello-world.html 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-09-08-LearnDocker1/"},{"title":"转录调控与生物信息","content":"cis-regulatory motifs 转录调控 Transcription start site (TSS) Transcription factor binding sites (TFBS) Cis-regulatory module (CRM) 有多个 TF 在一起 Proximal promoter and distal enhancer 近端的启动子远端的增强子 在人中，有 300 个 TF 结合在核心启动子区域；有 1500 个结合在基因其他区域，可以调节一系列基因 图示 其中的 insulator 可以阻隔 enhancer 起作用 全基因组研究调控原件的主要方法 ChIP-seq: peak 的高低体现了蛋白的富集程度 只能研究单一的蛋白，具有特异性 有时候不能找到合适的抗体 DNase-seq DNase I 超敏感位点（DHS）是对 DNaseⅠ 高度敏感的活性染色质区域，DNase 测序（DNase-seq）是进行全基因组 DHS 分析的常用方法 DNase I 是一种非特异性核酸内切酶，基于它们对切割的过敏性，长期以来就被用于对“开放”染色质位点的作图 chromatin open 的位置很容易有其他蛋白的结合 由于多种蛋白质可以与相同序列相结合，有必要整合 DNase-seq 测序数据和 ChIP-seq 测序数据来对引起特定 DNase 足迹的蛋白质进行定性鉴定 不依赖于抗体或表位标签，DNase-seq 可以用来在一次实验中分析大量蛋白质的基因组分布 从大范围来看，结合的位置凸起。如果从小范围来看，空着的位置刚好是一个可能的 motif ATAC-seq (Assay for transposase- accessiblechromatin using sequencing) 通过 Tn5 转座酶，优先标记和测序核小体之间的 DNA ATAC-seq 提供的信息与新 DNase-seq 法差不多，但步骤更为简单，需要的细胞也更少 在无法获得大量细胞的情况下，ATAC-seq 更有帮助。 文章原图 A genomic locus analysed by complementary chromatinprofiling experiments reveals different aspects ofchromatin structure ChIP–seq reveals binding sites of specifictranscription factors (TFs); DNase-seq, ATAC-seq andFAIRE–seq reveal regions of open chromatin; andMNase-seq identifies well-positioned nucleosomes. In ChIP–seq, specific antibodies are used toextract DNA fragments that are bound to the targetprotein, either directly or through other proteins ina complex that contains the target factor. In DNase-seq, chromatin is lightly digested by theDNase I endonuclease. Size selection is used toenrich for fragments that are produced in regions ofchromatin where the DNA is highly sensitive to DNaseI attack. ATAC-seq is an alternative method to DNase-seq thatuses an engineered Tn5 transposase to cleave DNA andto integrate primer DNA sequences into the cleavedgenomic DNA (that is, tagmentation). Micrococcal nuclease (MNase) is an endo–exonucleasethat processively digests DNA until an obstruction,such as a nucleosome, is reached. In FAIRE–seq, formaldehyde is used to crosslink chromatin, and phenol–chloroform is used to isolate sheared DNA. 结合在哪里 Some TFs almost always bind in proximal promoter regions Others bind to many regions 常用的表示方法 Position weight matrix (PWM) 把所有碱基出现的次数相加，高度表示可信度 这种方法过于简单，不能表示出碱基之间的关系。 假设各个碱基之间均为独立 How is specificity of binding achieved motif 定义 有时并非直接和 DNA 结合 How to identify TF binding sites? 没有序列比对的时候 Given a collection of genes that are likely to be regulated by the same TFs (or orthologous genes across different species — methods based on phylogenetic footprinting principles), find the TF-binding motifs in common 但是问题是不知道 motif 是什么，找不到相关的基因，而且如何排除背景干扰 最原始的方法是多重序列比对 MSA 比较保守的非编码区域可能有 PhyloCon — comparative genomic approach 结合序列比对和共表达基因 共表达基因很可能收到相同的 motif 调控 但并不是所有的 elements 都保守 Expectation-Maximization (EM) 目前最常用的方法（MEME） Expectation-Maximization In each iteration, it learns the PWM model and identifies examples of the matrix (sites in the input sequences) 在每一次迭代中，学习一个 PWMmodel 然后再通过输入的序列进行比对 MEME works by iteratively refining PWMs and identifying sites for each PWM（不同的迭代直到找到一个最合适的 PWM) The intuitive idea is as follows: Estimate motif model (PWM) Start with a k-mer seed (random or specified) 通常是 6 个 Build a PWM by incorporating some of background frequencies 根据背景生成一个初始的 PWM Identify examples of the model For every k-mer in the input sequences, identify its probability given the PWM model 计算 k-mer 在输入序列中给出 PWM 出现的概率 Re-estimate the motif model Calculate a new PWM, based on the weighted frequencies of all k-mers in the input sequences 根据 input 序列中 k-mer 出现频率的权重更新 PWM Iteratively refine the PWMs and identify sites until convergence 例子 1 1.1 1.2 1.3 在 MEME 中 相关文献 过程 首先设置 model, 然后经历 Estep 和 Mstep, 找到合适的 PWM 然后将 PWM 进行极大似然转换并取 log 然后看输入序列中出现该 motif 的概率 What does transcription factor binding mean in terms of regulating target genes? 人的大多数结合位点都是在内含子和基因间区 Stronger sites are not closer to differentially regulated genes (not necessarily more functional) Majority of functional sites not conserved 目前很难预测靶基因 ChIP-seq call peak 的策略和思想 ChIP-seq 技术 核心思想 macs 原理 TF 在基因组上的结合其实是一个随机过程，基因组的每个位置其实都有机会结合某个 TF，只是概率不一样 peak 出现的位置，是 TF 结合的热点，而 peak-calling 就是为了找到这些热点。 热点：位置多次被测得的 read 所覆盖（我们测的是一个细胞群体，read 出现次数多，说明该位置被 TF 结合的几率大）。 read 出现多少次算多：假设 TF 在基因组上的分布没有任何规律，测序得到的 read 在基因组上的分布也必然是随机的，某个碱基上覆盖的 read 的数目应该服从二项分布。 当 n 很大，p 很小时，二项分布可以近似用泊松分布替代 λ\\lambdaλ是泊松分布唯一的参数，n 是测序得到的 read 总数目，l 是单个 read 的长度，s 是基因组的大小。 我们可以算出在某个置信概率（如 0.00001）下，随机情况下，某个碱基上可以覆盖的 read 的数目的最小值，当实际观察到的 read 数目超过这个值（单侧检验）时，我们认为该碱基是 TF 的一个结合热点。反过来，针对每一个 read 数目，我们也可以算出对应的置信概率 P。 实际情况由于测序、mapping 过程内在的偏好性，以及不同染色质间的差异性，相比全基因组，某些碱基可能内在地会被更多的 read 所覆盖，这种情况得到的很多 peak 可能都是假的。 MACS 考虑到了这一点，当对某个碱基进行假设检验时，MACS 只考虑该碱基附近的染色质区段（如 10k），此时，上述公式中 n 表示附近 10k 区间内的 read 数目，s 被置为 10k。当有对照组实验（Control，相比实验组，没有用抗体捕获 TF，或用了一个通用抗体）存在时，利用 Control 组的数据构建泊松分布，当没有 Control 时，利用实验组，稍大一点的局部区间（比如 50k）的数据构建泊松分布。 read 只是跟随着 TF 一起沉淀下来的 DNA fragment 的末端，read 的位置并不是真实的 TF 结合的位置。 在 peak-calling 之前，延伸 read 是必须的。不同 TF 大小不一样，对 read 延伸的长度也理应不同。 我们知道测得的 read 最终其实会近似地平均分配到正负链上，这样对于一个 TF 结合热点而言，read 在附近正负链上会近似地形成“双峰”。 MACS 会以某个 window size 扫描基因组，统计每个 window 里面 read 的富集程度，然后抽取（比如 1000 个）合适的（read 富集程度适中，过少，无法建立模型，过大，可能反映的只是某种偏好性）window 作样本，建立“双峰模型”。 最后，两个峰之间的距离就被认为是 TF 的长度 D，每个 read 将延伸 D/2 的长度 ChIP-seq 后续分析 If we are given a set of ChIP-seq peaks, how to identify motif for the TF— use MEME To find out what the sequence motif resembles — use TomTom Use known motif to search peak regions — use FIMO Study common biological pathways or functions of potential target genes of the TF — use GREAT 刘晓乐实验室 ChIP-seq 数据分析流程 http://cistrome.org/Cistrome/Cistrome_Project.html 说明 http://cistrome.org/chilin/index.html 基因调控网络 贝叶斯网络 定义：包括一个有向无环图（DAG）和一个条件概率表集合。DAG 中每一个节点表示一个随机变量，可以是可直接观测变量或隐藏变量，而有向边表示随机变量间的条件依赖；条件概率表中的每一个元素对应 DAG 中唯一的节点，存储此节点对于其所有直接前驱节点的联合条件概率 性质：每一个节点在其直接前驱节点的值制定后，这个节点条件独立于其所有非直接前驱前辈节点 类似 Markov 过程，贝叶斯网络可以看做是 Markov 链的非线性扩展。这条特性的重要意义在于明确了贝叶斯网络可以方便计算联合概率分布。 通过基因表达来推测网络 model 图形说明 DAG：有向无环图 Conditional probabilitydistribution (CPD) 条件概率分布 多变量非独立联合条件概率分布 P(G1，G2，G3，G4，G5) 求取公式 模型选择 训练参数 CPD for discrete expression level 实际含义 module network 模块网络 每个节点不是一个基因合适若干基因 经典文章 主要过程 具有隐藏变量 首先将基因进行 cluster 然后 M 步学习，E 步调整 无方向图 分析过程要给已经构建的相关性矩阵取逆 当样本很小时无法进行转换要使用 lasso 算法 关键在于如何确定公式中的 lamada 这样不需要所有节点之间都有边 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-08-18-longxing-bioinfo-tf/"},{"title":"表观遗传与生物信息","content":"不同层次的表观 Broadly, features at different levels of chromatin organization are generally associated with inactive (off) or active (on) transcription. From the top, genomic DNA is methylated(Me) on cytosine bases in specific contexts and is packaged into nucleosomes, which vary in histone composition and histone modifications (for example, histone H3 lysine 9 trimethylation (H3K9me3)); these features constitute the primary layer of chromatinstructure. Here, different histone modifications are indicated by coloured dots and histone variants such as H2A.Z are brown. DNA in chromatin may remain accessible to DNA-binding proteins such as transcription factors (TFs) and RNA polymerase II (RNAPII)or may be further compacted. Chromatin can also organize into higher-order structuressuch as nuclear lamina-associated domains and transcription factories. DOI:10.1038/nrg2905 表观实例 基因印迹 表观遗传定义 A mitotically or meiotically heritable state of different gene activity and expression (phenotype) that is independent of differences in DNA sequence (genotype) – based on Conrad Waddington, 1942 The sum of the alterations to the chromatin template that collectively establish and propagate different patterns of gene expression (transcription) and silencing from the same genome. Epigenetic changes influence the phenotype without altering the genotype. While epigenetics often refers to the study of single genes or sets of genes, epigenomics refers to more global analyses of epigenetic changes across the entire genome. 表观基因组 epigenome The complete number,location, and types ofepigenetic modificationsthat occur in a given cell Epigenetic mechanisms DNA methylation Normal cells — role in gene expression and chromosome stability Cancer cells — consequences of aberrant hypo- and hyper-methylation Histone modification Normal cells — the histone code Cancer cells — consequences of altered histone modifying enzymes Interaction between DNA methylation, histone modifications, and other players such as non-coding RNAs Cell and tissue type specificity Gene-environment interaction, disease susceptibility DNA methylation human 特征 DNA methylation occurs mostly in CG context, but also non-CG sequences (mCHG, mCHH) DNA methylation is generally depleted from promoters, and enriched within gene bodies DNA methylation is partially depleted at regulatory element 植物中有特殊的 RdDM bisulfite sequencing 基本原理 DNA 的重亚硫酸盐转化来检测未甲基化的胞嘧啶 在文库制备过程中，重亚硫酸盐将未甲基化的胞嘧啶转化成尿嘧啶 转化后的碱基在测序中被识别为胸腺嘧啶（PCR 后），并通过序列计数来确定甲基化胞嘧啶的比例 比对的过程需要进行转换 常用 mapping 软件算法 bismark bsmap Bisulfite seed table, using the original seed and bisulfite variants as keys and corresponding coordinates in the reference genome as values. Each read was looked up in the seed table for potential mapping positions. A positional specific mask of the corresponding reference sequence was generated by setting 01 to C(light blue) and 11 to A, G, T(black). The original read was masked by a bitwise AND operation with the positional specific mask. The reference sequence and the masked read were compared with a bitwise XOR operation. Non-zero XOR results were counted as mismatches (red). Bisulfite alignment is marked in green. Methylated DNA immunoprecipitation (MeDIP) 甲基化 DNA 免疫共沉淀测序 use 5-methylcytosine antibody 富集甲基化的 DNA 序列 有甲基化的地方会有 peak 不能精确到单碱基分辨率，这能知道一段区域的甲基化程度 Methyl-sensitive restriction enzymes (MREs) Unmethylated CpGs are identified by sequencing size selected fragments from parallel DNA digestions with the methyl-sensitive restriction enzymes (MREs) 没有甲基化的地方会有 peak 甲基化敏感性限制酶测序 (MRE-seq) 技术主要利用甲基化敏感性限制性酶 (methylation-sensitive restriction enzyme, MRE) 对基因组 DNA 进行切割，未甲基化位点可以被酶切而产生不同长度的片段，然后，结合高通量测序技术获得序列的甲基化信息 和 MeDIP 结合使用 plant DOI:10.1146/annurev-arplant-043014-114633 human DOI:10.1038/nature08514 组蛋白修饰 H3K4me3 含义 组蛋白修饰功能 Promoters, gene bodies, an enhancer and a boundary element are indicated on a schematic genomic region. Active promoters are commonly marked by H3K4me2, H3K4me3, acetylation (ac), and H2A.Z. Transcribed regions are enriched for H3K36me3 and H3K79me2. Repressed genes may be located in large domains of H3K9me2 and/or H3K9me3 or H3K27me3. Enhancers are relatively enriched for H3K4me1, H3K4me2, H3K27ac and the histone acetyltransferase p300. CTCF binds many sites that may function as boundary elements, insulators or structural scaffolds 如何整合众多的 ChIP-seq 数据 半自动基因注释 两种常用算法 ChromHMM 输入参数 算法是 HMM，具体隐马尔可夫模型参考另一篇笔记 属于 HMM 中的 learning 类问题 使用迭代方法是 EM 200 bp resolution Bernoulli to model emission Posterior decoding Single model for all cell types Segway 基于贝叶斯动态网络 1 bp resolution Gaussian to model emission Viterbi decoding One model per cell type 基因浏览器展示 具体学习地址 ensembl Genome Segmentations from ENCODE human 表观数据库 encode 网站 https://www.encodeproject.org/ 数据下载地址http://genome.ucsc.edu/ENCODE/downloads.html roadmap 网站 http://www.roadmapepigenomics.org/ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-08-17-longxing-bioinfo-epigenetic/"},{"title":"马尔科夫模型","content":"马尔科夫是谁 马尔科夫是一位俄国的数学家，他最为人所知的是他在随机过程方面的研究。他早期研究的重点是数论而在 1900 年之后他所研究的重点转向了概率论。他研究的成果颇丰以至于在他 1905 年正式退休之后他仍然在教授课程直至去世。 在他的研究中，马尔科夫成功地拓展了大数定理以及中心极限定理，并将其应用于由独立随机变量组成的特定序列中，如今这也被称为马尔可夫链。 马尔可夫链被广泛的运用于物理学，经济学，统计学，生物学等方面。两个最著名的应用是布朗运动以及随机漫步。 什么是马尔科夫性质 一类随机过程：在给定当前状态的条件下，将来的状态独立于过去的状态。 假定我们用一枚正反面概率一样的硬币玩一个简单的抛硬币的游戏。抛去质疑，假设马尔科夫性质不是已知的，并且我们希望去预测在十次抛掷以后，第 11 次正面朝上的概率。在条件依赖的假设之下（硬币对于过去的状态有记忆特性并且未来的状态也依赖于过去状态的序列）, 我们必须记录导致第 11 次结果的前十次结果的特定序列，并计算它们的联合概率。这个序列的联合概率就是0.510=0.00097656250.5^10 = 0.00097656250.510=0.0009765625。在条件依赖下，第十一次抛掷正面朝上的概率就是0.0009765625∗0.5=0.000488281250.0009765625 * 0.5 = 0.000488281250.0009765625∗0.5=0.00048828125 这真的是第十一次抛掷正面朝上的概率吗？当然不是！ 我们知道硬币抛掷这一事件并不依赖于先前抛掷的结果。这枚硬币并没有记忆特性。这个连续抛掷的过程并没有编码先前的结果。每个抛掷都是独立事件并且是正反面概率一致的，又叫做与过去状态的条件独立。这就是马尔科夫性质。 什么是马尔科夫模型？ 马尔科夫链（模型）描述了一类随机过程，假定未来状态的概率仅仅依赖于当前状态，不依赖于先前的状态。 让我们以一个简单的例子开始。假设你的小狗处于三类状态之一，在给定当前状态的条件下，你想要模拟出未来状态的可能性。为此我们需要去指定状态空间，初始概率和转移概率。 想象一下你有一只非常懒的胖狗，所以我们定义了状态空间为：睡觉，吃饭，赖皮。我们设置对应的初始概率为 35%, 35%, 和 30% 。 下一步就是定义转移概率。在给定当前状态的条件下，他们就是保持相同状态的概率或者转移到不同状态的概率。 画图表示 如果你想从任意节点开始沿着某一条边，他会告诉你这条小狗从一个状态转化为另一个状态的概率。举个例子来说吧，如果这条狗正在睡觉，我们能够发现有 40%几率这条狗会继续睡觉，40%的几率狗会醒来并且耍赖皮，还有 20%的概率狗会醒过来吃饭。 定义 A Markov chain describes a discrete stochastic process at successive times. The transitionsfrom one state to any of all states, includingitself, are governed by a probabilitydistribution 一组离散状态之间在不同时刻的转移关系 转移关系可以由概率分布描述即可 唯一的要求是 t 时刻状态的概率分布由此前有限个 m 状态决定，m 阶马尔科夫 如果最简单，则是一阶，仅与前一个状态相关 齐次马尔科夫链 比对过程有三个状态，每个状态转移有一个概率，得到转移概率矩阵 可以根据乘法定理计算比对的概率值 通过引入马尔科夫链给出了比对的概率解释 隐马尔可夫 HMM 是一种用参数表示的用于描述随机过程统计特性的概率模型，是一个双重随机过程，由两个部分组成 马尔可夫链：用来描述状态的转移，用转移概率描述 一般随机过程：用来描述状态的转移，用转移概率描述 描述一个我们看不到系统状态，只能看到观测（但观测和状态之间有确定性的概率关系）的状态 如何理解隐马尔可夫模型 假设我们有三中筛子，6 面体，4 面体和 8 面体 初始状态概率（ the initial state probabilities）：假设我们开始掷骰子，我们先从三个骰子里挑一个，挑到每一个骰子的概率都是 1/3，就是所谓的初始状态概率 可见状态链：我们掷骰子，得到一个数字， 是 1，2， 3， 4， 5， 6， 7， 8 中的一个。不停的重复上述过程，我们会得到一串数字，每个数字都是 1， 2， 3， 4， 5， 6， 7， 8 中的一个。例如我们可能得到这么一串数字（掷骰子 10 次）：1 6 3 5 2 7 3 5 2 4 隐含状态链：在隐马尔可夫模型中，我们不仅仅有这么一串可见状态链，还有一串隐含状态链。在这个例子里，这串隐含状态链就是你用的骰子的序列。比如，隐含状态链有可能是： D6 D8 D8 D6 D4 D8 D6 D6 D4 D8 转换概率（transition probability）：在这个例子里， D6 的下一个状态是 D4， D6，D8 的概率都是 1/3。 D4， D8 的下一个状态是 D4， D6， D8 的转换概率也都一样是 1/3。这样设定是为了最开始容易说清楚，但是我们其实是可以随意设定转换概率的。比如，我们可以这样定义， D6 后面不能接 D4， D6 后面是 D6 的概率是 0.9，是 D8 的概率是 0.1。 输出概率（ emission probability）：尽管可见状态之间没有转换概率，但是隐含状态和可见状态之间有一个概率叫做输出概率（ emission probability）。就例子来说，六面骰（ D6）产生 1 的输出概率是 1/6。产生 2， 3， 4， 5， 6 的概率也都是 1/6。我们同样可以对输出概率进行其他定义。比如，我有一个被赌场动过手脚的六面骰子，掷出来是 1 的概率更大，是 1/2，掷出来是 2， 3， 4，5， 6 的概率是 1/10。 下图表示可见状态链和隐含状态连以及输出概率 形式化定义 模型三要素 模型难点 如果提前知道所有隐含状态之间的转换概率和所有隐含状态到所有可见状态之间的输出概率，做模拟是相当容易的。但是应用 HMM 模型时往往是缺失了一部分信息的 如上面那个故事中，有时候你知道骰子有几种，每种骰子是什么，但是不知道掷出来的骰子序列 有时候你只是看到了很多次掷骰子的结果，剩下的什么都不知道 如何应用算法去估计这些缺失的信息，就成了一个很重要的问题 解决的三个问题 评估问题 evaluation 怀疑自己的六面骰被赌场动过手脚了，有可能被换成另一种六面骰，这种六面骰掷出来是 1 的概率更大，是 1/2，掷出来是 2， 3， 4， 5， 6 的概率是 1/10。你怎么办？ 算一算正常的三个骰子掷出一段序列的概率，再算一算不正常的六面骰和另外两个正常骰子掷出这段序列的概率 前向算法 后向算法 解码问题 decoding 知道我有三个骰子， 分别是六面骰、四面骰、 八面骰。我也知道掷十次的结果（ 1 6 3 5 2 7 3 5 2 4），我不知道每次用了哪种骰子，我想知道最有可能的骰子序列 Viterbi 算法（一种动态规划算法） 学习问题 learning 对于 HMM 的参数选择和优化问题， 目前使用较广的处理方法是 Baum-Welch 算法（也就是 EM 算法）。 该算法是一种迭代算法，初始时刻由用户给出各参数的经验估计值，通过不断迭代，使各个参数逐渐趋向更为合理的较优值 总结 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-08-16-longxing-bioinfo-markov/"},{"title":"机器学习在生物信息学中的应用","content":"recap Machine learning methods general-purpose approaches to learn functional relationships from data without the need to define them a priori Advantage derive predictive models without the need for strong assumptions about underlying mechanisms, which are frequently unknown or insufficiently defined (especially for genomic data) Example he most accurate prediction of gene expression levels is currently made from a broad set of epigenetic features using linear models or random forests However, how the selected features determine the transcript levels remains an active research topic four steps Most of machine learning applications in genomics can be described within the canonical machine learning workflow with four steps data cleaning and pre-processing feature extraction model fitting/training evaluation It is customary to denote one data sample, including all covariates and features as input x (usually a vector of numbers), and label it with its response variable or output value y (usually a single number) when available. Supervised machine learning model Unsupervised machine learning approaches aim to discover patterns from the data samples x themselves, without the need for output labels y. Methods such as clustering and principal component analysis are typical examples of unsupervised models applied to biological data 深度神经网络 Neural networks An artificial neural network, initially inspired by neural networks in the brain, consists of layers of interconnected compute units (neurons). The depth of a neural network corresponds to the number of hidden layers, and the width to the maximum number of neurons in one of itslayers. When training networks with larger numbers of hidden layers, artificial neural networks were rebranded as “deep networks”. The term “neural network” largely refers to the hypothesis class part of a machine learning algorithm: Hypothesis: non-linear hypothesis function, which involve compositions of multiple linear operators (e.g. matrix multiplications) and element wise nonlinear functions Loss: “Typical” loss functions for classification and regression: logistic, softmax (multiclass logistic), etc. Optimization: Gradient descent architectures Recurrent neural networks Maintain hidden state over time, hidden state is a function of currentinput and previous hidden state Traditional RNNs have trouble capturing long-term dependencies Problem has to do with vanishing gradient, for many activations like sigmoid, gradients get smaller and smaller over subsequent layers One solution, long short term memory (LSTM) (Hochreiter and Schmidhuber 1997), has more complex structure that specifically encodes memory and pass-through features, able to model long-term dependencies application DeepBind CNN architectures to predict specificities of DNA-binding and RNAbinding proteins Outperformed existing methods, to recover known and novel sequence motifs, and could quantify the effect of sequence alterations and identify functional SNVs The neurons in the convolutional layer scan for motif sequences and combinations thereof, similar to conventional PWMs The learning signal from deeper layers informs the convolutional layer which motifs are the most relevant. The motifs recovered by the model can then be visualized as sequence logos paper Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning, doi:10.1038/nbt.3300 Important considerations related to data Need sufficient amount of labelled data Need to be trained, selected and tested on independent data sets to avoid overfitting and assure that the model will generalize The training set is used to learn models with different parameters, which are then assessed on the validation set. The model with best performance, for example prediction accuracy or meansquared error, is selected and further evaluated on the test set to quantify the performance on unseen data and for comparison to other methods. Typical data set proportions are 60% for training, 10% for validation and 30% for model testing. If the data set is small, k-fold cross-validation can be used Categorical features such as DNA nucleotides need to be encoded numerically. Typically represented as binary vectors with all but one entry set to zero (one-hot coding). The four bits of each encoded base are commonly considered analogously to color channels of an image to preserve the entity of a nucleotide 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-08-15-longxing-bioinfo-mlinbioinfo/"},{"title":"序列比对其他相关问题","content":"全局比对 Global Alignment 由芝加哥的 Needleman 和 Wunsch 两位于上个世纪 70 年代初提出，常被称之为 Needleman-Wunsch 算法。算法针对用户指定的打分函数，确定性地找出两条序列间的最优比对。 Needle-Wunsch 算法对两条序列所有残基进行全局比对的局限性。 功能相关的蛋白之间虽然可能在整体序列上相差甚远， 却常常会具有相同的功能域 序列片段能够独立发挥特定的生物学功能，却在不同蛋白之间相当保守 仅靠全局比对的算法无法发现这样的片段 内含子的发现使得在做核酸水平的序列比对时必须要正确处理内含子导致的大片段的差异 局部比对 Local Alignment 1981 年，物理学家 Temple Smith 和数学家 Michael Waterman 在 Journal of Molcular Biology 上发表了一篇仅有四页的文章，提出 Smith-Waterman 局部比对算法 race back begins at the highest score inthe matrix and continues until you reach 0。And also the secondary best alignment 核心思想是给分数增加了下限 0 分 所有的回溯都是局部的，所有的最终比对也是局部的。引入止损下限，差异扩大之后重启比对，找到局部水平的相似性 空位罚分的改进 Affine gap penalty opening a gap receives a score ofd extending a gap receives a score of e Penalty = d + (n-1)* e 有限向量机 扩展公式 全局比对的时间复杂性 O(mn) 正比于 m*n 全基因组比对 同源 homology 的分类 直系同源 ortholog 来自于不同的物种，演化过程中基因没有丢失，各物种中都有 chaining 旁系同源 paralog 来自于一个物种内部基因组的复制 netting NGS: Sequence alignment Map the large numbers of short reads to a reference genome In a broader sense: Identify similar sequences (DNA, RNA, or protein) inconsequence of functional, structural, or evolutionary relationships between the them Applications: Genome assembly, SNP detection, homology search, etc short: greater search sensitivity large: faster search speed In-exact alignment BWA 和 bowtie 的相关算法，大大减少了对服务器的要求 如何快速的知道某段序列大约在基因组的哪个位置 如何定义大约这个概念 Hamming Distance or Sequence Similarity Ungapped vs Gapped Global vs Local All positions or the single best Efficiency depends on the data characteristics &amp; goals Smith-Waterman: Exhaustive search for optimal alignments BLAST: Hash-table based homology searches Bowtie: BWT alignment for short read mapping BWT 算法 核心是绕最后一个序列转圈 先给每一个 T 做 rotations, 再进行 sort, 生成 bw 矩阵，最后一列从头到尾就是 BWT 回溯 给每一个 T 的字母一个出现次数的排序，图示如下 Suffix（后缀） Arrays 类似于电话本中的索引结构 What if we need to check many queries We don't need to check every page of the phone book to find 'Ma' Sorting alphabetically lets us immediately skip 96% (25/26) of the book withoutany loss in accuracy Sorting the genome: Suffix Array (Manber &amp; Myers1991) Sort every suffix of the genome 所有具有相同 prefix（前缀）的 suffixes（后缀）会聚在一起，这样就可以进行类似于二分法的排除 全基因组建立 index An array of integers giving the startingpositions of suffixes of a string inlexicographical order 从中间的 index 开始找，过滤一半 效率 Total Runtime: O(m log n) More complicated, but much faster! Looking up a query loops 32 times instead of 3B Searching the array is very fast, but it takes time to construct This time will be amortized over many, many searches Run it once &quot;overnight&quot; and save it away for all future queries 非常消耗内存 BLAST/Dot matrix Indexing-based local alignment Basic Local Alignment Search Tool 围绕最优比对路径进行计算 BLAST Ideas 核心思想：Seeding‐and‐extending Find matches (seed) between the query and subject 找到高度相似的小片段，种子 Extend seed into High Scoring Segment Pairs (HSPs) 向两端延伸并进行比对 Run Smith‐Waterman algorithm on the specified region only Assess the reliability of the alignment 打分评估 将序列切分，在数据库中定位候选序列和位置 得到候选序列和查询序列的 heatmap 去掉零散的 hit, 直留下对角线，形成 hit cluster 以 hit cluster 为基础向左右进行延伸直到分数不符合要去 在扩展的区域进行局部比对 blast 加速 标记低复杂度，易产生假阳性 考虑与种子相似的邻居单字 分数评估，避免随机因素 E value n 数据库大小 k 和打分矩阵相关 m 长度 s 比对的分数 在随机情况下获得比当前分数高的可能比对条数，不是概率是个望值。p 为 0.05 时，E 也是 0.05。 BLAST 是一种启发式算法，不确定有最优解 只在有效区域应用动态规划算法 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-08-14-longxing-bioinfo-blastmore/"},{"title":"序列比对与动态规划","content":"生物信息的思考方式 biological question 生物学问题 有什么意义 data 输入数据是什么 哪些可接受的数据格式 A model 如何用计算的方法解决 什么是数据的 model algorithm 算法是什么 效率如何，有哪些局限性 序列比对 问题 如何判断两条序列的相似性 相似序列带来可能的相似功能 网站实例 根据替换矩阵来衡量打分 替代矩阵是三角阵，冒号是比较相似，点是不太相似，线是完匹配 indel（insertion or deletion 的缩写）=gap 空位罚分 gap opening 和 extending 不同 penalty=d+(n-1)*e Affine gap penalty: opening a gap receivesa penaltyof d; extending a gap receives apenalty of e. So thetotal Penalty for a gapwith length n would be:Penalty= d + (n-1)* e Final Score = (sum of substitution scores) + (-1) *(sum of Gap Penalty) 序列比对使用穷举法是不现实的 算法 残基的比对方式只有两种 空位 比对到另一个残基 比对分数为各个残基比对分数之和 参数 gap: 插入或者缺失 cost(x,y)：the cost of aligning character x withcharacter y 最简单情况：cost(x,x) = 0 and cost(x,y) = mismatchpenalty 罚分为 0 目标 Can compute the edit distance by finding thelowest cost alignment Cost of an alignment： sum of the cost(x,y) for the pairs of charactersthat are aligned + gap × number of - characters inserted 打分规则图解 识别比对图解 The best alignment that ends at a given pair symbols is the best alignment of the sequencesup to at point, plus the best alignment for thetwo ditional symbols. 动态规划 Dynamic Programming Dynamic Programming solves problems bycombiningthe solutions to sub‐problems 三步策略 （现在好的加之前最好的是总体最好的） Break the problem into smaller sub‐problems. Solve these sub‐problems optimallyrecursively. Use these optimal solutions to construct anoptimal solution for the original problem 动态规划公式 公式解读 1 公式解读 2 公式解读 3 公式的迭代转换为对矩阵进行填空（动态规划矩阵），从上到下，从左到右进行迭代 迭代过程 以 F(1,1) 为例，可以是 0+2；-5-5；-5-5，选最大的是 2, 以 F(2,1) 为例，可以说-5+2；2-5；-10-5, 有两个途径可以，且最大值是-3 以此类推，迭代至终点 回溯过程，得到最终比对 尝试理解 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-08-13-longxing-bioinfo-blast/"},{"title":"cluster SV 和 CV 相关算法","content":"cluster 为什么关注聚类 k-means 原理 相关内容 Start with suitable choices of K cluster mean-vectors. Then iterate the following two steps： For each object, find the closest mean vector and assign the the object to the corresponding cluster. For each cluster, update its mean vector according to the current assignments. Convergence is easy stop when cluster assignment no longer changes The choice of initial values is more difficult Hierarchical Clustering Produce a nested sequence of clusters, a tree, also called Dendrogram 结构变异 Genomic alterations 癌症中尤为明显 适合用 circos 来展示 SV Mechanisms of SVs NAHR - non-allelic homologous recombination NHEJ - joining of DNA double-strand breaks without extensive sequence homology by ligation of DNA ends Breakage-fusion-bridge (BFB) Telomere loss or double-strand breakage creates an unprotected DNA end Ligation of broken chromatid ends connects the two sister chromatids Chromothripsis： A large number of genomic rearrangements have been acquired in a single catastrophic event 用高通量数据 short reads 来探测 SV 一些具体方法（可参考原始文献） 通过以下四个信息来进行预测 read pairs read depth split reads and also assembly of the reads into contig Copy number alterations （CV） Use network flow to find out the traversal in the genome with CNAs Aneuploidy 非整倍体，染色体中出现非整倍体的变化，癌症中很常见 Quantify allele-specific SVs and CNAs 软件：Weaver 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-08-12-longxing-bioinfo-cluster/"},{"title":"究竟应该如何学习","content":"说明：本文涉及两本书和一个视频 TED 视频 :The First 20 Hours: How to Learn Anything （Josh Kaufman） 两本书： 学习的两种策略 完全不懂到了解和基本掌握 也就是所谓的从 0 到 1，这种策略可以涉及不同领域的多个技能，所要达到的状态是基本掌握，拿得出手，能用来装逼。 达到这样的程度不需要太长的时间，一种观点认为是 20 小时。 从基本掌握到精通和专业 这种策略只能涉及某一个技能，它应该是你最擅长或者最有兴趣的。这项技能是你对自身的投资，应该在未来有最高的价值和收益。 达到专业水平往往需要 10000 小时的刻意练习，这 10000 小时通常是一个人全职工作五年或者通常状态下十年的时间。 20 小时快速掌握一项技能 两条技能习得曲线 练习时间-完成时间曲线 When people first start it took them a long time to learn something. With a little practice they get better and better. And that early part practice is really efficient — people get good at things with just a little bit of practice. 练习时间-掌握程度曲线 When you first start, you are grossly incompetent and you know it. With practice, you get really good really quick. Then you reach a plateau and subsequent gains become much harder to get. 这两条曲线说明，我们可以在很短时间内快速掌握一门新技能：既不用太痛苦，又不用花太多时间和精力。另外，掌握一项技能，早期的练习非常有效也非常重要。 掌握一项技能的三个阶段 根据思维适应性控制模式（Adaptive Control of Thought，简称 ACT 模式），人掌握一项技能需要三个阶段。 早期认知阶段 (Cognitive stag) 人类大脑使用已有的产生式对某种新技能做出陈述性解释，对这一技能的各项条件以及在这些条件下将要执行的相应行动形成最初的陈述性编码表征。 通俗的说就是要对新技能进行研究，理解和思考，将技能拆分为可控易掌握的若干个部分。 中期联系阶段 (Associative stage) 在认知阶段所做的陈述性表征通过操练和反馈进行程序化处理。所谓程序化，就是在执行程序时逐渐减少对陈述性知识表征的依赖，自动的匹配过程将取代对有意识搜索，从而使技能的执行更迅速、更精确。 通俗的说在这个阶段就是要进行练习，注重反馈，并基于反馈对练习进行调整。 后期自主性阶段 (Autonomous stage) 程序化的信息组合在第三阶段获得了进一步的精致和协调，对所形成技能的有意识控制越来越少，并将其推广到其他条件下运作。 通俗的说就是在这个阶段人们可以高效地执行技能而不再需要花费过多精力和思考。 四步走的学习过程 分解所学技能 (Deconstruct The Skill) 我们要学习的技能和要完成的任务其实都是由多个分支技能或任务组成的。我们需要把技能做最大程度的分解从而找到哪些部分能更好地帮助我们达成目标，接下来就可以先学习和练习这些最重要的部分。 学到可以自我修正即可 (Learn enough to self-correct) 掌握任何技能有一定的理论基础都是必不可少的，我们可以先找 3 至 5 种学习资源（书，视频）进行学习，但是一定不要因为学习理论知识而推迟练习。很多人常说“我仔细看完这本书就去练习”的观点是错误的，理论学习不用太多，能支撑你开始练习即可，随后可以在练习中再进行自我修正和自我调整。 排除干扰 (Remove practice barriers) 排除网络和手机等干扰，学习时要让自己全神贯注，确保学习过程不轻易被打断。 练习至少 20 小时 (Practice at least 20 hours) 接触一个新技能时，在学习过程的开始阶段我们都会存在一种挫折障碍 (frustration barrier)，也就是一种“我很菜而且我知道自己很菜”的感觉。挫折障碍并不利于我们静下心练习，所以至少投入练习 20 小时去克服这种障碍从而增强自信心。有了这二十小时的专注练习，你也就初步掌握了一项技能。 几个注意事项 尽量每次只学习一个技能 制定一个** SMART **目标 具体（Specific）：究竟是要做什么 可衡量（Measurable）：清楚自己的进度 可以实现（Achievable）：有挑战性的同时也可以实现 有诱惑力（Rewarding）：有足够的动力激发兴趣 有时间规划（Timed）：有截止日期和具体的时间节点 练习前需要做好充分的准备工作，比如工具 很多事情都有固定的模式，会反复用到（所谓套路） 学习新事物最大的障碍不是智力，而是情绪主要是情绪上会觉得自己很笨 短时间高效学习的要点 学会通过泛读搜集信息（3-5 本） 评分最高的畅销书籍 评分最高书籍的相关书籍 不畅销但系统性强的书籍 泛读过程中 先看序言和目录有助于了解框架 略过所有的故事案例和证明 重点在于了解专业概念和相关观点 及时记录自己的问题和想法 建立联系并构造模型 将前面的概念和观点联系起来 结合已有的知识构造模型 对要学的技能和知识形成整体框架 了解知识的可靠性和局限性 清楚规律的适用和不适用领域 提出自己不理解的问题 请教专业人士解决困惑 理解复述并以教为学 用自己的话和模型把学到的讲给别人听 重点记录自己讲不明白和别人听不懂的地方 重新学习和理解，再次讲解 10000 小时刻意练习 通过训练可以铸就天才 《刻意练习》这本书重点介绍了比如音乐家，专业运动员等专业人士的成功方法。 作者指出人人都可以是莫扎特，只要经过训练就可以获得和天才一样的表现。日本曾做过一个心理学实验，一年训练时间可以让 24 个幼儿具备和莫扎特一样的完美音高。 究其原因，研究发现通过高强度的训练能够改造人的身体和大脑，产生像天赋一般的奇迹能力，从而造就天才。 为什么多数人没有被训练成天才 训练可以分为无效训练和有效训练两种类型，也就是说，如果你经过了长期训练而没有什么显著提升，那很可能就是你一直在进行所谓的“无效训练”。 不少对训练有三种误区：训练无用；时间够长训练即有效；足够刻苦训练即有效。 其实，训练当然是有用的，但是要有正确的方法，否则就是简单的无效重复而停滞不前。只有有目的的训练，才能够让我们快速的进步。 那什么是有目的的训练呢？这里涉及四条标准：有确定的目标并可以不断改进；训练中必须保持专注；保证有及时的反馈；必须跳出“舒适区”，也就是不能只进行简单无意义的重复。练习一万遍十以内加减法还是算不来乘除。 什么是刻意练习 刻意练习是“有目的训练”的一种。刻意练习的目的是建立一个更强大的心理表征来思考问题，而所谓“心理表征”是说我们在思考事物时对应的一种心理结构。我们经常说，某某人看问题特别有深度和高度，这种“格局”的差别就是心理表征的差异。 刻意练习的两个标准 刻意练习必须符合两个标准，其一是该领域有一整套成熟的评价标准和高效方法，反之很难进行所谓“刻意练习”；其二是要有一个能够布置训练作业和及时反馈的专业老师。 只有具备这两个条件，才是严格意义上的刻意训练。从这个标准看，钢琴和小提琴等音乐领域是最容易通过刻意练习来造就天才的。 刻意练习的实际应用 虽然大多数的行业不符合这个标准，但是我们仍旧可以用刻意练习的原则来训练。 明确目标，即明白要实现哪方面的能力提升； 尽可能找到领域中最优秀的高手，或者经典书籍。这样做的目的是能够和这个领域高水平的心理表征进行对比，获得高质量的反馈； 如果没有实际导师，可以研究最杰出的导师或者成功案例背后可能的成功原因； 如果连案例都没有，我们也要学会及时反思自己的结果和行为间的关联，形成积极的反馈体系； 最后就是要不断地投入时间精力去训练。 总结 20 小时快速掌握一项技能和** 10000 小时刻意练习**，看似中间隔了 9980 个小时，但二者核心的理念和思路其实都是相通的，其中最为明显的一点就是要建立良好的反馈。 还记得小时候老师总是问我们“会了么”，没人说话；然后老师又问我们“哪里不会”，还是没人说话。虽然课也听了作业也写了，但是还是不知道自己会不会，差在哪里。所谓良好及时的反馈，无非就是让我们更加清醒地认识自己的学习状态并有一个明确的参照。 两者的差别其实在于着重点不同。“20 小时掌握一项技能”更多的是让我们能开窍，一个东西过了最难的起始阶段，至于后面要不要持续进行刻意练习由你决定；而“10000 小时刻意练习”更清楚地解释了为什么很多看起来努力了还是不能取得大进步。 看完书我感觉这些内容确实都很对，但是，看完了理解了，然后呢？ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-05-05-HowToLearn/"},{"title":"如何发言更自信","content":"上周末在个人公众账号推送的文章《一个月过去，世界发生了什么》中有这么一段内容： 转博成绩谈不上多好但也不坏，能让十几个做功能研究的 PI 听我扯上半个小时的生物信息和网站开发，每个人还能听得认真（老板原话是“他们全程都没有人看手机啊”）问得尽兴，已经知足。两年硕士过去，即将开始（争取）为期三年的博士生活，不大不小值得纪念一下。 有人就问我在公众场合怎么扯能让别人不犯困呢？ 小学说了 4 年相声，中学学生会和大学社团的各种活动让我有了比部分人更多在公众场合发言的机会。尤其是大学做语言艺术协会负责人的那段时间，参加了不少培训也培训了不少人，掌握了一点点交流和谈话的方法。 想要有一次成功的发言最核心的就是以下三点： 言之有物为根本 表达方式是关键 肢体语言是辅助 对于讲演而言，前两点落实在“讲”上，也就是说什么和如何说；第三点落实在“演”上，也就是我们在公众面前的姿态和动作。 **“说什么”**包括你发言的内容，这里要符合发言的主题也要适合在场的听众。 **“怎么说”**包括了你讲话的方式和一些表达技巧。 肢体语言恰当得体将是整个发言很大的加分项，如果运用不当很可能会搞砸整场发言。 更具体的内容不能展开了，因为今天要谈的是如何在公众场合发言更加自信。接下来就针对这个问题写一点想法和大家分享。 发言前的准备 永远不要相信有什么“即兴讲演”，所谓即兴无非就是平日的积累罢了。 一次公众场合的发言需要事前准备多久并无定论，这里面涉及讲演人对内容的熟悉度和内容深度等诸多变量。面对一个全新的主题，如果你有 5 分钟的发言机会最好能用 5 个小时去准备，如果是 15 分钟最好就用 15 个小时去准备。 这里的 15 个小时并不是说从发言那一刻开始算起的前 15 小时。而是从规划，准备讲稿，练习预讲再到最后的修改，这可能会经历一周或者半个月的跨度。 如果你的讲演经历并不丰富，准备的越充分越好。 很多人说我一上台就紧张，那有没有想过为什么紧张？无非就是害怕忘词，上台以后不知道该说什么。上台前你给自己“我还没有准备好”的心理暗示越强烈，就越可能把事情搞砸。降低这种心理暗示程度的唯一方法就是充分的准备，别指望太多所谓的积极自我暗示。我就是没准备，你让我上台前一直深呼吸干吗？ 发言过程中 不要告诉自己不紧张，而是假装自信 很多心理学实验表明：你越是让人们抑制某个想法，那个想法就越与人纠缠不休。其中比较有名的是哈佛大学心理学家丹尼尔魏格纳的“白熊实验”。 还有很多心理学实验表明：如果你想快乐起来，就要让自己表现得像个快乐的人，如果你想自信起来，同样如此。 曾经有一项研究，参与者要求观看一个大型屏幕上不断移动的物体，然后统计这些物体对他们是否有吸引力。有些物体是垂直移动的，有些物体是水平移动的。很有趣，结果表明参与者们更加喜欢垂直运动的物体，而这正是点头（看竖直移动的物体）和摇头（看水平移动的物体）的动作促成了他们无意识的选择。 如果你感觉自己准备的不好（其实不少人坚信自己永远也不会准备好），从走到听众面前那一刻开始的前几分钟，一定不要想着让自己不紧张，同时一定要假装自己特别自信！ 一开始的十几秒里，你甚至可以不说话（一说话就紧张），只需强迫自己微笑，环视面前的每一个人，尤其是那些也对你面露友善的听众。如果你把开始的一两分钟假装自信利用好，后面也会越来越顺利。 使用恰当的肢体语言 另一个提高自信心的方法就是使用恰当的肢体语言。前一段时间，《哈佛商业评论》在线发表了一篇文章，作者卡西·韦佐西亚在文章中提到了让演讲者看起来更加自信的 6 种简单肢体语言。 **The box ** 想象自己面前有一个盒子，手的移动范围不要超过这个盒子，这可以控制你自己不去乱动乱甩手。 Holding the ball 想象自己手里抱了一颗篮球，这种姿势能让你看起来更有控制力。有没有想到教主乔布斯？ Pyramid hands 金字塔手势，防止紧张带来的手抖。但是这种姿势用不好容易显得傲娇。 Wide stance 站立的时候双脚与肩同宽或者超出一点，三角形具有更好的稳定性，也能让你显得更加稳重。 Palms up 双手在胸前打开，手心向上。这是一种开放式的姿势，能让大家感受到你的诚恳和开放。 与之相反，很多人说话时喜欢两个胳膊在胸前交叉，这种防御性的姿势会给他人一种自我保护和拒绝的信号。 Palms down 双手在胸前打开，手心向下。虽然也是开放式的姿势，但是更能显示出自信和力量。潜台词其实是“你们别瞎嘚嘚了，就是我说的这么回事”。 希望这篇文章对你有所帮助，如果你有其他相关的经验和建议可以评论和大家分享。 参考资料： 题图和文章配图来自 Harvard Business Review 怀斯曼（WisemanR.）：《一本正经又怪诞的行为心理学》 Kasia Wezowski：6 Ways to Look More Confident During a Presentation 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-04-25-HowToTalk/"},{"title":"如何让别人回答你的问题","content":"虽说是硕博连读，但还得有一个转博的流程。昨天才交了转博材料，后面几天紧接着要转博预答辩和正式答辩，所以每天都忙得很。 趁着小假期回答一个最近在公众号后台出镜率很高的问题。 你为什么不回答我的问题？ 引子 不知道你有没有过这样的经历。 小时候无意中做了一件事情结果受到了老师或者其他人的表扬，在以后很长一段时间中，为了对得起这份夸奖你不得不一直重复做这件事。 从当事人的角度用一个词概括也许是所谓的“偶像包袱”；从围观者的角度用一个词概括可能是所谓的“道德绑架”。 差不多三年前，我因为“闲着没事”写了几篇很长的文章，发在一些社交平台后反馈出乎意料的正面。越来越多的关注让我不自觉的深感“责任重大”，于是关于“考研”这个话题的内容也越写越多。前前后后差不多写了 100 来篇和“考研”或者“考研英语”相关的文章，直到最终整理成册，免费供大家阅读 《靠谱学长说：聊聊考研复习这件事儿》（尽管我为此自己花钱买了域名）。 文章比较走心再加上一些侵权辅助的传播，给大家带来的好处是连续几届考研人或多或少得到了些帮助，给我个人带来的困扰是连续一波一波的人总是反复问相同的问题。 我对待提问的态度从一开始有问必答、随问随答，逐渐过渡到现在的不定期回答、选择性回答。于是不少人从微博私信杀到公众号留言，见我还不答直接抛出“你为什么不回答我的问题”终极一问，更有人为了引起我的注意（据他事后解释）直接出言不逊。 这个过程中逐渐有人留言说“你怎么就开始耍大牌了”或者“还好意思说靠谱”。哎，其实我手里都是三四五，连个顺子都没有，哪里有大牌可耍。 我为什么不回答你的问题 借这篇文章就说说“我为什么不回答你的问题”，希望你能降低以后再被别人拒绝的概率。 总体而言，我不回答的问题都有以下两个特点之一 这个问题我已经非常详细回答过了 这个问题我三两句话肯定回答不完 很多人认为自己在提问时属于弱势方，毕竟自己是一个提问者。但在这种问答性质的沟通中，回答者才是真正的弱势群体。 原因一：交流压力不同 在问答性质的沟通中，从提问者角度来看，多是一对一的交流环境，我向对方提出一个问题，其结果自然是对方给我一个答案；从回答者角度而言，多是一对多的交流环境，同时有二十个人向我提问，我不得不给每人提供一个答案。 原因二：交流成本不同 在问答性质的沟通中，对于提问者而言付出的成本就是提十几或者几十个字的问题，如果你在提问前经过了一点点思考，可能还会多花上 1 分钟时间想想怎么把问题问清楚。 对于回答者而言，要回答一个问题必须先读懂提问者问什么，然后思考提问者需要哪方面答案，接着组织语言去整理答案，如果哪里不确定还要再查资料。这么一来，回答者付出的时间成本自然是极大的。 基于上述两个原因，看到一个问题在我之前的文章里已经有明确回答时，我自然不愿再浪费交流成本；看到一个问题需要我用几个小时来整理时，我自然舍不得宝贵的时间。所以，只能选择不回答。如果这个时候，你还不停地追问甚至为了引起别人注意而出言不逊，剧增的交流压力很可能会让对方先怼回去然后再把你拉黑。 当然，有些时候我明知对方的问题要花不少时间来回答还是抽出时间回答了，为什么呢？ 因为好多文章赞赏里都有她（微信只会提示每篇推送的前三次赞赏） 因为几乎每篇文章他都会留言和我谈谈自己的想法 因为她总在我挺长时间没更新的时候留言写几句鼓励的话 因为他给别人分享经验时引用了我的文章并且提前打了招呼 因为她得到我分享的资料后向我反馈过几次学习心得 当再公众号后台点开提问者的头像看到他有“4 次赞赏 7 次留言”记录时，我潜意识里不得不提高这个问题的优先级。不是因为势利，而是因为他也付出了更高的交流成本，最起码认可我所传递的内容和观点。 如何让别人回答你的提问 提问本身就是一门学问，市面上相关的书也不止一本，比如尼尔•布朗和斯图尔特•基利的《学会提问。下面我只是根据上文内容提一些针对性的建议。 降低回答者的交流压力 咄咄逼人的问题往往不会有结果，难免给人一种不远万里赶来砸场子的感觉；过于尖锐的问题往往会让回答者胆怯，好像一句话说错了就要对提问者的下半生负责一样。比如 ……，实在不知道怎么办了，我就相信你； 急，在线等，……，真的很急 。 开门见山，不要“在吗” 很多提问者自以为上来就提问是不礼貌的，总是先问对方在不在、忙不忙，聊几句有的没的，然后看似随意地话锋一转“对了，我有个问题”。这种做法其实就是单纯增加回答者的交流压力。你们的交流并非一对一，寒暄十句还不说正题，是等着对方先说“您好，请问有什么可以帮您”么？ 自力更生，学会搜索 微博很早就有了在关注者个人主页的内容搜索功能，微信公众账号现在也支持历史消息搜索功能了。点击查看历史消息，最上方就有搜索框。如下图所示 你不妨把自己的问题拆分出几个关键字先进行搜索，在以前的文章中如果已经有你要的答案当然好。就算没有，你至少还可以说 我看了你之前写的……文章，很受益，但是关于文中提到的……还有一点疑问想和你交流”。 这效果就不一样了。 对于我而言，所有和考研相关的内容都在那本免费的 《靠谱学长说：聊聊考研复习这件事儿》 里了，之所以要做成在线的开源版本，一个主要原因就是方面随所随地直接对全文进行检索。想问什么就搜什么，直达要害。 拒绝夺命连环问 很多人的问题起初看起来非常简单，有的时候顺手就回答了，然而悲剧才刚刚开始。 一旦回答了一个问题，提问者就开启夺命连环问模式，用自己早就设计好的套路一路下去直到对方崩溃。看似用小聪明和回答者建立了联系，但事不过三，印象分已经为负了。比如 “1+1=？” “1+2=？” “那你顺便把 1+1=2 给我证明一下吧，谢谢”。 平衡双方交流成本 在上文，我们谈到了为什么问答式沟通中提问者和回答者的交流成本是截然不同的。 如果你想提高问题被回答的概率，最好的方法就是平衡你和回答者之前的交流成本。俗话说将心比心，你在交流的过程中付出了必要的交流成本，自然也会得到对方的重视。 如果你不愿意提高自己的交流成本，过了河就打算拆桥。最起码应该主动降低对方的交流成本，比如： 提问前把能解决的部分解决掉，该查的资料查好； 不提宽泛的问题，细化到一个具体单元； 减少二次交流，比如写清在参考哪篇文章时用什么软件的哪个版本出现了问题。 平日里做什么事情我们总喜欢找熟人帮忙，这就是因为你在求助前已经为所谓的熟人付出了大量交流成本，而他帮你很可能也是因为你帮过他或者可能之后会帮到他。 从这一层面来说，并不涉及太多人情社会。说到底，还是让对方感到你的诚意和尊重。 拿自己举个例子。平时提问的时候，很多人看到自动回复都会不爽，觉得后台应该是个活人接待才好；但下载一些资料的时候，回复完关键字立马走人，觉得后台肯定是个机器人。 如果本身就是完全不对等的交流，我们还真的没理由要求太多。 最后，希望我们都能学会提问，希望你的问题能得到别人的回答。但在这之前，你要做的可能还有很多。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-04-03-HowToAskQuestion/"},{"title":"给犹豫的你","content":"这是一个放弃的季节，空气里弥漫着不安的味道。 最近一段时间不少人有了放弃考研的念头。 考研这一年时间从大多数人的经验来看会有三个主要的迷茫期。 一是寒假前后，考哪不知道，考啥不知道，怎么复习不知道；二是七月左右，别人比你看得多看得快，自己看不进去；三是考试前一个月，发现自己什么都不会了，阅读越错越多，数学算不对数。 到了考研复习中期这个阶段，很多人到现在才发现考的学校还没有定下来。就像我之前说过，这个阶段没有了复习前期的冲劲和新鲜感，也还没有最后一百天的紧迫感，拼的就是你的定力和内心的渴望。 很多人不知道该怎么坚持下去。有的以为有了“更好”的选择于是就想放弃考研，有的人因为突然没了动力就想放弃考研，有的因为自己看不进去书就想放弃考研。 我不是不同意放弃但是希望你能想清楚以下三点问题。 你是不是真的有更好的选择，这个选择并不能只是看起来很美好而且还不应该唾手可得，因为得到的太容易往往不会有好结果，无论什么（包括爱情）。 是不是还记得自己当初为什么考研又为什么能坚持到现在，如果那种感觉还在而你只是进入了一个疲劳期最好先别急着放弃。 你是不是理解什么叫做坚持和靠谱，你感觉自己坚持不下去时候恰恰是最需要你去坚持的时候，顺风顺水的做一件事其实称不上坚持，在困难面前还能咬牙向前走而且走的坚定正确才叫坚持。所谓靠谱，最基本的是对自己靠谱，知道自己要什么并为之努力，为自己的选择和行为负责。 最后，我可以给你一点小的建议。 做一件事情不管怎么样都不要轻言放弃，如果想好了要放弃就走的潇洒利索也别再回头。 如果你现在正在犹豫要不要放弃，最好先看看自己的目标和考研的理由是不是太空泛。如果你考研的理由是“过不同的生活，遇见有不同梦想的人”，这样的理由可能多半会比较危险，因为你会发现考不考研其实都能遇到有不同梦想的人，你做任何事情都可以让自己过和以前不一样的生活。 你最好去细化自己的目标，比如：我要考到哪里，为什么要考到那里，我考上之后有什么大概的想法。 短期目标越不浮夸，你的动力也就越具体。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-03-15-ToSadPeaple/"},{"title":"如何阅读科学文献","content":" 原文 来自《Science》杂志 原作者：Adam Ruben 从来没有什么事能像阅读科学期刊里的文章一样让你感觉自己如此愚蠢。 我记得自己第一次读这些极度枯燥文章的经历，这些手稿如此复杂难懂以至于科学家有时会被撞见正在吃这些文章以让自己保持正常。那时还在读大学的我参加了一门讨论课程，它要求我们每周阅读一篇最新的文献并且进行讨论，可有些东西对我并不起作用。 每周我都会拿着文章坐下来，然后盯着文章一句话一句话地读，每次读过之后又都会发现自己一点东西也没有学到。上课时我总带着这样一个确切的念头：我知道自己读过这篇文章。然而当老师问一个问题时，我却连她在问什么都不知道，就算她换一个简单的问题，我仍旧不知道她在问什么。可是尼玛我明明读过这篇文章啊！ 这让我想起了在幼儿园的日子，那时每当我读完一本超过自己所在年级的书时我都感觉非常傲娇，可如果你问我一个关于书本内容的简单问题，比如 Wilbur 是一种什么动物（译者注：Wilbur 是美国作家 E. B. White 所写 Charlotte's Web 一书中的角色，是一头小猪）、Encyclopedia Brown 如何知道 Bugs Meany 不是真的在赏鸟（译者注：Encyclopedia Brown 是 Encyclopedia Brown 系列丛书的主人公，他的名字是 Leroy Brown，因为非常聪明和博学所以人们都叫他 Encyclopedia 百科全书，而 Bugs Meany 则是这本书里的反派头目），我却回答不出来。 参加讨论课几周之后，我真的受够了。我决定在读懂一篇文章之前绝不去读下一篇。于是我拿着那周的文献去图书馆，注意，不是普通图书馆而是一个阴暗的小型生物学图书馆，这种充满灰尘的学术藏身之处只存在着两种最不幸的生命形式：虫子和博士后。 我把文章发在一个很大的空桌子上，消除所有其他的干扰。为了防止朋友叫我出去喝酒，是的，这是大学朋友之间经常做的事情，我特意坐在了一个幽暗且人很少的前厅；为了避免手机的干扰，好吧，我确定那时是 1999 年，我还没有手机。 最重要的是，如果某一句话中有一个单词我不理解，就不允许自己去读下一句，直到查字典找到这个单词之后反复阅读理解了这句话为止。 对于上述过程，exogenous （译者注：这个单词的意思是“外源的”）这个词让我记忆犹新。不知为何我过去总是忽视这个单词，好像它对整个句子不重要一样，但这是错误的！ 一篇三页的文章我花了两个多小时。但这一次，我真的理解了。 我心想，“哇，我懂了，我真的懂了” 我又想到，“尼玛，我还要再来一次，不是么？” 如果你刚要开始自己的学术生涯，那么也可能面临着同样的问题。看完阅读科学论文的十个阶段之后可能会帮助你更好地认识自己。 1、乐观 “这不可能有多难，”你微笑着告诉自己。你用同样的方式告诉自己“一天喝八杯咖啡都没有坏处”或者“还有一大堆终身教授的职位”。毕竟你已经读了几十年文字，所有的科学论文不都是字么？但真的是这样么？ 2、恐惧 这一阶段你会意识到，“呃，这些根本不是字啊。”所以你开始慢下来，开始试探音节，分析术语，查找缩写并且反复重复这些工作。恭喜！现在你已经读完题目了！ 3、后悔 你开始意识到自己本应该为这项工作预留更多的时间。为什么，为什么你认为自己用坐单程公交的时间就能读完这篇论文？这个时候你会想，如果你有更多的时间就好了；如果你有 20 世纪 60 年代工厂里那种蜂鸣器，你可能会按响它然后说，“Phoebe，取消我一月的行程”；是不是这篇文章有一个精简版本，大约只有不到 250 个字，用粗体打印在文章的开头…… 4、投机取巧 什么，这是什么？为我准备的摘要么？祈祷科学期刊的编辑们知道这些文章是没法理解的，所以他们要求作者提供一个很短的版本。没错，就这么干，去要摘要。 5、迷惑 什么鬼？这篇摘要究竟想说什么？为什么平均 40 个单词的句子这么长？为什么有这么多缩略语？为什么作者要用五次 “characterize”？ 6、分心 如果有给鸭子用的手机会怎么样？它该如何工作呢？鸭子们会拿它干什么？Paul Simon 那首歌词里“You Can Call Me Al，”是什么意思？如果有一台面包机你的人生将如何改变？首先你得去买酵母，那酵母贵么？每隔几天你就能给自己做点面包，但之后面包可能会变质。它和商店里买来的面包不一样，是的，不一样。哦，对了，Paul Simon 还活着么？你应该查查维基百科，你有时候会把他和 Paul McCartney 或者 Paul Shaffer 搞混。还有，你能把咖啡放到加湿器里么？ 7、意识到 15 分钟已经过去然而你还没有进行到下一句 8、决心 好了，这次要真的认真读了，真的要开始了。是的，是的，是的，读文章才是现在该做的。让我们数一数纸上干油墨里的那些小孔。 9、愤怒 这尼玛是人能写出来的句子么？ 10、陷入了对人文学科发展过程的深深思考 非科学题材的人文类文章应该更好理解一些，对么？ 科学期刊的论文是一种多么奇怪的文章形式。我们为了它花费数月甚至数年的时间，用高度专业化的语言来撰写以至于很多其他领域的科学家也不能理解。我们把文章放在支付墙后并且要花费一些滑稽的数额，比如 34.95 美元，来获得阅读权限。我们如此坚定地认为它们难以理解以至于需要召开“杂志俱乐部”（journal clubs）以期我们的朋友可以理解并且为我们总结那些文章。 你能想象如果主流杂志的文章都像科学论文会怎样么？Time 的封面文章有 48 个作者，或者 The Economist 里就算只占一小块的文章，在描述完每一个物品之后都需要一个附加说明来介绍生产该物品的公司以及公司地址，再或者 People 一篇关于 Jimmy Kimmel（译者注：美国的一位脱口秀主持人）的文章只有在经过研究 Jimmy Kimmel 同领域专家的严格审查之后才可以发表。 但你知道你会如何评价一篇要求知识产权审查的杂志文章么？你可能会说那是一篇烂文章。 所以那些刚刚开始阅读科学期刊的人，欢迎你们。祝你们好运！不过非常抱歉，虽然我们正在尝试写易于理解的文章，可有时我们的学科分支过于具体以至于需要百万个缩略语，有时我们尝试通过复制每篇我们读过的文章的口气来使自己听起来像是好的科学家，有时我们仅仅就是写的很差。 Quackberry。这就是你对为鸭子生产的手机的称呼。（译者注：Quackberry 是作者创造的词汇，其中 quack 形容呱呱叫，暗指鸭子， berry 则来自知名的 Blackberry 黑莓手机。） 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-03-10-HowToReadPaper/"},{"title":"过来人，想对年轻的自己说些什么？","content":"最新一期的 CELL[1] 杂志发表了 这样一篇文章，文章开头说到： Looking back at the time spent in graduate school and postdoctoral training can be illuminating. We asked postdoctoral researchers to tell us what kind of advice they would give to their younger selves. 他们采访了 11 位已经（或者即将）开始自己独立科研生涯的博后，问他们回顾过去想对年轻时候的自己说些什么。 不少内容让人读完确感 illuminating，在这里挑一部分记录和分享。（说句题外话，原文中有每个博后的照片，不少男博后确实发际线都很高） 首先列出这 11 个人给的 title Expand Your Bubble The Long Journey Bringing Knowledge Home Not Easy but Well Worth It Take Every Chance to Better Yourself Cut Yourself Some Slack Trust Your Gut and Be Independent Keep on Persevering It Takes a Village Use Your Time Strategically Find Your Passion, Maximize Your Returns Explore the Big Picture Expand Your Bubble Frederic Westhorpe 来自 Stanford，他评价毕业的自己You are now in your personal knowledge bubble. Your expertise and network is, at this stage, narrow.，而他给自己的建议是Expand your network, expand your skill set. These are perhaps the most important factors for your future success and happiness. 从上研究生开始直到博士毕业，我们接触的东西越来越深奥也越来越狭窄。每个人都生活在一个自己的 knowledge bubble 里。你固然可以在自己的 bubble 里不出来，但是学会扩宽自己的圈子、增加自己的技能，很可能是你未来能否成功的关键。 做好实验是很重要的，但是还需要走出去，和更多的人接触和交流。尝试组织一些 seminar，和之前的实验室成员保持沟通和交流。帮助别人并学会像别人寻求帮助。寻找各种可能的机会提高自己的沟通能力，并学会有效地向别人介绍你的研究成果。 Take Every Chance to Better Yourself 纽约大学的 Gaurav Jain 则告诫年轻的自己Becoming a scientist means mastering many skills, thus, take opportunities to broaden your education at every step of the way. 他也提到了要学会和身边不从事科研的人们交流科研。积极地去创业公司参加各种实习，了解毕业不久的校友他们的工作体会和职业前景。把握机会，争取每年参加一两个学术会议，了解你自己所在的领域。 It Takes a Village It takes a village 的原话出自古老的非洲谚语It takes a village to raise a child [2] ，来自 Harvard Medical School 的 Sabrina Absalon 用这句话来形容自己的科研生涯。 她认为年轻的科学家要想更好的成长，需要三类重要的 mentor。 在短期内，你需要找到someone who can be in your shoes and with whom you can develop a casual relationship，这个人可以在你日常科研中那些基础的问题上帮助你。 在中期内，你要能找到这样一个人，他和你有着共同的目标，而且有一部分目标已经先于你完成。 在职业方面，你需要找到一个自己尊重敬仰的高人，而他则可以对你的整个职业和研究生涯给予指导。 Find Your Passion, Maximize Your Returns 剑桥大学 Pedro Madrigal 的研究领域是计算生物学，他的第一条建议就是focus most of your time addressing an important problem and learn to say no to others. 让自己集中精力专注于重要的问题并且学会向别人说不。什么是重要的问题呢？在他看来，一方面要在你的研究领域内足够有趣，而另一方面则要能帮助你实现中长期的职业目标。 除此之外，让自己研究课题成功的可能最大化，这需要你和自己的导师在一开始就说清楚。 第三点，也是非常重要的一点，就是找到一个合适的实验室。了解你自己实验室同伴的需求和兴趣，寻求一个双赢的局面。举个例子，如果你对计算生物学有着非常大的兴趣，那么你必须要在那些真正尊重你劳动成果并且把你当作同等重要成员的团队里工作，而不只是把你当成一个生物信息服务的提供者。 Explore the Big Picture Kedar Natarajan 来自英国的桑格研究所，自己的专业是生物信息学。他认为最重要的建议是to always ask larger scientific questions and not be tied down to specific themes from present labs 。 翻译成中文，我感觉比较恰当的应该是“视野开阔，格局要大”，督促自己去开发更广泛的兴趣，在不同的领域之间寻求联系。在职业生涯早期就把自己限定在一个过分专业的领域是十分危险的。 回过头来看，他说I would put effort into communicating science and engaging with non-scientific audiences, including family and friends。 另外，他也建议自花时间去培养爱好或者去运动来缓解和分散科研中的各种艰辛，并学会珍惜和享受那些有小小成就和突破的时刻。 最后，引用文章里的一句话和你共勉 It is crucial to learn to let go of some projects and to prioritize. Science is indeed for the long run and it’s important to inspire, enjoy, and learn continuously. 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 顶尖的学术期刊，和 Nature，Science 可以并称为学术期刊（生命科学领域）的三座大山 ↩︎ 希拉里克林顿 96 年写了一本书名字就叫“It Takes a Village”来强调家庭教育的重要性，这种说法也被更多的人开始使用。 ↩︎ ","link":"https://kaopubear.top/blog/2017-02-25-WhatWouldYouTellYourYoungerSelf/"},{"title":"数据科学家的成长之路 [译]","content":"数据科学家的成长之路 可能是最全面的数据科学入门文章，文中有大量资料和相关链接。 英文原文地址：Becoming a Data Scientist 数据科学技能 数据科学家每天都会用到很多综合技能，其中的许多技能都是在工作或者其他时间自学的。他们并不需要具备某种特定的文凭，而是来自不同的背景。 本文讨论的所有技能都可以自学。我们为此准备了一些资源让你可以沿着这条路走下去。而你则可以把这篇文章看成是数据科学家的培养指南。 数学 数学是数据科学的重要组成部分。请确保你了解从微积分到线性代数这些大学数学的基础知识。当然，关于数学你知道的越多越好。 过大的数据量通常会显得笨拙且难以操作，这时你将不得不使用数学对你手头的数据进行处理和结构化。 如果你忘了本科阶段就该掌握的线性代数和微积分概念，别无选择，你必须要学会理解如何处理数据矩阵并大致了解其背后的数学算法。 资源︰ 这个列表中的 15 门数学公开课 可以帮你补上这些数学技能。另外，麻省理工学院也提供了关于数据科学的开放数学课程。 统计学 你必须知道那些可以从小数据集推断总体情况的统计学知识，这是数据科学的基本准则 。统计学将数据科学家的成长之路铺平道路。 要知道统计学总是和数据结合在一起的，统计学将使你更好地理解所观察到的数据模型，并能提炼出做合理推论所需要的洞察力。例如，理解 统计推断 将帮助你从一个小样本中得到符合总体中每个个体的一般性结论。 要理解数据科学你必须知道基本的假设检验，并且能设计实验来理解数据的意义和背景。 资源︰ 我们的博客发布过一篇 如何将贝叶斯定理，概率和统计结合起来 的入门文章，这篇博客为你理解成为一名数据科学家需要的统计基础提供了一个很好的参考。 算法 算法是让计算机遵循一定规则或模型的能力。在处理分析大数据时，了解如何使用机器来完成工作至关重要。 为了让自己胜任数据科学中各种繁重的工作你不得不理解算法选择和优化背后的理论。你必须确定自己的问题是否需要进行回归分析或者需要用某种算法将不同数据点进行归类。 你会想要知道很多不同的算法，也会想要学习机器学习的基本原理。所谓机器学习就是能让亚马逊基于你的购买历史记录向你推荐商品而无需人为干预。这类算法可以借助机器的力量来帮你挖掘信息。当然，为了处理大型数据集，你也需要机器来扩展你的思维。 资源︰由 KDNuggets 提供的这份 指南 解释了十种常用数据科学算法，里面 19 个免费的公共数据集 可以供你进行实践。 数据可视化 完成数据分析仅仅是成功的一半。为了扩大影响力，你不得不说服别人相信并且采纳你的观点。 人是视觉动物。根据 3M 和 Zabiscod 的研究，传输到大脑的信息里几乎 90%都是视觉化的，而且大脑对视觉信息的处理速度要比文本快 60000 倍。 数据可视化是一门通过图表和其他可视化工具来呈现信息的艺术，从而使观众可以很容易地理解数据并从中提取观点。什么样的信息最适合在条形图中展示，哪种类型的数据又应该用散点图呈现呢？ 人类生而善于回应视觉线索。你呈现的数据结论越清晰，别人就越有可能根据你的结论而采取行动。 资源︰ 这里 有一篇博客 供你参考。另外，Nathan Yau 的博客 提供了各种各样的数据可视化要诀和技巧，这些可以使你更上一层楼。 商业知识 没有背景的数据是没有意义的，你必须明白你正在分析的事情。思路清晰是成为一名数据科学家的关键。 大多数公司雇佣数据科学家不仅是为了挖掘数据，还需要他们将研究结果传达给各位股东并且提供当即可行的建议。 最好的数据科学家不但有能力处理大型复杂的数据，也能理解他们为之工作的那些错综复杂的企业或组织。即便是在商业因素的制约下，广泛的业务知识令他们能够提出正确的问题并拿出有见地的建议和切实可行的解决方案。 资源︰ 这个 免费的商业课程列表 可以帮助你获得需要的知识。我们的 商业数据分析课程 也可以帮助你获得这方面的技能。 领域专长 作为一名数据科学家，你应该了解自己所做的事情以及它所处的行业。 除了深入了解你为之工作的公司，你也需要了解整个领域来培养商业洞察力。来自于生物学研究的数据和来自心理学实验的数据很可能有截然不同的背景，你应该对那些行业术语有足够多的了解。 资源︰ 这在很大程度上具有行业依赖性，你必须找到你自己的方式并且尽可能多的学习和你行业相关的内容 ！ 分析思维 想在数据科学领域做好，你需要严谨的分析思维。大量的数据科学在解决问题时都需要有一个敏锐的头脑。 资源︰ 通过书和难题来保持你的头脑敏锐。类似于 Lumosity 这样的网站可以帮助你在任何时刻都保持敏锐的认知能力。 数据科学工具 随着各项技能的完善，现在你需要学会使用现代数据科学工具。每个工具都有其长处和短处，并且每个工具在处理数据的过程中都扮演着不同的角色，你可以使用其中之一或者全部。下面是数据科学中最流行的工具以及你想要深入了解他们需要用到的资源。 文件格式 数据可以存储在不同格式的文件中。下面是一些最常见的︰ CSV︰ 逗号分隔值。你之前可能用 Excel 打开过这种文件。CSV 使用分隔符来分割数据，这些分隔符有助于把不同数据点的数据分开。 SQL : 结构化查询语言。SQL 将数据存储在关联表中。如果把一行数据从右向左读过去，你会得到一个对象的不同数据点 （例如，一个人有年龄、性别和身高等数据类别）。 JSON: Javascript 对象表示法是人和机器可读的轻量级数据交换格式。来自 web 服务器的数据通常用这种格式进行传输。 Excel 简介︰ Excel 往往是通往数据科学的入口，从某种意义上讲每个数据科学家都能从学习它的过程中受益。 Excel 允许你所见即所得的轻松处理数据，你可以对数据进行方程计算而完全不需要使用代码。它对那些想不通过编程而得到结果的数据分析师来说是一个非常方便的工具。 Excel 非常容易上手，这个程序可以让任何人在分析中有直观的理解。你和不具备任何编程技能的人进行数据沟通时，Excel 都是非常有用的工具，因为这些人仍然能对数据进行处理。 谁在使用︰数据分析师倾向于使用 Excel。 难易程度：初级 示例项目︰尝试导入一个 NBA 球员的小型数据集并制作简单的图表展示联赛中的高得分球员。 SQL 简介︰SQL 是最流行的用于查找数据的编程语言。 数据科学当然需要数据，而 SQL 正是一种专门用于从数据库中提取数据的编程语言。 SQL 是数据科学家中最流行的工具。世界上的大部分数据存储在需要用 SQL 来访问的表格中。你可以通过 SQL 对数据进行筛选和排序。 谁在使用︰数据分析师和一些数据工程师倾向于使用 SQL。 难度等级︰初级 示例项目︰尝试使用 SQL 从 Billboard 100 的榜单中查询最流行的十大歌曲。 Python 简介：Python 是数据科学中一种功能强大且用途广泛的编程语言。 一旦你下载好 Rodeo （一种 Python IDE），你很快就会发现 Python 究竟有多直观 。作为一种可以从开发网站到跨网络收集数据的多功能编程语言，Python 有很多致力于使数据科学工作更加简单的代码库。 记住，Python 是一门语法简单的多功能编程语言，很容易学习。 Python 程序猿在这个网站的调查中 平均年薪是$102,000，而 Python 目前是 大学教学中最流行的编程语言，Python 社区对于 Python 教学也充满热情并且开发了很多有用的工具，这都会节省你的时间从而让你有更多的精力来分析数据。 许多数据科学家都在使用 Python 解决他们的问题︰ 在 O'Reilly 的一项调查中，40%的受访者在明确的数据科学研究中使用 Python，而使用 Excel 的人是 36%。 谁在使用︰ 数据工程师和数据科学家将使用 Python 来处理中等规模数据集。 难度等级︰ 中级 示例项目︰ 使用 Python 来获取名人的 tweets，然后分析他们使用最频繁的一个词。 R 简介︰ R 是数据科学界的一门主要语言，因为它是明确地根据数据科学的需求而设计的。在数据科学界，R 是最流行的编程环境，超过 43%的专业人员都在使用 R 语言。 R 是一个专门为数据分析而设计的编程环境，当你需要建立统计模型和进行结果展示时，R 会大放异彩。它可以适用于各种各样的统计和图形技术。 类似于 Python，R 社区成员贡献了各种各样可以扩展 R 代码库核心功能的包，这些包可以应用于一些特定的问题，如测量财务指标或分析气候数据。 谁在使用︰数据工程师和数据科学家使用 R 处理中等规模的数据集。 难度等级︰ 中级 示例项目︰ 使用 R 来展示过去五年的股票市场走势。 大数据工具 大数据来自于 摩尔定律，即计算机的计算能力每两年就会翻一倍。这使得数以百万计的计算机生成大规模数据集。想象一下 Facebook 在任何一个特定时间能生成多少数据吧！ 根据 麦肯锡的调查，任何一个使用 SQL 和 Excel 等常规数据工具无法完成分析的数据集都可以说是大数据。最简单的定义就是，大数据并不适合在你自己的计算机上进行处理。 下面是解决这一问题的一些工具︰ Hadoop 简介︰通过使用 Hadoop，你只需要通过一个服务器就可以控制存储在多个服务器的数据。 这种解决方案是一种叫做 MapReduce 的技术。MapReduce 是一个抽象的概念，它把一系列计算机当作一个中央服务器。这就允许你将数据存储在多台计算机，仅通过其中一台对数据进行处理。Hadoop 则是开源生态系统的工具，它允许你在不同的服务器上存储庞大的数据集，也允许你在一台计算机上管理多个数据集。 谁在使用︰数据工程师和数据科学家会使用 Hadoop 来处理大规模的数据集。 难度等级︰ 高级 示例项目︰ 利用 Hadoop 将大规模数据集进行实时更新，例如 Facebook 用户生成的赞的数目 。 NoSQL 简介︰ NoSQL 允许您管理数据而无需不必要的负担。 囊括所有数据的表格可能会非常笨重。NoSQL 包括许多数据存储方案，可以将巨大的数据集分离成易于管理的数据块。 NoSQL 是由谷歌引领的一种趋势，google 用它来处理自己存储的那些难以想象的大数据。NoSQL 经常以 web 开发人员欢迎的 JSON 格式进行数据结构化，类似于 MongoDB 这样的解决方案已经创建了可以用类似 SQL 处理的数据库，这些数据库可以用更小的结构和密度来存储数据。 谁在使用︰ 数据工程师和数据科学家使用 NoSQL 来处理大型数据集，通常是那些有百万计用户的数据库网站。 难度等级︰ 高级 示例项目︰ 存储部署在 web 上的社交媒体的用户数据。 联系起来︰ 数据处理过程中的工具 我们已经介绍过的每一款工具都是可以互补的，且有自己的长处和短处。而每一款工具也都可以应用于数据处理过程的不同阶段。 数据收集 有时数据分析不是难事，难的是找到你需要的数据。不过好在我们有很多资源。 你可以通过所谓的 API（应用程序接口，Application Programming Interface）来创建你想要的数据集。API 允许你从某些数据提供商那里获取结构化的数据。比如你能从 Twitter、Facebook 和 Instagram 查询各种各样的数据。 如果你想要处理公共数据，美国政府 已经将其中一部分免费向所有人开放，Reddit 就追踪了其中 最受欢迎的数据集。数据搜索引擎 Quandl 则可以用来搜索最匹配的数据。 我们的博客也列出了 19 个我们最喜爱的公共数据集，当你马上就需要好数据的时候它可以帮上你。 如果你就是想找点没那么严肃死板的东西，看看 这篇博客 吧，其中竟然包括了信鸽比赛 ！ **Python **支持大多数的数据格式。你可以处理 CSV 数据或来自 web 的 JSON 数据，当然，你也可以 把 SQL 表直接导入 到你的代码 。 你还可以从 web 创建数据集，Python 的 requests 库 让你可以运行一行代码就从不同的网站获取数据。你可以先从维基百科的列表中获取数据，然后用 beautifulsoup 库 清洗数据，随后便可以进行深入的分析了。 **R **可以从 Excel、CSV 和其它文本格式文件 中获取数据。Minitab 或 SPSS 格式的文件也可以转换为 R 的数组。 在 R 中，你可以使用 Rvest 包 进行基本的网络数据爬取，magrittr 包 则可以用来进行数据的清洗和分析。这些包和 Python 中的 requests 库和 beautifulsoup 库类似。 数据处理 **Excel **可以让你通过菜单轻松地清洗数据，例如删除重复值、按列筛选排序或者删除行和列的数据。 **SQL *具有基本的筛选和排序功能，因此你可以准确地获取自己需要的数据。当然，你也还可以随时更新 SQL 表和或者删除其中的某些值。 **Python **则可以使用 Pandas 库 进行数据分析。与 Excel 相比，它处理大型数据集的速度更快且功能更多。你可以通过编程的方法来使用 Pandas 库，例如，通过一行代码将数据集的所有错误值替换为某些默认值，例如 0。 **R **可以帮助你在信息中添加列、改变数据结构或者进行数据本身的转换。很多新的 R 语言包，如 reshape2，可以让你处理各种各样的数据框使它们符合你所设定的标准。 **NoSQL **允许你提取大型数据集的子集并依据自己的意愿更改数据，你也可以借助这些功能清洗数据。 探索性分析 **Excel **可以进行列求和、均值计算，也可以借助漂亮的方程进行基础的统计和数值分析。 **Python **和 pandas 可以对数据进行更加复杂的分析从而让你轻松发现更高级的趋势。 在 Pandas 中你能够做深入的 时序分析，比如跟踪股票价格的变化。 **R **语言设计的初衷就是进行大型数据集的统计和数值分析。你可以构建概率分布、对数据进行各种统计检验，也可以进行机器学习和数据挖掘。 而** NoSQL** 和 Hadoop 都允许你在 SQL 这一层级上进行探索性的数据分析。 数据分析 **Excel **对数据进行高层次的分析，使用 数据透视表 可以动态的展示数据，使用 高级公式 和 宏编程 可以让你以编程的方式来分析数据。 Python 则提供了数据分析库 Numpy。你可以通过 SciPy 进行科学计算与计算或者通过 scikit-learn 代码库 获取大量已经预构建的机器学习算法。 **R **有大量的包供你进行各种特定分析，比如泊松分布和混合概率。 数据呈现 **Excel **具有基本的图表和绘图功能。你可以轻松构建仪表板和可以进行数据实时更新的动态图表。 在数据可视化方面，Python 有很多非常强大的选择。你可以使用 Matplotlib 库将 Python 中的数据生成基本的图表。如果你想要更高级的东西，可以试试 Plot.ly 和它的 Python API。 除此以外，你也可以使用 nbconvert 函数将你的 Python 笔记变成 HTML 文档。这样你就可以把代码块嵌入到交互网站或你的项目档案中。有很多人使用这个函数来写 Python 学习的 在线教程。 **R **是用来做统计分析和 结果展示 的。因为 R 中有很多专门的包可以用来做各种类型的图表结果展示，因此它是一个非常适合用来做科学可视化的强大开发环境。你可以用基本图形模块从数据矩阵中构造所有你想要的基本表格和图形，然后把这些文件保存为。jpg 等图像格式或者保存为单独的 pdf，你也可以使用 ggplot2 中更加高级的图表，比如带有回归线的散点图。 开始求职 你已经了解了入门数据科学和成为数据科学家所需要的技能和工具，现在是将这些理论应用到寻找一份数据科学工作的时候了。 构建数据科学项目集和简历 你需要为自己进入数据科学领域提供一个不错的第一印象——那就是项目集和简历。许多数据科学家都有自己的网站，里面既有和工作相关的项目集也有展示自己想法的博客。 这些网站使他们能够展示自己的经历和在数据科学领域创造的价值。为了使你自己的项目档案也具有相同的效果，它必须具有以下特点： 你的项目集应该突出自己最棒的项目。专注于几个令人难忘的项目通常比展示大量平淡无奇的项目更好。 它必须经过精心设计并且要有一个迷人的故事，让大家了解你是谁而非仅仅是你的工作。 你应该通过突出自己在工作中的创造的影响力来为你的访问者创造价值。也许你开发了一个对大家有用的工具？也许你有一个教程？把它们在这里展示出来。 应该很容易找到你的联系信息。 例如，你可以看看我们网站导师 Sundeep Pattem 的个人项目集中的几个项目。 Sundeep Pattem 致力于研究和实际生活联系紧密的复杂数据问题。他有五个项目分别涉及医疗成本、劳动力市场、可持续能源、在线教育和世界经济。这些领域中每一个都有大量的数据问题需要解决。这些项目都独立于任何真正意义上的工作，它们表明 Sundeep 是发自内心地喜欢为那些复杂的数据科学问题提供解决方案。 如果缺乏想法，你可以参加数据科学竞赛。类似于 Kaggle，Datakind 和 Datadriven 这样的平台允许你去解决真实的企业或社会问题。通过利用数据科学技术，你可以展示自己的影响价值，创造出最有说服力的项目集，向别人证明自己的执行力。 在哪里找工作 Kaggle 为数据科学家提供了一个 工作公告栏。 你可以在工作搜索引擎 Indeed 中找到一系列公开的数据科学工作招聘信息。 Datajobs 提供了一个数据科学网站清单，这是一个学习如何成为数据科学家的好地方。 你也可以通过人际交往或者联系导师来寻找机会。我们再一次强调，最好的工作岗位往往是通过与数据科学界人士交流而找到的。这就是你成为一名数据科学家的方式。 你还可以在很多创业论坛找到就业机会。Hacker News 有一个专门属于 Y Combinator（也许是世界上最著名的创业孵化器）的工作公告栏。Angellist 是一个为初创公司寻求资金的数据库，它也有工作板块。 数据科学面试宝典 有关数据科学面试的内容可以写成 一本书，事实上，我们就是这么做的！ 如果你得到了面试机会，接下来该做什么呢？在数据科学面试中有这么 几类常见的问题：个人背景、编程问题和机器学习应用问题。你应该预料到在任何一场数据科学面试中都会有技术性和非技术性的问题。首先确保复习一下编程和数据科学相关的知识，然后尝试把它们与你自己的故事融合在一起！ 通常你还会被要求分析一些数据，也很可能被问及文化契合和统计学问题。为了准备编程相关的问题，在某种程度上，你必须将数据科学面试看作一次软件工程训练。你应该复习一下所有的编程面试资源，其中大部分都是 在线 的。这个列表是你可能 会遇到的数据科学问题。 你会看到几类常见问题： Python 和 R：在某种情况下你更喜欢哪种语言？ 什么是 K-means（一类特殊的数据科学算法）？请描述一下使用它的场景。 给我们讲讲你最近参与的一个数据科学项目。 你对我们业务增长的关键驱动因素有什么了解？ 第一类问题测试你的编程知识；第二类问题测试你对算法的了解，并请你分享自己的实际使用经验；第三个问题则是深入了解你以前的数据科学工作；最后，第四类问题将测试你对面试企业的了解程度。 如果你能展示自己的数据科学工作帮助潜在雇主的受益方式，那会给他们留下深刻的印象。这样，他们才能知道，你在关注公司的工作内容，并且对这个行业有着充分的了解，也无需进行入职教育。 以上，就是一名数据科学家的成长之路。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-02-22-BecomingADataScientist/"},{"title":"不可不知的快捷键","content":"整理的原因 提高键盘上的工作效率 一个入门级别的机械键盘 习惯使用常用工具的各种快捷键 挽救小拇指不变型 更换 Capslock 和 Control 的映射关系 更换原因看完下面的快捷键设置就晓得 快捷键操作 和其他键不冲突时：C 代表 ctrl； A 代表 alt； S 代表 shift; W 代表 win 加粗的内容尤其常用 Win 10 创建虚拟桌面 W+C+d 关闭当前虚拟桌面 W+C+F4 切换虚拟桌面 W+C+左右键 切换窗口 A+tab 调整窗口位置 W+上下左右键 任务视图 W+tab 临时显示桌面 W+, 显示桌面/恢复应用 W+d 打开我的电脑 W+e 锁屏 W+l 最小化所有窗口 W+m 切换任务栏程序 W+t 打开搜索框 W+q （然后当计算器用） 投影模式 W+p 印象笔记 全局 新建笔记 C+A+n 查找笔记 W+S+f 应用内 新建笔记 C+n 快速搜索 C+q 重命名笔记名 F2 添加标签 F3 笔记编辑器 简化格式 C+spaces 删除格式 C+S+spaces 高亮 C+S+h Google 浏览器快捷键 标签页和窗口 打开新窗口 C+n 隐身模式打开新窗口 C+S+n 打开新的标签页 C+t 重新打开最后的标签页并跳转 C+S+t 关闭当前标签页 C+w 统统关掉 C+S+w 功能 搜索当前网页 C+f 查看历史纪录 C+h 查看下载记录 C+j 打开清除浏览记录选项 C+S+delate 开发者工具 F12 地址栏 直接跳转地址栏 C+l 使用其他搜索引擎 搜索栏输入搜索引擎名称并按 Tab 键 需要提前设置关键字 在页面任意位置内搜索 C+K 新标签页搜索 A+Enter 地址栏其它功能 直接当计算器来使用 chrome://plugins 查看插件 chrome://history 查看历史纪录 chrome://bookmarks 查看书签 网页 查看可点击链接 Tab 放大网页内容 C 和+ 缩小网页内容 C 和- 恢复默认大小 C+0 大范围滚动网页 Spaces 大范围回滚 S+Spaces Google Vimium 插件 仿 VIM，基本都常用 Navigating the current page ? 查看帮助文档 h 左 j 下 k 上 l 右 gg 顶部 G 尾部 d 向下一半 u 向上一半 f 当前页打开新链接 F 新标签页打开链接 r 重新加载 gs 查看源代码 yy 复制当前 url Navigating to new pages o 当前 tab 打开 url/书签/历史记录 O 新建 tab 打开 url/书签/历史记录 b 打开书签 B 新建 tab 打开书签 Using find:（支持正则） / 进入查找模式 n 查看下一个匹配内容 N 查看上一个匹配内容 Manipulating tabs J, gT 左移 tab K, gt 右移 tab g0 去第一个 tab g$ 去最后一个 tab ^ 查看上一个 tab t 新建 tab x 关闭当前 tab X 打开刚刚关闭的 tab T 查找已经打开的 tab Additional advanced browsing commands gi 聚焦页面第一个输入框 ge 编辑当前 URL gE 编辑当前 URL 并在新 tab 打开 Sublime text3 快捷键 整体 打开控制面板 C+S+p 搜索项目文件 C+p 切换当前窗口标签页 C+Tab 窗口分屏 左右两列分屏 A+S+2 上下两行分屏 A+S+8 恢复默认 A+S+1 开启/关闭侧边栏 C+k+b 移动 光标括号内移动到开始或结束 C+m 向左整词移动 C+左键 向右整词移动 C+右键 任意位置下一行插入新行 C+回车 任意位置上一行插入新行 C+S+回车 选择 连续选择相同文本 选中文本后 连续 C+d 选择全部相同文本 选中后 A+F3 整行选中 C+l 上选 S+上键 下选 S+下键 左选 S+左键 右选 S+右键 整词左选 C+S+左键 整词右选 C+S+右键 查找 查找关键字 C+f 支持正则，大小写敏感，整词匹配 ​ 查找框 C+p 查找文件名 直接输入名字 查找函数名 @ +关键字 查找变量名 # +关键字 定位行 : +行号 编辑 图片拖进去可以直接看 多行同时编辑 选中多行，C+S+l , 每行行尾插入光标 按住 C, 鼠标依次点击，同时编辑多行 按住 S 移动鼠标右键 多行合并 选中后 C+z 复制所在行并插入下一行 C+S+d 删除光标后的内容 C+k+k 删除整行 C+S+k 注释单行 C+/ 注释多行 选中 C+S+/ 多行缩进 C+[ 或者 ] 关闭标签 A+. XShell 从一个窗口切换到下一个窗口 C+tab 清屏 C+l 光标向前移动 C+b 光标向后移动 C+f 跳到行开头 C+a 跳到行结尾 C+e 删除光标处字符 C+d 删除光标前一个字符 C+h 删除光标之前内容 C+u 发现 C+u 删错了要恢复 C+y 删除光标之后内容 C+k 锁屏 C+s/恢复 C+q 查询历时命令 C+r 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-02-11-Shortcuts/"},{"title":"如何使用 Google","content":"写在前面 在上一篇文章 关于 Markdown，你应该知道的 最后，我写了这么一句话 如果你决定开始用一个东西，你还会担心学不会么？ 从我个人目前有限的经历来看，我想学的东西还没有学不会的。学不会的要么是不想学要么是用不到。 写文章至今，不断有人问我如何学一个东西。比如问我如何备考，如何学英语；上了研究生，有人问我如何上手做实验，如何入门生信。 我的回答：你只要想学，只要用起来，方法自然就有了，因为自己会去找会摸索。 讲个故事 你还记得自己怎么学会骑自行车的么？ 我记得小时候看着别人家的小孩儿都有自行车我心里羡慕的不得了，于是捡了我哥的旧车子。因为车子太高，我根本坐不到车座上！ 一开始只能双手扶着车把，坐在后座上，肚子顶着车座，两脚交替蹬地（就和两个浆划船一样）前行。 我心里那叫一个高兴！ 过了一段时间，我可以坐在后座上骑车了（双脚离地放在脚蹬子上），突然有一天，我发现在骑车的过程中只要抓紧车把，两腿一使劲就能把屁股从后座抬起来顺势坐在车座上。 我心里那叫一个高兴！ 但是我忽略了一个问题：怎么从车子上下来。不过这没关系，最惨的不就是从车子上摔下来么？能上去了还怕下不来。 学骑车的这个过程，在我后来的所有学习过程中都反复重现，不论学什么。从最初的考研备考，到分享英语学习经验，到经营微博和公众号，到做自己的博客和实验室网站，到入门生物信息。 不管行不行，直接先上车，在车子上慢慢摸索，你自然就会了，还能总结出自己的一套方法。 今天再提供点儿值得摸索的东西 如何使用 Google 需要说明的是，**你掌握了再多的资源和工具，如果不会用都没有和别人吹牛的资本。**比如你有 1000 本书，1 本没看，你趁早别告诉别人你书多；比如你花钱买了 VPN，天天就是为了看些外国小电影，你趁早别告诉别人你能翻墙。 首先回答一个问题： 有没有 Google 搜不出来的问题 有，但是很少，或者说对于任何一个领域的初学者来说很少。 要知道，我们现在学的东西很多都已经诞生 5—10 年甚至更久了，而且每一个学习者之前不会谁比谁聪明多少。你在学习过程中遇到的问题，在如今的大牛还是初学者的时候很可能也遇到过，而且已经提问过。所以，当你搜不出来的时候很可能是因为你搜索的姿势不对。比如使用了中文，或者写了一长串无关痛痒的描述。 从另一个角度讲，如果你真的碰到了一个 Google 无法解决的问题，比如一个非常个性化的需求或者一个别人没有发现的 bug，那你应该为自己庆幸，并且下定决心去解决它。这说明至少在这一个小方面，你已经走在了别人的前面。恭喜。 以下是几个常用的 Google 搜索技巧 常用的前提是得用 用双引号**&quot;搜索内容&quot;**进行精确搜索 很多时候，我们需要使用精确搜索，比如在进行一些常用软件安装或者使用的过程中会出现各种各样的报错，这时你把软件的报错信息用双引号括封装，后面再加上软件的名字和版本，Google 就会进行精确的匹配搜索。很可能第一条搜索结果就是你要的。 用 -搜索内容 进行排除搜索 在一些情况下，一个主题词往往会和若干个内容关系密切。这时候我们希望明确排除某个我们不想要的内容。 给大家举个例子，比如搜索“靠谱学长说”，你可能会看到发布在微博的内容，也可能看到博客里的内容。效果如下 但是如果我不想看到那些发布微博的文章，你只需要这么做：靠谱学长说 -微博 然后神奇的事情就会发生： 具体文档类型搜索 这个技巧当你在想要查找具体类型文档的时候非常有用。如你想要 pdf 版本的只需要在搜索内容的最后加上 filetype:pdf 指定网站搜索 对于码农而言 stackoverflow.com 是一个常用的网站，对于生物信息工作者来说 biostar 是一个非常好的论坛。如果我们想在某个特定的网站进行搜索的话，你可以在搜索内容之后加上** site:****.com**，你得到的答案就全部来自这个网站了。 善用相关推荐内容 当你开心地查到自己想要的答案，解决了自己的问题之后，在网站最下面的一些相关推荐通常也值得你去看看。比如我们通过搜索 “如何通过运动减肥” 解决了困惑，Google 还会给你一些大家都在搜索的类似问题。 比如，呃，如何不运动减肥。 这些东西现在你知道了，怎么熟练的掌握呢？ 很简单，用起来。 比如现在就去尝试搜索解决一个问题：如何正确的使用 Google 和百度。 **彩蛋：**在 Google 里搜索 “zerg rush” 后，你的搜索结果会慢慢消失。另外，Google 的 doodles 都非常有趣，你也许可以在这个网站玩儿一年 https://www.google.com/doodles 送上两个我非常喜欢的与你分享，注意，会动哦！ 不好意思，是三个。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-02-09-howtosearchingoogle/"},{"title":"关于 Markdown 你应该知道的","content":"写在前面（写作原因） Markdown 近两年太火了，以至于 MAC 端 Markdown 编辑器基本上一个月就能新出一款。很多人对 Markdown 依旧没有多少了解，这主要体现在两方面： 一方面有些人觉得 Markdown 是万能的：一看别人推荐什么工具自己就跟着用，一上来就学各种所谓语法；或者自己还没体会一个东西的精髓就到处给别人推荐，别人不用他还生气。 另一方面有些人觉得 Markdown 是万万不能的：一部分选择固守自己的舒适区域（比如 word），不愿意接触，认为学习难度大；另一部分用着更高级的 LaTeX 等其他工具觉得 Markdown 太 low，用着丢人。 为了让上述两部分人不本末倒置，能够先脱离那些基本的语法，从一个不同的视角去了解 Markdown，所以简单写一些东西。 Markdown 诞生历史： Markdown 由 John Gruber 在 2004 年创建，至今已经是 12 年的时间。 关于 Markdown 最初的定义如下： a plain text formatting syntax（注意：是纯文本的语法） a software tool, written in Perl, that converts the plain text formatting to HTML 最初的设计理念： The overriding design goal for Markdown's formatting syntax is to make it as readable as possible. The idea is that a Markdown-formatted document should be publishable as-is, as plain text, without looking like it's been marked up with tags or formatting instructions.（简单说就是易读） Mrakdown 有哪些优点 通过 Markdown 的起源和最初的设计理念可知，Markdown 最大的一个特点是易读，而另一个特点是易写。 所谓易读 绝对不要理解为排版之后呈现出来的结果易读，你认真想一下格式化都完成了，打两个符号和点几下鼠标得到的最终效果是一样的，怎么可能是指格式化后的结果易读呢？ 这里的易读是说你读最原始的 Markdown 文件（也就是以 .md 结尾的文件）非常容易，不会像读 HTML 网页那样满屏幕都是*&lt;尖括号&gt;和各种缩进*（最近正在写网站的我对这一点有很深的体会）。易读的特点，对于要看各种文档的程序员是非常友善的。 所谓易写 一方面你可以和类似于 office 之类的软件去对比，写作的过程中你（基本上）可以脱离对鼠标的依赖。这样就带来了两个好处：你不需要先辛苦码字，然后再辛苦地用鼠标点来点去格式化你的文本；你可以集中精力在文字上，只要你事先有了一个清晰的框架，写作和格式化文本可以一气呵成，如果使用即时呈现的编辑器，那么所见即所得 另一方面你可以和类似于 HTML 之类的东西去对比，你不需要记住太多和写作无关的 tag，也不需要让那一堆尖括号和各种缩进扰乱了自己的写作思路。 除此之外，Markdown 的学习曲线非常平缓，找个介绍语法的网站读半个小时，找个在线编辑器练习一个小时，你就可以比较顺利地运用这种轻量级标记语言。 Markdown 和 HTML 的区别 在这里需要强调一下 Markdown 和 HTML 的区别。 如果你了解一点前端的知识就应该知道 HTML 的全称是超文本标记语言（英语：HyperText Markup Language，简称：HTML），所以 HTML 也是一种文本标记语言。Markdown 的定义是“轻量级”标记语言，而 HTML 是“超”，所以 Markdown 是基本不可能取代 HTML 作用的，你倒是可以把它看成 HTML 的一个子集。 就工作原理而言，你所写的 Markdown 格式文本，也是最终转换为 HTML 进而在网页上呈现。 Mrakdown 有哪些缺点 从辩证的角度看问题，任何一个事物的优点在另一个维度都可能变成它的缺点。 在这里同样如此，因为 Markdown 诞生之初就被定义为面向纯文本的语言，所以不管如何进化，插入图片和表格永远都是它的硬伤。优化图片和表格的插入体验也是后来各种编辑器突出的卖点；因为 Markdown 诞生之初就被定义为轻量级的语言，你要知道，即便是对文本而言，也有很多它应付不了的事情。 让某一行居中？做不到 让某一行右对齐？做不到 想更换字体？做不到 想改变颜色？做不到 想改变布局？做不到 其实不止这些，Markdown 根本就不支持其它和布局格式相关的内容。原因很简单，如上文所述，Markdown 是 HTML 的子集，而和布局格式相关的内容是 CSS 的本职工作。 和 LaTeX 的区别 如果你不知道什么是 LaTeX 的话自行百度吧。LaTeX 从它生下来，能定位以及量级和 Markdown 就都不是一个水平。 LaTeX 是一个强大的排版工具，注意，是排版工具。绝大多数高质量的书籍排版或者论文版本，一些逼格很高的简历排版都会使用 LaTeX。另外，LaTeX 最强大的功能在于其对各种复杂数学公式的支持和呈现。而 Markdown 根本就不能称之为一个排版工具，真正意义上的排版功能它一个没有。虽然它可以定义一个题目（语法是若干个#），但是这个题目放在你页面的左边右边还是中间它不关心。不过，现在已经有很多编辑器支持在 Markdown 中插入 LaTeX 语法了。 所以用一句老话总结：革命只有分工不同，没有高低贵贱之分。 没有完全统一的标准 这个缺点你可能感受不到，但其实是最大的问题。 比较有趣的是，早些时候多个使用 Markdown 的互联网巨头联合起来想制订一个统一的标准叫做** Standard Markdown**。结果这个事儿被创始人知道了，老爷子不开心，说你不能用 standard 这么官方的名字，因为我就没想让它统一。后来这个计划更名为** Common Markdown**，对了，这个计划牵头的人就是大名鼎的 Stack Overflow 创始人。 为什么近些年如此火爆 首先是因为 Markdown 本身易读易写的特点。 另一方面，一个东西发明出来，如果没人推广那自然就会默默无闻直至灭亡。那么近些年都是谁在推广使用并且支持它呢？Reddit, Github, Stack Overflow, BioStar 等等，**Rstudio **甚至有一套专门的 R Markdown 供使用 R 语言的人们来运用。如果你了解上面哪怕一个东西目前的火爆程度，都应该可以理解为什么他们使用的 Markdown 会被更多人了解和接受。 此外，有人说 21 世纪是生命科学的世纪，但目前看起来更像是程序员的世界，程序员在各种社区大量使用 Markdown，再加上近几年互联网的发展，火爆也就不足为奇了。 适用于那些群体 基于 Markdown 的优缺点以及火爆的原因，我们可以得出如下的结论，Markdown 这套东西比较适合： 经常阅读书写各种技术文档的技术人员 混迹于各种技术论坛和社区的程序猿 经常码字并且追求效率和流畅度的文字工作者 只求排版简单明了不求过分花哨的网站编辑 喜欢分享，爱好写作的博客或者专栏作者 喜欢整理各种读书笔记学习笔记的学生党 如果你是上述中的某一类人，笔者推荐你对 Markdown 进行一些基础的学习和应用。你的生活应该会有所改变。 如果不是，那么我想说：任何一个工具即使它再简单再火爆，只要不能提高你的效率或者改善你的体验都请你无视它。 有哪些编辑器可以使用 Markdown 这里仅仅列举部分我个人体验过的 Windows Typora（好用且免费） Mac OS Ulysses （文字工作者最爱，不仅仅是编辑器且贵） MWeb （国产，完成度高，支持多平台分享，如印象笔记和 WordPress） Typora （好用且免费） iOS MWeb （同 Mac OS） Bear（免费有内购，不只是编辑器） 锤子便签（免费，易用，全平台） Android 锤子便签（免费，易用，全平台） Chrome 插件 Markdown Here（神器，免费，可以配合印象笔记使用） 国内写作平台 简书 笔记类应用 为知笔记（自身支持） 有道云笔记（自身支持） 印象笔记（因为印象本身的设计机制（支持全文及图片内文字搜索) 和附件（图片等）存储机制，并不支持，但是原生的各种快捷键已经足够强大。如果你想使用的话，配合马克飞象、Markdown Here 或者 MWeb 使用，效果都很好） 如何学习 Markdown 一旦你清楚了自己要不要使用 Markdown，那么学习它的用法根本就没有什么难度。 这里推荐一个网站：Markdown 语法说明 记住，如果你决定开始用一个东西，你还会担心学不会么？ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-02-04-trymarkdown/"},{"title":"关于考研复试你该了解的","content":" 对于通过初试的 16 考研人而言，从三月中旬开始就要陆续到报考院校参加复试。 最近有很多人问我研究生考试复试时有哪些注意事项，这里做一些提示。 复试前 和复试内容无关的部分 我们相（jia）信（ding）绝大多数院校的复试招生工作都是公平公正的，但这也不意味着你可以等复试那天到了直接去复试就可以。 如果你是理工科类的考生，条件允许的话，你可以提前联系自己中意的老师，看看是否可以过去实习或者完成毕业设计。 如果在实习过程中表现良好进而得到老师的认可，那你复试时通过的可能性无形会增加（对于导师在复试中没什么发言权的学校这一点不成立，对于有众多老师面试且绝对公平的学校这一点不成立）。 如果你没有时间实习，最好提前联系报考院校的师兄师姐，首先弄清复试内容；最好找到感兴趣导师的学生，弄清具体的招生情况以及老师有没有特殊要求，比如是不是只招男生或者女生，今年究竟有没有招生名额等。 如果你找不到上述的师兄师姐，也应该尝试给感兴趣的老师发一发邮件，说明自己想要向其学习的心意以及自己的一些基本情况。虽然这么做不一定有什么用，万一呢。 和复试内容有关的部分 知道了复试内容之后就需要针对复试内容做一些准备，无非就是基础的专业课知识，英语听力和口语的考察。 这里说明一点，很多人恐慌复试过程中的英语部分，这一部分确实很难在短时间内有所提高，但是其所占比例一般也就是 30%左右，不要太过担心。常见的英语听力考察也就是六级难度，而面试多数就是问几个简单的英语问题，老师也没指望你说的多溜多全面，就是大概了解一下你的口语水平。 复试中 笔试 如果有笔试内容，按照考试要求复习，安心答题就好。 面试 至于面试，我想大家长这么大多多少少都参加过几场面试，比如高校里的学生组织，社会中的志愿者，或者企业的实习等等。无非就是在衣着，表达等方面需要注意。 我本人曾在大学期间还算活跃，参加过很多面试，也担任过很多活动的面试官。还是学校语言艺术协会的会长，曾经给学生会的成员也做过一些语言表达和面试方面内容的培训，但是那些方法和技巧放到考研复试中来其实都没有多大必要。 关于着装 你只需要衣着干净得体，那什么叫衣着干净得体呢？我相信大多数人日常的衣着都是干净且得体的。男生不会穿裙子，女生不会露肚脐露后背（现在这么穿也冷啊），大家出门上街都不会穿睡衣。 如果非要给一个建议，就是穿你最正常最普通的衣服就可以了，西服这类正装可以穿但也不是必须，学生有个学生样就好（某些专业或者学校有特殊要求除外）。 穿着的最理想状态就是你进去以后，让老师不在意你穿了什么而是集中于你的回答和表现本身。 关于表达 希望你克服最要命的紧张，说话声音尽量不要抖，放慢自己的语速，再克服哼哼啊啊的口头禅就好好。 如果你的谈吐能表现自己的风格，比如严谨或者幽默，那最好；如果不能就别想太多所谓的技巧反而弄巧成拙，老老实实回答老师的提问，说出你自己的见解。 一般情况下，老师不会难为你，他们会看你的简历或者顺着你的回答往你擅长的方面引导；如果有老师咄咄逼人的连续发问，很可能是压力测试的一种，想看看你面对这种环境下的应变能力，不用害怕，不知道也不用瞎说。 另外，还有一种情况需要注意，有人在紧张的情况下，会不由自主的多说，根本停不下来。在面试的过程中，也要克制自己的回答欲望，不要抢话，学会倾听，能用 3 句话说清楚的内容就别变成 5 句，老师时间宝贵，后面还有人等着。看到老师已经给你一些反馈，比如点头或者微笑，就可以适可而止。 复试后 以上是在复试前和复试中需要注意的一些问题，复试后耐心等待录取通知书就好。 最后，祝各位复试成功 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-31-kaoyanfushi/"},{"title":"非功利性英语学习工具推荐_iOS 版","content":"一年前（2016 年 2 月），我曾经在简书发表过一篇文章 《如何用英语打开一扇门 ——我的非功利英语学习法》，里面比较详细又浅显地介绍了我对英语学习的一些理解，并介绍了一些所谓的“非功利性”英语学习工具。 非功利的英语学习是指你暂时没有要应对某一具体英语考试的需求，仅是希望利用一些业余（零碎）时间学习英语。 这里的“非功利”并不等同于“无目的”，如果做一件事情没有目的就很难有做下去的动力。所以你不要说自己是为了学英语而学英语。 这种非功利的英语学习，其最大的目的就是给自己打开一扇门，可以去看看外面的世界，而这种目的是长期的也是有巨大吸引力的。 文章发布之后，获得了不少英语学习爱好者的喜欢和评论。 当时写文章的时候用的是 Android 系统手机，所以介绍的工具都是基于 Android 系统来的。现在接近一年时间过去了，自己日常主力机也从 Android 变成了** iOS 系统；另外自己日常的英语学习工具也经历了精简和升级**。所以，趁着过年休假再简单写些东西，给大家介绍几个目前我的手机和 iPad 里日常用到的英语学习工具。欢迎交流。 需要说明的是，下文内容全部针对最新版本的 iOS 系统展开，如果你是 Android 阵营，看完这篇文章之后可以移步 《如何用英语打开一扇门 ——我的非功利英语学习法》 进行对比。 上图显示的就是我目前常用的 9 个英语学习相关的 APP，最常用的词典类工具 欧路词典 并没有放在里面，主要是因为那样一页就放不下了，也从侧面说明把它单独拿出来对我有多么重要。 下面选择几个进行重点介绍。 HSW HSW 是 howstuffworks.com 网站的官方 iOS 版本 APP，通过这个网站的名字，你就应该猜到它绝对是你学习英语并且增长见识的不二选择。HSW 提供的并不是时事新闻，但是它推送给你的内容又会结合当前的热点。 当你进入 APP 后，你可以通过点击最下面的 Topics 来了解最新的话题，另外你还可以选择自己感兴趣的话题类别减少自己的阅读压力。 除此之外，你还可以选择 Quizzes 进入闯关模式，不同于 Topics 的阅读模式，在这里你可以测试自己是不是真的“知道的太多了”，非常有趣。遇到好的文章，你还可以选择在 HSW 中进行稍后读，或者同步到自己的稍后图应用。 SmartNews 如果只要一个新闻类 APP，我觉得有 **SmartNews **就足够了。SmartNews 是新闻聚合类应用，就新闻来源而言，你能叫出名字的各种类型媒体基本上都有收录；就阅读体验而言，可以提供 Web 和 Smartview 两种阅读模式。 强烈推荐大家使用 Smartview 模式，它类似于 Safari 的阅读模式，可以为你排除其它干扰，专注于阅读。另外，很多文章当用 Web 加载很慢时，使用 Smartview 模式基本秒开。 顺便提一句，使用 SmartNews 本身不需要特殊的上网环境，但是不排除当你看部分特殊的新闻源时会遇到困难。 得益于 iOS 优秀的操作系统和内置词典，在这个 APP 中，你查单词也是异常得简单。当你在任何一篇文章中看到生词时，只需要长摁选中这个单词，选择** Look Up 就可以直接调用 iOS 内置的牛津英汉汉英词典或者 New Oxford American Dictionary** 进行学习，一气呵成非常流畅。 如下图所示。 News Digest 雅虎出品的这个新闻阅读应用已经多次被我推荐了，推荐的理由只有两个：好看和好读。 好看是说整体的设计风格，而好读则是指它每天只会在早晚推送两次，共计 20 篇左右的文章。 这个 APP 有两个看似不起眼的小功能深得我心，你可以感受一下什么叫做用心地做一个 APP，真正地考虑用户体验。 当你读完了当天的一次推送时，会有一个赏心悦目的动画告诉你完成了阅读任务，但是这还不够，它还会给你一个**“每日一句”**彩蛋，如果没有读完你是看不到的这些的。 如果你想知道自己近一段时间是不是偷懒，这个应用还默默地记录了你的阅读情况。当你看完某次“每日一句”后，就可以继续查看自己的阅读记录了，效果如下图所示。 看着一片空心圆是不是感觉被打脸？ 这里需要强调一下，和 Android 系统不同，iOS 版本不允许在阅读界面直接选词进行查询等操作，也不允许你直接把自己喜欢的文章发送到 Pocket 或者 Instapaper 这类稍后读应用。但是根据我的个人经验，你可以选择通过邮件分享的方式，放松到自己的 Instapaper 邮箱（Pocket 邮箱似乎不能正确识别），然后在 Instapaper 中进行各种高亮、备注以及查词。对了，不晓得你知不知道，Instapaper 所有高级功能在早些时候已经全部免费啦。 wikiHow 你可以把 wikiHow 理解为接地气版本的 HSW，这里面你可以看到各种各样的奇葩（英文）教程，比如如何在演讲时不紧张，如何和另一半正确的 kiss，如何让自己的猫咪多吃点东西。 真的是无所不有，谁用谁知道啊。 这个 APP 还给你提供了另两个小功能。 如果你觉得某个问题下的某个建议正中你的下怀，你只需要轻轻划一下屏幕，就会带来一种“恩，深得我心，朕已阅”的小乐趣；在文章的最后还会贴心地给你提供各种 tips 和 lists。 Newsela 这一款阅读类应用有两个最大的特点让我爱不释手。 阅读难度选择 自动配套习题 也正是因为这两个特点，让它有了那么一点点“功利”的意思。非常适合正在准备各种考试的朋友。 首先，你可以根据自己考试的难度来选择每一篇文章的单词数。 然后，你还可以在读完一篇文章之后捎带做几道阅读理解题，当然，你也可以先看题目，然后带着问题再去快速阅读。 怎么样，是不是想起了自己做阅读理解的日子（三长一短选最段，三短一长选最长，实在不会就选 C）？ TED、朗易思听、Dictionary、Vocab.com 这四个 APP 因为非常容易上手或者我已经在 《如何用英语打开一扇门 ——我的非功利英语学习法》 进行了比较详细地介绍（iOS 端和 Android 端基本没有区别），就不再重写一遍了。 其中，TED 和朗易思听对大家提高听力和口语能力会有帮助，而 Dictionary 和 ** Vocab.com** 绝对是你学习单词（注意不是机械背诵单词）的大杀器。 iOS 系统中的欧路词典 看过我之前文章的朋友应该知道，我绝对是“欧路词典”的死忠粉。其实市面上目前支持自导入词典的 APP 有很多，但是这一款绝对是我在桌面端和移动端用的最顺手的，不过，也可能是因为我都买了高级版，舍不得换吧（笑中带泪。gif）。 其在最新版本 iOS 的表现也没有让人失望，目前已经支持了在 Spotlight 中直接查词，效果是这样子的。 另外，当你在使用** SmartNews** 一类支持取词的 APP 时，如果觉得系统自带词典不能满足需求，欧路词典也给你提功了一个非常便捷的选择。 你可以直接长摁想要查询的单词，然后选择** Share**。 随后在分享界面中，选择**“欧路词典”** 就可以立刻看到类似于下图的解释页面，如果你觉得重要还可以收藏。看完之后只要再点击“完成”，就可以继续愉快地读新闻咯。 这篇介绍我自己 iOS 系统中常用非功利性英语学习工具的文章就写到这里。 欢迎各位英语学习爱好者一起交流。 以上。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-30-EnglishToolsios/"},{"title":"致考研人 20：我过去的 2015","content":"写在前面 写下这篇文章的标题时，我知道 2015 年的事情该告一段落，2016 年的奋斗又要开始了；当我看着正在整理的第三版《靠谱学长说》时，我告诉自己这篇文章别写太长。 因为回忆这个东西，你只需要留个线头露在外面，没必要偏得给它织件毛衣。以后自己再翻看这篇文章的时候能想起自己这一年大概都经历了什么，足够。 这篇文章是“致 16 考研人”系列的最后一篇，但也可能是你看到的第一篇。如果说这一年来笔耕不辍的意义在哪里，我不在乎它究竟帮助了别人多少（因为这要看机缘巧合）， 更重要的是我比以往更能看清自己。如果说这一年来和考研人分享点点滴滴的意义在哪里，我想是感受到了彼此信任的力量，这种彼此间信任最大的好处是可以让人更加自信， 咦，我也是这么想的，他能做到那我没理由不可以啊。虽然很多人说因为我他们或多或少地发生了一些改变，但是我一直以为这与我无关。如果一定要扯上一点儿关系，最多就是我说出了一些他们本来想说的话，而之后他们顺势做出了一些本来就想改变的改变。 记住，没有人能改变你，只有你可以改变你自己。 谨以此文，送给过去的 2015，也希望你可以借此机会梳理一下 2015 年的自己。 经验分享的开端 2015 年 1 月，考完试的我百无聊赖又有点儿着急。看着墙角那一摞复习资料和参考书总觉得自己必须要留下些什么来纪念 2014 年，纪念一下复习的日子，于是就有了《我过去一年的考研之路（综述篇）》。 当然，那会这篇文章写的粗糙且着急，写的时候没想着写完能怎么样，也没想着这一写就写了一年，更没想着这一写就是一个系列，这一写就整出了一个近 200 000 字的合集，自己还对着电脑整理到了第三版。（当然，如你现在看到的，我又把第四版放到了自己的博客上） 那篇文章（也就是《致考研人 1》）写完之后最先贴在了一个考研相关的论坛上，就在刚刚我又去看了一眼，遗憾的是已经忘了论坛注册的名字和密码，不过那篇帖子（在我没有太多回复的情况下）已经有了 85 页的评论。 不过后面的事情说来也怪，此篇文章之后的其他文章就从未再通过审核了，再加上论坛版面满满的广告，挣扎了几次遂放弃。 作为一个“扯淡”技能五颗星的人，写完第一篇我发现自己有些地方没写清楚，于是就有了第二篇。写完第二篇有研友问了一个关于如何使用手机的问题，我觉得很好，于是就他的提问写完了第三篇。 事不过三，当我写完三篇之后感觉事情并没有按自己预想的展开，越来越多的考研人给我评论交流，新浪微博的关注人数也一点点增加。重点是，还有人表示会持续关注期待后续。那个时候我感觉这个事停不下来了，琢磨着你敢持续关注我就敢持续写呗。于是，微博和微信公众账号就这么慢慢地开始了……写到今天，其实我一年来发的微博总数不到 1300 条，在唠叨的背后更多是克制。 提前实习的日子 时间来到 2015 年 3 月 10 日，正在学校神游的我突然收到一封邮件，大概的意思是告知我通过初试又免复试。 那一刻我觉得，嗯，该来的总会来。 和身边的同学以及家里人分享了这个消息之后，我就做好了提前去实习的打算。因为听前辈说就算去了那边也是竞争激烈，那个地方名牌大学的牛人多得是，厉害的大老板又没有那么多，如果想找个不错的老板必须要提前去实习。但从我自身角度而言，其实是因为自己小白，怕九月开学直接去会丢人，不得不提前学习。事实证明之后实习的两个月虽然个人没长什么本事，但还是提前体会了中科院的科研生活，完成了本科的毕业论文。 在这里我需要给看文章的你强调一点，中科院（至少我所在的上海分院）和其它高校的培养制度不同，这边是 PI（Principal Investigator）制，没有教授这种说法；学生和 PI 之间双向选择。说的具体一点就是研究生入学的第一学期每个人至少会有两轮轮转的机会。所谓轮转就是去你感兴趣的实验室学习，老板看你适不适合实验室，你也看自己对其研究的内容是不是感兴趣，所有的轮转结束之后如果你想留下实验室的老板也愿意要你，那你就可以定组了。因为有这样的轮转制度，我实习时候的压力不大，相当于是为自己多争取了一次轮转的机会。 但对于大多数考生来说，这个时间段的实习（如果你打算过完年到复试之前这段时间去实习的话）其实非常关键，如果你能找到心仪的老师并且获得老师的认可，那你复试通过的可能性无疑会增大很多。当然，事情都不是绝对的，有些高校研究生复试最终拿主意的不是那些教授而是招生办的老师。 两个月的实习生活，我逐渐适应了食堂的饭菜。 毕业季那点事 完成毕业论文之后，大概五月份中旬我就回到了学校准备毕业，说是准备毕业其实就是吃饭睡觉打牌出去浪，浪里个浪（你们可能五月六月也会是这样的状态，好好珍惜，这是你的最后一个长假）。这段日子回忆很多但是写不出来，姑且放几张图。对了，就在这段时间我收到了录取通知书。 实验狗&amp;程序猿之路 2015 年 7 月底，我回家没过多久又坐上开往上海的火车。坐在哐当哐当的火车上，我想起了小时候开运动会广播员播报运动员入场的声音：“看，现在，向你迎面走来的，是你五年的硕博连读生活！” 高考前我们以为考上大学就解放了，然而并没有，考研复习的时候，你是不是想过考完你就解放了，我可以告诉你，并没有。我爷爷都 80 多岁了，现在记性也不太好还每天坚持上街溜达。生活，除非你进到那个小盒子里，否则都停不下来，身体和思想总要有一个在路上。 从 2015 年 8 月到 2016 年 1 月，我这五个月的主旋律就是学习。在课堂里学，在图书馆学，在实验室学，在休息室学，在宿舍学。学实验技能，学编程语言，学如何和他人相处，学如何面对异地恋。 很多人都好奇研究生的生活究竟是什么样子，想听听我的体会。说实话，这不到半年的时间我还真顾上体会，应该说没什么时间可以让人体会，这一天天过得太快了。不过，用家里人的话说是“你们这天天加班这么晚也不给钱”；用不读研同学的话说就是“天天上学不仅不要学费还给这么多补助”。那我究竟过着怎么样的日子呢？ 这里又要给读文章的你强调一点。我们的祖国现在研究生很多，有各种各样的研究生，各种各样的专业，各种各样心态。把范围放大一点儿说，现实中每个人的生活都是不同的，那自然每个研究生的生活也不可能相同。 从这个层面来讲，我过着怎么样的生活都和你无关，最多只能满足一下你的好奇；从这个层面来讲，我所说的，于你都是错的，你姑且全当满足一下自己的好奇。日子，都是自己过出来的。 我大致描述一下自己过去半年和今后五年很可能的生活。 早晨不晚于 8 点半到实验室，晚上不早于 10 点半回宿舍，每周休息不过 1 天，每年假期原则上 3 周。一年级大部分时间都在上课，但是也符合以上所有的时间点。大部分时间是程序猿，对着两个硕大的电脑屏幕在键盘上敲来敲去；小部分时间是实验狗，围着各种各样的试验器材和模式植物转来转去。 无聊么？你很可能觉得无聊。 有意思么？我觉得还挺有意思。 我感觉做研究和打英雄联盟是一个流程，这五年不过就是打一盘长时间高强度的英雄联盟人机对战。 在确定自己的研究方向之后就等于选好了自己的英雄，轮转结束之后定课题组就等于选好了自己的队友。实验室的师兄师姐就是混迹多年的老手，而自己是新人求带。良好的实验室氛围能让你在对战的时候尽量少受队友的嘲讽。导师会给你匹配对手（课题），你可以预判但是很难确切地知道对手的级数（解决科学问题的难度）。 进入游戏之后你的英雄会自带一些招数，但这些远远不够。和强大的对手刚正面之前（也就是解决核心的科学问题之前），你必须不断打野或者打小兵（也就是学习各种各样的实验技能）。光学习实验技能还不够，你还有必要学习一下攻防战术，在这个过程中多看几场比赛直播（参与几个小课题锻炼合作自己能力）也是很重要的。在这个漫长的过程中，你必须要让自己不断地升级攒大招，不断地买更牛的装备。 当然，打游戏免不了要死几回一样，实验上也难免会碰上各种各样棘手的障碍。个人能力达到一定程度之后就可以开始推防御塔了，对方每个的防御塔都是你的一个挑战，在科学研究中它可能是你的某个关键实验或者你一个重要的过渡课题。每推掉一个防御塔，你就和对手的水晶更近了一步。如果你通过自己的努力最终解决了未知的科学问题，或者更幸运地发了大 paper，那就意味着这局游戏你胜利了。 流程类似，可做研究和打游戏又绝不一样。游戏输了可以再来一局，做研究五年没什么结果就很难让你再来另一个五年；游戏里打野和练级其实就是为了一局比赛的胜利，而做研究这几年你所学的技能和知识以及你所培养出的严谨逻辑都将会使你受益终生。 如果在你面前有几条路可以选择，难走的那条路反而可能走得更远。做研究，好奇心和求知欲是一个人可以笃定前行的不竭动力。其实何止是做研究呢。 从时间的线索来讲，就是上面这些了。但是还有几件事情不得不单独拿出来记录一下。 很荣幸能从一千两百多人中被选中成为锤子科技 2015 夏季新品发布会的志愿者，通过自己的努力让现场 8000 多人那一天的生活更美好了一点； 微信公众账号（ibear_share）开通几个月，靠自己傻写和大家的不取关被邀请开通“原创功能”； 微博用不到 1300 条微博和大家的不取关，做到了 9200 多个关注； 文章合集《靠谱学长说》更新了三版，不管有多少人看，反正自己是爽到了； 尝试组织了三期靠谱团队，到现在大家依旧会时不时聊聊，看着他们一点点进步，开心； 选择生物信息学作为自己今后的研究方向，开心，总能学到新的东西。 2016 年，走起。 靠谱学长：一只思考问题的熊 2016 年 2 月 5 日 于家中 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-26-tokyr20/"},{"title":"致考研人 19：关于调剂","content":"写在前面 关于调剂和二战方面的问题，说实话我个人没有经验可谈，本打算保持安静的。因为你没经历过的事情有什么资格指指点点呢？ 但是自 16 考研人考试结束之后，就总有人会问什么时候说说调剂和二战。关于调剂的问题，我身边有人经历过而且我也关注过一些，于是就有了这篇文章；关于二战，我身边二战的同学并不多，如果大家很想了解的话建议不妨咨询一下身边有二战经历的师兄师姐，我就不再专门就二战的问题胡扯了。 这篇文章是我邀请一位靠谱并且有成功调剂经历的师姐所写，她报考一所 985 高校差几分，但顺利调剂到了另一所 985。只是前者在北京后者不再北京。 就大家比较关心的问题，我向她进行了咨询。出于对原作者的尊重，我并未进行删改，只是把一点点自己的观点加在了文章的括号中。 何时开始准备调剂 一定不要等到调剂系统开放之后。查完成绩后，按照往年国家线及各个学校的分数线，就能够知道自己能否进入目标院校的复试。若是以下两种情况便要考虑调剂。 各科均能过国家线，但不够目标院校分数线。 报考一区院校，但分数只够上二区学校（何为一区、二区请自己解决）。 对于第一种情况，只要你过了国家线，就代表一定有学上（只是看你想不想，其实每年多会有一些学校招不满学生）。到了调剂这一步，就代表你要对自己进行正确地估计，不要好高骛远，失去最后一次机会。 调剂最容易成功的情况 首先，根据自己的分数，看能否在报考院校内部进行校内调剂，主要是针对总分较理想，某一科没过线或各科均过线但总分或排名不高的学生，可以向该校研究生院咨询，看其他专业是否有名额。当确定无法校内调剂，比如报考的是 985、211 生源很好的学校时，就要进行校外调剂了。 若你的本科院校是 211 或某些专业是重点学科，你又不排斥回本校的话，就及时与自己本科院校专业的老师联系，只要有空缺，调剂回本校成功的可能很大。 调剂前的准备工作 从出成绩后就应该积极主动关注这些可能的院校研究生院及对应专业学院的通知，收集好该校往年接受调剂人数、录取分数、复试时间、复试科目等比较重要的信息。最好准备 3 个左右调剂学校的信息。 在出国家分数线之前，可以先给一些老师发发邮件。这里需要注意一点，最好可以问你想联系的老师前几届的学生要到老师经常会用的邮箱，我当时是从学校网站上找的邮箱，发了好几个没回复，后来才知道老师根本就不用那个邮箱。 如果他直接说没有名额就是你希望不大，但大多数都会回复的比较模棱两可或者根本不回复，因为老师根本不认识你，你也邮件也可能被拦截，但还是要试试，有些老师就很喜欢主动地学生。 一定要和该校上届考过去的学长学姐保持联系，他们会对你整个过程有所帮助，会告诉你很多有用的信息。同时，也要关注你的第一志愿院校，成绩过线就一定要去试试，万一过了呢。 利于调剂的几个方面 本科院校的老师可能会有你想调剂院校相关调剂信息，不妨可以让自己的本科老师帮你联系一下，或者给你写推荐信之类，往往会有事半功倍的效果。 联系你第一志愿报考院校的招办，有助于校内调剂。另外，一些科研院所很可能给你推荐一些今年生源不太好的兄弟院所，你可以提前去与一些老师接触，很可能就会调剂成功。 不要忘了和那些一起考研的小伙伴多交流，不要认为自己成绩不理想就难为情，他们会给你鼓励，也会给你出出主意，通过复试的还可以给你传授一些面试经验。 调剂进行时（重要） 在国家分数线公布后就可以及时与调剂院校招生办联系，询问调剂名额，这时候成绩越高，本科院校越好的学生往往会很受欢迎，有些会直接要求你寄过去相关资料等。但是大多数只会告诉你是否有缺额而已。 在调剂系统开放后尽早报名，一次可以同时添加 4 条调剂信息，在 48 小时内不能修改供报考院校查看，期间会有老师通知你面试的时间，48 小时之后如果没有消息就一定要自己打电话给招办确认报考院校是否有看到你的信息，若未能进入复试就要及时更改志愿继续等待调剂。越往后可供选择的院校就越少。 若能够进入复试，应该根据往年复试的要求提早准备。在时间不冲突的情况下，可以接受多个院校的复试通知，但若通过最早复试的院校之后，在 24 小时之内必须确定拟录取，否则将取消资格。在确定拟录取后就不能参加其他院校的复试了。若第一个参加复试失败，仍可继续参加其他学校复试。 调剂的过程是非常折磨人的，尤其是在多个院校之间奔波，你需要耗费大量的精力和财力，所以要争取尽早调剂成功。 调剂之后 选择考研，就有失败的风险，调剂也一样。有些人很幸运，但不是所有人都幸运。 就算失败，但起码你尽力了，心里上的压力要慢慢缓过来，重新审视自己，不管选择二战或是工作，记得要给自己最无悔的决定。 成功了，或许也会有失落，人总是不知满足，会与那些一步到位的同学进行比较。其实，你比别人多跨过了一道坎，你要相信一切都是最好的安排。 *加油。 2016 年 1 月 23 日 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-26-tokyr19/"},{"title":"致考研人 18：写在考研结束后","content":"写在前面 虽然明天我就有一门期末考试，还是没忍住陪了大伙两天。看到不少&quot;名师&quot;已经在为明年打广告，这是现实，而我却还是想和你说点什么。这篇小文送给你和你身边的研友，今后我们继续一起靠谱。加油。我去复习了，让我静静。以下为正文。 正文 恭喜，当看到这篇小文的时候，你刚刚结束了两天的奋战，不知道此刻你是怎样一种心情。也许你感觉自己答得如鱼得水，也许你感觉自己答得一塌糊涂，也许你感觉自己要来年再战，也许你感觉自己要开始写复习心得了。 不管怎样，从今天开始你的考研之路就正式的画上了一个逗号，是的，逗号。 你可以稍作休整，但这件事还远没结束，最后你会给它画上一个句号、感叹号还是省略号要看你的造化。不过，你终究还是没有半途而废，还是走进了考场，还是坚持经历了四场考试的洗礼，还是顺利走出考场，可以用“哥（姐）也是过来人”的心态来读这篇文章，终究有机会和别人聊聊你复习的感受。所以，值得恭喜。 还记得去年考完最后一门专业课走出考场，我曾试图冷静地分析一下自己考的如何，一方面感觉自己有一门专业课答得不好，可能考不上；另一方面对另外三门都比较满意，感觉应该没问题。那时我有感受到在复习过程中从未有过的无力感，感觉自己能不能行就看专业课老师如何给分了。 当我认识到后面会怎么样很大程度上并非自己所能把握时，就做了一个非常理智的决定——出去好好犒劳一下自己的胃。对了，那天我还收到女盆友送的新手机，这绝对是我考研周期里最难忘最开心的一件事。 此刻，于你而言，考研这件事也已经完成了所有复试之前自己能做的事情，至于分数和结果很大程度上不是你能控制，尽管我依旧认为努力的人运气一般不会太差。 当自己坚持了很久的一件事或者很看重的一件事结束时一般人都陷入一定程度的感伤、感慨以及短暂的空虚和迷茫，我更喜欢把这种状态称之为“矫情”。结束“矫情”之后，不知道接下来几天你打算怎么度过，我想无非是“要再嗨三天三夜”或者“要再睡三天三夜”。 我的建议 我根据自己去年的经历和感受，给你一些建议供参考。 可以放松不可以放纵 作为一个考研汪，过去的几个月甚至一年的时间你都看着别人潇洒自在吃香喝辣，自己天天食堂教室两点一线，那一颗火热的心可能早已经按捺不住，终于可以释放。我也建议你好好放松一下，比如 KTV 吼一吼、篮球场打打球、万达银座疯狂购或者火锅大餐可劲吃。 但放松可以，不可以放纵。唱歌别唱到说不出话，打球别伤了自己，购物别只能吃土，喝酒别狂喝到吐。大家都是成年人，该有的分寸自己把握。毕竟，你不才刚画了一个逗号，得瑟啥。 感谢身边的人 也许你觉得自己复习实在不易，但也应该想到，那些在你备考过程中默默陪伴你支持你的人同样不容易。比如你的父母，比如你的男（女）盆友，比如你的研友。有机会的话，多陪陪他们，向他们表达你的感谢，尤其是你的父母，以后可能陪他们的时间会越来越少。好好珍惜这段还可以陪他们的日子。 整理相关复习资料 虽然初试结束，但是后面还有很多事情要做，比如复试。找时间和已经考上的师兄师姐聊一聊，问问他们关于报考学校复试的情况，整理一下自己的专业课复习资料，按照以往复试的要求准备一下你的专业课复试，当然还有口语听力等等可能复试中会涉及到的内容。 另外，如果很明显地感觉到自己考的不理想，更要整理好自己的复习资料。你有多种选择，当然也就不排除二战的可能性，这些资料以后都用的到。 了解报考学校的导师或者调剂院校 初试过后，复试或者调剂依旧是一场没有硝烟的战争。那个时候，拼的就不仅仅是你背了多少个单词或者会做几道数学题，更重要的是对相关信息的了解。比如你想报哪个老师，这个老师今年招不招生，那个老师对学生有什么特殊的要求。如果真的有自己中意的老师又感觉自己通过初试的可能性比较大，不妨通过邮件的方式联系一下，简单介绍自己的情况。如果能联系到那里的师兄师姐，也可以让他们帮忙做一个引荐，有机会可以和老师亲自面谈。 如果感觉自己的成绩可能会面临调剂，那你更需要提早了解一些退而求其次的院校和老师信息。关于调剂的问题，如之前预告，过一段时间会专门再写一个小文来讲。 如果足够自信且有时间有想法请联系我 我是从去年考研结束之后开始整理自己过去一年复习心得的。去年一月份虽然还没出成绩但是基本有把握可以通过初试，于是就开始慢慢写考研复习的系列文章，好在最后确实免复试录取到中科院没有打脸。 今年考研复习后期，我逐渐关注了一些 16 考研人，他们在考研复习的过程中已经开始和大家分享自己的复习心得，这种做法我虽不提倡但也不反对，只要你觉得自己应付的来就可以。 现在考试已经结束，如果你对自己有信心且有时间有想法的话，我鼓励你总结一下自己的复习之路，暂且不提对别人有没有帮助，也算是对自己过去的一个总结。我现在有时间还会时不时翻翻自己以前写的东西，虽然很多地方都略显幼稚但却实实在在地记录了自己的变化和成长。 如果你对自己有信心且有时间有想法的话，如果愿意，写好之后可以联系我。我会尽力帮你分享在微博或者微信公众平台，以期对后来人能有一点点帮助。如果联系我的考研人多，可以考虑把大家的文章整理成集，做成类似**《靠谱学长说》**的形式与后来的考研人分享。当然，如果你我意气相投，我也希望以后我们可以有机会一起做一些事情。 不管结果怎样，有了这样一段经历，你肯定会有收获和成长。 不管今后怎样，希望我们可以继续在靠谱的道路上越走越远。 最后，祝顺利通过初试，共勉！ 靠谱学长：一只思考问题的熊 2015 年 12 月 27 日晚 于中科院上海生科院 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-26-tokyr18/"},{"title":"致考研人17：考前提醒","content":"写在前面 本来计划最后五天每天发布一点考前提醒，一来是保持自己微博和微信的活跃度，二来是保持自己微博和微信的活跃度，三来是保持自己微博和微信的活跃度。我深感自己作为一个八千多粉丝的博主，每天刷微博煮鸡汤的频率过低，以至于除去早期的内容，这一年才发了不到一千条微博。 但考虑到去年考前十来天自己都处在断网状态，现在反而每天吊人胃口实在过意不去，干脆把能想到的考前提醒都写出来。你要是觉得不踏实，我不反对每天看一遍。 考前提醒之复习 英语 如果你看过我之前的文章或者听取了我的一些建议，目前为止你应该已经完成了所有真题，并且进行过两到三次的完整模拟。我建议你剩下几天回顾自己的真题阅读笔记，并整理阅读思路和解题思路。 作文方面，我在这里做一个不负责任的押题，今年考题应该还会在历年真题中找到似曾相识的原型。我建议你从真题中找出 8—10 个大小作文话题（去年考过的就别看了），每天过两个；另外要留意复习各种题材可用的例证，比如我去年准备的京剧例证虽然没有用到大作文中，但是最后还是巧妙地写进了小作文。 如果你没有看过我之前的文章，或者说到今天你还没有完整的做过一次三小时的模拟，没有写过一篇完成的作文。我建议你抽出一个下午的时间，做一套完整的题目，主要目的是看看自己体力能不能跟上。 政治 剩下几天回顾自己做过的各类模拟卷的选择错题，复习相关选择考点。 大题方面，以肖四等押题为主，除了记忆背诵外一定要亲自动手写，规范自己的答题语言。 大家都预测的重要考点要整理答题思路，一些大家眼中的次重点如果有时间的话，依照大纲解析能范本记忆要点，如果考试真的出现最起码可以将关键点写出来再适当补充。 专业课 专业课猜题真的挺重要，不是让你去花钱买所谓绝密卷。根据自己对课本和真题的整理，归纳历年重点，结合最近研究热点，你完全可以给自己出两套模拟试卷练练手。 考前提醒之衣食住行 衣 毕竟是冬天，务必做好保暖，但是不建议穿的太过臃肿。 考研的考场多半是初中或者高中教室，如果教室里面没有放外套的地方而且恰好座位又非常挤，那穿着厚重的外套答题可能会不太方便。 另外，因为每场考试要坐 3 个小时，在路上和教室里做好手脚的保暖工作十分必要。 食 吃的东西不用嘱咐太多，唯一建议的是从现在开始到考研结束最好规律饮食，不用大补，没吃过的吃不惯的留到考试后再尝试。考试前可以适当吃一点巧克力，但如果之前很少吃的话也不建议，确实有考试过程中流鼻血的现象发生。 住 如果你的宿舍离考点非常远，我想你和你的小伙伴已经提前订好了宾馆，但愿你定的地方正规而且靠谱。如果住考点附近宾馆的话，你考前一天的下午可能就会出发，带好最精华的复习资料就够了，真的不用背着一个大箱子拿着一个大书包去。另外，带好必须的生活洗漱用品。 行 如果你的宿舍离考点比较近，我想你也许会选择打车前往考点。我建议你考前一到两天最好和小伙伴提前订车，谈好接送的时间。如果有可能的话，提前走一趟计算好路上的用时，考试的时候一定不能迟到但也不要太早，在考场外冻着划不来。 出门前要检查一下该带的东西有没有带好，比如身份证和准考证。至于铅笔橡皮小刀，绝大部分考点都是提供的。如果不放心可以自己准备好，不让带进去放在门口就是了。 考前提醒之心态 我知道如果我在这里过分强调不要紧张，你反而可能会更紧张。 从现在开始，希望你逐渐把十分紧张中的八分转化为兴奋，留下二分紧张就够了。毕竟准备了这么久，有点紧张是正常的，不要过分担心。进入考场后，一旦写完名字做一小会题，你自然会投入进去，只要注意力集中在题目上也就顾不上紧张了。 要想调整好心态，最简单的方法就是规律生活规律作息，剩下的这几天每天保证 8—10 个小时复习时间足够，我相信有奇迹存在，但是不知道会落在哪个“倒霉蛋”头上。你可能会说自己睡不着，心里面很着急，最好用这几天尽快调整，如果考试那两天失眠就不太好了。 考前提醒之其他 建议这几天尤其是考试那两天尽量减少上网或者不要上网，踏踏实实过几天日子。我可以很负责地告诉你，从现在到考研结束，你接触的 90%的信息都是无效信息，剩下 10%的信息就算有效也只会在不同程度上分散你的注意力或者造成你情绪的不必要波动。 到目前为止你该知道的都知道了，该了解的信息也都了解了。如果你还指望着考前从别人的话语里给自己找点上考场的勇气，那我就词穷了。 另外，去年考政治那天早晨我有同学很早起床看某名师的微信账号押题，背了好久之后上考场，考完和我吐槽“丫说的都没考，这不是坑学生么”，但从某种程度上来说他也是找坑。你懂我什么意思么？名师可以早晨 7 点发一条微信预测三道考题，如果真考了一道那他可以拿出来说一年，如果没考呢？不说话就是了，明年继续。这种不亏本的事大家都愿意干，如果你选择在这上面押宝或者考前了还没有上考场的自信，那我就又词穷了。 最后 送给你我在《靠谱学长说》封面写过的一句话：我以为，做成一件事只需要三个条件，努力坚持，正确的方法，良好的心态，当然偶尔还需要一点点运气，但是能做到上述三点的人运气往往不会太差。 加油，16 考研人！ 等你们的好消息！ 靠谱学长：一只思考问题的熊 2015 年 12 月 21 日 于中科院上海生科院 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-26-tokyr17/"},{"title":"致考研人 16：剩下 20 天，Inner Peace","content":"写在前面 这篇小文无意于告诉你如何 20 天提高 50 分，而是想告诉你这 20 天如何过得踏实。 去年复习最后一个月我基本处于断网状态，如果现在你还能看到这篇小文，我希望你认真看的同时也尽量少受外界干扰。 正文 10 个月、7 个月、5 个月、100 天、50 天，这些数字里面可能就有你的考研复习时间。 现在我们不回忆之前的日子你如何度过，只希望你把剩下这 20 天过好。 我不晓得你在哪个时间点知道有这么一个自称靠谱学长的人，以至于现在有缘分通过微博或者微信看到这些文字。就我个人而言，去年大概不紧不慢地复习了十个月，所以我所有经验和体会都是从这十个月时间里得来；没有几战的体会也没有冲刺三个月考上的历史，所以不敢像有些人那样告诉你那些速成或者救急的秘籍。之所以敢自称靠谱，只是因为自己不会乱说，嗯，不会言之凿凿地乱说。 今晚做实验回来写这篇小文是因为最近听到太多这样的反馈。 “学长，我感觉自己好多都不会，看不完怎么办？” “学长，我觉得自己肯定考不上怎么办？” 到了最后这 20 天，不少人的问题已经不是如何复习而是还能不能复习了。 去年临考前一个多月，我看着桌子上摞得高高的专业课课本和各种参考书，也觉得自己不会的、没背下的东西太多，我也觉得自己考不上了。但是看看身边的小伙伴有不少人也觉得自己考不上，我就稍微踏实了一点（认真脸），因为如果大家都觉得考不上，那我还是有可能考上的咯。这里先把结果告诉你们，最后我们那个教室觉得自己可能考不上的人绝大多数都考上了，剩下的很小部分人也都有学上或者有了其他的出路。 有了这些问题，该如何克服？ 首先我默认你不是那种明明都会了还自认为什么都不会的人，其次我默认你也不是什么都不会的人，这样一来“有好多不会”就是一个既定事实。事实如此，你能改变的就只有看待问题的角度和面对事实的方法。 去年整理完专业课课本和历年真题后大概还有 30 多天时间，那时我发现自己有不少内容还没有理解，不少要背的题目都没有背下。我感觉自己的复习时间似乎不够了，不可能达到预期复习效果，一度慌张并且效率低下。 注意，这里我提到了“预期复习效果”，所谓“预期复习效果”无非就是“复习的很好，该理解的都理解，该记住的都记住”。你现在之所以烦躁不安无非就是发现自己实际复习效果无法达到预期，这种落差夹杂着自责和恐惧，你能想到就只有名落孙山的幽怨和来年再战的悲壮了。 我去年在面临这个情况时，很快地选择了“破罐子破摔”。心想还有几十天，反正也达不到预期复习效果，怎么办，那就算了吧。 放弃达到预期复习效果之后，我用半天时间认真整理了自己不理解与没记住的内容，又列了一个清单。我也不定什么 10 天规划或者 5 天规划了，就“目光短浅”“得过且过”地制定 1 天计划。 如何计划？很简单，既然没想着都会，能多会一个就多会一个得了。 早晨 6 点半到了教室，从那张单子里钩几个觉得重点的内容，开始理解开始背，解决一个划掉一个。晚上 10 点半一到，不管那张纸上划掉了 4 个还是划掉了 2 个，因为不会的又少了几个，我都觉得挺踏实。回宿舍之后再回忆一下今天解决的几个问题（确保真的解决了），然后想想明天还能搞定几个，便安然入睡。就这样，我感觉最后那几十天不知不觉就过去了，而且每天都很充实。 所以我建议，就算你发现自己不会的东西再多，也要尝试去把看似绝望的情况具体化缩小化变成一个一个问题。保证让自己每天只面对眼前的一个或几个题目。无论你花一个小时还是两个小时，只要把眼前的内容搞定你不会的就又少了一个。这种做法看起来消极并且没有远见，但是可以保证你在某个时间段里注意力相对集中而不至于心里装着一堆问题反而不知如何是好。 你不是觉得自己考不上么？其实谁都不敢说自己一定能考上，我只是希望你换个角度思考。既然感觉考不上那就争取每天增加一点自己考上的概率。你踏实地解决一个具体问题或者背一道重点题目都可能让你在考试里多得几分，进而可能让你最后增加一点考上的概率。 就这样一天一天过，别想别的（其实要是专注于眼前的具体内容也没时间想），也没有必要打消耗战，与其混乱地背 10 道题还不如认真地思考背上 5 道题。我想能亲眼见证自己每天不会的内容在减少，考上的概率在增加，足够让你睡个踏实觉。而这 20 天，能踏踏实实过去，减少不必要的情绪波动和身体损耗就是最好的状态。 说句实话，别指望最后 20 天发生翻天覆地的变化，我知道人在特殊状态下会激发特殊潜能，但长时间的复习惯性也会左右你的复习状态。 逐步调整自己的心态和状态，平稳度过考试并且不留遗憾地正常发挥就是胜利。 如果看到这里，你心里嘀咕：“不行啊，平稳地度过那就是考不上的节奏！”我建议你再从头读一遍这篇小文，如果又看一遍你还是嘀咕：“这肯定考不上啊！”哎，既然你已经固执地排除了自己考上的可能性，那可能就真考不上了，早干嘛去了。我只能说：“17 年 ，我还在……” 好在我相信，大多数人你们心里嘀咕“自己考不上”的同时也会有一个更大的声音在嘀咕“我应该差不多也能考上” 这就好办了，剩下 20 天你过得越踏实，这种“应该差不多也能考上”的信念就自然会越强。什么？如果你还想问怎么能过得踏实，那我建议你再从头读一遍这篇小文…… 写到这里，我脑海中不断浮现出《功夫熊猫 2》里师父（Master Shifu）的形象，他从一开始就不断向阿宝唠叨“Inner Peace” 我也不厌其烦地说三遍：Inner Peace、Inner Peace、Inner Peace I found inner peace and was able to harness the flow of the universe. 文章的最后，分享几点更具体的建议： 留着模拟用的英语真题不能再留着了。作文一定要动手仿写，去打印几张答题卡，感受一下行间距。 政治押题卷大家看什么你跟着看什么就行，不用标新立异。我去年用的肖四，5 道题压中 2 道就不错了，救命可以但是高分还得靠自己。仔细分析模拟题选择题的错题，通过一道错题反而大纲解析复习相关考点；仔细分析真题和模拟题大题的答题思路和语言。 如果感觉自己过了两遍课本两遍真题突然不知道该看什么了，那就给自己划重点出卷子。有时候你以为自己会，真的在固定时间落笔去写就不是那么回事了。 数学这类学科不要一味地再做新题，好好看自己的错题本，争取给错题归类并归纳方法。考了这么多年试你也知道，平时做错的题目类型在考场出现的概率蛮高，而且多数还是不太会做。 靠谱学长：一只思考问题的熊 2015 年 12 月 5 日夜 于中科院上海生科院 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-26-tokyr16/"},{"title":"致考研人 15：最后三个月该如何度过","content":"写在前面 本来想把标题写成《最后 97 天该如何度过》，但是具体到若干天的倒计时方法让人听起来略感残酷，还是改为三个月稍微温和一些。一开始没有写这篇小文的计划，想以两条微博代之。 ‌‌‌ 但微博发出后，有一些小伙伴在评论中对我提出了一些质疑和建议，认为问我还**“来不来得及”**的同学只是希望从我这里得到鼓励，如果我不说些好话他们就会消极复习，进而很可能考研失败…… 读到这类评论，我还真是“担心”有人会因为别人的一两句话而丧失考研复习的动力，所以赶紧抽 (ao) 空 (ye) 和大家聊聊这三个月大致可以怎么度过以及应该注意的一些问题。 以下所写的内容全部是基于我的经历和体会，也就意味着你依旧看不到“90 天轻松搞定考研”之类的内容，但是你这三个月可能遇到的大多数情况里面都会涉及。 在文章最后，我会给 9 月份才开始复习的同学提一点点纸上谈兵的建议。 心态 这三个月的时间对于即将迎来考试的你来说，最重要的也最难搞定的很可能就是心态问题。 印象中我最后三个月有一部分时间是在复杂的情况下度过的，这其中交织着亢奋、恐惧和偶尔的迷茫。 经历过若干次重要考试的我们，似乎对百天倒计时有一种极度的敏感，我现在还能回忆起中考百天时带领全班宣誓，高考百天时全校集会的震撼场景。到了考研这一百天倒计时，虽然没有太大的动静但是看着黑板上的倒计时突然变成两位数还是会让人有一种莫名的兴奋，这种兴奋既包含着即将解脱的暗爽也包含着“我要大干一场”的自我暗示所带来的肾上腺素异常分泌，以至于我每天起床的时间能从之前的 6 点 15 自动调整为 5 点 45，而且都不需要闹钟。 但人也是一个能量守恒的物种，正能量的急剧激发必然会导致负能量的潜在积累，进而影响你的心态。这种恐惧的负能量来自多个方面而且很难避免。 比如来自你自习教室前后左右的同学，你听到你前面的同学和他的同桌说那套政治模拟题他只错了四个选择，而他的同桌说自己做某一年的英语真题阅读就错了三个；比如来自你报考院校的消息，你听说你要报的那个学校那个专业只有几个统考名额，而你身边就有五六个人和你报了相同的专业，更可怕的是似乎他们都还复习的不错；再比如来自你的时间安排不合理，你前一天晚上信心满满地制定了今天的计划，可烦人的是已经晚上 9 点半了你竟然有一门课还没看，于是十点半你拿着书回到宿舍，不考研的哥们儿姐们儿正在聊天，你不看心里发慌看又看不进去。 除了亢奋和恐惧的交叉，迷茫也是会时不时光顾的。听到高中同学的实习工资已经有 6000，听到和你一起的小伙伴已经保研，有时候坐那会想自己究竟在干嘛，甚至会纠结为啥自己之前就没多用点功。迷茫，于是翻看数学做不下去又打开英语，接着读篇阅读读不下去干脆看看政治，最后政治多选题永远选不全，迷茫。 对于复习而言，你我都知道重要的是有一个平静的心态，可是很难静下来到底怎么办？ 我去年的做法是让复习时间安排的尽量紧凑，多动脑子多弄手，少比少问少打听。如果有人故意炫“优越感”，你就回敬：“你错四个已经不错了，这年的题确实不好做，我还错了三个。”即便你实际错了七个也不重要，大家这个时候都是图一乐呵，谁也别太当真，好好复习自己的就行了。 我们不能消除复杂心态的情况下要尽可能的缩短心态波动的时间，如果实在烦躁可以暂时做点自己拿手的东西，比如我就会做一篇英语阅读。有意识的投入会让你逐渐平静下来，之后再攻坚克难。 如果还是烦躁不淡定，干脆停下手头的工作出去走走运动一下，或者就是让各种复杂的情绪一起袭来集中释放，任其发展。这种破罐子破摔的方法会让你过一小会就自动意识到这样下去也并没有什么用，负能量释放了你也就自动又开始淡定地复习。 复习策略 克服恐惧的唯一方法就是行动，三个月的复习多少还是应该有一些方法。 以下是我当时的思考过程，供参考。 首先，到了这个阶段你应该清楚自己四门科目中哪些相对强哪些相对弱。在复习策略上你可以选择让强科更强、让弱科补强、所有科目齐头并进。我当时的原则是让弱科补强，于我而言，英语政治都还不错，专业课才是后期的大重点。于是最后三个月我在英语上花费的时间可以说已经很少了（当然这得益于我前面 6 个多月的积累），政治也只不过跟着王老师的课，晚上再做做练习题，白天的绝大部分时间都用来整理和消化两门专业课的课本内容和真题。 其次，你要学会分析自己每一科的弱项和强项。比如当时我考研英语的阅读部分感觉已经没问题，完型又提高不了太多，于是在本就有限的英语复习时间里主要都用来准备两篇作文。后期政治复习选择题基本达到了预期目标（每套模拟题的选择部分分数达到 40)，就需要花时间去重点整理各个专题，并学习答题思路和答题语言。 这一思路看起来很简单，但其实很多人是做不到的。因为人是一个会自动扬长避短趋利避害的物种，我们都喜欢做自己擅长的能给自己带来成就感的事情，尽量避免接触自己不擅长的东西。对于复习而言，直接体现就是花更多时间在你已经相对不错的内容上而有意回避自己真正的短板。 最后，还要时刻把握复习的方向。自己复习相对好的内容绝对不可以放下不碰，比如你自己英语阅读复习的好就干脆一周没有做过一篇阅读。这样下去，你一周之后会发现自己阅读其实根本复习的就不好。一定要隔一两天就做上两三篇保证做题的感觉。补短板固然重要，但是也有一部分人最后就是死在自以为最擅长的东西上。 在还有九个月的时候，我们要做的是学会怎么复习；在还有三个月的时候，我们要做的是知道什么重点复习什么捎带复习什么不复习。 时间剩下的越短，越考验你规划时间的能力。 注意事项 把握好追求最新信息资料和处理好已有信息资料的平衡 考研时间临近，你可能会听到越来越多的爆炸信息，看到越来越多的“高大上”复习资料。时刻留意考研院校的最新动向是对的，但是没必要刻意搜集，尤其是还能招几个人的问题，除非你还有再换学校和专业的勇气。如果只招一个人，为什么不可以是你？ 时刻留意最新的复习资料也是对的，但是不要见题就复印见题就做。这一情况在政治上尤为突出，今天这个押题王出了五套卷，明天那个专家压了二十题，后天网上又流传了一份“看完这个，毛中特满分”的资料。你说你看还是不看，做还是不做。我个人的建议是，找一本公认比较好销量最多的去重点研究，其他的看看题目用已有的知识体系找一找答题思路就可以。 不要有一种别人的资料永远是好的这种心态，关键是你怎么用好自己手里的东西。切记，不要把有限的时间投入到无限的找资料打印资料中去。 把握好强力复习和适度休息的平衡 这三个月的时间确实关键，在强力复习的同时你必须要学会逐步调整自己的状态和兴奋点。明白什么样的节奏是最呀最摇摆，什么样的复习才是最痛快，苍茫的天涯是我的爱……（但愿你没有和我一样唱起来） 我去年最后三个月每天的复习时间其实是逐步缩短的，我也碰到有同学复习到考试前突然病倒了。其实，这三个月你必须要找到一个属于自己复习和答题的节奏，不要时紧时松，也不要一味的加量。节奏对了，每天不会太累还能保持一个好的心情。 当还剩 30 天的时候，我感觉一个人的水平已经很难有极致的飞跃，重点是保证如何充分发挥自己的已有水平。这其中，后期的三到四次模拟考尤为重要，每个周五准备好四科题目，周六周日按照考试的作息和时间安排进行模考，晚上可以适当放松休息，下周一再对四科题目进行分析总结，适当调整一周的复习计划。 如果你想模拟更加真实的考试状态，甚至也不妨早上出门先去做半个小时公交模拟一下考试那天赶路的情景，而不是从宿舍悠闲地走到教室。这样三四次循环下来，到了考试的那个周末你应该会有一种相对好的考试状态。 把握好与研友交流和自我独立思考的平衡 如果你身边有考同一院校或者同一科目的研友，那么后期的交流是十分必要的。手里有的资料不要掖着藏着，决定最后成绩的不是你手里有什么而是复习的如何，只要你心诚，多数人还是愿意和你坦诚交流。 你们可以时不时地交流一下复习的感受，或者彼此又分析出了哪些可能的考试重点，或者去请教一些你一直搞不清的问题，或者去给对方讲讲他不理解的内容（如果你能给别人讲清楚，那就是真的理解了）。 另一方面，只要你和别人交流就会面临着别人比你复习的好或者你比别人复习的好这两种情况。把眼界放开阔一点，不是只有你们两个人考试，还是把重心放在复习本身上来，不要因为谁复习的好而影响了自己的节奏。不管你复习的好还是不好，不都要继续复习么。 九月开始复习的建议 如果九月开始复习，我相信你一定是经过了慎重的思考。 比如你报考的学校只要过线就行，比如你要考本校的研究生而且还是比较容易的专硕，比如…… 我身边的确是有一些同学九月开始复习然后顺利的考取本校研究生的。通过对他们的观察以及我自己复习的感受，可以给你一些建议。 英语 用一个月时间背单词，同时用两个月研究近十年的考研英语真题。最后一个月背一些作文的模板，再做几套模拟题。（我有同学就是这样英语考了四十多，够用了） 政治 其实政治大多数都是 9 月开始复习的，没什么问题。看大纲解析，或者直接背市面上的辅导书，比如风中劲草或者知识点提要之类的，再做肖八和肖四的模拟题，然后背模拟题的答案。（我有同学就是这样政治考了五十，够用了） 数学 数学算是专业课中的一门，我 9 月开始复习的同学多数是考数学农（比数三还简单一点儿的那种），看一遍课本认真做做课后习题，再做一下十来年的真题基本过线没有太大问题。 另一门专业课 我那些敢 9 月复习的同学，很大的原因之一就是专业课比较简单。考前两个多月背背课本重点，背背复习资料和历年真题的答案，过线基本不成问题。 靠谱学长：一只思考问题的熊 2015 年 9 月 20 日 于中科院上海生科院 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-26-tokyr15/"},{"title":"致考研人 14：政治复习的七问七答","content":"政治报不报班 **答：**我在政治复习的文章里写过，这里再简单说一下。 我想你问过的学姐学长肯定都告诉你政治是最好得分的，那么怎么高效率的复习就是一个很关键的问题。我去年没有报政治班，一是不想报一个视频班和人们挤在一起看大屏幕，二十不想浪费我的时间（固定时间坐在一个屋子里面听政治）。 但是政治涉及的科目和内容既多又杂，如果自己光恳书有时候又容易走神，似乎又需要一个人给你讲讲马原的那些原理，帮你串串史纲和毛中特的考点。于是我就发现了王一珉老师，政治复习的过程中听了他全部免费的考研基础强化和冲刺课程。 之所以跟着一个老师，也是出于效率的考虑。考研辅导机构政治多数是一个老师负责一门课程，每个人都觉的自己讲的内容重要。这么一来你跟着五个老师，在整个政治上投入的时间自然会无形增加（对这一问题，你也可以选择对这些课程有选择的听）。而跟着一个老师他能做到比较好的详略得当。 今年不知道王一珉老师还会不会继续按时出免费的课程，如果不出那我只好把去年藏的课程分享出来了。 对于这个问题我的建议是，没必要跟着辅导班那么多老师跑来跑去，跟着一个老师让他把该过的东西带你过一遍就可以了。 政治看谁的书 **答：**考研政治辅导有一个很明显的特点：老师多，老师里的名师也多，名师里面能压题的大师也多。对于这件事到底是什么情况我在这里先不解释，就说说用谁书的问题。 首先，以走穴讲课为主的老师的书没必要买，原因见我写的文章。 其次，没必要剑走偏锋。十个人里有八个人买 A 的书，你就觉的 B 好，就偏用 B 的书。不要这样，你乖乖用 A 的书就可以。至于原因不想解释了，想不通可以问我。 我把去年用过的书按照时间顺序再和大家交代一下。 《王一珉 2015 考研政治轻松学》： 书如其名，整本书读起来非常轻松。原因有二，一是书比较薄，只讲重点和基础，看起来没有压迫感；二是采用了一种类似于授课的方式来写这本书，整本书看起来更像是讲课稿和教案。讲课稿内容通俗易懂，教案里的逻辑图和知识架构完整简洁，若干个专题总结的也恰到好处。基于“轻松”这个原因，这本书尤其适用于你在零基础的情况和《2016 年全国硕士研究生入学统一考试思想政治理论考试大纲解析》没出版的情况下下入门使用。 《2015 年全国硕士研究生入学统一考试思想政治理论考试大纲解析》： 编这本书的人不是某个人而是教育部考试中心。它是最权威的一本政治复习参考书，当然在很多人看来也是最枯燥的。但你可以和市面上绝大多数同类别的那些知识点大集合的书进行一下比较其实它算是薄的，其它不少书就是对这本书的再排版，加空格，加颜色和加例题。这本书每年 9 月出版。 注意：以下提到的书就都是**肖老的《命题人》**书系了，去年我除了《知识点精讲精练》没有买（因为和大纲解析以及考研政治轻松学重复）其他的书都买了也都做了。这其中比较重点的几本是《知识点精讲精练》《命题人 1000 题》《肖 8》《时政》《肖 4》。 至于这几本书什么时候看的问题其实也挺简单。除了 1000 题随着大纲解析的顺序看一章做一章之外，其它的书出一本买一本做一本就可以，更具体的问题咱们之后再谈。 另外，冲刺阶段除了《肖 4》有几本题是比较火的，比如《任 4》《蒋 5》《20 天 20 题》。即便都很火其实质量也参差不齐，不出意外的话我你应该都会买，但是建议以《肖 4》一本为主其他当做参考补充。 政治是不是看书背书就行 **答：**不行。 虽然我给你推荐了书，但是你也知道全中国考研学生手里的政治参考书都差不多。虽然你有传的神乎其神的各种押题卷，但是你也知道你有的全中国考研学生手里差不多都有。 现在我不想展开说押题卷的作用究竟有多大，只想从另一个角度问你：每个人手里的参考书都差不多，每个人手里都有那几本押题卷，可为什么大家考出来的分数有 70 有 50 也有 30？这里面就涉及到大家都在背你该怎么背，大家都在做你该怎么做的问题。 我把自己认为比较合理攻克选择题的流程简单介绍一下： 前期看《考研政治轻松学》对这门课整体内容有一个学习，对重点内容有一个理解解。9 月出了大纲解析，每次首先浏览一章的内容，再根据王老师的课（去年免费强化课程的配套教材就是官方大纲解析）勾画一遍重点再过一遍书，听他讲完之后再浏览一遍勾画的内容，再做 1000 题对应章节习题，做完之后不缺的和做错的题目在回归课本等于又过了一遍书。这样下来你一章内容等于看了 5 遍，很多选择题的考点不用背也就记下来了。这样做看起来费事其实要比囫囵吞枣猛刷题更有效果。 就是靠着这个流程，我后期再做肖 8 和肖 4 的时候基本每套题选择题得分都在 40 分往上，这是什么概念？对于大多数人来说，你的政治总分基本就是你选择题分数的 2 倍。 从现在开始复习早不早？ **答：**不早，慢慢来学扎实。如果你 7 月一天有 10 小时复习时间，可以拿出 1 小时看看政治。 从现在开始复习晚不晚？ **答：**不晚，考前两个月突击就行。你现在一天复习 5 个小时还是先别看政治了。 那些押题卷是不是没用？ **答：**如果复习的扎实其实没多大用，从今年的情况来看大题会越来越活，光靠那几套题不会得什么高分的。 那些押题卷是不是很有用？ **答：**嗯，放心，你考前一个月突击，最后再做几套押题卷把那 20 多道大题一背就没问题了，只要都写满肯定过线。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-26-tokyr14/"},{"title":"致考研人 13：英语作文备考经验","content":"写在前面 不管之前着急不着急，进入暑假不少人一下子都慌了起来，有的人高价报班有的人四处求医。就英语而言，多数人已经了解该如何学习历年真题中的阅读部分。今天，我们来谈谈英语作文该如何准备。 需要说明的是，我并非英语专业学生同时才疏学浅，只是就个人去年复习和自己学习英语的经验和大家进行交流，供考研人参考。文中提到的各种观点以及方法难免有不妥之处，即希望你多多指正也希望你多多包涵。 前文回顾 将之前**《致考研人 2：英语复习心得》**中涉及到作文的部分摘录如下。建议没有看过的看下，看过的适当重温。 考研英语写作分为 A 部分和 B 部分。总分 30 分，其中 A 部分艺名为应用文或者小作文（约 100 词；10 分），书信形式居多；B 部分艺名大作文（200 词上下；20 分）英语一通常是图画作文，英语二通常是图表作文。 对于作文，我个人感觉是最偷懒不得、最没有技巧可言又最有可能大幅度进步的一部分内容。 近些年作文命题的趋势就是反押题！不能指望靠着某些机构老师最后的押题救命，虽然年年不少老师都说自己压中了题。这些人要么是扯，要么是考前一个月出本书（大小作文 X 十篇，一篇涉及一个话题）。考研这么多年作文一共就几个主要话题，你稍加了解和学习之后自己出本书也不是没有希望压中。 拿今年（2015）的作文题来说。小作文考前有人预测求职信、推荐信、感谢信和投诉信等等，范围已经够大了。可是最后考试内容是让你“推荐一本书”。虽说是推荐信的一种，但是大多数人预测的推荐人还是相差不少的…… 如果你只靠押题或者模板，在考场上看到这样的题目难免焦虑。 如果你要是按照话题分类背了历年真题范文并进行了仿写练习呢？ 2011 年英语一小作文的要求是让你推荐一部自己喜欢的电影，如果你老老实实背了那篇文章并进行了仿写，看到今年的小作文题目你不会偷着乐么？ 请问如果要仿写一篇介绍电影的作文，你要怎么仿写？我觉得正常的孩子第一反应就是介绍一本书，这不就是今年的作文题么。就算你没有仿写过 2011 年的小作文，但是背了关于环境保护或者传统文化的历年真题范文又进行了仿写，并且背的足够熟练。考场上看到这篇要你推荐书的作文你要怎么写？ 在考场上，我的第一反应是“最近我读了一本书叫做《哭泣的地球》，里面讲了环境恶化和保护环境的重要，我觉得很有意义推荐给大家”或者“最近我又读了一本书叫做《遗失的美好》，里面主要讲了传统文化的流失和保护继承传统文化的重要性，我觉得很有意义所以推荐给大家”。就这样，不小心一下子就写出了两篇小作文。 今年（2015）大作文给的漫画是“一伙人在一起吃饭，没人说话都在低头玩手机”。考前人们很多都预测会考保护传统文化、网络谣言、重视文化交流等等。当然由于“手机”这个话题实在很常见，也有不少人预测到“科技对生活的影响”。 我想说：今年的考题就是 2009 年的真题重现。请看图： 2009 年的漫画是“网络的近与远”，是说网络拉近了人与人的距离，又疏远了人之间的距离。今年是“手机让人们的生活更方便，但也让人们的交流减少”。如果让你对 2009 年的考题进行背诵并仿写你会怎么写，我觉得一个正常的孩子都会写“手机对人们生活的影响”，这不就是今年的考题么？ 所以别觉得考过的不会考，反而是就那几类话题来回出现。 考研作文什么最重要 回顾完过去，让我们聊的更仔细些。 首先来正一正自己的三观：到底是“框架”重要还是“内容”重要？写了这么多年作文，你一直在准备的是什么？ 到底是“框架”重要还是“内容”重要？ 所谓“框架”不同人有不同的定义，在这里可以理解为模板或者可以成套背的东西，字数或多或少，往往一个框架可以应对 4—5 篇文章及以上；所谓“内容”就是除了这些“框架”以外的东西，每一篇文章可能都对应着不同的内容，往往很难大范围的背诵。 为了说明哪个更重要，请看下面一例： 假设你是一个语文老师，判卷的过程中看一个老外写的中文作文开头如下你会是什么感受。“这篇寓意深刻的漫画形象地反映出了一个振聋发聩的问题：报互坏精波在眉睫。” 也许你要么想掐死他，要么想掐死自己。 “这篇寓意深刻的漫画形象地反映出了一个振聋发聩的问题”就是所说的框架（模板），可以背诵然后用到多篇文章，里面可以有“寓意深刻”“振聋发聩”等高级词汇。“保护环境”（文中错写为“报互坏精”）就是我们所说的内容。如果你连题目涉及到的最基本内容都无法准确的描述出来，那框架模板再高端也没什么用。 写了这么多年作文，你一直在准备的是什么？ 学了这么多年英语，不管是何种考试，我们准备作文的思路基本如下： 考前一个月：翻看以前自己的作文或者真题范文。 考前一周：从中选择开头句型 5 个，中间段句型 5 个，结尾句型 5 个。 考前 2 小时：背一个开头句型，背一个中间段句型，背一个结尾句型。一共准备三个精彩句型。 考试中：不管考什么内容，反正一定要把自己背的三个句型写上，然后再随便编编就感觉差不多了。 其实大多数人所谓的准备就是在准备框架，而非内容。 考研作文有哪些思路 正了三观之后，我们再说一下准备考研英语作文有哪些思路。 我结合自己、身边同学的复习经验以及接触过的老师提供的方法，给大家介绍如下几种。 按照考研真题年份顺序逐篇背诵 这类方法适用于英语基础比较薄弱并且愿意背诵的同学，所谓薄弱可以理解为英语句子提笔即错的可能很大，即包括基本的单词拼写错误也包括简单的语法错误。你只有背诵一定数量的文章并且做到滚瓜烂熟倒背如流甚至中英混背的程度，才可以在下笔时从背过的作文中迅速地寻找出相似话题的内容，并尽量减少低级错误的发生。针对考研作文备考而言，这种方法是最不费脑的，对一部分人而言也是最高效的。 话题内容与相关句型自由搭配成文 这种方法适用于英语基础较好或者不喜欢背诵的同学，这些人英语基本功比较扎实不会提笔即错，但又很难熟练的背诵全篇文章。你要做的就是整理出尽可能多的备考话题，平时积累尽可能多的写作素材，并且提炼丰富的可用写作句型。写作素材包括每一个话题你需要掌握的基础词汇搭配短语，以“环境保护类”话题为例，你需要尽可能多的掌握和主题相关的各类单词（conservation / utilize /deforestation /depredate /devastation）和短语（keep ecological balance /deteriorating environment /sustainable development strategy），掌握尽可能丰富的可以用来表示观点，建议等内容的句型。 考试出现这类作文时，你需要将话题相关的核心词、短语与表达相关内容的句型进行正确地搭配组合，再将每一个句子进行整合形成一篇完整的文章。这种准备方式背诵量最小，但是也很考验你的功力。 话题内容积累配合范文背诵 如果你做不到疯狂背诵完整范文也做不到熟练搭配自由组合，可以尝试这一种灵活背诵的方法。虽然需要你尽可能地背诵范文，但并非按照年份而是按话题归类背诵。具体操作流程参考如下： 以准备有关“两代关系”话题的作文为例。其实，所谓“两代关系”话题无非就是上一代怎么对待下一代（溺爱还是严厉）和下一代怎么对待上一代（虐待还是善待）。 第一步 平时留意积累和这一话题相关的内容并整理记忆。比如“孝敬”、“代沟”、“溺爱”怎么写，比如“给父母提供舒适的生活环境”、“学会独立，不给父母增加负担”、“承担赡养父母的责任”如何表达。 第二步 集中归纳相关真题并进行范文的背诵整理，体会写作思路。涉及“两代关系”的真题一共有三篇：温室花朵经不起风雨——父母溺爱子女（2003）；养老“足球赛”——子女不赡养父母（2005）；相携（父母养育子女，子女瞻仰父母）——子女赡养父母（2014 英语一）。这里的背诵当然越熟练越好，但更重要的是理解总结写作思路：这一类的话题应该如何入手；漫画描述段可能会用到哪些表达，第二段应该从哪些方面展开叙述，第三段应该发表什么样的看法或者提哪些建议。例如：漫画内容偏负面，比如 2005 年，第二段可以写漫画所反映问题在社会上存在的种种表现（不给父母提供基本的生活保障，不陪父母，没有尽到子女应尽责任），第三段提出改变这种局面的建议；如果漫画内容偏正面，比如 2014 年，第二段可以写出提倡这些正面做法的原因（父母为我们付出很多，抚养我们长大），第三段可以写我们应该如何对待自己的父母（提供基本的生活保障，多陪父母，尽到子女应尽的责任）。 第三步 将自己积累的话题相关内容带入到范文中进行简单的替换练习，比如进行建议的替换、理由的替换和主题词的替换等等。 第四步 用模拟题进行全文的仿写联系。 完成这四步，也就意味着对这一类话题你进行了比较全面的准备，如果在考场上遇到“两代关系”类的作文，首先不会无从下笔，另外也不会出现框架精彩高端但内容跑偏错误百出的情况。 考研作文复习的 9 个疑问 内容素材去哪里积累 个人认为，最理想的是各种类型外刊文章和新闻报道。从三月开始我就在坚持着“英语新闻一起读”栏目和“国情咨文赏析”栏目，虽然不多，但这些内容中也涉及到各种话题的词汇和搭配。如果你有每周都看几篇《经济学人》的习惯，不用说学什么写作手法，只要能学几个地道的搭配都是非常好的。 第二理想的材料是近 20 年的真题。考研真题涉及的话题相对全面，同时文章的来源也保证其中的表达足够地道。另外，不少考研文章其实都是“提出现象，阐释现象，分析原因，提出措施”的思路，里面很多句子我们都可以借鉴和参考。 比如 1996 年第四篇文章可以提炼出： What accounts for …话题…in today's society? Among the many shaping factors, I would single out…A; B; and above all C. 再比如 2000 年第四篇文章的原文：While often praised by foreigners for its emphasis on the basics, Japanese education tends to stress test taking and mechanical learning over creativity and self-expression. 虽然是对日本的评价，但是用在关于我们教育话题的作文中仍然是适用的。 第三理想的材料是市面上口碑上佳的考研作文辅导书以及真题书所给的参考范文。关于考研作文的辅导书市面上有很多，但是口碑不一，很可能是 A 老师会挑 B 老师的毛病，B 老师会挑 C 老师的毛病，C 老师又反过来挑 A 老师的毛病，雅思老师挑考研老师的毛病。这里面可能涉及的合作和利益关系我们抛开不谈，还是有几本作文书口碑不错可以推荐，比如王江涛的 《考研英语高分写作》和顾家北的《手把手教你雅思写作》（虽说是雅思写作，但是里面关于写作思路的训练和写作语法的讲解对于考研亦有学习的价值）。 仿写的原则是什么？ 仿写的原句越直接简单越好（各种从句掺和一起的长难句不要仿），仿写的改动越少越好（比如只改下主语或者宾语）。原因很简单，就是为了降低出错的可能性。 大小作文怎么准备？ 大作文上面已经说的够多，这里简单提一下小作文。小作文普遍的分类方式是申请信，求职信，介绍信，推荐信，倡议信，感谢信，邀请信等等。但是这样分类其实远远不够，比如你会写求职信那辞职信你怎么写，你会写感谢信那投诉信你怎么写。 对于小作文而言，有一类需要直接背诵，比如求职信，咨询信等，这些文章背一篇基本就可以解决类似题目。另一类题材，更好的方法是和大作文结合起来复习，例如和环保相关的倡议信就可以和环境保护类的大作文结合复习，而所谓的辞职信可以和网络相关的话题结合复习（辞职的原因和网络危害的原因都可以是熬夜、作息不规律导致身体不适），再结合各种话题书信该有的格式、开头结尾的写法就可以组合成一篇小作文。 我去年写小作文“推荐一本书”时一开始有点茫然，后来就编了一个关于传统文化的书名，写了为大作文准备的一个关于京剧的例子。 有没有其他的复习方法？ 有，比如分段复习法。考研作文出题形式相对固定，写作模式其实也比较死板。考研文章往往会写成三段，第一段描述图画；第二段指出内涵，对寓意进行阐释；第三段发表评论或提出建议。从这个角度出发，我们甚至可以采取分段复习法。 比如你首先集中精力学习真题中第一段的写法，由于第一段是图画描述段，你要学会总结可能用到的关键信息词（多为描述动作、状态、心态的词和描述地点、数量的词）。比如男人、女人、老人、小孩、大学生、网民、游客、顾客、商家、肩并肩、手拉手、背靠背、看、坐、睡、推、喊、踢、吃惊、紧张、乐观、悲观、失望、高兴等等的表示方法。 再研究第二段的写法，就是可能用到的各种句型，和各种话题相关内容的表达。 再研究第三段的写法，比如怎么提建议（完善法规、增加投资、制定计划、给出建议、个人提高意识、学会自立、培养自信），怎么评论（对的，应该坚持；错的，应该改正）。 最后，再练习写完整的文章。 跟着某辅导班的某老师行不行？ 我不知道。个人感觉说不用背的，或者说背几个就能解决问题的恐怕悬；凡是考前给你几个模板让你填空的恐怕悬；凡是倡导什么两步（三步）作文，给你一种看起来写作竟然如此简单的感觉的恐怕悬。 作文不拉分的关键是什么？ 书写工整的同时减少低级的错误，比如单复数问题，时态问题，单词拼写错误问题。 作文得高分的关键是什么？ 书写工整的同时减少低级错误的基础上，用词稍加变化，稍加运用几个语法结构，不使用“一篇能应付十篇”的模板。 作文最后真的不能用模板么？ 如果把自己整理过的每一个话题对应的专属作文进行掏空一部分内容后当作自己的专属模板的话，我感觉是可以的。 因为我就是这么做的，在之前准备的基础上，考前半个月常见话题我都整理了一个自己的专属“模板”，然后看各种各样的模拟题确定话题范围进行代入练习。 还有什么要特别注意？ 书写！书写！书写！ 不求好看但求整齐，不求飘逸不要连笔。 一笔一划越像打印出来的感觉越好，因为你的作文是被扫描之后放到电脑屏幕上看的。至于怎么检测自己的书写，建议大家可以将写好的作文用手机拍成照片，然后存到电脑里让你的研友对着屏幕做一个评价。 这篇文章就先写这么多，之后想到什么再不定期补充。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-26-tokyr13/"},{"title":"致考研人 12：比较危险的三类考研人","content":"写在前面 以下内容只针对考研人，只代表我个人看法。如果批评不自由，则赞美无意义。我不太会说好话，只能看到一些问题。下面是最近发现普遍存在的三类患者。如果你幸运的是其中一个，呵呵 资料搜集症患者 我现在基本上每周都会和大家分享一些外刊， 除了经济学人还有卫报、泰晤士报和纽约客等等。经常会有人说“学长你真牛 X，这个东西我找了很久啊”或者问我“学长你这个东西是哪来的啊我怎么找不到。“其实，一开始分享这些东西我是拒绝的，因为我觉得这些东西对你们没什么卵用或者说绝大多数人并不知道怎么用，但是我实在不忍心看你们在搜集资源的道路上越走越远、越走越偏，不得不开始做这么一件事情。 希望那些热衷于搜集资源的人能省省能醒醒。已经到了五月下旬，如果你每天做的还是到处搜集资料，不停的点链接、输密码、点保存的话那你有点儿危险。如果你看着自己的网盘里东西越来越多并且有一种快感的话，这是一种病，得治。 考研不是比谁的资料的多，是比谁用的好。我曾经问过一个考研人你有什么，他说我有好几 T 的视频，和学长学姐要了好多辅导书还有他们的笔记。我又问他你到底有什么，他又说你们常说的那些老师的书和视频我都有啊。其实，那几 T 的视频，那好几百块买来的笔记，那一摞辅导书都和你没有半毛钱关系，只是在你那放着而已。 你有的就是自己的脑子自己的手。你以为你关注了我，每天我分享的东西就是你的了？你以为你关注了很多资源号，天天刷微博保存资源那些东西就是你的了？哎，你真是 NAIVE。 看书画书小达人 说完资料搜集的问题，就不得不再说一下资料的使用问题。 如果到了现在你还是一个只会看书的人，那你危险了。每当有人给我反馈说学长你推荐的某某老师真厉害，他的书写的真好。我总是忍不住补刀：你看出什么问题了么。 我一直说参考书的作用就是参考。只有一本书真的为你所用，才能发挥其最大的价值。 《外刊超精读》这本书我没有精读，我用这本书是学精读的。接受一个新的思想学习一个新的体系你必须仔细地读一本书作为敲门砖，这本书之于我就是一个敲门砖的作用。 我没有花 7 个小时去精读一篇文章，注意我不是说一篇文章不值得花 7 个小时去精读（虽然有的文章确实不值得）。那我为什么没有用 7 个小时去精读呢？因为我那个时候就不会精读。在基础知识薄弱的早期，我就是主要掌握书里给出的内容，除此之外我更关注的是怎么精读。 我在意的是从哪些角度去分析一篇文章，查单词要查什么样的单词，记短语要记什么样的短语，分析句子要分析什么样的句子，仿写要怎么仿写，分析段落结构要从哪些方面去分析，利用什么去分析。学习了 20 篇文章之后我对所谓的精读有了一个大致的了解，后 20 篇文章我尝试着自己去精读，然后再根据书里的内容进行对比和补充。 看完外刊，我就买了老丁的《真题超精解》。你可能会问”既然你没怎么看为什么还要买，还要给我们推荐呢？“ 我所说的“没怎么看”可以理解为我没有从上面直接吃多少鱼，但是我学会了捕鱼的方法。 有了精读的思想做指导，通过之前的学习有了自己精读的方法，我就放心的开始做真题。至于怎么做真题、做了几轮的问题之前的文章写过了。 我是怎么用《真题超精解》这本书的呢？是的，说实话还是没怎么用。如果说精读一篇真题的平均时间是 3 个小时，我看这本书的时间不会超过半个小时。我用从《外刊超精读》学来的方法自己对真题进行超精解。真题和外刊的最大不同是涉及到题目，这本书里对题目的解析是很详细的，但是再详细的解析也是别人的思路。我们要做的是整理自己做题的思路，分析自己做错的原因，参考老师的解析，调整自己的分析方式。如果你只是一有问题就想看别人的解释，努力试图理解别人的想法，哎，你真是 NAIVE 对了，再重申一遍，不推荐上面提到的两本书。 考研急行军 这类人有一个显明的特点就是想的比较长远。这不是好事儿么？有时候步子大了容易扯着蛋。 我每天收到的各种私信中，如下问题占了很大一部分。 “学长，听说你考的中科院你有复试资料么？” “学长，听说复试要考口语我该怎么办？” “学长，你认识 XXX 老师不？你向他推荐一下我吧。” “学长，我给想报考的老师发了邮件，他怎么不回我啊？” 关于上述若干问题，之前的回复都是开玩笑的说”别叫我学长“。现在我统一说一下自己的看法。人很多时候特别容易产生幻觉，尤其是你特别想做成一件事并且努力在做的时候你往往会潜意识里以为自己已经做成了那件事。我不是不想告诉你怎么准备复试，怎么准备口语，可是你初试过了么你就准备复试，你英语能考 60 么你就准备口语。 至于要不要提前联系导师，你需要先从这么几个方面考虑考虑。 你有没有给提前联系老师的必要？ 不用明说，大家都能理解你提前老师的目的。但是你知道么？有些招生单位老师有很大的权利，他可以在复试的时候决定要哪个学生不要哪个学生；有些招生单位的老师却没有，反而招生办的老师有很大的权利，你可以从他那里得到很多关于复试有用的信息，如果你是为了……还不如直接联系招生办的老师。有些招生单位，比如我所在的地方，你考上研究生之后采用的是轮换制确定导师，复试的筛选方法是打分算平均分进行排名。你和老师之间是双向选择，所以他们也不知道哪个学生最后会跟着自己，他们只负责挑好的学生，这也不需要你提前联系老师。 你有没有想好你要联系哪个老师？ 给老师发邮件自然要明确给哪个老师发邮件。是给有名气的老师发还是给有潜力的老师发？假设你给一个年轻有潜力的老师发邮件而且他回复了，再假设他给你保证了什么，再假设你又顺利通过了初试。但是你去了那边又了解到一个自己更感兴趣更有名气的老师，同时他也表示可以接收你。你怎么办？ 你有没有让老师给你回邮件的资本？ 很多人费尽心机地思考怎么让老师回复自己的邮件。但是你想没想过你有什么让老师给你回邮件的资本？假设你是一个老师，看到什么样的邮件你会回复？你又会怎么回复？ 一些普通的高校具体是什么情况我不太了解，但是科研院所很多高级别的大牛都很忙。他们不是不想理你，只是不知道自己为什么要理你。你有什么经历和东西值得他们感兴趣，就算他们对你的某方面感兴趣他们又没法确定你能不能来。于是很多老师会这么回复你：“我看了你的来信，非常感谢你对我们实验室感兴趣，也欢迎你考上之后来我们课题组实习。”看到这样的回复你是不是以为自己这一段时间的联系老师的努力终于有结果了？大家都是成年人了，哎，你真是 NAIVE。 你能不能考上你就联系老师？ 假设你一切关系都打点好了，老师喜欢你，你也喜欢老师，他答应你只要过线就保证能来。结果……结果……初试你英语没过线或者总分没过线，你还要和老师说“老师，你放心，你再等我一年我明年肯定来”么。那你最好现在去联系一下考试院的人看看能不能到时候帮你改个成绩。 究竟什么人应该先去联系老师呢？ 如果你成绩优秀，保研的可能性很大，由于保研政策的改变你应该先去自己心仪的学校联系一下老师；如果你要参加夏令营了，想去某个老师那了解一下具体情况你应该先联系一下老师；如果你专业特别突出已经有所成果，但是考研考高分的可能性比较小你应该先去联系一下老师；如果你报了一个很好的学校又担心自己考不上，那你可以先联系一下准备调剂学校的老师。 如果以上条件你都不满足，先好好准备初试吧。过了初试咱们好好聊聊怎么联系老师，怎么准备复试。该干什么的时候就干什么，想太多其实并不是一件好事。你就认真地去做，很多时候结果往往比你自己一开始预想的还要好。记住，不管干什么步子太大小心扯着蛋。就算想迈大步也要学会用什么正确地姿势。 资料收集症患者 看书画书小达人 考研急行军 如果你是其中一类且觉得没问题，那你继续大步向前，我为你祝福你。如果你觉得这样下去有点问题，我也为你祝福，想想该怎么办吧？ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-26-tokyr12/"},{"title":"致考研人 11：我的电话采访文字稿","content":"写在前面 今天下午本来打算潜心写论文，后来接到了一家日报记者的电话说想进行一个电话采访。 其实一开始我是拒绝的，因为你不能说采访就采访，我得想一下说什么，我不愿意采访之后那些记者加很多特技。后来记者告诉我一定不会删减我的回答内容，所以我就愉（wang）快 (le) 地 (xie) 答 (lun) 应 (wen) 了。 以下为此次电话采访的文字稿，大家可以看看。 问了挺多问题，如果有一两个问题看完解决了你的痛点那就是纯属走运，如果看完觉得没啥意思也纯属活该。毕竟记者问什么我也决定不了。 参访内容 Q：简单介绍一下你自己吧，你为什么叫“一只思考问题的熊”呢？ A：其实一开始觉得叫这个名字没有什么歧义，只是因为那段时间比较喜欢布朗熊，为了装 X 就用“思考问题”来修饰一下，我本身并不姓熊，最近越来越胖身材确实更像一只熊了。当然大家称呼我“熊学长”我也没有意见。 我现在就是一个“准”研一的学生，即将迎来在中科院硕博连读的五年时光，硕博的方向是植物学这一块，算是基础学科。其实就是利用分子生物学的一些手段做一些基础性生命科学研究。 Q：为什么要做现在做的事情，你不是说考完研应该更忙么？ A：从小比较能说，愿意把自己的想法和学到的东西和比人分享，另外过去一年的备考经历教会了我很多东西，绝对不拿出来说说憋在肚子里也消化不了，所以就写出来。 至于后来的英语新闻以及其他的东西，目的就是为了让自己保持一个持续学习的状态，顺便希望给那些愿意看的考研人带来一些帮助。 Q：从备考角色进入辅导角色究竟是怎样一种体验？ A：不能说是辅导，刚才已经提到了就是学习，和研友一起学习。我没有多大的本事能谈得上“辅导”这两个字，其实就是交流而已。我把自己想法告诉你，你觉得有用就听一些觉得扯淡就乐呵一下。前两天有人问了我个问题，我查了半天资料自己也没弄明白，后来请教了更专业的人士才解决。 去年备考的时候我就是整天埋头学自己的，管好自己的事情就可以，现在虽然不用那样复习了但是感觉比以前还要累一些。因为，每次你要写点什么说点什么的时候都要更多考虑别人的感受，要想这个东西写出来别人看了有没有用，有多大用，会不会坑别人，其实挺累的。但是看到一些积极的反馈心里还是会有一些成就感。 Q：简单说一说你对现在的辅导机构和辅导老师的看法吧？ A：这个真的可以说么？ Q：后期我们会加马赛克的。您可以放心。 A：既然你问了我就说说，我是一个死理性派，从来没有迷信过哪一家辅导机构或者哪一个老师。 我看过谁的东西，学过谁的东西，如果有收获我就觉得这个对我有帮助，但是如果回过头来看有一些问题我也会说出来。可能当老师的不会喜欢我这样的学生吧…… 我看到很多研友都特别推崇自己跟过的老师，有的像狂热的追星一样，整天就在微博里喊“老师你好帅”，“老师你是我的女神”……如果别人说这个老师的不好，他就说“你说他不好是因为你不懂，别在这瞎 BB”。还有些所谓的经验贴就像是广告贴，全篇读下来就是告诉你一月份买这个老师的这本书，二月份买那个老师的那本书，三月用这个老师的这个视频。 Q：关于上个问题能举几个具体一点的例子么，你其实也推荐过一些老师和书啊？ A：既然说到这一步，我就举几个例子。记住要加马赛克啊。本身我给大家推荐过的东西也不多，那我就找我推荐过的稍微吐槽一下。 去年在（此处马赛克）老师还没那么火的时候我就已经看过一本他的词汇书，书里的单词都是结合着真题例句，而且他的视频课会根据一个词汇给出相应的扩展，拿到以后我觉得这个书真好。但是因为涉及到太多真题例句而且词汇编排比较乱，没有在前期背单词的时候使用，放在后期精读真题之后复盘总结使用的。 看这个老师视频课的时候，他的书里涉及一到阅读真题，当时屏幕上只有选项并没有配套的文章。课上他说这四个选项有三个单词都是情绪向下，只有另一个情绪向上，所以选那个情绪向上的，最后还补充“你把单词学到这个程度，阅读真的很简单”。可是我明明做过那个题，我知道答案还真就不是他说的那个。可能你会说“谁不难免出个错？”，但是我隐约觉着一个专讲考研词汇的老师能把考研真题的错误答案讲成正确的还这么肯定是不是真的有些不妥？后来我发现是我错了，因为他不光讲考研，托福啥的也讲；也不光讲单词，火了之后一年一下子出了十几本书，涵盖了考研的各个领域。我不知道这些书里有多少东西是他写的，也没再看过，只是希望不坑学生就好。 但是在我的之前的文章里还是推荐了我最开始用过的那本词汇书，仅仅是因为在我通过真题学单词的过程中这本书确实给了我很大的帮助。 另外，在英语复习中对我帮助最大的应该是（此处马赛克）老师，之所以说帮助最大并非因为书里的知识点多么完善讲课多么精彩，而是通过他和他的书我学到了两个最重要的东西：精读文章和轻技巧重基础。正是这两个指导性的理念让我没有走很多二战甚至三战的研友的错误道路：以为一切都有技巧，有空可钻。 但是最近总有研友问我一篇外刊文章要看三天怎么办，一段话要看四个小时怎么办？ 首先，大家应该明白读得精不等于读得慢，精读不是瞎读也不是抄字典，那么精读应该怎么读呢？ 外刊是一本教会你精读的书而不是一本需要你瞎精读的书。看看老师针对一遍文章精读出了哪些内容，做了怎样的扩展，精读的重心在哪里，如何分析一篇文章的结构和行文思路。学会这些东西，远比你早期复习多记了一个短语查了一个单词重要。如果想打基础的话主要掌握书里给出的内容就可以了，没有太多必要为了一篇外刊里的文章花好几天的时间。学会了如何精读，用这套方法去啃近二十年的真题。 Q：刚才你提到了技巧的问题，你觉得什么叫技巧啊？ A：说实话，有时候技巧和方法是挺难区分的。考研复习的后期我自己也有些方法，似乎也可说是技巧。但是一上来就学技巧我觉得挺扯的。 你想想，我们学一门技能应该先整体的把握和学习，熟练了之后再用自己的“小聪明”创造一些方法，这些方法是在你对所学内容整体把握的基础上结合自己发现的规律总结出来的，用起来自然能达到和一开始相比速度提高正确率增加的效果。 如果你一上来先学技巧是一种怎样的体验呢，就好比我现在告诉你做好阅读只需要知道六个字“定位、替换、排除”，会了这六字大法你阅读就无敌了。你不相信？那我就给你拿出一篇真题来讲，我就靠这六个字，用 10 分钟的时间做完了一篇阅读而且全对。 你信了吧。好了，那你现在做题吧，你默念定位定位替换替换排除排除，（此处马赛克）老师保佑。但是你发现自己竟然不知道怎么定位，自己竟然不知道题干里的那个词和原文的那个短语可以替换，有一道题你定位了也替换了，可是你竟然只排除了两个选项。你还想，为什么老师用这六个字就可以为什么我不行呢？老师真是太厉害了，一定是我对这六个字没有很好的顿悟。其实他没有告诉你，他是在单词都认识、看懂文章又讲了这么多年课之后总结出来的六个字。当然也有人说这六个字非他原创，这不是我关心的问题。 我本身不反对技巧，可是你要掂量自己有没有使用技巧的资本。从小老师对我说，基础不牢地动山摇。我觉得在老师为数不多的真话里这是很重要的一句。 Q：你怎么看待像你这样活跃在考研人中的过来人？ A：这是一个好问题，也是我最近一直在思考的问题。 我们这些人大多数本来就是看起来很纠结的，这是一个共性。 举个例子，我一直都在关注一个学长，他是一个老师的入室弟子这让我感觉更加神秘，他的文章给过我很多启发。这几天他发了一篇长微博，其中有一个观点是认为一些老师和过来人讲的真题几遍论不重要并告诉研友要根据自己的具体情况来看，几遍论的东西不用太当真。这篇文章得到了很多研友的赞同，这一观点我也是很认同的，但是就在前几天他发了微博说这个“阶段数学复习要保证每天 6 小时、最好 7 小时”。我个人感觉这种观点和做几遍真题的观点应该是一个意思或者说类型。 如果觉得几遍论的方法有问题那为什么要规定别人每天最少复习几个小时数学呢？如果觉得这些论调不重要，而是需要取经者自己感觉，为什么要给别人这样的建议呢？或者说过来人真的知道现在的考研人每天有几个小时复习么？也许很多人现在一天的复习总时间都达不到六个小时。 当然这个现象的存在是和我们过来人的对应群体——取经者有关。 Q：你可以解释一下么？另外你是不是也经常被打脸？ A：我个人认为过来人之所以经常纠结或者看起来自己打脸是和前来取经的考研人有关。为什么这么说呢？ 第一，如果他们想问一个具体的问题比如“英语真题做几遍”，我就不能回答“你要根据自己的实际情况来看。”这样说的话会被骂街，因为人家问你做几遍，你就要说你做了几遍；如果他们问你“真题要做三遍么？”我就会说“不用，要看你的具体情况。”我要是说必须做三遍也是要被骂街的。 对于这类问题我现在只能用特效来答。你问我做几遍，我就只能告诉你我做了三遍，每做一遍真题都做了什么，重点在哪里，如果你觉得自己一遍能解决我三遍的问题那么随你。还有一类问题我是随机应变回答法，你要是问我“现在开始做真题早么”我就回答“不早”，你要是问我“现在开始做真题晚么”我就回答“不晚”，你要是问我“什么时候开始做真题啊”我就回答“现在”。 Q：既然你提到了前来取经的考研人，你有什么想对他们说的么？ A：没有，因为我基本每天都在对他们说。 Q：还是说几句吧，毕竟有一些认可你的人。 A：我就是希望每个人都尽量做一个有独立思考能力的人，看到什么要有自己的判断，不迷信不盲从。当然，这个判断可能是对的也可能是错的。 另外，大家和别人交流尽量要找有共同理念和有认同感的人交流，如果你对一个人有生理性反感，即便他的话是对的你也听不进去。比如我是一个 smartisan T1 的用户，如果看到一个人手里拿着锤子手机，那么即便不认识我们交流起来也会比较顺畅，这就是因为我们在某个问题上有一样的认同感。 Q：最近很多寒假或者三月开始复习的考研人似乎都进入了一个迷茫期和困惑期，你怎么看？ A：确实，我今天还发了个微博让大家吐槽，很多人都说自己的状态不好很迷茫。 我觉得原因有两个，一是有的人以为自己是从二月复习的，但是这两个月根本没怎么好好看书，看着别人都复习了一段时间来这儿假装难受，说什么复习效率低看的慢。看的慢是没问题的，只要你看了有收获而且掌握的扎实，即便看的慢也会很开心。只不过很多人怕被人鄙视，把没怎么看等同于看的慢。 对于这些人我只能说：“迷茫你妹！起来学！” 很多人确实埋头复习了两个月，但是感觉自己很累。这第二个原因可能是你自己的方法不对或者给自己强加的任务太多，这个时候回头看看及时调整是很重要的。拿出几天时间，把之前复习的内容看一下，再休息两三天开始下一阶段的复习，这样做往往能缓解一直往前冲的焦虑。 Q：这几个月下来你对于自己接触过的考研人最深的感受是什么？ A：充满理想，充满干劲。 Q：对他们你最担心什么？ A：过犹不及。因为总是把一个终极目标摆在眼前很容易疲劳和崩溃，结果反而不会达到预想的目标。我当时就是想着每天把该看的东西看好，该学的学完，最后的结果反而比我预想的还要好。 Q：你怎么看待现在你在的这个圈子，我是指考研辅导圈？ A：你这个记者问这种问题也太没有水平了吧。谁在考研辅导圈，你才在考研辅导圈，你全家都在考研辅导圈。我辅导你你愿意么？ Q：对不起，那你觉得做成一件事需要什么条件？ A：这个我之前总结过。 我觉得做成一件事只需要三个条件：坚持努力；正确的方法；良好的心态。另外可能还需要一点运气，但是要相信，努力的人运气总不会太差。 Q：你有没有自己比较崇拜的一些人？ A：罗永浩。从他的老罗语录开始，到后来的牛博网，到现在的锤子科技。他改变了我的三观，让我开始试着做一个让这个事情更美好的人。 还有我女朋友，总是可以让我无话可说，你要知道让我无话可说其实挺难的。 Q：那我还有最后一个问题。 A：爱过。 Q：逗比，不是这个问题。我是想问你个傻 X 一个人自问自答写了这么多有意思么？ A：这不是过节么，任性。另外，假装有个人问，我不会显得我太能说。 参访单位：《靠谱日报》 记者：另一只思考问题的熊 本文观点仅代表采访者个人，和本报无关。 2015 年 5 月 2 日星期六 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-26-tokyr11/"},{"title":"致考研人 10：政治复习经验","content":"政治考什么 考研政治大纲内容如下： 思想政治理论考试涵盖马克思主义基本原理概论、毛泽东思想和中国特色社会主义理论体系概论、中国近现代史纲要、思想道德修养与法律基础、形势与政策、当代世界经济与政治等高等学校思想政治理论课课程。（注意：我们通常说考研政治考五门课，指的就是以上五门，多数时候我们分别简称为马原、毛中特、史纲、思修法基、形策政经） 要求考生： 准确地再认或再现学科的有关知识。 准确、恰当地使用本学科的专业术语，正确理解和掌握学科的有关范畴、规律和论断。 运用有关原理，解释和论证某种观点，辨明理论是非。 运用马克思主义的立场、观点和方法，比较和分析有关社会现象或实际问题。 结合特定的历史条件或国际、国内政治经济和社会生活背景，认识和评价有关理论问题和实际问题。 政治怎么考 考试形式和试卷结构 本试卷满分为 100 分，考试时间为 180 分钟。答题方式为闭卷、笔试。 试卷内容结构 考察科目 所占比例 马克思主义基本原理概论约 约 24% 毛泽东思想和中国特色社会主义理论体系概论 约 30% 中国近现代史纲要 约 14% 思想道德修养与法律基础 约 16% 形势与政策以及当代世界经济与政治 约 16% 试卷题型结构 题目类型 所占分数 单项选择题 16 分（16 小题，每小题 1 分） 多项选择题 34 分（17 小题，每小题 2 分） 分析题 50 分（五门课各一道分析题） 用什么心态面对考研政治 近几年关于考研政治这门课有没有用、要不要考的讨论从没停止过，有些人（包括一些砖家叫兽）认为政治和多数学术科研没有多大关系，很多考生一听到政治这两个字就有抵触情绪。那么，我们到底应该用一种什么样的心态来面对政治（准确得说是考研政治）呢？ 首先，我们看看官方说法：这门考试的目的是科学、公平、有效地测试考生掌握大学本科阶段思想政治理论课的基本知识、基本理论，以及运用马克思主义的立场、观点和方法分析和解决问题的能力。（我的翻译版本：考虑到我们国家的政治体制以及治国方针，让你们这些想要成为高层次人才的人在学到更多知识、接触到更多西方先进文化之前花上几个月的时间了解一下我国的基本情况，了解一下我党成长的过程，学一学你们一直嘴上说的马克思主义，顺便正一正你们的三观还是很有必要的。） 我认为说到政治大家头脑里的第一反应不应该是那些所谓的政治斗争或者是贪污腐败；提到考研政治，更不应该将它和为某某说好话画等号。的确，在目前的这个大环境下如果你有这样的想法也不足为奇，但是我觉得作为或者想要成为一个有独立思考能力的人，面对任何事情你都必须通过自己的观察和了解再下结论。 你可以说马克思主义不好，但得到这个结论的前提是你对马克思主义有一个相对全面的了解，知道还有哪些其他的主义并且可以将它们做一个相对正确地比较。你可以说我们国家的各项制度还不够完善，但得到这个结论的前提是你对我国的各项制度有一个相对全面的了解，然后再结合在现实生活中遇到的各种实际情况进行一个相对正确地分析。 考研政治这门课，最起码可以给你一个了解的机会，了解一些你急于评论其实又根本不知道的东西。说实话，在去年 7 月之前我对政治这个东西没什么兴趣，但是现在我觉得每天看一些政治新闻和报道是一件很正常的事，看完西方媒体的各种报道也可以说出一两句自己的看法。 关于用什么心态面对考研政治，说了这么多就是想告诉大家：一件事情只要存在就一定有它合理的成分，哪怕它不合理的成分更多，在无法改变现实的前提下你也要从中找到合理的那部分并争取做到收获最大化。 政治复习用什么书 说明一点，我下文提到的都是我看过并且对我的复习有很大帮助的书。对于我没有提到的书，要么我觉得不好要么我根本没看过（没听说过或者身边没什么人用），所以希望大家不要和我较真。 《2015 年全国硕士研究生入学统一考试思想政治理论考试大纲解析》 注意，只有这一本书可以叫做考研政治红宝书（封面多为红色，且有一个大大的 K 字），其他的各种红宝书可以说都是借名宣传。另外，这本书的出版机构叫做高等教育出版社，编这本书的单位是教育部考试中心。其他任何模仿这本书封面以及借高教社之名出的多少题之类的书我个人建议大家不要买。理由很简单，如果一本书需要靠抄别人的名字，抄别人的封皮来打开市场，你觉得这本书的质量会好到哪去？ 另外，考研政治复习中大块头的书只需要这一本（实际上，这本书比很多老师的知识点总结类书要薄）。其他老师各种知识点精讲之类的书籍我个人认为都不需要，这些书无非就是对这本书里内容的摘抄整理重排，然后再加上几道真题，再把书里的文字印成几种不同的颜色。去年这本书做了一个小的改动，那就是把一些相对重要的内容加黑了，想必今年肯定还会这样。如果你觉得一本书全是字看不出重点则完全不用担心，在下文我会给大家推荐一位叫做王一珉的老师，他的强化课（免费）就是以这本最权威的大纲解析为教材，会带着你把书完整的过一遍并勾画出重点方便你复习。 每年最新版的《考试大纲解析》出版日期在 9 月上旬左右（新的考试大纲出来之后），如果在这之前要复习政治我推荐下面这本书。 《王一珉 2015 考研政治轻松学》 注意，这里我提到了王一珉老师，这个老师在我之后关于政治复习的内容里应该还会经常出现，因为考研政治复习的这几个月里他对我的帮助实在太大。这本书有免费的试读版本，我会把链接发给大家，你们可以看看。 书如其名，整本书读起来真的非常轻松。轻松的原因有两个，一是书比较薄，只讲重点和基础，看起来没有压迫感；二是王一珉老师采用了一种类似于授课的方式来写这本书，整本书看起来更像是在读老师的讲课稿和教案。讲课稿内容通俗易懂，教案里的逻辑图和知识架构完整简洁，若干个专题总结的也恰到好处。基于“轻松”这个原因，这本书尤其适用于你在零基础的情况下入门。 我在政治复习的前期中期和后期一共把这本书看了三遍，不是因为我时间多，而是因为确实可读性强，不同时期看都有不同的收获。 《真题》 对英语复习而言我个人的观点是唯真题论，对政治复习我认为真题也有其不可替代的价值。你可能会问政治不是每年的题都不一样而且结合最新的时事热点为什么还要做真题呢？ 针对选择题而言，虽然每年题干的原话不会相同但是知识点肯定是会重复的，重复考的内容一定是重点，既然是重点明年考试出现的可能性也就并非没有。你必须通过做近些年的真题来熟悉命题人出题的方式和思路，做完一遍真题之后再做市面上的模拟题你就会有判断一套模拟题质量好坏的标准。 这一点在中后期是非常重要的，很多时候你做模拟题会出现错一片或者不错的情况，这些并不能说明你的实力是超群还是没救，而是和模拟题的质量有很大的关系。如果你整套题目做下来发现它和你之前做过的真题出题风格相近，那这样的模拟题就能相对客观的反应的你真实水平。 针对分析题而言，虽然每年的热点不同，但是从近些年的真题中你还是可以发现一定的命题规律和方式。更重要的是你要从历年真题和标准答案中学习如何答题，如何组织答案并找准采分点。 真题书市面上有很多，我不推荐具体的哪一本，但是给大家一个选择的标准：选择题的编排方式最好按照考试科目和章节来分类而非简单的按照年份来分类，分析题答案最好有比较详细的分析过程而不是简单的几句采分点就草草了事。针对这一条标准来选择一本适合你的真题书就可以了。 《肖秀荣考研政治》系列 在考研政治圈里老师大体可以分为两类。一类讲课为主，一类写书为主。讲课为主且名声比较大的老师多半都出几本书，但是能写好的我感觉没几个。肖老在前些年是命题组成员，年事已高讲课并不多，能在考研政治圈里积累下这么多名气主要是靠他一系列的辅导书。他的书我基本上都看过或者做过，推荐大家除了《知识点精讲精练》（和官方大纲解析同类型，可以不看），其他比如《1000 题》《8 套卷》《4 套卷》《知识点提要》等等都可以在新版出来之后买来看看。 其他书 在此，我将没提到的书都称为其他书。你们可以在当当或者京东搜一下，考研政治相关的书实在是太多了，而且同质化非常严重。各位一定不要想着我做了 A 老师的书，万一 B 老师的书没做是不是不太好啊。要知道，就算你看完了 A、B、C 老师还有 D 老师，而且你一查发现他们都说自己压中了五道大题（关于各种押题王的问题我们在之后的日子里慢慢说）。那到底应该怎么选择呢？ 我的建议是，如果你报了某一个辅导班，而且那个辅导班的老师恰好又出了本书你可以拿来看看。这些书很多就是那些老师上课用的讲义，你报的辅导机构一般会免费把书发给你。如果这些书多半的作用在于报班赠送，你要是没报班买它的意义就不太大了。如果你什么班都没报，或者跟着的老师没有“闲工夫”出书且你没有功夫看很多书再进行比较，我说一个简单的选书原则，那就是绝大多数人用什么你就跟着用什么。政治这种东西没必要剑走偏锋，如果你对分数要求不高，那么大家看什么你就跟着看什么，跟着大伙的步子走并且付出应有的努力，政治的分数都不会太低。 政治复习听谁的课 这也是一个比较棘手的问题，现在各大辅导机构都有一两个比较火的政治辅导老师，这里不再一一点名，而且多数学长学姐都会告诉你政治不用太着急，最后报个班听一听押题就可以了。那么到底该听谁的课呢？ 首先，这个老师一定要合你的眼缘和耳缘，如果你一打开他的视频，他的样子或者说话的音调音色都让你不太能接受那我劝你你最好不要跟下去，因为大多数老师政治讲都相对枯燥，如果他的声音或者样子都和你不投缘那你要想坚持学下去还是蛮难的。 其次，不要把每个老师的课都听了。如果有一个老师的课让你感觉听着还算舒服，你最好这一门课就跟着他。虽然说大多数老师讲的内容都差不多，但是不同的老师会有自己不同的路子，听太多人反而无益。 再次，一定要考虑效率最大化，这一点对于政治复习是尤为重要的。政治这门课你复习的时间本来就不会太多，另外需要你在这有限的时间里再拿出大部分的时间进行习题练习以及对大纲解析内容的熟悉和理解，后期还需要你对重点和热点进行背诵记忆，因此用大把的时间来听政治课显然并不是很明智的选择。而现在的辅导机构政治辅导多数是这样的节奏：不同的老师负责不同的内容，每个老师都会告诉你自己讲的内容多么重要；在课程的安排上又分为各种导学班，春季基础班，暑假班，秋季提高班，冲刺班，押题班……这些都看的话不知道要用掉你多少时间。 综上几个原因，我在复习前期大体听了几个老师的课之后到考研结束只跟了王一珉一位老师。大家如果想了解这个老师可以上网搜索一下“一珉教育”或者关注王一珉老师的微博。 王一珉老师的课有这么几个特点我可以介绍一下我的个人感受，具体的你们可以自己听。 王老师这两年一直在倡导公益考研辅导的理念，他的课程会通过各种渠道更新，大家可以免费下载收听（注意，这已经是 2015 年的事情了）。这里的免费不是说让你试听一节课然后交钱，而是基础班，强化班和冲刺班全部免费。当然，之所以推荐他绝不是仅仅因为课程免费，而是满足了我对于考研政治辅导课程的全部要求。 首先，王老师授课内容风趣幽默又不乏深度而且节奏紧凑没有犯困的可能性；其次，一个人负责整个考研政治内容的讲授，各科时间分配合理详略得当，理解是难点的地方（比如马原）他会详细讲解，识记是重点的地方他会说清楚你要记什么背什么；最后，课程只分为基础课，强化课和冲刺课，没有乱七八糟的噱头，利用最合理的时间给你说清楚你要知道的问题，并且告诉你听完课之后要怎么做。 如果你考研政治复习像我一样不想太费心只想跟着一位老师的话，那就跟着王一珉老师吧。 如何把握复习的节奏 其实我本想直接写一句跟着王老师就可以。但是为了让 16 考研人能体会到我是一个比较负责任的靠谱学长，也告诉你们我没有逼你跟着哪个老师的意思，我还是用最简练的语言介绍一下几门课的特点以及我当时复习的流程。 马原 这门课大约占 24 分，内容以理解为主，指望死记硬背是绝对搞不定的。这门课涉及到很多的原理和方法论，我当时是结合着王老师的《考研政治轻松学》和他的基础课来理解学习的。 毛概 这门课大约占 30 分，是分数最多的一门课。选择题中涉及到的知识点比较庞杂，很多大块的内容也是后期背诵记忆的重点。 史纲 这门课大约占 14 分左右，分析题部分可能会和毛概的内容结合在一起考察。应对选择题要把握主要历史事件发生的时间点、 参与者和内容，应对分析题要知道历史事件的意义。 思修和法基：这一部分我个人感觉难点在选择题，各种名词和修饰语的搭配往往容易让人搞混。比如，书上会写：A 是 D 的基础，B 是 D 的底线，C 是 D 的原则，然后问你 D 的基础是什么。 时政和政经 时政到后期会有各种各样的总结，大家不用着急，应付选择题是没问题的，政经部分只会考分析题，最后老师会把可能的考点都列举出来大家理解记忆就可以。 复习流程 A: 基础课视频+《考研政治轻松学》：主要是理解马原部分的内容。 B: 强化课程视频+《考研政治大纲解析》+真题+《肖 1000 题》：听课前大概浏览一下书里的内容；听完一节强化课程跟着老师勾画一遍重点看一遍书；做相应章节的真题，不会的地方回归课本；做相应章节的模拟题，不会的地方再回归课本进行总结。这样一遍下来基本上过了 4 遍《大纲解析》。 C: 冲刺课程视频+时政总结+重点热点考点总结+模拟题练习：这一阶段主要使用的书就是《肖 8》《肖 4》这类的模拟卷，选择题不会的地方要再次回归教材。关键是学习各类分析题的答题方法，对重点和热点内容进行记忆背诵。 关于复习时间 我是从 7 月逐步开始复习的，越到后期给政治复习的时间相对越多。我只能说个人感觉从 7 月开始还不算晚。如果你指望着最后半个月背各位老师的押题来获取政治高分我劝你醒醒，如果你打算现在开始就每天狂背政治或者天天看新闻联播来获取政治高分我也劝你醒醒。 最后，我的政治复习全程跟着王一珉老师，在这里给各位认真的推荐一下这位老师，还不知道他的可以去了解一下，听听他的课、看看他的书、了解一下他的教学理念，如果觉得比较你合你心意，跟着他复习政治我觉得还比较省心。 今天就先针对考研政治复习经验进行一下宏观的分享，更具体的内容之后再说。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-26-tokyr10/"},{"title":"致考研人 9：具体的复习建议","content":" 今天我们按照时间段来谈一谈复习规划 四月开始复习的一些建议 翻了下 《致考研人》 的前几篇文章发现已经是 1 月份的事情了。今天是 2015 年 4 月 7 号，不知不觉 2 个多月过去，也怪自己当时说了一句不同的时间有不同的复习安排，这些天就不断有人问我现在开始的话应该怎么复习。可以预见的是，6 月 9 月这几个时间点也会有人问我同样的问题。 所以抽时间写这么一篇小文，按照时间的跨度说一些复习安排的建议。至于具体的复习思路和方法，比如做真题还是拟题，要不要报辅导班，怎么精读文章之类的问题一概不再赘述，有疑问的可以去查看我的微博（一只思考问题的熊）里的置顶微博，里面涉及的很多问题都解释的比较清楚。 进入四月刚刚打算复习的人不用太着急。如果能按部就班的用正确的复习方法坚持下来是绝对来得及的，另外我下面提到的所有和时间段有关的内容都是针对大多数人而言，以供参考。 关于每天的复习时间 关于每天的具体复习时间，我的建议是** 5 月之前不少于 5 小时，6 月到暑假结束之前不少于 8 小时，9 月开学到考前一周不少于 10 个小时**。 通常 5 月之前课会比较多，第 10 周之后的课会相对少一些，暑假之后基本没什么课了。但是以上情况对于一些需要实习的同学（比如多数学医的人）而言是不适用的。至于每天复习几个小时我给建议的是至少，也就是说这个复习时间是一定要保证的。对于一些还在上班或者二战的人来说可能出于上班忙或者感觉自己基础不错而达不到这个时间那我只能祝好。 另外，很多人问至少要保证的时间还是保证不了怎么办。这个问题我之前在一篇关于考研期间反对泛社交化和碎片化阅读的文章中提到过，假设现在你平均每天有三节大课，在你不逃课的情况下早晨复习 1 小时、1 节空课再加上晚上复习 3 小时就足够 5 个小时的时间了。 增加可利用时间非常简单，只需要早起睁眼之后的第一件事是下床洗漱而不是刷微博签到，中午吃完饭尽快午休而不是狂刷微博微信，晚上睡前不要躺在床上狂刷微博微信。 三轮真题精读的时间安排（阅读部分） 我做了 95 年到 14 年的真题，其中 95 年到 04 年的真题做了两遍，05 年到 14 年的真题做了三遍。 第一轮：3 月——6 月 这期间我还看完了《外刊超精读》那本书。基本上是一天一篇外刊或者真题的节奏。 看外刊的目的是学习精读的方法和老师分析文章的思路，并没有做特别多的扩展，主要是掌握书里给出的内容，为之后自己真题的精读打基础。 真题精读细致且扩展比较多，但重点是词句本身的扩展上和难句的分析以及翻译，对于文章的结构和题目的分析没有很深入，更没关心过题目的对错。 精读一篇真题前期需要 3 个小时左右，做到 05 年以后时间就缩短了，尽管越往后的文章越难可是用的时间却越少，这就是进步的体现。 如果你之前只是背了背单词刚刚打算开始复习，我建议你可以适当缩短读外刊的时间（每篇文章不超过 3 个小小时）或者只做近 15 年的真题也可以。 第二轮：7 月——9 月初 这期间因为有了第一轮精读真题的基础，读文章基本不会因为太多生词或者难句卡住，就把精力重点放在对文章结构思路和题目的分析上。 由于距离上一次做相同的真题已经过去了三四个月，况且第一遍做真题就根本没在意过题目，也就不存在所谓很多人说的做过一遍真题就浪费了真题的伪命题。 第二轮真题流程 第一遍：按照每篇文章 18 分钟的要求（这个时间就是你在考场上完成一篇阅读的时间）完成题目然后对答案； 第二遍：对于自己还是不熟悉的词句再进行学习，分析文章整体结构和段与段之间的逻辑关系，再分析每一段的结构和句与句之间的逻辑关系； 第三遍：分析每一道题目在文章中考察的位置，分析每一个选项正确或者错误的原因，分析错误选项的命制特点和正确选项的特点。结合文章结构和逻辑关系整体把握几道题目的命题思路，同时反思自己做错题目的原因。最后再看一下第一轮精读时的笔记。 第三轮：9 月中下——11 月上 这一轮 05 年之前的题很快就整理完了，所以前面说 05 年之前的真题做了两轮。其实做第三轮真题已经不用花费多少时间，重点是一个整合归纳然后升华的过程。但还是用两个多月的时间是因为后期每天给英语的时间偏少，且要准备除阅读之外的其他题型，另外重心也转移到了专业课和政治上。 第三轮的真题流程 第一遍，按照每篇文章 18 分钟的要求完成题目，一般连续做两篇或者四篇再对答案； 第二遍，要特别重视又一次错做的题目（不要以为做两遍之后肯定不会再错，我当时就依然有错题，这一类的题目很可能在考场上你还会犯错），分析题目类型、命题角度和错误原因； 第三遍，整体把握几篇阅读的题目并进行横向对比，分析每道考题的题型以及每种题型的考法。 最后再看一遍自己之前做过的笔记并对一些内容进行扩展练习，比如仿写造句，积累作文素材。 第四轮模考：11 月中下——考前 特别说明一点，在第三轮真题做完之后要保证有三套真题没有碰过，建议你们留下 10,14 和 15 三年真题（原因是难和新）。在考前一个月每个周末完全按照正式的考试时间完整并之后的一周时间进行消化。 三遍真题做下来之后争取要达到一种什么效果呢？你随便翻出一篇文章里的一道题，能很快地反映出它考察的重点和命题的思路，最好还能想到其他年份考过的一两个类似考题。我在考前还做过一个很无聊的训练——只通过文章结构和逻辑关系找命题点进行解题，用 40 分钟完成四篇阅读。 英语其他题型 作文 6 月开始准备，这个时候你通过精读历年真题已经有了一定的基础。作文准备的具体方法我到时候会再写，主要思路就是以历年真题为重要素材，按照话题来整理相关词汇和句子，背诵真题范文并进行仿写练习。注意，虽然我在这里只写了这么简短的几句话，但是每一点都非常重要！！按照这个思路来准备作文是绝对没问题的，重点是你自己的执行力和完成程度。 翻译 精读真题的过程中其实你也经不知不觉练习翻译，我个人认为 7 月开始精读翻译的近二十年真题就可以，每天只解决一句翻译真题，20 年真题一共 100 句，到 9 月底也就解决了。 新题型 这一部分是按照可能考的几个题型进行分类联系，虽说有一些小的技巧和方法但归根到底还是利用文章结构和逻辑关系解题。 完型 我个人的建议新题型和完型从 10 月开始做历年的真题就可以了。 政治 不用着急但也不能不当回事，因为政治不过线而悲剧的例子时有发生。我的建议是从做完第一遍英语真题（6 月底 7 月初）开始逐步把政治拿起来。复习政治的具体方法会在五月初写给各位。 专业课 专业课的复习我的情况比较特殊，7 月之前我准备报考的学校是考数学的，所以 6 月底我完成了数学的一轮复习。如果你要是考数学的话，我也建议在 7 月之前完成数学的一轮复习。 7 月我参加了中科院夏令营并拿到拟录取通知书之后，经过几天的权衡决定改考中科院。所以从 7 月才开始看 N 本巨厚的专业课课本，由于时间确实很紧张而且考的几门专业课在复习时间的分配上不是很合理导致最后差点栽在一门专业课上。 在这一方面希望吸取我的教训。对于专业课难且多的同学一定要在 7 月前过完第一遍课本对所考内容有一个整体的把握。 专业课如何看课本 第一遍看课本要面面俱到，也就是要尽量看着细致一些可以不区分什么重点，并且对每一个章节梳理一个大体的框架。 第二遍看课本要结合考试大纲来看，分清大纲要求，要求掌握的要重点看，认真整理笔记。要求了解的可以稍微简单一些。 第三遍看课本要结合历年真题来看，做题是碰到不会的内容要回归课本相关知识点。 第四遍看课本要学会自己预测可能的考点和重点来看。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-26-tokyr9/"},{"title":"致考研人 8：夏令营那点事","content":"写在前面 转眼间就要到四月，各个招生单位的夏令营活动又将要开始。这两个月以来一直有考研人问我关于夏令营的事情。今天抽出时间和大家聊聊关于夏令营的问题。 什么是夏令营 经历过高考的人都应该听说过自主招生的情况，记得我那个时候有华约（以清华大学为首）北约（以北京大学为首）和卓越（以北理工和哈工大为首）之类的招生联盟，夏令营就相当于自主招生。 随着研究生招生制度的逐步改革，越来越的学校和科研院所有了更多的自主权来选择招收的学生，知名的高校和科研院所更是如此。其中不乏有推免生名额占到招生总数 70%多的情况。夏令营就是各个单位招收推免生的一个主要方式，一般会在前一年的暑假进行，学校会组织学生参观实验室和导师进行交流，最后会组织考试，选拔出一部分同学。 这些被选出来的同学得到的福利也各有不同，有的单位会发拟录取通知书，所谓拟录取就是我有意向接收你，只要你有自己本科学校的保研名额，就可以不参加统考直接被我录取，说白了就是保研；一些招生单位有降分政策，比如你参加统考之后我可以给你降一定的分数进行录取或者只要过了我的初试线可以免复试录取；各个学校的政策都不同也挺复杂，具体某个学校的情况可以自己了解一下。 夏令营时间 各个学校夏令营的时间不尽相同，一般 5 月左右是报名的阶段，7 月左右是正式夏令营的阶段。所以进入四月中下旬以后，有意向参加夏令营的各位一定要时常关注一下自己想报考学校的网站，一般在招生页面或者研究生院的主页都会有通知。如果新的还没有出来，你可以翻翻它以前的通知看看去年举办夏令营的时间。一般一个学校每年夏令营的时间不会差太多。 有一点需要特别说明，从去年的情况来看，有一些知名高校和科研院所之间的夏令营时间是重叠的，有可能是巧合也有可能考虑到生源竞争的问题。 报名条件 这可能是大家最关心的一个问题，具有什么样的条件才能参加夏令营呢？这也要根据不同招生单位的情况而定。但是有 3 个普遍规律。 211+985 的高校只喜欢 211+985 高校的学生，很多招生简章里直接写明了 211+985 高校的学生才可以报名； 211 的高校，很喜欢 211+985 高校的学生，对于 211 的学生也乐意接受，比如会在招生简章里写明 211+985 高校专业排名前 30%的学生可以报名，211 高校专业排名前 10%的学生可以报名，普通高校的专业前 3 名可以报名； 科研院所因为自己不算是大学，所以有一些（注意：是有一些）并不会特别在意 985 或者 211 的名号，一般在报名条件里只会写一些相对宽泛的条件比如学习成绩优秀有一定科研能力英语水平较好之类的内容。 另外，还有一些具体的条件是需要注意，比如你的英语成绩（四六级或者雅思）越好，有一定的实验经历，参加过一些相关的科研实践活动被选上的可能性就越大，这些东西不用解释大家能都明白原因。 需要注意的是，即便一些招生单位没有写明非 985 或者 211 高校的学生不要，实际上他们也是这样做的，所以你在决定报名之前最好能找到以前参加过这个地方夏令营的学长学姐咨询。 报名材料 这些东西没什么可细说的，报名通知里都会写到。主要包括本科成绩单，各类证书复印件，报名表，教授推荐信等等一些内容。报名表里一般都会让你填写自己的学分绩点、参加过的活动、获得的奖励等等内容。 如何准备（夏令营考什么） 如果你觉得自己够心仪院校夏令营的基本条件，我建议都不妨一试。因为正如一开始所说，随着招生政策的逐渐改变越来越多的学校加大了推免生录取的比例。 一般来说，夏令营考察的内容其实是不需要你花太多时间准备的，主要看你平时的积累。但是如果你报考的专业和你本课所学专业不同，那你就得提前看一看拟报考专业的专业课课本了。 前期的准备需要针对你所报考单位夏令营考察的内容进行。 考察内容无非包括专业课知识、英语水平和综合素质这三个方面。专业课和英语的考察又可以分为笔试和面试两种形式，综合素质这一部分主要是通过面试考察。拿我自己参加的夏令营举例，当时只有面试没有笔试环节，一进去老师示意我坐下先念了一段英文文章并进行翻译，然后又问了一个英语问题，需要用英语回答（之前准备的英文自我介绍没用，可能老师也知道这个体现不出什么真实的英语水平，但提前准备一个还是必要的）。第二个环节是专业课知识测试，会有考官专门负责提一些专业课相关的问题。第三个环节就是在场的众多院士和研究员与你进行交流提问，问的问题说五花八门，即涉及实验专业课问题也涉及和时事热点有关的问题。 所以在参加夏令营之前可以适当的练一练口语，看一看专业课一些基本的概念，整理一下本科参加的实验和活动相关的一些内容，另外对相关领域的一些热点问题也有必要适当了解。 其他几个问题 报几个夏令营比较好 个人认为最多不要超过三个，可以挑一个自己感觉把握比较大的，一两个自己比较想去的。如果能通过不止一个初选而且夏令营的时间不冲突那你可以都去参加一下，如果有时间冲突的就自己做一个选择。 用不用提前联系那边的老师 我是没有联系，去夏令营的目的就是了解那边的学校和老师的情况，如果真的通过了最后的选拔，并且在夏令营的过程中发现了心仪的老师可以参加完夏令营再有目的的和老师联系。 怎样通过的可能更大一点 这个问题其实没法回答，你越牛通过的可能性就越大。多数学校会将几项考察内容按一定权重加和，所以你最好在某一个方面做的比较好。要么英语对答如流，要么专业课基础很扎实，要么在和老师交流的过程中思路清晰答出他们想要的点。再或者，人品很好，问的都是你会的。 应该怎么对待夏令营 夏令营之类的活动虽然说越来越多但是毕竟还是有一定条件限制的，而且决定参加就势必会投入一定的经历和时间，这就有可能打断自己之前的复习计划。参加夏令营被很多人认为是高回报的事情，必然也会伴随着一定的风险，所以希望考研人要先对自己的情况有一个正确的认识，如果决定参加就能认真准备。 附两个招生单位的报名要求 浙江大学某学院 本次夏令营拟面向全国“985”、“211”院校及普通高校国家重点学科专业招收营员 50 名，活动旨在促进全国高校优秀大学生间的交流互动，激发大学生对农业与生物技术相关领域研究的兴趣和热情，促进大学生了解相关专业领域的前沿动态，并创造优秀学子继续深造的机会。活动期间将为营员安排参观校园和实验室、2015 年研究生招生政策及 ZJ 大学研究生培养政策解读、学术讲座、名师面对面、优秀学长交流、基地考察等活动。 一、申请条件 1、具有浓厚的科学研究兴趣，并有较强或潜在的研究能力，有志于科研工作； 2、英语水平较好，学习成绩优秀。本科期间成绩总排名“985”院校在本专业 20%以内，“211”院校在前 15%以内，普通院校重点学科专业前三名。如有出色科研成果者学习成绩标准可适当放宽； 中国农业科学院 申请资格 1．来自全国高校的 2015 年优秀应届毕业生； 2．本科现阶段成绩排名在专业前 5%，“211”或“985”高校毕业生可放宽至 15%； 3．能够获得所在学校推荐免试攻读硕士研究生资格者优先； 4．对所学专业有浓厚兴趣，愿意从事科学研究工作； 5．英语四级成绩在 425 分以上，通过英语六级者优先 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-26-tokyr8/"},{"title":"致考研人 7：四六级那点事","content":"这两天四六级出成绩，毫无意外的，不少人和我说 “我六级还没过，对考研没信心了。” “我四级还没过，是不是没法考研了？” “你说我考了三次六级还没过，是不是在学习英语上先天就有缺陷？” 操心如我，再把四六级和考研英语的问题说一下。 首先，我说四六级和考研英语没太大关系。你可能会问：“不对啊！四六级考试是英语，考研英语也是英语，都是英语怎么能没太大关系呢？”老实说，我觉得这两个考试本身和真正的掌握一门语言最多就有半毛钱关系。你考试分数高就敢说自己英语好么？既然这两个考试和真正的英语没太大关系，你也就别用英语把他们往一块扯。 我们就把其当作两个单纯的考试来看。这两个考试考察的侧重点不同、目的不同。四六级考试整体的难度在于给人一种时间上的紧迫感，对英语文章的逻辑性和其他细节方面的考察并没有多难多深；而研究生考试其目的是为了选拔高层次人才（姑且这么说，我知道研究生其实也没什么层次），这些人多数是要做实验阅读大量外刊文献的，所以考研英语尤其注重阅读能力的考察，阅读上又尤其注重对文章细节和逻辑关系的考察。 另外，四六级的分数和考研英语分数没太大关系。首先说明，我的意思不是说你四级考 300，考研英语就一定能考 60，尽管这种可能性是确实存在的。 面对四六级成绩，你首先要分析自己没考好的原因。我之前说一件事情如果做不好只有两个原因，一是你不够努力，二是你努力的方法不对，现在我再补充一个心态的原因。不过话说回来，如果你准备的足够充分，考场上是不会过分紧张的。 如果你六级考了三次没过的原因是因为次次裸考，它只能说明你的学习态度有问题，就是不够努力。 如果你六级复习了半年还是没过，那就是你复习方法的问题。今天有一个人给我说：“我一直是阅读好但是听力不好，不过平时练阅读的时间要远大于练听力的时间。”我追问他为什么听力不好反而要增加练阅读的时间，他的回答是：“你不知道，我一开始是想准备听力的，后来听了一段时间发现没什么提高就又做阅读去了。”（这种现象就是我在之前的文章**《致考研人 6：写在开学之前》**中提到的“人都有这么一个心理，总是喜欢做能让自己体会到成就感的事情。换句话说，很可能你某一门课之前学的越好，你就越不自觉得花更多的时间在这门课上。再换句话说，很多时候你不是因为喜欢一件事情而把它做好，而是因为你发现自己能做好才喜欢。”） 四六级不过你要做的是分析原因而不是整天担惊受怕心灰意冷（又回到了之前文章中谈到的“幻想”问题）。分析出原因然后对症下药，如果是不努力你就要比自己努力（不过次次裸考的人想在考研复习中做到努力并不容易）。如果是方法有问题，你就要去学习摸索适合自己考研复习的方法。 至于考研英语的复习方法可以参考我的文章**《致考研人 2：英语复习经验》**。 好了，以后强迫自己写东西尽量不超过千字，就写到这儿吧。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-26-tokyr7/"},{"title":"致考研人 6：写在开学之前（关于困惑和迷茫）","content":"写在前面 开始之前先说一点题外话，我发现在微博上只要我说个什么自己的小故事或者和你们扯几句，这浏览量就蹭蹭的往上升，每天发的那些干货，还真没多少人搭理我。 各位不要不在意这种现象，我说个小故事。之前我听一个老师的课时，他说：“每年我的基础班全国能有十几万考生听，到了强化就剩几万了，到了冲刺就没剩下多少人。成功的学生其实就是那些坚持到最后的人。” 关于困惑和迷茫 今天是 2 月 27 号，上午有人跟我感叹“好快啊学长，再过 3 天就到 3 月了！”我当时是真想说一句“（你连一个月多少天都活糊涂了）你要是这么准备考研，肯定是重在参与。” 这些天你们应该就陆陆续续的返校准备开学。寒假不管长短就这么溜走了，现在回头想想放假前你自己的那些豪言壮语是不是觉得自己根本就是猴子请来的逗比？ 以我个人的经历和其他学姐学长的经验来看，每年的这个时候考研人应该会遇到考研周期的第一个迷茫期。一部分迷茫自己要考什么学校；一部分人迷茫自己要不要跨专业；大部分人是回到学校，看到身边有那么一两个考研的同学已经开始复习，于是自己心里内疚惶恐可是又懒得动。（你觉得这类人奇葩么？但你仔细想想，心里着急可就是不行动，这种情况是不是发生在你自己的身上？） 关于选学校和专业的问题，我之前是用“教你找男女朋友”这事来解释过，如果想看可以翻一翻我 2 月 6 号发的长微博。 另外，针对“心里光想却不行动”的情况，我前几天写过一篇文章**《致考研人 5：写在新年之前》** 今天我还被问到了这样三个问题： “你说怎么样就算下定决心了” “你说我是不是考不上想考的学校” “学长，你说复试我该准备点啥” 如果你是我，你说这三个问题我该怎么回答。 三者看似没关系，但就目前这个阶段来看，其共性就是“幻想”。整天很忙的活在自己想象的生活中，要么想着自己考不上之后的悲惨人生，要么想着自己顺利通过初试的光明坦途，要么就是一只在想自己到底想没想好（有点拗口~）。 我的建议很简单，还是那句话，拿起书踏下心真的开始做点什么，哪怕是每天用 20 分钟时间看看我分享的内容然后整理整理笔记。无论什么看似简单的事情，只要坚持一段时间都会有很大的改观。举个通俗的例子，你连着睡上一个月（睡觉多简单）什么也别干，估计就能进化成一只可爱的考拉。 希望你们记住，大多数人都不是靠拼智商取胜的，只有少部分人可以靠智商碾压对手，而且针对绝大数人来说根本就轮不到拼天赋得地步。 一个人如果最后没有做成一件事，我能想到的只有两个理由：要么他不够努力，要么他努力的方法不对。所以对你们而言，最重要的是摸索出一个适合自己的正确复习方法然后坚持下去。 开学以后，大部分人都开始复习了，在这里我还有两个特别重要的提醒！ 人都有这么一个心理，总是喜欢做能让自己体会到成就感的事情。换句话说，很可能你某一门课之前学的越好，你就越不自觉得花更多的时间在这门课上。再换句话说，很多时候你不是因为喜欢一件事情而把它做好，而是因为你发现自己能做好才喜欢。 对于复习而言，复习初期你一定不能逃避，越是心里没底的越是不会的越要迎难而上。我有一门专业课，一共有 4 本参考书，每本都是 600 多页。你知道看第一遍的时候我有多么绝望无助么？可是咬牙挺过来，生活原来这么美好！当然，在复习的后期如何平衡各科的时间就是后话了，到时候我们再谈。 人还有这么一个心理，总是喜欢拿身边的人和自己比较。就是表面不说也会背地里偷偷地打听别人的复习进度。我觉得研友、同学之间相互多交流多沟通完全没有问题，但是你一定要摆正自己的心态。所谓摆正自己的心态是指，看到别人复习的慢不狂喜，看到别人复习的快不慌张。 现在，让我们一起背一遍：“不以快喜不以慢悲”。 如果别人英语真题做的快，你别慌，可能他根本不懂什么叫做精读。等他做完一遍真题，你就上去这么问他，“听说你真题都做完啦？好厉害呀！我昨天做了一遍没读懂，你给我分析分析文章结构，讲讲这几个单词怎么用吧”。看他崩溃不崩溃…… 如果没人数学复习的很慢，你都做完全书了他还没做完课后习题。你可以和他说：“来，我课本都看完了，你哪些题有问题咱们交流一下，或者你有什么定理不明白我给你讲讲”，他问完，你看看自己崩溃不崩溃…… 如果你对总体的复习或者英语的具体复习方法还没有什么头绪，可以参考我已经写好的几篇文章，没准就会对你有些启发。 16 考研人，让我们一起在靠谱的路上越走越远，加油！ 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-25-tokyr6/"},{"title":"致考研人 5：写在新年之前（关于行动和幻想）","content":"写在前面 继致 16 考研人系列的前四篇文章之后，打算再写篇稍微长点的文章，和过去的一年道个别，也给和大家一起成长的 2015 个头。 今天是除夕，作为一名考研党不知道你是不是已经进入了过年模式。昨天在微信公众账号里做了一个只有两道题的小调查，截止到写这篇文章时，一共有 99 个人参与了调查。第一道题关于整体复习进度，其中犹豫报考哪所学校的人有 13 个，正在搜集资料中的有 19 个，已经开始复习但是效果不理想的有 59 个，每天有固定时间复习且有一定效果的有 8 个。第二道题关于英语复习进度，其中整理资料的有 16 个，已经开始背单词但没什么效果的有 45 个，每天有固定时间背单词且有一定效果的有 27 个，已经开始做早年真题的有 11 个。 把结果公布在这里目的只有一个，请对号入座你自己是哪一类人。 为什么已经开始复习却感觉没效果 先给大家说一个可能很多人都存在但却没有意识到的问题。 为什么已经开始复习了却感觉没有效果？（关于决定、幻想和计划） 也许高考发挥失常你去了一个自己不是很满意的大学，也许在大二大三的时候你开始思考自己今后想过一种什么样的生活，也许最近你突发奇想要给自己找点儿事儿做，不管什么原因，你做了一个考研的决定。 做决定是一件很简单的事情，你躺在床上、走在路上或者看见各种考研成功的经验贴，然后血脉喷张就可以做出一个决定，比如”我要考浙大！“”我要考清华！“”我要考中科院！“”我要……“。人一旦做了某个决定，就会处于一种极端兴奋的状态，比如当你嘴上说出我要怎么样的时候，你心里其实想到是自己已经怎么样之后的情景。这种情况可以称为美丽的幻想。 你看着别人的成功心里想象着自己成功时的样子，你看着别人失败心里想象着自己可不能这么失败。 当你稍微冷静的时候你就又会想我是不是考不上，我是不是定的目标太高，然后又开始看各种经验贴，你看着别人说看什么书，你看着别人怎么复习，每读一遍你就又会自我麻痹的在心里想象着自己成功了一次。 这类人最怕的是面对现实，一个念头让你做了决定，然后依靠每天的幻想度日。 这类人的具体表现 每天想的最多的是两个问题：我到底能不能考上？我考上了以后应该怎么办（怎么准备复试，我有两篇论文能不能为复试加分）？ 这类人有自己的目标和计划（比如背单词）也有自己可以支配的时间（比如下班后每天有 4 个小时，寒暑假每天有 8 个小时），可是每天却在惶恐中度日。 白天在思考上面两个问题中度过，晚上睡觉前想着我装装样子也要背两页单词。拿出一本很厚的词汇书，心想这么厚的一本书要想看出点效果必须要用整块儿时间，我还是明天拿出两个小时认认真真的背一下。然后你躺在床上又拿出手机继续看别人的经验贴，看那些心灵鸡汤，继续幻想。 翻着朋友圈你看了一个“自我管理的 XX 条法则”又看了一个“XX 成功的 XX 条经验”，再想想自己一天的得过且过内心既惶恐又亢奋，接着心中又幻想出自己明天奋发向上的样子。 然后呢？你又刷了一个小时微博，看到了某名师分享的“教你如何 7 天搞定考研单词”，心想尼玛这不就是我要找的东西么。然后赶快收藏保存安然入睡。 周而复始，每天晚上闭眼前你都后悔自己又虚度了一天的时光，每天早晨睁眼后又都迎来了即将虚度的一天的时光。你在这样的状态下复习，在这样的状态下背单词是不可能有效果的，甚至在背单词的时候你想的都是你记住这些单词的画面。 **你每天用很多的时间幻想，用很少的时间复，你幻想着把你看过的东西都记住，可是每天晚上你又发现自己什么都没记住。**为了让自己有继续下去的动力，你不得不继续幻想第二天记住更多的东西。 其实，并不是你记住的太少，而是你根本就没看什么。 并不是你已经开始复习却没有效果，而是你根本就没开始踏实复习。 这些都是自己的幻想罢了。 一定不要活在“今天的努力是为了明天的成功”这样一个状态里。各种各样的心灵鸡汤告诉我们“你今天的努力是为了明天的成功”，这种说法本身就让你陷在自己的幻想中。谁都不知道明天会不会成功，甚至你连自己今天有没有努力都不清楚。 我希望大家暂且放下“我要考 XX！”的宏伟目标，暂且放下“我要用一个月背会 XX”的想法。你要做的就是去复习，去看书，去背单词。每天起来自然而然的背单词，每天下午自然而然的看专业课，每天晚上自然而然的精读一篇英语阅读。其他的不要想，不要想着我今天一定要背多少单词，不要想着我考试的时候英语要得多少分。就是简简单单平平淡淡的把该做的事情都最好，一周之后、一个月之后你再回头看一下，你会发现自己其实不知不觉的就掌握了很多东西。 这也就是我会给大家分享复习的方法，分享一些考试内容，却没有给大家定一个具体时间表的原因。如果你定了 4 月开始精读真题，可你有没有想过其实本来明天就可以开始？如果你定了 5 月之前把考研词汇搞定，每天幻想着自己 5 月之后搞定考研词汇的幸福生活，然后到了 4 月发现自己其实只翻了几页词汇书，这个时候你要怎么办？你肯定就崩溃了。 你要做的只是规定一个大概的时间段完成一件可以完成的事情，比如每天 2 个小时用 20 天的时间把我目前不会的单词过一遍，记不住也没关系。再用 20 天把还不认识的单词再过一遍，这样重复 5 个 20 天，同时这期间你已经开始精读文章开始学单词，对很多词汇都有了更深层次的掌握。100 天之后你再拿出词汇书看看自己还有多少个单词不认识。很多事情功夫下到了都是水到渠成的事情，别再活在幻想中然后惶惶不可终日了。 再说说我自己 2015 年 1 月 26 日开始在新浪微博（一只思考问题的熊）每天和大家分享一些与考研相关的内容，到今天微博关注人数从 200 增加到了 785。 2 月 1 日开通微信公众账号（ibear_share），不定期的和大家分享一些考研资料和自己的心得。到今天关注人数已经有 279 人。 从考完研决定为 16 考研人做些什么事情开始到今天，我只是和大家分享了一些自己关于考研的感悟，每天在空间和微博上分享一些和考研相关的内容（比如一些英语新闻的解析）。能有越来越多的人信任我，其实很简单，就是因为大家认可这样一个相对靠谱和认真的人同时也希望自己能够靠谱和认真的复习下去。 当然，我也深知这样的信任来之不易，想要保持更是难上加难。这 20 多天来，很多第二天一早你们看到的内容都是我在前一天很晚或者第二天早晨很早起来整理的；微信上发的一些文章也是我在白天抽时间一点一点码出来的；每一个人的问题，只要我能回答的我都尽量去回答。现在基本上每天都有几个小时坐在电脑前和大家扯淡答疑。那么问题就来了，和我相比，看到这篇文章的 16 考研人，你是否已经把一件事情坚持了 20 多天，比如每天背 2 个小时单词，每天精读一篇阅读，每天看 2 个小时专业课，亦或者坚持 20 多天每天看看我分享的东西，做做笔记顺便找找茬。 我一个已经考完研的人，都能够不为了什么宏大的目标就是简简单单地做一件事情，然后开始慢慢地坚持下去，你作为一个已经决定了要考研的人为什么就做不到？坚持其实没那么难。 我不知道自己再过一阵子会有什么事儿，但是可以想象毕业论文、实验实习等等都不会让我过的太悠闲。我不知道要做的那些事情能让我的明天变成什么样子，也不知道我今天为大家做的这一点事情对于明天的我有什么意义。但是这都不重要，我想只要在自己力所能及的范围内坚持下去，再过一个月、半年、一年之后回头看看，肯定能体会到这段日子对我自己的影响。而你们只要把这将近十个月的时间坚持下去，回头看看，肯定也能体会这段日子对于你们的影响。 最后再说说你们 所谓春节，无非就是一个普通的时间点罢了，两个春节之间就是一年。对于一个考研人来说，更重要的一个时间点是考试。春节该过还是要过，压岁钱该拿还是要拿，只是如果你已经开始复习，这七八天最好不要停下。考研复习这件事，什么时候开始不是最重要的，最重要的是开始了就不要停下。 春节这几天我会再把这 20 多天分享的内容做一个整理和汇总。如果你们有关于考研整体复习、英语复习、如何使用好手机、怎么选学校、保研、感觉复习没有效果等等问题都可以翻翻我这一阵子的微博、空间或者微信公众账号，这些内容我都有涉及到。 祝各位春节快乐，每天都过的充实幸福。 2015，让我们一起进步，再靠谱的路上越走越远。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-25-tokyr5/"},{"title":"致考研人 4：关于保研","content":"写在前面 这篇文章是拜托我的学霸同学所写，她今年（2015 年）拿到了本校（非 985 非 211) 的保研名额并且顺利保送至自己心仪已久的北京林业大学（211）的重点专业。希望这篇文章能为在保研问题上有疑问的同学提供一些帮助。 以下为文章正文。 文章正文 浩浩荡荡的考研刚刚过去，对于我这个保研党来说有着说不出的感觉，不知道自己是幸运还是遗憾。最近有个热心的靠谱学长找我写一写关于保研的文章，一时不知道从何说起，对于保研我也是从 2014 年九月份才开始了解，所以只能说是总结小小心得，希望对想要保研的学弟学妹们有所帮助。 首先，对于保研最关键的问题是自己要想清楚：你到底要不要读研究生，想要报哪个专业，是不是对研究生的生活真正有兴趣。 通过这次保研，我发现老师们关心的是：学生到底是不是真的对某个专业有兴趣以及学生的研究思维。保研的好处在于可以提前确定自己的研究生资格，省下时间做自己的实验或者其他想做的事。但是，没有了考研党几个月甚至一年的系统复习，就我自己来看似乎专业知识不如考研党掌握的牢固。 再解释一下 2015 年入学的研究生新的保研政策。今年之前很多院校（包括我的学校）保研名额只限报本校的研究生，所以想要考到北林的我一直没有考虑保研的事，新的保研政策真的是施行得太及时。 保送研究生与统招研究生报名系统今年在研招网（研究生报名的官方网站）第一次彼此独立，也就是说参加保研的同学就不用再报名参加研究生统考报名（以前是得到保送名额还要参加统考报名只是不再考试）。参与保研的学校（至于你所在的学校有没有推免资格你应该比较清楚）有推免资格和接收资格，想要保研的同学首先得到自己本科学校的推免资格，之后登录研招网的研究生报送系统进行网络报名选择自己心仪的学校与专业（一次最多选择三个学校，有点类似于高考填报志愿儿），得到复试通知后再参与报考学校的复试，若通过复试即可得到报考学校的接收资格，在教育部审核通过后，即代表保研成功，可以登录研招网查询到自己的相关信息。 但如果不幸没有成功保研，大家还是可以再报名研究生统考的，一般保研结束时间都在研究生统考正式报名截止日期之前，大家不用担心保研失败后不能再参加研究生统考的问题。 关于保研成功的条件。参加研究生统考，不管你在大学是学渣还是学霸，只要复习的这一年方法得当能够坚持，基本上都会有好的结果。但是想要保研的话就需要你前三年的成绩比较优秀，拿我所在的学校举例，前三年综合测评成绩在专业前 15％的学生有资格参与学校组织的推免面试，最终选出专业人数 3％的学生得到推免资格。所以想要保研前三年成绩不过关的同学基本是没戏了。 当然，学校不同教育部给的推免名额也是不同的，简单的说就是如果你的本科学校越好推免名额就越多。 除了成绩优秀外，我觉得还需要尽可能的获得心仪学校与导师的信息，最好的方法就是问自己本科的导师与已经读研的学长学姐们（最好是研二及以上的，他们对于每个导师的信息了解更加全面）。你可以提前与报考的导师联系（但也不用明天就去联系导师），我建议现在学校网站上了解老师的相关信息，再发邮件向老师说明自己的意向和个人情况等，一般老师们都会给回复的，发邮件尤其注意礼貌。老师都喜欢实践经验丰富的学生，你们如果有在做实验的话也可以问一下联系的导师，他们会很乐意回答的。 我在联系导师时看过一些论坛的经验贴，有些人是一次联系同一学校的几个导师，也有些人是联系不同学校的导师，我觉得想要保研成功率最大，多联系几个导师是自然的，但是大家也要考虑多个导师同时说想要你的情况，不要到最后弄的自己很尴尬。对于那些目的性很强的同学，就不要纠结，选定自己心仪的学校与导师就行，大不了保研不成功再参加研究生统考，不要最后让自己遗憾。我当时就是纠结了好久，选了无数个学校和导师，最后还是没有放弃自己一直想去的北林，坚持一下没想到就成功了。总之，考虑太少就会太草率，考虑太多就会让自己很混乱，越来越怀疑自己。 另外，关于保研复试考什么的问题不同的学校不尽相同，你可以向有复试经历的学姐学长请教。但是无外乎是专业课知识、英语水平和现场的面试表现，所以你如果有比较大的把握能够拿到推免名额参加面试的话好好复习你的专业课知识和英语（包括口语）是很必要的。至于什么英文的自我介绍这类比较浮夸的东西临近准备一下也可以，老师们最看重的还是你的真本事和思维能力。 最后，我想说的是，保研没有想象的那么困难，要相信自己的实力。如果保研不成功也要踏实复习，争取在统考中取得好成绩。 原作者：清风笑露 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-25-tokyr4/"},{"title":"致考研人 3：如何用好你的手机","content":"写在前面 最近有不少准备考研的人都问到过所谓“怎么利用好手机”的问题。 今天就这个问题谈谈我的建议，作为致考研人系列的第三篇文章。在写这篇文章之前需要说明，我绝非鼓励你在考研复习这个阶段每天在手机上花费的时间过多。但如果你是一个离不开它的人，了解一下怎么高效地利用好你的手机就是一件非常有意义的事情。 你接下来看到的文章是我最初写于 2015 年的，这次整理我删除了一些已经变质的部分应用和公众号，补充了一些近段时间发现的还不错的内容。 近半年来，其实我一直也在思考如何提高信息的获取效率和吸收效率，下面这些内容其实都很难做到获取和吸收得高效率，我目前主要是使用 RSS 配合 Pocket/Instapaper 再加上印象笔记来处理信息。 有时间的话可以在博客单独新写一篇文章。 手机里不要有什么 如果你手机里有类似于“我叫 MT”或者“阴阳师”亦或者之类需要每天刷副本的手游请卸载，想玩游戏的话下载一个“糖果传奇”就得了。 如果你酷爱看韩剧的话，手机里的“爱奇艺”一类请卸载。如果实在忍不住就用电脑看一眼吧。千万别在手机里缓存上五六集电视剧，到了教室背一页单词就看一集电视剧。但挑上一档综艺节目每周看一次还说得过去。 手机里需要有什么 微信 自从第一篇文推荐了几个公共账号之后就不断有人问我相关的情况。这里给大家再推荐几个我觉得还不错的微信公共账号（直接搜括号里的内容即可），之后如果有更好的，我会及时给大家推荐！ 政治 侠客岛（xiake_island）; 学习小组（xuexixiaozu） 推荐原因：第一篇文章里写过如果想看麻烦你自己找找吧，其实这两个我已经很久没看过了。 英语： 孟庆伟英文写作（justintheeconomist） 英文阅读（read_the_economist）幕后作者是大名鼎鼎的魏剑峰 英语学习笔记（ericzenglish） 推荐原因：这可能是目前相对靠谱的三个英语学习经验分享平台了，尽管他们已经完成了最初的阅读量积累并开始寻求变现，但是历史消息里的英语学习方法论都值得你去思考和琢磨，当然，能实践成什么样就看个人得造化了。 中国日报网双语新闻（Chinadaily_Mobile） 推荐原因中国日报官方的公共账号，会涉及很多热点的新闻和最新的词汇，我现在每天也在看。 译者说（translatorcn） 推荐原因：翻译爱好者民间自发组织，应该也是魏剑峰牵头，不定期推送主要是经济学人的文章和译文。 英语 PK 台（goingforgold774） 推荐原因北京外语广播英语教学节目《英语 PK 台》由主持人京晶和多位来自不同国家不同文化背景，英语教学经验丰富的中外籍嘉宾共同搭档制作。节目风格热情活跃幽默，英语教学实用性强，而微信公众账号则提供了主要的广播学习文本。 综合类 一只思考问题的熊（ibear_share） 强烈推荐 平时阅读 如果想读一些高质量的文章，摒弃太过碎片化的阅读，推荐两个自己时常会看的公共账号：大象公会（idxgh2013)；果壳网（Guokr42） 学术类 如果你认为自己考上研究生基本已成定局，想提前了解一些学术方面的东西，这里也有几个公众账号推荐给你：中国科学院下属的官方账号中科院之声（zkyzswx）；《环球科学》杂志下属的环球科学 ScientificAmerican（huanqiukexue）；饶毅主办的知识分子（The-Intellectual）；如果你是大生物类的学生，那么 BioArt（BioGossip）和 23Plus（epi23plus）你不应该错过。 考研用得到的应用 英语词典 欧路词典或类似离线词典软件 自己在使用了市面上多数词典软件之后，最终选择了欧陆词典，我想这应该是安卓手机上最好用的离线词典了。在软件后台运行的情况下，可以自动取词即指即译；支持 Mdict 词典格式和灵格斯词典格式。 也就是说之要你有 mdx 格式词典资源都可以存到手机里进行使用，无论是柯林斯还是牛津双解还是朗文通通没有问题。注意，完全不需要联网。 用这类应用查单词，实际上你每次翻的都是柯林斯、牛津、朗文这样的词典，至于这几本词典的牛逼我就不赘述了，再次强调一定要多看英文释义。 vocabulary.com 注意，作为考研英语的学习而言，使用欧路词典完全可以解决问题。但如果你也是一个英语学习爱好者，并且想要感受单词的力量，我想你推荐下面这个网站以及它配套的手机应用。 vocabulary.com 本身是一个英语词汇的在线学习网站，这个网站主要有两个功能：The Dictionary 和 The Challenge （查词典和巩固练习）。对于单词的解释首先给出一个情景，然后在情境之中，利用简单的语言来描述这个单词。另外，高级搜索功能允许你选择词性，或者限定同义词、反义词、首字母等进行搜索。Vocabulary.com 中的例句绝对是来自最新的外刊报纸，比如 Time, The New Yorker, The Economist。更加黑科技的是，你可以选择这个词来自不同领域的例句。 至于练习功能，你完成网站注册后，在学习单词的过程中可以选择 “start learning it now”, 然后这个单词就会自动进入到你的学习计划中。同时你也可以在自己 Profile 中查看对这个单词的掌握程度，在 Challenge 模式下中，系统会以不同的方式来检验你的学习效果。真的是一个神器！ 和网站配套的也有 Andriod 和 iOS 系统下的客户端，当然需要联网使用但不需要翻墙。 英语新闻 Smartnews：是一款综合类新闻阅读应用，不需翻墙，新闻订阅源异常丰富，包括 Bleacher Report，FOX News ,BBC,CNN,Retuers,NBC, USA today,Business Insider 等等，如果手机内存有限，只要这一个完全没问题。另外，新闻内容可以无缝保存到印象笔记或者 Pocket，方便进一步阅读学习（针对安卓，）。 News Digest： Yahoo 出品，从用户体验和相关新闻扩展以及产品设计上来说完胜上面两款软件，每天早晚各推送 10 篇左右新闻。喜大普奔的消息是，现在它暂时也不需要翻墙就可以阅读。但是这个软件本身不支持选词和复制，通过邮件分享到 instapaper 中进行精读会更加方便。 Newsela：非常科学的英语阅读利器，每一篇文章都有若干个不同的难度供你选择，而且更加神奇的是还有阅读理解题等着你。简直不能太适合考研的学生。 英文阅读 Quora：类似于中国的知乎，关注你感兴趣的话题即可以学英语又能长知识，但貌似需要翻墙使用才会更快。 Medium: 类似于中国的简书，文章较长题材和内容十分丰富。但现在好像需要翻墙阅读。 英语听力 朗易思听：这应该是目前资源最多最好用并且每天都有更新，同时在 iOS 系统和 Android 系统都可以用的听力学习软件了。顺便推荐一个播客：English as a Second Language，不仅可以练习听力，里面还涉及到大量的英美文化背景知识，有时间的话多了解一些没坏处。 背单词应用 我的个人观点是背单词最主要的还是有一本单词书踏踏实实去看，用手机背单词最好只是辅助。这类应用有很多，我也试用过不少，但是没有什么特别值得推荐，相对而言扇贝应该用的人更多些，有打卡机制和学习小组。 其实，最实用的还是各种英语词典软件上都有的单词本功能，查完不认识的单词加入生词本有时间都翻看一下。另外，还记得 vocabulary.com 么？用来学习单词也绝对是神器。 政治类应用 注意政治类的应用已经很久没看了，其实这些软件发展到后期都是一个平衡如何挣钱和不坑学生的问题，大家明辨是非自己下载体验一下吧） 粉笔考研题库&amp;口袋题库考研 这两个应用的主要功能都是配套后期做题使用，尤其以政治选择题为主。相比而言前者题库较大（但是有些解释和答案会有问题），而后者有知识点总结。我个人比较喜欢后者，没事的时候可以背背考点，有兴趣可以自行体验，不再赘述。另外，需要说明的是，这些东西仍然只是非常次要的辅助手段。 社交类应用 新浪微博 微博现在时间流之混乱广告之多已经让我忍不了，所以现在基本也不怎么用。但是如果你一定要用，我还是可以给你一点建议。 设置特别关注分组或者申请考研专用小号，只关注你需要关注的人（比如这篇文章的作者）。当你在犹豫要不要关注一个人时，可以先翻看一下他的微博，关注一下更新微博的频率和内容。如果全是自拍照全是广告建议慎重关注。 固定浏览微博的时间：中午饭后，或者晚上在宿舍泡脚的空档。如果有，建议改掉早晨一睁眼躺在床上先刷微博和晚上睡觉前狂刷微博的习惯。 学会如何找到自己想要的东西，一般来说一个博主会把最想让你看到的内容编辑到置顶微博，所以有置顶微博的一定要留意一下。另外，在每个博主的主页都有搜索功能，比如你想看看他有没有发过关于考研政治的内容，那你可以尝试输入微博进行搜索。 阅读笔记类应用 电子书阅读器 很多时候我会分享一些 mobi 格式，epub 格式和 pdf 格式的电子资料，然后很多考研人并不知道该怎么使用。在这里进行一下简单的介绍。 如果你想阅读** mobi 格式的电子书，有一个 kindle 那自然是再好不过了。如果没有，你可以在其官网或者应用商店下载 kindle 阅读软件，读起来也是没有什么障碍的。至于怎么导入书籍怎么购买书籍，自己去百度一下就可以。 如果你想阅读 epub 格式或者 pdf 格式**的电子资料。手机是 andriod 系统，推荐大家使用“多看阅读”。这款应用的用户体验确实不错，而且 pdf 格式和 epub 格式的电子书都适配的比较好，当然，广告的事情就别说了。如果你是 iPhone 用户，那自带的应用 iBooks 就完全可以满足你的阅读需要。 稍后读类应用 Pocket &amp; Instapaper 很多时候我们在手机里或者电脑上都会看到自己喜欢的文章可是却没有时间立即读完，这类应用就可以帮你解决这个问题。目前绝大多数应用和浏览器的分享功能（比如知乎日报，Smartnews，和锤子手机的自带浏览器）都支持将你看到的文章保存到里 Pocket 和 Instapapr 这类应用中，而且会根据算法将文章自动进行排版和优化。目前这两个我都在用，英文文章都保存在自己 Pocket 中，而中文文章都保存在 Instapapr 中。如果你能很好的使用这两个应用并且知道如何结合印象笔记深度学习，那效率真的很惊人。 笔记类应用 印象笔记&amp;有道笔记 这两个笔记早前我都在用，后来则把有道笔记的内容完全迁移到印象笔记，并购买了印象笔记的付费服务。之所以这样做是因为印象笔记的配套插件和软件实在是太方便高效了。如果想介绍清楚印象笔记的牛逼之处完全可以再写一篇很长的文章。 简单说，学会结合印象笔记的电脑客户端（主要用来编辑整理），网页版插件印象笔记剪藏（保存网页链接，文字，截图）和印象笔记阅读（保存网页端文章），印象笔记手机客户端（主要用来阅读）以及 Skitch（印象笔记独立图片编辑应用，在图片上添加笔记），你就会由衷的感叹一句：科技改变生活。 图像 OCR 应用 这类应用的作用就是把照片上的文字变成可编辑的内容，市面上这类扫描识别的应用也有很多，比如 Scanbot、扫描全能王等等。 TextGrabber 的特点不仅在于可以在于识别几十种语言，而且整个 OCR 过程不需要联网，即可以在本地完成。在实际的使用过程中，只要照片够清晰，其英文和中文的识别正确率都很高，而且速度也很快。另外，如果你知道怎么翻墙，它还可以自动利用 Google 翻译将简单的中英文进行互译。识别完成后，可能出错的内容会用红色显示，也允许你对识别内容进行二次编辑。 阅读类应用 尽管我的手机里聚合类阅读应用有锤子阅读和即刻，但是我依旧保留了好奇心日报&amp;知乎日报这两个阅读类应用，无论从内容的质量还是阅读的体验上来说都非常优秀，就算每天再忙再累，抽出 20 分钟读几篇自己感兴趣的文章也是一件幸福的事。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-25-tokyr3/"},{"title":"致考研人 2：英语复习心得","content":"写在前面 本文将从以下几个层面和你探讨考研英语得复习心得 考研英语试卷结构 如何复习 对辅导班的看法 关于单词 关于真题的使用 你可能会有的两个疑问 关于作文 关于翻译 英语参考书和使用建议 词汇书 英语历年真题 单项参考书 考研英语试卷结构 英语是考研四门课中的一门公共课，考试时间是周六的下午。时常 3 个小时，满分 100 分。 英语知识运用（10 分） 艺名叫完形填空。20 个空，每个 0.5 分。这种题每年的平均分不是很高，在多数考生看来有些鸡肋，食之无味又弃之可惜。大多数辅导老师都会建议学生在考试的最后 10—20 分钟作答。 阅读理解（60 分） 采用 4+1+1 的形式，阅读 A 部分有 4 篇文章（每篇文章 400 词左右），每篇文章涉及 5 到题目，每题 2 分，四篇文章共 40 分；阅读 B 部分有 1 篇文章，艺名叫新题型（500 词左右）。这篇文章有几种题型供选择，比如句子匹配题和段落匹配题以及选择小标题等，通俗的说新题型有点像长胖了的完型填空（也就是填词变成了填句子）或者粉碎性骨折的完形填空（文章段落顺序完全打乱让你还原正确的段落顺序）。必须要强调的一点是，阅读理解这前 50 分无疑是你整个英语复习过程中的重中之重。阅读 C 部分艺名是我们熟知的英译汉。翻译这部分英语一和英语二稍微有一点区别，英语一是一篇文章有 5 处划线句子（150 词左右），把这 5 句话翻译成中文即可。英语二是 150 词左右的一段或两段文章，要求全部翻译。这个题看似简单，其实是整个英语试卷中得分率很低的题型，多年平均分都是 3 分上下（满分 10 分）。因为很多人在考场上写的中文不能用是否通顺来形容，而是根本不说人话。 写作（30 分） 考研英语写作分为 A 部分和 B 部分。总分 30 分，其中 A 部分艺名为应用文或者小作文（约 100 词；10 分），书信形式居多；B 部分艺名大作文（200 词上下；20 分），其中英语一通常是图画作文，英语二通常是图表作文。 简单说明一下，在这 3 大部分中，阅读理解的 A 部分和 B 部分再加上写作部分一共占了 80 分，绝对是复习的重点。完形填空和翻译占 20 分，可以说是复习的难点，但并非重点。 如何复习 这个问题可以从两个方面来说，第一个方面是每种题型的复习方法，第二个方面是不同时间段的复习方法。当然这两个分类方法自然在内容上会有交集。（这篇文章主要从题型上来说，时间段的分配因人而异，如果你想了解我更具体的英语和其他科目在时间上的复习安排，可以参考文章**《致考研人（9）：具体的复习建议》 **） 对辅导班的看法 在**《致考研人 1》**中我已经提到，去年寒假年少的我报了某机构在北京的考研英语面授强化班。老师们讲得很给力，我也听得很认真，但是个人感觉效果并不明显。分析原因是因为那个时候无论从单词量还是阅读量上都远远没有达到跟上强化班的水平。老师上课讲的一些方法在课上似乎是听懂了，可是课后自己拿出一篇文章依旧做不对几个。单词都不认识文章结构都看不懂，会所谓的做题方法自然也没有什么用。 但是连续十多天的学习客观上说让我找到了复习的状态。 市面上考研的辅导班可以说鱼龙混杂，而辅导班的质量重点取决于老师的水平。我这一年从一开始什么老师都看一看听一点，到最后只关注几个老师，总结下来还是有一些个人的见解。我不喜欢太多花里胡哨的讲法（比如讲着讲着站在讲桌上挑个脱衣舞），比较喜欢那些踏踏实实讲课的老师。虽然听起来可能比较吃力，但只要自己肯下功夫学，效果还是非常明显。 在这篇文章最后我会对我所了解的老师和英语复习参考书进行一下评价和推荐。 还有一类机构是面授为主也有网络课程。这类机构一般名气比较大，老师比较多，每个老师负责自己的一部分（比如只讲阅读或者只讲马原之类的），但是费用相对较高。经济条件不错的同学可以尝试。毕竟考研的过程中投入些财力还是必须的，也算是教育投资的一种。 另外，在目前这样一个版权保护不到位的现状下，互联网上或者某宝上都充斥着各种各样的盗版资源。随着打击力度的逐渐加大，这些东西会越来越少，但可以预见还不会很快消失。如果你打算花几百块钱买一套原价几千元的盗版录屏课程我想说我不支持但也不反对，只是希望你辨别清楚不要上当受骗，也不要心安理得。 好了辅导班的问题就到此为止。 关于单词 从多年来学姐学长的实际情况看，一说考研复习大家第一反应就是复习英语，一说复习英语我们的本能反应基本就是背单词（躺枪有木有），接下来发生的事情是什么？ 就是从小到大我们最熟悉的一个单词abandon开始，好不容易坚持到了 B 开头，没过两天书就扔下了。过了一段时间想起来要背单词，又开始abandon。 **单词要不要背，花多大精力背，背什么，怎么背，似乎都成了问题。**这几天不断有人联系我，多数一上来就会问：“学长我要怎么背单词更用效率，推荐本书吧，” 以下是我对单词的一些个人看法。而且所说的内容仅针对研究生入学的英语考试而言。 首先单词是一定要背，背单词的目的功利的说就是为了最大程度减少你的阅读障碍，让你在做阅读的时候首先能够比较顺利的把文章读下来。如果你不背一背，一篇阅读理解文章 400 个单词有 200 个不认识，那你不是在做阅读而是在看词猜意。阅读理解题如果连阅读都读不下来，你确认你可以做到理解么？ 尽管市面上有不少老师或者辅导书都号称可以教会你怎么在不认识单词的情况下看懂文章做对题目，不知道你信不信，反正我是不信。 那么既然要背单词应该怎么背？从我将近一年的复习情况来看。既然背单词的最主要目的是降低阅读障碍，就没有必要每一个都会写。传说中的 5500 个单词，你只要看到英文能比较快的想到一两个常见的中文意思就可以。 你可能会问那不会写单词怎么写作文呢？别闹，准备考研这 30 分的作文，高中水平的词汇量就够用了，常用的写作词汇也就是几百个，而且大多数人的作文是背出来的。关于作文的问题下文会详细说。 背单词的方法，只能说因人而异。首先每个人的基础不一样，词汇量有的可能是初高中水平（即便你通过了四级也不一定说明你都认识四级的单词）有的可能已经是雅思 7 分的水平， 另外每个人从小培养的背单词方法不同，很难说哪种方法很好。你自己百度一下也会出现各种方法和词汇记忆大师。有词根词缀记忆法，有浮想联翩记忆法，也有臭不要脸记忆法等等。要我说，背单词应该没那么多道道，就是重复而已（这还是要回到我们背单词的主要目的，只要看熟了，看到英文能想到中文即可）。至于重复的方法也有很多，稍后我会给大家推荐一种，仅供参考。 就书而言，我觉得市面上的单词书除了一些个人感觉明显不靠谱的浮想联翩派之外，其他的畅销书没什么太大差别。 找一本口碑好点的单词书，你首先要做的是过一遍目录或者它自带的词汇表，把里面那些弱爆了的初中词汇或者你能一下子就反应出中文意思的单词划掉，虽说有 5500 个单词，但是划完之后多数人应该就剩 3000 左右的单词需要你去背。这一步的目的是了解你自己的单词量，如果你连自己那些单词不认识，有多少单词不认都不知道，很难想象你背单词的效率会高。 这种方法是以 20 天一个周期（20 天可以背完一遍），不过需要你每天早晨和晚上各拿出 2 个左右的时间来背单词，当然，如果你本身不认识的单词不多，那每天需要抽出的时间就可以相应缩短。寒假做这个工作比较合适，开学以后时间有限。下面这个表格的数字代表天数，A-T 20 个字母意思是把你划完剩下的单词分成 20 个部分（注意不是代表单词的第一个字母），每个字母代表你所有不认识单词的二十分之一。表格给出的顺序就是你背诵的顺序，比如第 6 天，早晨背 F 那部分，晚上复习之前背的 CEF 三个部分。 从 21 天开始是一个第二轮复习的过程，我当时并没有严格执行这个方法，而是每天早晨和晚上都拿出 40 分钟左右的时间，背 1 个周期后，可以把比较难记住的再整理出来然后分成 20 个部分再继续背，这样一直坚持下去，到了后期背单词的时间越来越少，9 月以后基本不用刻意去背单词了。 背的时候，你可以拿一张白纸，按照你单词书合适的大小掏一个洞，最好的状态是可以露出英文而挡住中文。背的时候只要脑子里能反映出一到两个常见的中文意思就可以过。 以上内容是关于如何背单词，和背单词相对的就是学单词。 从个人经验来看，学单词远比背单词更重要。我是通过精读近 20 年的英语阅读真题来学单词的（怎么使用真题下文会详细谈），通过精读文章可以发现，很多重要的词汇都会重复出现，另外也会有很多你不认识的单词。这些单词就必须要掌握它所谓的熟词僻意、同近义词以及具体用法和常见搭配等等。学单词我最好是放到具体的文章和语境中自己去掌握去总结。 下面举例说明： 在 1997 年 text4 的文章中，形容一个人时前面用了 late 这一形容词 ，有一道题目题干问“以下哪个选项正确”，其中一个选项是说“这个人已经去世了”。要想准确的判断出这个选项你就要知道 late 在文中的含义（我知道你想说“迟的”，但其实 late 在作形容词修饰人时有“已故的”含义）。这就体现了精读文章学习单词的重要性。这个意思在背单词的时候大部分人是背不到的，可是就考了。 另外，考研英语阅读理解题里选项诞生有一种常见的方法叫做同意替换，即将文章考点信息句中的单词进行部分甚至是全部同意替换，看你能不能认出来。 学会准确地使用形容词和副词，掌握一些经典单词的经典搭配，背诵和仿写一些简单例句又会对写作部分有极大的帮助。（关于从哪里找同近义词和固定搭配例句等，可以阅读**《致考研人（3）：如何用好你的手机》**，里面会介绍我在这一年里常用的各种软件。） 关于真题的使用 在这一部分我会谈到为什么要用真题和怎么使用真题的问题。也会涉及到阅读理解、作文和翻译的复习方法。 为什么要用真题 复习英语肯定自始至终都是要做题的，做什么质量的题在一定程度上会直接影响你的复习思路和复习效果。你随便从某宝上一找就会发现各种各样的参考书数不胜数。就阅读而言，各种《XX 阅读 XX 篇》还都说是命题专家或者考研命题组成员命题，是最接近真题的模拟题。但是再接近真题不都是模拟题么？那我们为什么不直接用真题呢？用脚想一想也知道是每年好几个专家在小黑屋里整出来的那四篇阅读质量高还是某老师（或者团队）再加几个编辑整出来的上百篇阅读质量高。 另外，做 20 年的真题你可以发现这 20 年的英语文章命题思路和很多出题点以及常考题型都是没有什么变化的，只是可能说某一年或者某几年试题的难度会有不同。整体来说越久远的试题文章长度和难度越小，02 年之前的试卷有 5 篇阅读，每篇有 4 道题。02 年开始变成了 4 篇文章，每篇有 5 道题。建议各位如果是从现在开始复习英语的话可以从 20 年前的真题做起，文章的难度比较合现在这个阶段。 可能在很多文章中大家都会推荐《某某阅读 100 篇》，这么多人推荐而且毕竟也卖了这么多年自然有其道理。考前一个月我曾做过 10 篇左右练手，我并不是认为这套书不好，但做完这 20 年的真题再做这些模拟题会有一点说不出来的感觉，可能和文章里面的生词数量文章难度有关系，也可能和题目设置有关系。做过了真题再做模拟题觉得模拟题不顺手没关系，我们可以说模拟题出的不像真题，因为只要最后考场上感觉是对的就可以。 我只是担心，大家如果一味地只做某本模拟题，最后做真题时会觉得不顺手。可我们总不能说你这真题出的怎么不像我平时做的模拟题，所以我的建议是如果实在想做，模拟题可以在后期拿来稍微练手，重点一定要放在对真题的的精读和研究上。 关于阅读理解 下面从真题出发，我来说说怎么利用好历年真题里的阅读文章进行复习。 包括 04 年以及之前的阅读真题我做了两遍，04 年之后的阅读真题做了 3 遍（其中 06、10 和 14 年这 3 年的题目是当做模拟题在考前一个月的每个周六成套完成）。 做真题阅读的方法说起来很简单，就是精读。 精读的理念随着近些年网络的传播已经越来越普及，市面上类似名为《xxx 超精读》《精读 XXX》的参考书也越来越多。但是精读的概念并不是某个辅导老师的首创，其实你如果有英语专业的同学，问问就知道他们有一门很重要的课程就叫做精读课。 精读的标准是什么 针对考研英语的学习而言，我在这里所说的精读简而言之就是做到每篇文章没有一个不认识的单词，没有一个不理解的句子，做完之后首先进行口头翻译，又卡壳的地方就老实把那句话翻译出来，如果全文很多处都翻译不顺说出来不像人话，就进行全文翻译练习。如果做到这几点就算完成了一篇文章的精读。（当然，即便完成精读也只是学习真题的第一个阶段，这是第一轮学习真题的重点。在第二轮学习真题的过程中重点是分析文章的逻辑结构行文思路以及题目。关于做几轮真题，每轮要达到什么样的要求以及如何精读，可以参考**《致考研人（9）：具体的复习建议》**和本资料的第三部分：浅谈考研英语真题。） 针对单词而言 在上文关于单词的部分基本已经说清，就是遇见不认识的单词首先要查出单词的意思，然后看其在文章中的意思（可能是所谓的熟词僻意），再看其在文章是不是以固定搭配的形式出现，最后查这个单词的同近义词，看单词在字典里给出的例句。 强调一下究竟哪些单词需要进行这么多步骤的学习。 如果这个单词是名词，你只要知道它的意思即可，最多在注意一下它的一些词组。如果是专有名词（比如经济类，法律类）的话你还要想想相关术语用英语怎么说。比如碰到“通货膨胀”你要想想“通货紧缩”，甚至也可以查查“垄断”，顺带的可以把所有表示“经济萧条”的词都给找出来，这就是所以的精读扩展的思路之一。 如果不认识的单词是形容词或者副词，你就要重点关注一下这个词的同近义词，因为阅读文章里这些形容词的同近义词很可能出现在某个选项中。还有一些词长得就不想我们认知范围内的，这些词很可能是考研专家给你设置的超纲词，目的是为了让你在考场上看到之后心神不宁手脚冰凉。这些词大多是不会出现在考点信息句里的，和你能不能做对题目没有太大关系，稍微查一下，睁一只眼闭一只眼就过去了。另外很重要的一点，题目和选项里的的单词也绝对不可以放过！很多时候今年题干里的单词会出现在后几年的文章里。 虽说有超纲词这种东西，但平时做题你可别看到个长点的单词就说人家超纲，很可能大家都认识只是你自己不知道罢了。 没有一个不理解的句子 这里的句子就是你们常说的长难句，所谓长难句其实包括了长句和难句，要做到没有长难句首先要能区分哪些句子是长难句。我在复习中的判断标准一般有以下几个：首先是长，有些情况文章的某一段可能就是一句或者两句话。由于中间插入了很多修饰成分，所以主谓宾可能出现在不同行里，让人读起来不知所云；其次是句子不长，但逻辑关系复杂，体现在转折词和指代词上，这种情况你就要弄明白句子前后的逻辑关系（转折，递进还是举例等等）并且搞清楚代词具体的指代内容。 如果这两个标准你还是用不好，那么简单粗暴的说，在单词你能都认识的前提下如果一个句子就是翻译不通顺，那它就是所谓的长难句。而这些句子往往包含着关键信息或者会涉及到考题。比如你看一句话里面有个主语 They 搞不清楚到底指什么东西，那么题目里很可能问你这句话中 They 指的是什么（没错，命题人就是这么稳准狠）。面对这类句子，你要找到句子主干，分析主干的修饰成分，搞清楚前后逻辑关系，最后尽可能做到准确的翻译。对于比较优秀的句型或者句子，我建议你可以适量的背诵和仿写，这对写作有很大的帮助。 做好以上工作，你可能需要具备一定的语法知识（这个东西应该你在初中高中的时候学的最多），如果你觉得自己语法知识实在是捉襟见肘，我建议你翻一翻家里珍藏的高中语法参考书，把高中语法搞清楚，应付考研的这些句子基本就没问题。如果想比较系统的学一学语法知识，张满胜老师的《语法新思维》系列丛书值得认真研读，如果时间有限或者只是为了备战考研英语，仔细学习一下《考研语法新思维》这本书也就可以了。 全文翻译 我承认是一件费时费力的事情，所以我没有建议你每一篇都翻译，而我也只是翻译了不到 20 篇真题。认真地翻译了几篇文章之后，我觉得在读文章时确实轻松了。 做一篇阅读，当你完成了单词和句子方面的任务之后，你对文章的细节基本上会有一个比较准确的理解，如果你还能把文章比较准确的翻译出来，即翻译清楚段落句子之间的逻辑关系和各种各样的指代关系，那么你对文章的行文结构就会有比较清晰的认识了。 当然，如果没时间翻译全文，我也建议你翻译文章的中心内容和段落的中心句。当你能准确找到文章和段落的中心并进行准确的翻译时，那考研英语阅读这块你基本上就成了大半。这里又涉及到阅读的解题方法，可以简单提一句，大多数题型在你无从下手或者某两个选项间举棋不定的时候救命一招都是“从文章或者段落中心出发”（阅读理解的具体方法和流程可以参考本资料的第三部分：浅谈考研英语真题）。 以上，就是怎么利用真题进行阅读理解练习的方法。 你可能会有的两个疑问 如此精读真题是不是太浪费时间 为什么我没提到题目对错的问题 精读真题是不是浪费时间 首先这样做确实比较耗时，当我在做第一轮真题时，2000 年之前的阅读虽然相对简单而且短，可每篇文章我基本也要花费 2 个小时左右的时间。但是做到 2004 年的时候这种情况就稍微好些，从 2005 年开始还是做同样的工作但速度就有了明显的提高。为什么越难的文章耗时越来越短了呢？因为精读的过程就是一个打基础的过程，是一个逐渐提高的过程。 做第一轮真题时我还做了笔记，每篇文章的笔记也都是按照单词、句子和翻译的顺序整理。笔记本用的是小学生会用的那种横格本（有的地方也叫大练习，纸挺薄质量不是很好的那种），这样的本子正反面写我一共写了 6 本，不过到了 08 年以后的笔记一共就用了一本。越往后做你发现无论碰见的单词还是搭配扩展基本都是以前总结过的，所以可写的东西越来越少，花费的时间也就越来越少。 虽然耗时，可绝对不是浪费时间，如果你想快必须要先学会怎么慢下来。我有个同学，花了挺长时间把那个《XX 阅读 XX 篇》的阅读都做完了，但只是做完对下答案。可做完一遍再做别题目还是该怎么错就怎么错，该不认识的单词还是不认识，没办法，他又花了很长时间把做过的阅读重新整理了一遍。如果你不信，可以用一个月的时间试试，前半个月每天用 2 个小时做 4 篇文章，后半个月每天用 2 个小时作一篇文章，看看哪个效果更好。 为什么我没提到题目对错的问题 至于要不要在第一轮学习真题的过程中关心题目的对错问题，继续用我自身体会来说明。 在做早年阅读理解的时候，一篇文章 4 道题目我有很多篇都是错 2 个甚至 3 个，这种状况大约持续到 6 月份考六级之前。考完六级之后情况就有明显的好转（在完全没有复习的情况下，那次六级所有阅读部分包括信息匹配题我只错了 1 个空），到第一轮做近几年真题的时候，基本上一篇文章 5 道题错 1 个（全对的比例和错两个的比例差不多）。所以说，一开始做对做错由它去吧，只要坚持下去，越错越少是自然的事情。 看到这里，你也不要嘀咕这么复杂的事情你做不到，别人能做到的你为什么做不到，别人能做好的你为什么做不好？ 写到这儿已经 7600 多字了，后面还要说一说翻译和作文的问题，所以这篇文章我就不写做第二轮第三轮真题的时候我都干了什么，现在说这个还有点早，到时候我会写给各位。不过可以简单提一句，第二遍重点分析文章结构和逻辑关系（怎么找答案）分析命题方式（怎么设置正确选项和错误选项）以及文章和题目设置的联系，第三遍主要是成套做练习，用尽可能短的时间准确的把握文章中心找准关键信息然后做对题目。（关于这部分内容可以可以参考**《致考研人（9）：具体的复习建议》**） 第一轮做阅读理解的程序 在这一部分的最后简单总结一下第一轮做阅读理解的程序： 读文章（第一遍，不查词），做题； 读文章（第二遍勾画出不认识的单词和不理解的句子）； 精读，学单词分析句子，再做一遍题，对答案； 翻译（全文或长难句），对照参考译文进行修改。 关于作文 对于作文，我个人感觉是最偷懒不得、最没有技巧可言又最有可能大幅度进步的一部分内容。 近些年作文命题的趋势就是反押题！不能指望靠着某些机构老师最后的押题救命，虽然年年不少老师都说自己压中了题。这些人要么是扯，要么是考前一个月出本书（大小作文 X 十篇，一篇涉及一个话题）。考研这么多年作文一共就几个主要话题，你稍加了解和学习之后自己出本书也不是没有希望压中。 拿今年（2015）的作文题来说。小作文考前有人预测求职信、推荐信、感谢信和投诉信等等，范围已经够大了。可是最后考试内容是让你“推荐一本书”。虽说是推荐信的一种，但是大多数人预测的推荐人还是相差不少的…… 如果你只靠押题或者模板，在考场上看到这样的题目难免焦虑。 如果你要是按照话题分类背了历年真题范文并进行了仿写练习呢？ 2011 年英语一小作文的要求是让你推荐一部自己喜欢的电影，如果你老老实实背了那篇文章并进行了仿写，看到今年的小作文题目你不会偷着乐么？ 请问如果要仿写一篇介绍电影的作文，你要怎么仿写？我觉得正常的孩子第一反应就是介绍一本书，这不就是今年的作文题么。就算你没有仿写过 2011 年的小作文，但是背了关于环境保护或者传统文化的历年真题范文又进行了仿写，并且背的足够熟练。考场上看到这篇要你推荐书的作文你要怎么写？ 在考场上，我的第一反应是“最近我读了一本书叫做《哭泣的地球》，里面讲了环境恶化和保护环境的重要，我觉得很有意义推荐给大家”或者“最近我又读了一本书叫做《遗失的美好》 ，里面主要讲了传统文化的流失和保护继承传统文化的重要性，我觉得很有意义所以推荐给大家”。就这样，不小心一下子就写出了两篇小作文。 今年（2015）大作文给的漫画是“一伙人在一起吃饭，没人说话都在低头玩手机”。考前人们很多都预测会考保护传统文化、网络谣言、重视文化交流等等。当然由于“手机”这个话题实在很常见，也有不少人预测到“科技对生活的影响”。 我想说的是今年的考题就是 2009 年的真题重现。请看图： 2009 年的漫画是网络的近与远，是说网络拉近了人与人的距离，又疏远了人之间的距离。今年是手机让人们的生活更方便，但也让人们的交流减少。再请问如果让你对 2009 年的考题进行仿写你会怎么写，我觉得一个正常的思路都会写手机对人们生活的影响，这不就是今年的考题么？ 所以别觉得考过的不会考，反而是就那几个大的话题来回考。 我是从去年 8 月开始准备的，之前没怎么看。个人感觉稍微有点晚，不过还好。建议大家可以比我提前一个月开始，这样每天的任务量不会太大，考前一个月也不用突击背诵。在准备作文之前你要把单词的问题解决掉。然后自己在做阅读理解的时候积累一些即好又不难的素材备用。 简而言之准备考研这两篇大小作文，我觉得最省事省力的方法就是背诵，背诵绝不是背模板，而是按几大类话题（比如文化、环保、道德、个人品质、科技、教育等）进行分类后背诵历年真题的范文然后进行相关话题的仿写，每个易考的话题最后都要有一两篇自己的文章，考前找几套模拟题的作文题目练练手，考场上任你几路来我就一路去。 （关于作文的具体复习思路，可以参考**《致考研人（13）：英语作文备考经验》**） 关于翻译 写到这儿我实在是困了，好在翻译的问题在阅读部分提到了一些。做阅读理解的时的翻译练习对这 10 分的翻译题是很有帮助。 至于具体到翻译题型而言，还是练习近 20 年的翻译真题就可以。每年 5 句话，一共是 100 句，一天精读精译一句再复习前一天的内容，一百天可以搞定。至于怎么翻译当然还是那几样，查单词，及固定搭配，找主谓宾分析句子结构。其实翻译题中的很多词汇重复率依旧很高。很多词连着出现两三年，但可能意思不同，所以还是要注意重点词的常见意思。同一个词在不同的短语中可能意思也不相同，所以也要特别注意，平时练习时要注意积累。 英语参考书和使用建议 在这篇文章的最后，我简单介绍一下在我复习过程中接触的英语参考书和使用建议。 在《靠谱学长说》第一版，在这篇文章的最后我只是罗列了自己复习过程中所用到的参考书，并没有对任何一本书作出评价和使用建议。 起初这样做的原因有二：一是因为我预见到我写的文章一旦有一个比较大范围的传播（并非自恋），如果把某个老师或者某本书介绍的太过详细难免会给人一种写软文的错觉；二是因为半年之前我只能从一个备考者的角度来评价这些书给我带来的影响，即便这些书存在什么问题或者有哪些需要注意的事项也很难从备考者以外的角度说出自己的见解。不管从这两方面的哪一方面来看，都会既不主观也不客观。 但是经过半年的进一步学习，对更多同类型书籍的阅读比较，对不同辅导老师的观察了解以及对更多思想方法的实践，让我现在可以对自己之前使用的参考书稍作评价。 这个评价我尽量客观，但又无疑主观，因为毕竟这只是我的阅读和学习感受，所以仅供考研人参考。 词汇书 我的观点已经在之前的内容反复提到过，只要是市面上口碑较好销量较高的词汇书都可以用来背诵单词，比如新东方的绿皮书，还有使用者也较多的红宝书等。 我去年还看过两本书比较有特点的书： 《考研词汇速记指南》 刘一男、《恋练有词》 朱伟 。在这里对这两本书和老师做一个评价。 《考研词汇速记指南》 是我在寒假时和刘一男老师的 5500 词视频课结合使用的。这本书在编排上既非正序也非乱序，而是按照不同的记忆线索编排，主要涉及词根词缀和词源学的内容以及少量的联想记忆法。 至于刘一男老师，他曾经任教某东方主讲各种词汇课程，后期因为某些原因离开某东方成为了某都的考研词汇主讲老师。他的视频课我完整的听过并做了简单的笔记，讲课带有东北人那种自然的幽默。我为什么要强调东北人那种自然的幽默呢？因为这种幽默虽然不能说没有设（zhuang ）计（bi）的成分，但更多是大多数东北人与生俱来的那一点幽默细胞。讲课节奏比较紧凑，没有太多的废话，讲课思路也是围绕自己整理的几条主要的记忆线索展开。 值得一提的是，在某东方也好在某都也罢，他一直都只讲词汇课。当然，你既可以将其理解为专注，也可以理解为只会讲单词。我只不过是想强调一下，他一直就干这一件事。 如果你看见那种正序和乱序的单词书就有种莫名的恐惧，想要听一听所谓记单词的方法，喜欢在背单词的时候来一些所谓的规律，我向你推荐刘一男和他的《考研词汇速记指南》。另外，在同类型的词汇书中，这本书的价格也比较业界良心。 至于缺点，就我个人而言，虽然寒假在听课的时候一度感觉原来记单词可以这么神奇，这么简单，但是慢慢发现这种方法也许并不是多么适合我。我还是喜欢简简单单的背，然后找出不会的单词，再背，最适合我的方法就是重复。因此可以说这本书对我背单词有一些理论上的帮助和指导，但是实际效果并没有那么的明显。 《恋练有词》 这本书从我 2015 年考完研开始突然就一发不可收的火了，具体的原因我也不清楚。我只是就自己的使用体验和大家分享，因为我用的时候，我身边还没几个人用。 这本书也不是按照正序或者乱序的顺序编排，而是比较讨巧的和历年英语真题结合了起来。它以历年真题中的高频基础词汇为依托，衍生出其他相关的单词。这里的相关，更多纯碎是单词相貌的相似，这是和《考研词汇速记指南》的主要区别之一。比如在考研真题中做 live 的搜索，就从 live 引申出 alive 、deliver、 outlive 和 livelihood ，然后再配以真题中的例句。 这样的编写方式让考研人看完会有一种比较解渴的感觉，另外由于所用例句都来自真题，配合上这本书的视频也会给考研人一种管饱的感觉。同时，朱伟老师这个人兴趣（看起来）比较广泛，（看起来）懂的东西比较多，再加上颜值稍好以及上课风格偏向耍宝，他的视频课也给他最初积攒人气帮了大忙。 如果你想用这本书，建议你不要着急看。可以在完成第一轮真题精读后结合视频学习，这样也可以帮助你从另一个角度梳理自己已经精读整理过的重点单词。 我要承认的一点是，这本书对我的帮助比《考研词汇速记指南》大不少。 至于缺点，我给你讲两个小故事。 去年我听他视频课的时候，有一个例句是某篇文章的一道题目。他读完题目和选项之后非常自信的用自己的情感判断法给出了答案，还强调如果能把单词学到这个水平，好多题目都不用看文章就能做出来。非常不巧的是，那篇文章我刚刚做完，答案还恰恰就不是他判断出来的那个。于是，我不辞辛苦地截屏发私信告诉他这个题老师讲错了，尽管那个时候他的粉丝还没那么多，但结果当然是没有结果。 在第一版《恋练有词》出版的时候，他还是某小城市某东方老师，后来就去了魔都。人往高处走，这没有任何问题，但是最近一两年他的事业发展有些过快过猛。你可以在某宝上搜一下他的书，已经横跨多领域多层次异常高产。我本打算都看看再做一个评价，但无奈他的团队写书速度比我看书速度要快。所以我实在是没办法对他主编的书都给一个评价，也请读到这篇文章的你见谅。 综上，你有需要的话可以把他的《恋连有词》买来看看，至于其他内容的书，我还有别的老师推荐。另外，推荐《恋连有词》还有一个重要原因就是我手里这个版本的印刷质量是我看过的所有考研辅导书里最好的，虽然价格略微贵了一点，但也算值得。 英语历年真题 说到考研真题，种类更是数不清。我们不妨从考研英语辅导老师说起，随着近几年的各种社交平台兴起、互联网高速发展，考研辅导老师的路子就逐渐呈现为两个趋势。 一种是传统教育机构的辅导老师，类似于某东方的老师；另一种是依托于微博这一类社交平台逐渐打开知名度发展起来的老师，当然，现在这两条路子也有相互交叉的趋势。 而目前考研辅导教材中的真题种类则基本可以分为四类：一类是传统教育辅导机构为主体出的书，比如新东方就有自己绿皮的历年真题解析 《考研英语历年真题详解及复习指南》，这类书的编者往往没有太大的名气，主要依托新东方这个辅导机构的名义来宣传和销售；第二类是以大型辅导机构的有名老师为主体出的书，比如 《四大名师历年考研英语真题超详解及复习指导》由新东方的王江涛、唐静、舒阳和张销民四位辅导老师编著完成；第三类是以网络等社交平台为人们所熟知的老师为主体写的书，比如 《考研英语历年真题超精解上、下册》，其主编是丁晓钟老师；第四类是卖了挺多年也挺有名气但不知道作者是谁，比如《考研真相：历年考研英语真题》和《张剑考研英语黄皮书历年考研英语真题解析及复习思路》（前者没有写作者，后者这本书的作者有很多） 有这么多的真题，我们到底该怎么选择一本比较靠谱的辅导书。 简单的说你需要三看，一看出版社，二看作者，三看口碑。 一看出版社，可能这一点是我们大多数人买书的时候都会忽略但是又非常重要的一点，为什么这么说呢？现在出版行业的现状是出书的门槛很低，低到什么程度，可以说只要有钱就可以。只要你从一些小型的出版社买来书号，你就有了出书的许可（不懂的可以自己百度），就可以自己花钱编书印书卖书了。出版社本来具有一个重要的功能就是进行图书的编辑和校对保证内容的基本准确，但随着上述情况的存在，不少书籍的出版过程中就逐渐少了一项非常重要的手续，其结果就是书的基本质量得不到保证，导致书中出现一些明显的低级错误。越有名越大的出版社，其审稿的要求就越严格，也就意味着除去编书人的水平不谈，书中的低级错误最起码不会反复出现。 二看作者，这里的作者并不是指封面上那个人名，而是人名后面跟着什么内容。你有没有留意过书的封面写的是某某编著、是某某主编还是某某著，这看似没什么差别但差别其实真的还不小。 “著”是原创，“编著”是书稿中资料性文字或直接说是引用超过了总量的三分之一，“主编”是由其牵头，并最终统稿完成（以上内容来自百度，供大家参考）。 三看口碑，这个比较简单，也就是留意出版以来大家对这本书的口碑怎么样，这个大家不是某个人而是尽可能多的样本，比如你身边用过这本书的大多学长学姐。 有了以上三个简单判断标准，我想你可以对手里的真题书做一个基本的判断。 在复习过程中我接触的书有《张剑考研英语黄皮书历年考研英语真题解析及复习思路》、《考研英语历年真题超精解上、下册》、《考研英语历年真题详解及复习指南》，最近几个月又看了《四大名师历年考研英语真题超详解及复习指导》 。 其中看的比较细致的是丁晓钟主编的《考研英语历年真题超精解下册》和《四大名师历年考研英语真题超详解及复习指导》 。丁晓钟主编的《考研英语历年真题超精解下册》多年未有改版且有一些低级的错误硬伤。不再做过多评价。 对于《四大名师历年考研英语真题超详解及复习指导》 这本书，可以说就是这几位老师自己单项书的精编版。其中王江涛的作文单项和唐静的翻译单项参考书都我在后面的内容里要推荐的，这里不过多解释。舒阳是我在新东方上面授班时的阅读老师，我亲眼看见过他被编辑折磨的死去活来不断完善书稿的场面。另外，有外研社这样的出版社把关，书的质量是有保证的。如果喜欢这几位老师的风格又感觉没时间看他们单项书的话建议可以入手这套真题。另外书里除了配有真题和作文范文的 MP3 音频外，印象中还有几个小时的视频课程，不知道新版的书有没有了。 如果说缺点的话，个人感觉这套真题看起来并不太过瘾。因为把厚厚的几本书要浓缩在一起，自然会省略一些东西。另外阅读部分主要集中在对题目的解析，对文章本身内容的解读没有特别的详细，只是给出了一些难词的释义和个别长难句的分析。如果自学能力不强，自己精读不一定能扩展出多少内容。 单项参考书 说完词汇书和真题，下面就是我用过的一些单项参考书。 《考研英语英美外刊超精读》 这本书这两年比较火，但是写书的这个老师实在是不怎么样。因为这本书我看的比较多而且对我影响不小，我也多说几句。这本书以外刊为依托，按照精读的理念对每一篇文章进行解读，编写模式和其真题书类似只不过没有题目的解析部分。 如今回头再看，我不推荐，注意是不推荐考研人去看这本书，但是所谓精读的思路是需要每一个考研人去贯彻得。 说到缺点，在我初看这本书的时候最大的感觉是对外刊的选材标准不能理解，四十篇文章的难易程度和长短都有着很大的差别，不少文章实在太长而且比较难读懂。我也不敢花太多的时间对某一篇文章进行深究，比如详细了解某篇文章涉及的具体英美文化背景和它到底说了什么事。 如果你自己不能独立完成精读学习的过程，那必然会依赖作者对文章的解读。之所以说不推荐的另一个原因是我在初看这本书时，会有看不懂作者译文的情况，有些翻译的处理确实感觉比较绕人，甚至其实作者的翻译本身就是不准确得。 因此，后来只要有人问我这本书的学习方法时，我都是建议如果你买了这本书不要用它去精读里面的文章，而是用它学习作者怎么精读文章，自己再将这个思路应用到真题的学习中去。这么说似乎感觉这书买的不值，但我反而认为如此处理这本书更理性。 另外一个非常明显的硬伤。这本书重点在于对词汇和搭配等知识点的扩展，但对于文章含义的把握以及一些语法现象解释的准确性都有待商榷，有些翻译也略显粗糙。比如 ethical 翻译成“种族”还是“道德”，countrise 在具体语境下应该理解成“不同国家民族”还是“一个国家的不同地区”，anti-Nazis 是“非纳粹”还是“反纳粹”。 综上，要不要买这本书，一旦买来怎么用，你自己决定（虽然我现在的建议不要买）。如果你很想阅读学习一些最新的外刊文章愿意自己查查词典还希望最好再带上中文翻译，不妨看看由外交部主管，**英语沙龙杂志社编辑的《英语文摘》**这本杂志。每一期都是精选不同外电报刊可读性较高的文章，翻译的质量也比较高。 **《考研英语高分写作》**这本书已经出版好多年，口碑一直不错，是我作文复习过程中的主力参考书，书中涉及话题也比较全面。 如果说缺点，我觉得要是不按照年份编排而是话题类别编排应该更适合整理归纳和背诵。至于作文复习的建议，你不妨看看我写的文章。 **《考研英语语法新思维》 **张满胜 《考研英语拆分与组合翻译法》 唐静 这两个人的书我想了半天也不知道该如何描述，他们就只是在自己擅长的领域做到尽可能最好，但这往往就足够了。这两本书，我现在还会时常拿出来翻看，另外，想提醒大家，学习英语最不能忽略但也最容易被忽略的内容就是语法的学习。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-25-tokyr2/"},{"title":"致考研人 1：我过去一年的考研之路综述篇","content":"写在前面 靠谱学长说：今天是 2017 年 1 月 24 日，这篇文章写于两年前的这段时间，也就是 2015 年的寒假，而距离我开始准备研究生入学考试已经过去了三年。趁着这个假期我将这一系列文章重新整理发布在我的个人博客（点击进入博客）, 组成《靠谱学长说：聊聊考研复习这件事（第四版）》供考研人参考，希望对你们能有一些帮助和启发。 本篇文章你将看到以下内容： 为什么考研 考研政策变化 考研考什么 寒假怎么复习 每年到了这个时候，新的一个考研周期就要开始了。笔者是从去年（2014 年）寒假开始准备考研的。 这一年走过来有太多感受和太多想法和大家分享，尤其是给即将开始考研备战的小伙伴们。从 2014 年 12 月 28 日走出考场到今天，时间已经过去快一个月，可过去一年的经历依旧历历在目。在我的考研复习路上有不少经验也走过不少弯路，本来是想等 2 月上旬出了成绩在给大家一一讲出来，可是从考完试到现在有不少学弟学妹都通过各种方式咨询我，所以决定把我想告诉大家的慢慢总结出来，争取让更多的人看到。 关于我自己 我本科就读于某普通大学（非 211 非 985 高校） ，但在百度百科里搜到了小 211 的称号，我也不太明白“小 211”是个什么东西。本科专业属于农科类，自去年 2 月份底开始考研复习，一直到六月底，我的目标院校都是浙江大学。 但是（注意这里有转折），2014 年 7 月份我有幸参加中国科学院上海生命科学院（可以说是中国生命科学研究领域最牛的地方）的夏令营，并通过其保研面试获得硕博连读的研究生拟录取通知书。在此之后就将目标院校改为了中科院上海生科院，遗憾的是（注意又有转折）10 月份没有争取到本科学校的保研名额，于是继续备战考研。 也就是说在复习了 5 个月后我经历了一次换学校和换专业课的大变动，7 月之前复习的数学由于改后的招生单位不考，所以就等于白复习。另外，中间参加夏令营也耽误了一些时间。 至于考的怎么样，现在还没出成绩我也不好说。不过考完试我对了对英语的答案，阅读 5 篇（算上新题型），一共 50 分，我错了 2 个，能得 46 分（大家普遍反映今年英语还是挺难的）。政治估分应该在 65 分—70 分。专业课应该也没太大问题。（第一次写这篇文章的时候成绩还没出来，后来的结果是顺利通过初试并免复试录取） 这篇文章里没有的 整篇文章都不会有关于所谓考试“技巧”的东西，如怎么在不背单词的情况下把单词记住，怎么在不背范文只背模板的情况下英语作文得高分之类的东西你都不会看到。如果现在的你已经开始想这些那么请自行绕道。 如果你刚刚期末考试结束，不知道自己是否要参加明年的考研或者决定了考研还不知道该怎么复习，我将要提到的内容你不妨参考一下。 关于培训机构与“经验井喷” 每年考研结束之后，在各大论坛或者社交网站都会出现“经验井喷”的现象。所谓“经验井喷”就是你会看到各种各样的经验贴。这些经验贴基本上可以分两类，第一类告诉你比如报辅导班要报哪些辅导班，买书要买哪些参考书之类的问题。这一类中当然大多数是学姐学长的切身体验，但希望你擦亮双眼，很多辅导机构和出版社也是在各大论坛常年潜伏的（不把话说透我想你也懂得我的意思）。第二类是学姐学长的复习经验贴，现在你正看的这篇文章姑且可以算在这一类中。这一类基本上你是可以放心看的，但你要知道每个人的先天条件和后天努力程度都不相同，任何人的所谓经验都不可能完全成为你的复习方法。即使这些经验和理论是别人在实践的基础上得来的，它也不一定完全适合你。有人说 A 对就会有人说 B 对，而且这两个人可能都成功了。 所以希望你能做到 广泛地听取，谨慎地吸收，独立地思考。 如果你看到这儿还没觉得我是一个多么话唠、无趣的人，说明你我也许有缘，就继续看下去。 现在大家看到的这篇文章是我整个复习经验总结的第一部分，我将大体上给介绍我这一年都做了什么，并且告诉大家在开始复习前需要知道些什么。（当然，除了这篇还会写几篇总结我现在也不知道，要看大家的需求和我的时间，但只要写，一定都是肺腑之言。）唯愿这些只言片语对看到文章的你有一些帮助。能让你在下一个考研年里走得更稳更好些。 初识考研 目前的研究生招生政策变化、考研的动机、考研考什么 你可能会说，看到这篇文章的人不都是要考研的么，写这些东西有什么用。我先说一下身边的情况，去年寒假/我所在学校的众多考研机构纷纷展开了众多报名优惠的活动，比如报三科全年课程优惠多少钱再赠送价值多少钱的绝密资料。很多同学抱着考研的决心报了名，结果开始上课的前几周随处可见小广告，他们开始转让听课证了。 考研这事儿不是嘴上说说，希望大家可以根据自己的实际情况认真的想想究竟要不要考研。在这里个各位提几个醒，主意还是要自己拿。 关于招生政策 从 2015 年开始，招生政策发生了一次比较大的调整，主要体现在免试研究生的招收政策上。简单来说就是教育部按照你所在高校的水平分配保研名额，取得保研资格的学生可以自主决定想要报考的学校。学校不得限制学生必须保本校的研究生。这种政策一出，对于考研党来说压力无疑增加了很多。 如果你本科前三年成绩相对较好（比如本专业的前 10%），且想读研究生的话，建议你关注 5 月份左右开始的各个高校和科研院所的夏令营活动。如果能拿到你意向单位的拟录取资格，再拿到你本科学校的保研名额。那你将会有充裕的时间做你想做的事情，比如去找老师做实验或者提前开始你的毕业旅行。 如果你本科前三年的成绩不够好，且想读研究生的话。从现在开始你就必须要做好打一场硬仗的准备。不要抱怨也不要愤愤不平。因为，你之前的不够努力决定了你从现在开始必须要更加努力。如果你本科前三年的成绩不够好，且想读研究生的话。从现在开始你就必须要做好打一场硬仗的准备。不要抱怨也不要愤愤不平。因为，你之前的不够努力决定了你从现在开始必须要更加努力。 拿我自己举例，本人在去年暑假参加中科院上海生科院的夏令营，获得硕博连读拟录取的资格，报考单位的说法是只要我拿到本校的保研名额，就可以直接保研不用再参加考试（可惜本科学校非 211 保研名额不多，而且我成绩不是前几名没有拿到本校的名额）。每个学校的保研名额占招生总人数的多少是依据你报考的学校和专业的具体情况而定。很多好大学好专业保研人数占到了招生总人数的 70%，好大学一些不是特别好的专业可以占到 50%，具体情况你可以到你想要报考学校的官网去了解。另外，从多数官网上，你还可以查到诸如考试大纲，报录比等很多有用的信息。 知道了报考单位的保研情况你还要了解一下自己学校的保研情况。再拿我自己举例，我的本科专业 230 人但只有 10 个保研名额。越牛的大学保研越轻松，比如厦大某专业 200 人保研名额是 40 个，南农某专业不到 200 人保研名额 30 多个。相对而言本科学校实力稍差的学生保研就更难了。 总的来说，目前的大趋势是保研的名额越来越多，统招的名额越来越少。比如本人今年考的中科院上海生科院除掉保研名额，统招的名额就没几个了，可以说亚历山大。 考研动机 面对越来越难的考研形势，你要清楚自己究竟想要什么。做出考研的选择大多是由于以下几个原因：真心喜欢科研或者对某一方面有浓厚的兴趣；所学专业凭借本科学历找不到什么好工作，觉得读个研究生能找到相对好点的工作；本科所学的并不是自己真的喜欢的，想通过考研来重新选择一个自己喜欢的专业。在这里我并没有把父母要求之类的因素列入其中，因为作为一个二十出头的成年人我们应该也必须做出自己的选择，为自己的人生负责。别人的意见只能作为参考而不能成为你做决定的原因。 如果你不确定自己是否喜欢研究生的生活，可以咨询一下你所在学校或者想要报考所单位的学长学姐，问问他们每天过的是怎样的生活。注意，只听客观描述就可以，不要问他们对目前生活的满意度，因为别人的想法不能代替你自己的感受。 至于念个研究生能涨多少工资，这还真不好说。不同行业的情况不同，而且进入社会挣多少钱更多的是看你能创造的价值，学历仅仅是一个方面而已。比如，我有一个东南大学软件专业的同学，本科毕业后在上海工作月薪已经是 20k。 考研内容 即使你现在做了考研的决定也要明白决定考研是一回事，决定考哪个学校是另一回事。在这里首先简单说说考什么的问题。 因此，如果你想考中科院系统的研究生，一定要尽早决定考哪个所的哪个研究方向，弄明白要复习什么专业课，并尽早开始复习（他们的专业课考察范围广而且深，总之蛮变态的）。 考研从科目上来说包括公共课和专业课，从类型上来说包括联考统考和自命题。比如教育学联考，计算机联考和农学联考等，而同样是联考考的内容也可能不同，就算是同样的科目不同学校考的内容也可能不同。我本科专业是农学类，虽然考研考得不是农学联考但还是拿它举例说明。 农学联考包括 4 们科目：政治、英语、专业课一和专业课二。政治全国都是一张卷子，英语分为英语一（学硕）和英语二（专硕）也不再赘述，专业课一对于农学联考而言，如果你想报考的学校（比如浙大、华中农大或者西北农林）使用的是统考的卷子，那么考试内容是数学农（或者化学，考生可以自己二选一），专业课二是植物生理和生物化学（每科各 75 分，在一张卷子上）。如果你报考的单位（比如中国农业大学或者中国农业科学院）是自命题，那么考试科目的名字可能不变，但其考试内容和侧重点则要看自命题学校自己的爱好了。如果你是管理学联考，或者是经济类考生那就考试具体的科目就要去咨询一下你的直系学长学姐。 说两句略显鸡汤的话。走得再远，也不要忘了当初问什么要出发。自己选择的路，跪着也要走完。 现阶段（寒假）我该怎么复习 （如果你看到这篇文章时早就开学，略读即可） 概述 现在我们可以谈谈作为一个考研党，从寒假开始该如何复习了（关于每一门课具体怎么复习，在之后的文章我会具体给大家介绍我的经验）。 还是那句话，每个人考的内容不同，每个人的自身情况不同。有的人可能从大三上学期就开始准备考研了，有的人可能 2015 年的 9 月份或者 10 月份才开始准备考研。有的人英语雅思已经得了 7 分，六级能考 600+，有的人可能大四了英语四级还没通过。因此我只能就个人经验和前辈给我的经验从一般层面上来简单说说。 英语我是从寒假开始复习的，那个时候年少无知报了某东方的北京面授班，而且自己一时冲动直接报了强化班，各专项老师在课上讲了不少做题方法（有些方法到了 12 月份想想的确还挺有用，不过这些方法到了 10 月份我自己也能总结的八九不离十），那个时候我单词量惨不忍睹又没做几篇真题，所以对那些技巧和方法真心无法心领神会。 但是这个面授班也没有白报，最起码我让结识了几个很负责人的老师，他们在之后的复习过程中对我帮助很大。另外，报辅导班最明显的效果其实是督促自己学习，那个阶段我每天上接近 5 个小时的课，自己还会在自习室里背单词，可以说找到了开始复习的状态。你想想，花不少钱报个班，如果不好好学你对得起那钱么？ 寒假在英语方面我做的最主要的工作其实就是背单词，这里并不仅仅是拿着一本单词书一直abandon 下去，我利用寒假听了刘一男的 5500 词视频课并大致做了笔记，在这之后我又听了朱伟的恋练有词课。很难说哪个对我帮助更大，因为思路不同，都有一定的帮助，但我也不建议各位全看。（第四版补充：现在回过头来看并且结合最近朱伟疯狂出书得行为不建议你一上来就听恋练有词，甚至可以说不建议你听，如果要听，也希望你是完成了一遍真题之后再学习。） 注意，关于我的英语复习用书，在*《致考研人（2）：英语复习心得》*一文最后进行了详细得介绍 另外，关于辅导班和英语复习整年的计划以及英语复习具体的方法问题等等，在后面关于英语复习的文章里我也会具体谈到。 政治寒假用复习么？不用！ 我是接近 8 月份开始政治的，感觉完全来得及，而且 10 月份开始复习政治的也大有人在。如果你觉得作为一门公共课不搭理它良心不安，在这里我可给你推荐几个我关注的微信公共账号。这些公共账号和考研政治有关但又不仅仅局限于考研政治，直到现在这些公共账号我依旧一直关注着。（下面这几个公众号我已经很久没看了，也不知道它们现在是一种什么状态，这里仅仅是给大家引一下，具体关注什么还需要大家自行甄别。） 学习小组（xuexixiaozu）。简单介绍一下，这里的习其实指的是习大大，你懂的，里面的文章可读性很强。推荐。 侠客岛 (xiake_island)。这个账号的官方背景是人民日报海外版编辑部，聚焦时事热点，而且对问题剖析的比较深入。推荐。 澎湃新闻（thepapernews）。这个账号属于上海东方报业有限公司，它也有自己独立的手机应用，每天推送的新闻范围会更广一些，如果有时间看的话可以关注。推荐。 上述几个公共账号基本上每天会推送一次消息，所有内容都是最热点最有价值的事实新闻，而且进行了比较详细的分析，同时这些分析都是正面的（这里的正面不是说只表扬或者假大空，而是说符合事实和主流的观点）。对于考研政治而言，考试内容绝对都是一年里的热点和重点，所以考研最后的时事政治甚至很多考研的重点内容都会在这几个公共账号推送的文章中有所体现。今年考得几个大题的点没有太偏的，有好几个我都看过不只一篇相关的文章。类似的公共账号还有不少，我只推荐这几个，你且看且珍惜。 寒假，每天看看这几个公共账号里的内容，我觉得足够了。你不妨一试。当然，这一年怎么复习政治，在政治复习的具体部分我会详细和大家分享我的经验。 专业课怎么复习，这个我还真不敢一概而论。两门专业课总分有 300 分，无疑是非常重要的。但是不同专业课难度有不同，需要投入的经历自然不同。 提供一个大概思路吧。如果你的专业课很难内容极多，比如我考的中科院的专业课之一：生物化学与分子生物学。这门课参考书有三本，一共 2000 多页，再加上一些近年的新技术新热点还需要参考很多其他的专业书。这种情况下我建议你寒假就要着手开始复习专业课了。 至于一开始的复习方法，不建议你很细致的慢慢研究分析。而是看课本，真的只是翻看。翻看完一章的内容整理一个相关的知识框架，说白了就是把大标题小标题用大括号小括号之类的方式整理出来（类似于高大上的思维导图）。 这样做一是搞清楚课本知识架构，二是方便之后具体的复习。这里的翻看不是一目十行走马观花，也不是字字细究。而是读一章之后，在脑力过一下，想想大体说了个什么。 面对厚到变态的专业课指定参考书，你这个寒假最重要的是克服畏惧心理，也就是把书往你面前一摆，你要克服第一次看见它时的抵触。老实说，我第一次摸到专业课课本的时候，一是烦躁二是畏惧，根本没有什么翻的勇气，更别说看懂的信心了。可是硬着头皮读了一遍之后，觉得也没有那么恐怖，一想还有四个多月的时间（如前所述，我是 7 月后改了目标院校才接触新的专业课的）来细细学习也就踏实了不少。 另外如果你的专业课是数学（数学对很多人来说叫做专业课一），不管你是考数一数二还是数三，都建议你寒假有时间的话看一看高数或者另外两部分（概率和线代）的课本。把课本过一遍，看概念（尽量看懂）看例题（尽量看懂）做一部分基础课后题（尽量能做出来）。对于数学而言，基础真的非常重要。如果你在寒假执意要看什么二李全书，我觉得你是真大神。虽然二李全书之类的参考书有大量的总结，但都是干货不易懂。而课本有起承转合前因后果，概念定理推论是怎么来的都有一定的介绍和讲解，对于寒假阶段的复习我个人认为是更合适的。 寒假应该干什么 英语是重中之重，尤其是单词。学和背要结合起来。找一本单词书，哪一本不重要，电商平台搜一下，销量前几位的单词书均可。（第三版补充：关于英语复习用书，我在《致考研人（2）：英语复习心得》一文最后进行了详细得介绍） 如果还有时间，我建议你试着做一些阅读，从 96 年开始到 05 年的阅读，做到 00 年其实就可以了，05 年以后的最好在寒假先碰也别碰。早年的阅读内容偏简单且篇幅较短，难度和近十年相比较小。而且早年真题毕竟也是真题，是那么多命题专家辛辛苦苦整理出来的，远比那些所谓的模拟题或者《阅读 XX 篇》之类的书要靠谱太多。顺便说一句，对于英语复习我是唯真题论的支持者，过去的一年我也是这么做的。从六级的阅读分数（为了检验阶段性复习效果）和最后考研英语的阅读分数来看这么做我觉得行的通。（至于怎么复习英语和使用真题，要说清楚可能又得好几千字，不在这里细说。你可以看后面与英语复习相关的部分） 政治建议你真的不要看，尤其是不用看你本科的那几门政治课的课本。上文那几个个微信公众账号你能坚持看下去就够够的了 如果专业课的内容极多，建议挑一门内容最多的专业课把书翻看一遍，方法见上文。如果考数学建议看一下高数的课本，学习一下概念和例题。 我要特别强调的是：这个寒假应该是你考研结束之前的最后一个相对长的假期，我建议你不要太劳累，而且中间还隔着一个春节，好好休息是非常重要的。 另外，作为一个非学神的普通人，我感觉你想完成好上述 4 项内容基本不太可能。让我说，这个寒假重要的是给你未来接近一年的复习开一个好头，最关键的是找到一个好的状态。如果时间不够或者还想玩耍，把英语弄一弄就足够了。我去年的寒假其实就只看了英语…… 这篇文章读到这儿，我不知道你是看烦了还是没看够。不管怎么说，能坚持看完这篇文章我觉得在耐性和坚持上你就已经超过了不少人，或者说你真的有一颗想要好好复习考研成功的心。 最后，和大家说一下我对热衷于搜集资料这一现象的看法。 很多人说有好的资料就等于成功一半，我不反对这句话，但是很多人这一年不是在保存资料就是在寻找资料的路上。相对于你有多少资料而言，更重要的是如何在最大程度上利用好你现有的资源。我的微博和微信公众账号都会不定期分享一些我整理的资料，大家可以关注。 我希望通过这些文字能让自己过去一年忙的这件事更有意义。如果你愿意和我交流，我也非常欢迎，我一定会在我的能力范围和时间允许的情况下尽量帮助你。你可以在我的微博或者微信公众号里留言。这篇文章是我分享过去一年考研心得的开端，未完待续。 考研人加油！ 希望我们一起在靠谱的道路上越走越远。 本文作者：思考问题的熊 版权声明：本博客所有文章除特别声明外，均采用 知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议 (CC BY-NC-ND 4.0) 进行许可。 如果你对这篇文章感兴趣，欢迎通过邮箱或者微信订阅我的 「熊言熊语」会员通讯，我将第一时间与你分享肿瘤生物医药领域最新行业研究进展和我的所思所学所想，点此链接即可进行免费订阅。 ","link":"https://kaopubear.top/blog/2017-01-24-tokyr1/"}]}